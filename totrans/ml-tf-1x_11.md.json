["```py\nubuntu@ubuntu-PC:~/github$ git clone https://github.com/ethereon/caffe-tensorflow\nCloning into 'caffe-tensorflow'...\nremote: Counting objects: 479, done.\nremote: Total 479 (delta 0), reused 0 (delta 0), pack-reused 479\nReceiving objects: 100% (510/510), 1.71 MiB | 380.00 KiB/s, done.\nResolving deltas: 100% (275/275), done.\nChecking connectivity... done.\n```", "```py\ncd caffe-tensorflow\npython convert.py -h\nThe resulting console will look like this:\nusage: convert.py [-h] [--caffemodel CAFFEMODEL]\n                  [--data-output-path DATA_OUTPUT_PATH]\n                  [--code-output-path CODE_OUTPUT_PATH] [-p PHASE]\n                  def_path\n\npositional arguments:\ndef_path              Model definition (.prototxt) path\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --caffemodel CAFFEMODEL\n                        Model data (.caffemodel) path\n  --data-output-path DATA_OUTPUT_PATH\n                        Converted data output path\n  --code-output-path CODE_OUTPUT_PATH\n                        Save generated source to this path\n  -p PHASE, --phase PHASE\n                        The phase to convert: test (default) or train\n```", "```py\nubuntu@ubuntu-PC:~/github$ git pull origin pull/105/head\nremote: Counting objects: 33, done.\nremote: Total 33 (delta 8), reused 8 (delta 8), pack-reused 25\nUnpacking objects: 100% (33/33), done.\nFrom https://github.com/ethereon/caffe-tensorflow\n* branch            refs/pull/105/head -> FETCH_HEAD\nUpdating d870c51..ccd1a52\nFast-forward\n.gitignore                               |  5 +++++\nconvert.py                               |  8 ++++++++\nexamples/save_model/.gitignore           | 11 ++++++++++\nexamples/save_model/READMD.md            | 17 ++++++++++++++++\nexamples/save_model/__init__.py          |  0\nexamples/save_model/save_model.py        | 51 ++++++++++++++++++++++++++++++++++++++++++++++\nkaffe/caffe/{caffepb.py => caffe_pb2.py} |  0\nkaffe/caffe/resolver.py                  |  4 ++--\nkaffe/tensorflow/network.py              |  8 ++++----\n9 files changed, 98 insertions(+), 6 deletions(-)\ncreate mode 100644 examples/save_model/.gitignore\ncreate mode 100644 examples/save_model/READMD.md\ncreate mode 100644 examples/save_model/__init__.py\ncreate mode 100755 examples/save_model/save_model.py\nrename kaffe/caffe/{caffepb.py => caffe_pb2.py} (100%)\n```", "```py\n- git pull origin pull/133/head\nremote: Counting objects: 31, done.\nremote: Total 31 (delta 20), reused 20 (delta 20), pack-reused 11\nUnpacking objects: 100% (31/31), done.\nFrom https://github.com/ethereon/caffe-tensorflow\n* branch            refs/pull/133/head -> FETCH_HEAD\nAuto-merging kaffe/tensorflow/network.py\nCONFLICT (content): Merge conflict in kaffe/tensorflow/network.py\nAuto-merging .gitignore\nCONFLICT (content): Merge conflict in .gitignore\nAutomatic merge failed; fix conflicts and then commit the result.\n```", "```py\n    ubuntu@ubuntu-PC:~/github$ python ./convert.py examples/mnist/lenet.prototxt --code-output-path=./mynet.py\n    The result will look like this:\n\n    ------------------------------------------------------------\n        WARNING: PyCaffe not found!\n        Falling back to a pure protocol buffer implementation.\n        * Conversions will be drastically slower.\n        * This backend is UNTESTED!\n    ------------------------------------------------------------\n\n    Type                 Name                                          Param               Output\n    ----------------------------------------------------------------------------------------------\n    Input                data                                             --      (64, 1, 28, 28)\n    Convolution          conv1                                            --     (64, 20, 24, 24)\n    Pooling              pool1                                            --     (64, 20, 12, 12)\n    Convolution          conv2                                            --       (64, 50, 8, 8)\n    Pooling              pool2                                            --       (64, 50, 4, 4)\n    InnerProduct         ip1                                              --      (64, 500, 1, 1)\n    InnerProduct         ip2                                              --       (64, 10, 1, 1)\n    Softmax              prob                                             --       (64, 10, 1, 1)\n    Converting data...\n    Saving source...\n    Done.\n```", "```py\n ubuntu@ubuntu-PC:~/github$ python ./convert.py  \n examples/mnist/lenet.prototxt --caffemodel  \n examples/mnist/lenet_iter_10000.caffemodel --data-output- \n path=./mynet.npy\n```", "```py\n    ------------------------------------------------------------\n        WARNING: PyCaffe not found!\n        Falling back to a pure protocol buffer implementation.\n        * Conversions will be drastically slower.\n        * This backend is UNTESTED!\n    ------------------------------------------------------------\n\n    Type                 Name                                          Param               Output\n    ----------------------------------------------------------------------------------------------\n    Input                data                                             --      (64, 1, 28, 28)\n    Convolution          conv1                                 \n(20, 1, 5, 5)     (64, 20, 24, 24)\n    Pooling              pool1                                            --     (64, 20, 12, 12)\n    Convolution          conv2                               \n (50, 20, 5, 5)       (64, 50, 8, 8)\n    Pooling              pool2                                            --       (64, 50, 4, 4)\n    InnerProduct         ip1                                   \n   (500, 800)      (64, 500, 1, 1)\n    InnerProduct         ip2                                      \n (10, 500)       (64, 10, 1, 1)\n    Softmax              prob                                             --       (64, 10, 1, 1)\n    Converting data...\n    Saving data...\n    Done.\n```", "```py\nubuntu@ubuntu-PC:~/github$ export PYTHONPATH=$PYTHONPATH:.\nubuntu@ubuntu-PC:~/github$ python examples/mnist/finetune_mnist.py\n....\n('Iteration: ', 900, 0.0087626642, 1.0)\n('Iteration: ', 910, 0.018495116, 1.0)\n('Iteration: ', 920, 0.0029206357, 1.0)\n('Iteration: ', 930, 0.0010091728, 1.0)\n('Iteration: ', 940, 0.071255416, 1.0)\n('Iteration: ', 950, 0.045163739, 1.0)\n('Iteration: ', 960, 0.005758767, 1.0)\n('Iteration: ', 970, 0.012100354, 1.0)\n('Iteration: ', 980, 0.12018739, 1.0)\n('Iteration: ', 990, 0.079262167, 1.0)\n```", "```py\n    from mynet import LeNet as MyNet  \n```", "```py\n images = tf.placeholder(tf.float32, [None, 28, 28, 1]) \n labels = tf.placeholder(tf.float32, [None, 10]) \n net = MyNet({'data': images}) \n\n ip2 = net.layers['ip2'] \n pred = net.layers['prob'] \n\n loss =  \n tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=ip2,  \n labels=labels), 0) \n Finally, they load the numpy file into the graph, using the load  \n method in the network class. \n with tf.Session() as sess: \n    # Load the data \n    sess.run(tf.global_variables_initializer()) \n    net.load('mynet.npy', sess) \n```"]