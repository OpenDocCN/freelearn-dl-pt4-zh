- en: Application of Deep Learning to Signal processing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The current chapter will present a case study of creating new music notes using
    generative modeling techniques such as RBM. In this chapter, we will cover the
    following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing and preprocessing music MIDI files
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building an RBM model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating new music notes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing and preprocessing music MIDI files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will read a repository of **Musical Instrument Digital Interface**
    (**MIDI**) files and preprocess them into a suitable format for an RBM. MIDI is
    one of the formats of storing musical notes, which can be converted to other formats
    such as `.wav`, `.mp3`, `.mp4`, and so on. MIDI file formats store various kinds
    of events such as Note-on, Note-off, Tempo, Time Signature, End of track, and
    so on. However, we will primarily be focusing on the type of note--when it was
    turned **on**, and when it was turned **off**.
  prefs: []
  type: TYPE_NORMAL
- en: Each song is encoded into a binary matrix, where rows represent time, and columns
    represent both turned on and turned off notes. At each time, a note is turned
    on and the same note is turned off. Suppose that, out of *n* notes, note *i* is
    turned on and turned off at time *j*, then positions *Mji = 1* and *Mj(n+i) =
    1*, and the rest *Mj = 0*.
  prefs: []
  type: TYPE_NORMAL
- en: All the rows together form a song. Currently, in this chapter, we will be leveraging
    Python codes to encode MIDI songs into binary matrices, which can later be used
    in a Restricted Boltzmann Machine (RBM).
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s look at the prerequisites to preprocess MIDI files:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Download the MIDI song repository:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://github.com/dshieble/Music_RBM/tree/master/Pop_Music_Midi](https://github.com/dshieble/Music_RBM/tree/master/Pop_Music_Midi)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Download the Python codes to manipulate MIDI songs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://github.com/dshieble/Music_RBM/blob/master/midi_manipulation.py](https://github.com/dshieble/Music_RBM/blob/master/midi_manipulation.py)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Install the `"reticulate"` package, which provides the R interface to Python:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Import Python libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have set up all the essentials, let''s look at the function to
    define MIDI files:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Define the function to read the MIDI files and encode them into a binary matrix:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Building an RBM model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will build an RBM model as discussed (in detail) in [Chapter
    5](part0204.html#62HIO1-a0a93989f17f4d6cb68b8cfd331bc5ab), *Generative Models
    in Deep Learning*.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s set up our system for the model:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In Piano, the lowest note is 24 and the highest is 102; hence, the range of
    notes is 78\. Thus, the number of columns in the encoded matrix is 156 (that is,
    78 for note-on and 78 for note-off):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We will create notes for 15 number of steps at a time with 2,340 nodes in the
    input layer and 50 nodes in the hidden layer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The learning rate (alpha) is 0.1:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Looking into the steps of building an RBM model:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Define the `placeholder` variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Define a forward pass:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, define a backward pass:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Calculate positive and negative gradients accordingly:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Define the objective function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Initialize the current and previous variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Start a TensorFlow session:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Run `200` training epochs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Generating new music notes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will generate new sample music notes. New musical notes can
    be generated by altering parameter `num_timesteps`. However, one should keep in
    mind to increase the timesteps, as it can become computationally inefficient to
    handle increased dimensionality of vectors in the current setup of RBM. These
    RBMs can be made efficient in learning by creating their stacks (namely **Deep
    Belief Networks**). Readers can leverage the DBN codes of [Chapter 5](part0204.html#62HIO1-a0a93989f17f4d6cb68b8cfd331bc5ab),
    *Generative Models in Deep Learning,* to generate new musical notes.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Create new sample music:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Regenerate the MIDI file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
