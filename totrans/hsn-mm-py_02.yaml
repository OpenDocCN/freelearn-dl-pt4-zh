- en: Hidden Markov Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we discussed Markov chains, which are helpful in modelling
    a sequence of observations across time. In this chapter, we are going to study
    the **Hidden Markov Model** (**HMM**), which is also used to model sequential
    data but is much more flexible than Markov chains.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Markov models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The HMM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluation of an HMM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extensions of HMM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Markov models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Markov model is a stochastic model in which the state of the random variable
    at the next instance of time depends only on the outcome of the random variable
    at the current time. The simplest kind of Markov model is a Markov chain, which
    we discussed in [Chapter 1](c8b01245-1f2b-4b5e-837f-bdcc1d87343e.xhtml), *Introduction
    to Markov Process*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose we have a set of sequential observations (*x[1],. . ., x[n])* obeying
    the Markov property, then we can state the joint probability distribution for *N *observations
    as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5c66bf6e-6ea7-484b-994a-be9b41ebd265.png)![](img/6f36b56b-0134-419b-b19c-8b86f17fb3fe.png)'
  prefs: []
  type: TYPE_IMG
- en: Graphical representation of a first-order Markov chain in which the distribution
    of the current observation is conditioned on the value of the previous observation
  prefs: []
  type: TYPE_NORMAL
- en: The preceding representation of the Markov chain is different from the representations
    we saw earlier. In this representation, the observations are presented as nodes
    and the edges represent conditional probability between two observations, namely
    *Pr(x[n]|x[n-1])*. This is how probabilistic graphical models are generally represented,
    where nodes represent random variables and edges represent a conditional probability
    distribution between these two variables. This graphical representation gives
    us insight into the causal relationships between random variables.
  prefs: []
  type: TYPE_NORMAL
- en: State space models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can see that a simple Markov chain is very restrictive and does not work
    well for situations where we anticipate that several successive observations will
    provide important information required to predict the next observation. Fortunately,
    a Markov chain can be tweaked to support these cases as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7034d32a-d9eb-416a-93ee-7b3c690948ce.png)'
  prefs: []
  type: TYPE_IMG
- en: Second-order Markov chain in which the distribution of the current observation
    is conditioned on the values of the last two observations
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider a Markov chain where the probability of the next state not
    only depends on the current state but also on the last state. This type of Markov
    chain is called a **second-order Markov chain** and the joint probability distribution
    can be represented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f3e9a95b-56cb-46be-8cd9-eee411ac53a3.png)'
  prefs: []
  type: TYPE_IMG
- en: Using the d-separation property, we see that the conditional distribution of
    *X[n]* given *X[n-1]* and *X[n-2]* is independent of all observations, *X[1],
    . . ., X[n-3]*.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, we can extend this to an *M^(th)*-order Markov chain in which the
    conditional distribution for a particular observation depends on the previous
    *M* observations. However, we are now paying the price of a large number of parameters
    for increased flexibility.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose that the observations are discrete variables having *K* states. Then
    the conditional distribution, *Pr(X[n]|X[n-1])*,in a first-order Markov chain
    will be specified by a set of *K-1* parameters for each of the *K* states of *X[n-1]*,
    giving a total of *K(K-1)* parameters. If we extend this to an *M^(th)*-order
    Markov chain, where joint distribution is built up from conditionals, *Pr(x[n]|x[n-M],
    . . ., x[n-1])*, the number of parameters in such a model would have *K^(M-1)(K-1)*.
    Because this grows exponentially with *M*, it will often render this approach
    impractical for larger values of *M*. But, what if we want to build a model for
    sequential data that is not bounded by any order of Markov assumption, and yet
    it can be represented by a limited number of parameters?
  prefs: []
  type: TYPE_NORMAL
- en: 'Such models can be created by introducing latent (or hidden) variables. Latent
    variables allow us to create a rich class of models constructed out of simple
    components. Let''s assume that for each observation, *x[n]*, we have a latent
    variable, *z[n ]*(which may or may not have the same dimensionality as the observed
    variable). If these latent variables form a first-order Markov chain, this type
    of model can be called a **state space model**, which is represented in the following
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ab40bbf5-fbfa-40e5-b890-c60f1245c51f.png)'
  prefs: []
  type: TYPE_IMG
- en: State space model representing a distribution, where each observation is conditioned
    upon a latent variable
  prefs: []
  type: TYPE_NORMAL
- en: Using the d-separation property, we can see that there is always a path between
    any two observed variables, *x[n]* and *x[m]*, via latent variables and this path
    can never be blocked. So the *Pr(x[n+1]|x[1], . . ., x[n])* distribution for observation
    *x[n+1]* given all previous observations does not exhibit any conditional independence
    properties, and thus the prediction for *x[n+1]* depends on all previous observations.
  prefs: []
  type: TYPE_NORMAL
- en: 'As the latent variables form a Markov chain, they satisfy the following conditional
    distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/081d9b87-ab89-4b8c-95c1-9640bdf73bc2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Thus, the joint distribution of this model can be stated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2e6929df-c3e3-46b5-a85f-47bbd6b4565d.png)'
  prefs: []
  type: TYPE_IMG
- en: The HMM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An HMM is a specific case of state space model in which the latent variables
    are discrete and multinomial variables. From the graphical representation, we
    can also consider an HMM to be a double stochastic process consisting of a hidden
    stochastic Markov process (of latent variables) that we cannot observe directly,
    and another stochastic process that produces a sequence of the observation given
    the first process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before moving on to the parameterization, let''s consider an example of coin-tossing
    to get an idea of how it works. Assume that we have two unfaircoins, *M[1]* and
    *M[2]*, with *M[1]* having a higher probability (70%) of getting heads and *M[2]* having
    a higher probability (80%) of getting tails. Someone sequentially flips these
    two coins, however, we do not know which one. We can only observe the outcome,
    which can either be heads (*H*) or tails (*T*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ce6640f8-df25-4556-8bb7-6022359b457b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can consider the unfair coin selected to be the latent variable, and the
    outcome of the coin toss to be the observed data. To predict the next outcome
    sequence of observation, we would at least require information such as which coin
    was selected at first, the next coin to flip given the previous one, and the probability
    of getting *H* or *T* given the coin. Assuming that both of the coins have equal
    priority of getting selected at first and each coin is equally likely to get selected
    given the previous coin selected, we can create the following state diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/09da993d-b970-4820-ab7b-79f5e77e25f1.png)'
  prefs: []
  type: TYPE_IMG
- en: State diagram for coin toss HMM
  prefs: []
  type: TYPE_NORMAL
- en: In the previous diagram, **z[1]** and **z[2]** represent states of the latent
    variable coin selected *(***z[1]**representing coin **M[1]** getting selected,
    and **z[2]** representing coin **M[2]**being selected). The arcs represent transition
    probabilities of moving from one state of latent variable to the other and the
    straight lines represent the probabilities of the observed variable (toss outcome)
    given the latent variable (coin selected).
  prefs: []
  type: TYPE_NORMAL
- en: Parameterization of HMM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section, we saw an example of an HMM to get an idea of how the
    model works. Let's now formally parameterize an HMM.
  prefs: []
  type: TYPE_NORMAL
- en: As the latent variables of an HMM are discrete multinomial variables, we can
    use the 1-of-K encoding scheme to represent it, where the *z[n]* variable is represented
    by a K-dimensional vector of binary variables, *z[nk] ∈ {0,1}*, such that *z[nk]
    = 1* and *z[nj] = 0* for *j ≠ k* if the *z[n]* variable is in the *k* state.
  prefs: []
  type: TYPE_NORMAL
- en: 'With this in mind, we can create a matrix with the transition probability matrix
    *A*, where *A[ij]* = *Pr(Z[nj ]= 1| z[n-1], i = 1)*. As the *A[ij]* represent
    the probability of moving from state *i* to state *j*, it holds the property of ![](img/4ad55b94-7a14-470d-8994-feb70fc80bcb.png) and
    can be expressed using the *K(K-1)* parameters. Thus we can represent the conditional
    probability distribution as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3e8acc3f-3118-4382-8647-1bc598a13328.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The transition matrix is generally represented using a state-transition diagram,
    as we saw in [Chapter 1](https://cdp.packtpub.com/hands_on_markov_models_with_python/wp-admin/post.php?post=25&action=edit#post_24), *Introduction
    to Markov Process*. But we can take the same representation and unfold it across
    time to get a *lattice* or *trellis* diagram, as presented in the following image.
    We will be using this representation of HMM in the following sections for learning
    parameters and making inferences from the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/36f8e635-07bc-4c8a-8b27-b0cee3c2a0a3.png)'
  prefs: []
  type: TYPE_IMG
- en: Trellis diagram for an HMM with latent variables with three states
  prefs: []
  type: TYPE_NORMAL
- en: 'As the initial latent node, *z[1]*, does not have a parent node, it has a marginal
    distribution, *Pr(z[1])*, which can be represented by a vector of probabilities, *π*,
    such that *π[k] = Pr(z[1k] = 1)* with ![](img/afb5fed2-f1d9-48ac-9595-db3ef99d4465.png).
    Thus, the probability of *Pr(z[1]|π*) can be expressed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/28e79bdb-aea8-45be-9822-d4ca7b68eb50.png)'
  prefs: []
  type: TYPE_IMG
- en: The third and final parameter required to parameterize an HMM is the conditional
    probability of the observed variable given the latent variable, namely the emission
    probability. It is represented by the conditional distribution, *Pr(x[n]| z[n], Φ)*,
    which is governed by some parameters, *Φ*. If the observed variable, *x[n]*, is
    discrete, the emission probability may take the form of a conditional probability
    table (multinomial HMM). Similarly, if the observed variable, *x[n]*, is continuous,
    then this distribution might be a Gaussian distribution (Gaussian HMM) where ![](img/e188d3e6-22f0-4a60-abad-ca3b1d67a157.png) denotes
    the set of parameters governing the distribution, namely the mean and variance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, the joint probability distribution over both the latent and observed
    variables can be stated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f28a70f1-1d0d-49c6-872b-48f4785f4fd3.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, *X = {x[1], ..., x[N]}*, *Z = {z[1], ..., z[N]}* and *θ = {A, π, Φ}* denotes
    the set of parameters governing the model.
  prefs: []
  type: TYPE_NORMAL
- en: An HMM model is called a **homogenous model** when all the conditional distributions
    governing the latent variables share the same transition matrix, *A*, and all
    the emission probabilities share the same parameters, *Φ*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s try to code a simple multinomial HMM. We will start by defining
    a simple `MultinomialHMM` class and keep on adding methods as we move forward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the `MultinomialHMM` class, we can define the HMM coin that we discussed
    previously as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Generating an observation sequence
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For a given HMM parameterized by *{A, π, Φ}*, we can generate a sequence of
    observations, *{x[1], ..., x[N]}*, using the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Set *n = 1*
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose an initial state of the latent variable, *z[1]*, according to the prior
    distribution, *π*
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose an observation, *x[1]*, for the given value of *z[1]*, by sampling the
    emission-probability distribution governed by *Φ*
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Transit to the next state of the latent variable, *z[n+1]*, according to the
    state-transition probability matrix, *A*
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set *n = n + 1 *and repeat step 3 if *n ≤ N*, otherwise terminate
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We can add a method to generate samples in the previously defined `MultinomialHMM`
    class, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use the `generate_samples` method on our HMM coin example to generate
    an observation sequence:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Installing Python packages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'HMM can also have a Gaussian distribution for the emission probability. Just
    like `MultinomialHMM`, we can also sample from `GaussianHMM`. In the next code
    example, we use the `GaussianHMM` class provided in the `hmmlearn` library to
    see how the samples are generated from this type of model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the Python packages are installed, we can use the following code to generate
    samples from `Gaussian HMM`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/fded911f-78d0-4b3b-a756-2c15392d329b.png)'
  prefs: []
  type: TYPE_IMG
- en: Sampling from an HMM with a four-state latent variable, z, and a Gaussian emission
    model, p(x|z)
  prefs: []
  type: TYPE_NORMAL
- en: Evaluation of an HMM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section, we discussed generating an observation sequence of
    a given HMM. But, in reality, most of the time we are not interested in generating
    the observation sequence, mostly because we don't know the parameters of the HMM
    to generate observations in the first place.
  prefs: []
  type: TYPE_NORMAL
- en: 'For a given HMM representation, in most of the applications, we are always
    trying to address the following three problems:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Evaluation of the model**: Given the parameters of the model and the observation
    sequence, estimating the probability of the sequence'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Predicting the optimal sequence**: Given the parameters of the model and
    the observation sequence, estimating the most probable sequence of the state sequence
    that had produced these observations'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Parameter-learning**: Given a sequence of observations, estimating the parameters
    of the HMM model that generated it'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, we'll discuss the first problem, the evaluation of the model,
    and in the following chapters, we will discuss the other two problems in detail.
    As we will see in the later chapters, evaluating the model forms the basis for
    solving the other two problems. Thus, solving this problem efficiently is the
    first stepping stone toward parameter-learning and inference.
  prefs: []
  type: TYPE_NORMAL
- en: Let's formally describe the problem of model evaluation. Given an HMM parameterized
    by *θ = {A, π, Φ}* and an observation sequence, *X = {x[1], ..., x[N]}*, we need
    to compute the probability of *Pr(X|θ)*. From our discussions in the previous
    section, we can say that we can compute *Pr(X|θ)* by marginalizing the joint-probability
    distribution *Pr(X, Z|θ)*, where *Z = {z[1], ..., z[N]}*, with respect to *Z:*
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bf84a382-52f0-44a7-8f9b-dbfbf4dfc8fe.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the previous section, we saw that the following is true:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f3c9df46-6db1-4419-87a4-27c7d9cf0d74.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Thus the *Pr(X, Z|θ)* probability can be stated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/14fcbdbb-0a0a-4a54-a16a-4ae0eafe7249.png)'
  prefs: []
  type: TYPE_IMG
- en: For a model with *K* states and an observation length of *N*, there are *K^T* possible
    state sequences. Each term in the summation requires *2N* operations. As a result,
    the evaluation becomes a mathematical operation of the order of *2N X K^T*. For
    example, if we consider a model with five states, *K = 5*, and an observation
    sequence of length *N = 100*, the number of required operations is of the order
    of 10^(72), which makes this method of evaluation intractable even for a very
    small HMM.
  prefs: []
  type: TYPE_NORMAL
- en: Extensions of HMM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous sections, we discussed HMM, sampling from it and evaluating
    the probability of a given sequence given its parameters. In this section, we
    are going to discuss some of its variations.
  prefs: []
  type: TYPE_NORMAL
- en: Factorial HMMs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's consider the problem of modelling of several objects in a sequence of
    images. If there are *M* objects with *K* different positions and orientations
    in the image, there are be *K^M* possible states for the system underlying an
    image. An HMM would require *K^M* distinct states to model the system. This way
    of representing the system is not only inefficient but also difficult to interpret.
    We would prefer that our HMM could capture the state space by using *M* different
    *K*-dimensional variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'A factorial HMM is such a representation. In this model, there are multiple
    independent Markov chains of latent variables and the distribution of the observed
    variable at any given time is conditional on the states of all the corresponding
    latent variables in that given time. The graphical model of the system can be
    represented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/855f8b95-963e-4e71-89ff-1554067981f6.png)'
  prefs: []
  type: TYPE_IMG
- en: A factorial HMM comprising two Markov chains
  prefs: []
  type: TYPE_NORMAL
- en: The motivation for considering factorial HMM can be seen by noting that in order
    to represent, say, 10 bits of information at a given time step, a standard HMM
    would need *K = 2^(10) = 1024* latent states, whereas a factorial HMM could make
    use of 10 binary latent chains. However, this presents additional complexity in
    training, as we will see in the later chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Tree-structured HMM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous section, we discussed factorial HMM, in which the latent variables
    formed independent Markov chains. This independence assumption about the latent
    variables can be relaxed by introducing some coupling between them. One way to
    couple latent variables is to order them such that ![](img/5deeb537-39a8-40d7-b5e3-a2170aae1970.png) depends
    on ![](img/22d1629a-e9a1-4f2a-a8cd-32fadc0b78e5.png) for all *1 ≤ l ≤ m*. Furthermore,
    if all the output variables and the latent variables depend on some random input
    variable, *x[n]*, we obtain a tree-structured HMM represented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8702cf40-118a-4e62-9291-5358b5805598.png)'
  prefs: []
  type: TYPE_IMG
- en: Graphical representation of a tree-structured HMM
  prefs: []
  type: TYPE_NORMAL
- en: The architecture of this model can be interpreted as a probabilistic decision
    tree. Let's considered at first-time slice *n=1*, and try to understand how this
    model would generate data. Based on the value of *x[1]*, the top node, ![](img/e7a75457-434e-4c4a-b294-da1e2f2c5b9c.png),
    can take *K* values (assuming that the hidden variables have *K* states). This
    partitions the *x* space into *K* decision groups. The next node, ![](img/3c6d4a75-fd66-406f-a0fe-b874f461124b.png), further
    partitions into *K* subregions, and so on. The output, *y[1]*, is generated from
    the input, *x[1]*, and K-way decisions at each node. At the next time slice, the
    same thing is going to happen, expect that each decision in the tree depends on
    the decision taken at that node in the previous time slice. Therefore, this model
    can be interpreted as a probabilistic decision tree with Markovian dynamics.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we got a detailed introduction to Markov model and HMM. We
    talked about parameterizing an HMM, generating samples from it, and their code.
    We discussed estimating the probability of observation, which would form the basis
    of inference, which we'll cover in the next chapter. We also talked about various
    extensions of HMMs.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will take an in-depth look at inference in HMMs.
  prefs: []
  type: TYPE_NORMAL
