<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Finding Meaning</h1>
                </header>
            
            <article>
                
<p>So far, we mostly used TensorFlow for image processing, and to a lesser extent, for text-sequence processing. In this chapter, we will revisit the written word to find meaning in text. This is part of an area that is commonly termed <strong>Natural Language Processing</strong> (<strong>NLP</strong>). Some of the activities in this area include the following:</p>
<ul>
<li><strong>Sentiment analysis</strong>—This extracts a general sentiment category from text without extracting the subject or action of the sentence</li>
<li><strong>Entity extraction</strong>—This extracts the subject, for example, person, place, and event, from a piece of text</li>
<li><strong>Keyword extraction</strong>—This extracts key terms from a piece of text</li>
<li><strong>Word-relation extraction</strong>—This extracts not only entities but also the associated action and parts of speech of each</li>
</ul>
<p>This is just scratching the surface of NLP—there are other techniques, as well as a range of sophistication across each technique. Initially, this seems somewhat academic, but consider what just these four techniques can enable. Some examples include the following:</p>
<ul>
<li>Reading news and understanding the subject of the news (individual, company, location, and so on)</li>
<li>Taking the preceding news and understanding the sentiment (happy, sad, angry, and so on)</li>
<li>Parsing product reviews and understanding the user's sentiment toward the product (pleased, disappointed, and so on)</li>
<li>Writing a bot to respond to user chat-box commands given in natural language</li>
</ul>
<p>Much like the previous machine learning efforts we've explored, a decent bit of effort goes into setup. In this case, we'll spend some time writing scripts to actually grab text from sources of interest.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Additional setup</h1>
                </header>
            
            <article>
                
<p>Additional setup is required to include libraries required for text processing. Take a look at the following points:</p>
<ol>
<li>First is <strong>Bazel</strong>. On Ubuntu, you will need to follow the official tutorial on this link to install Bazel. <a href="https://docs.bazel.build/versions/master/install-ubuntu.html"><span class="URLPACKT">https://docs.bazel.build/versions/master/install-ubuntu.html</span></a>. On macOS, you can use HomeBrew to <kbd>install bazel</kbd> as follows:</li>
</ol>
<pre>      <strong>$ brew install bazel</strong></pre>
<ol start="2">
<li>Then, we will install <kbd>swig</kbd>, which will allow us to wrap C/C++ functions to allow calls in Python. On Ubuntu, you can install it using:</li>
</ol>
<pre><strong>      $ sudo apt-get install swig</strong></pre>
<p style="padding-left: 60px">On Mac OS, we will also install it using <kbd>brew</kbd>, as follows:</p>
<pre>      <strong>$ brew install swig</strong></pre>
<ol start="3">
<li>Next, we'll install the protocol buffer support, which will allow us to store and retrieve serialized data in a more efficient manner than with XML. We specifically need version <kbd>3.3.0</kbd> to install it as follows:</li>
</ol>
<pre>      <strong>$ pip install -U protobuf==3.3.0</strong></pre>
<ol start="4">
<li>Our text classification will be represented as trees, so we'll need a library to display trees on the command line. We will install it as follows:</li>
</ol>
<pre>      <strong>$ pip install asciitree</strong></pre>
<ol start="5">
<li>Finally, we'll need a scientific computing library. If you did image classification chapters, you are already familiar with this. But if not, install <strong>NumPy</strong> as follows:</li>
</ol>
<pre>      <strong>$ pip install numpy autograd</strong> </pre>
<p>With all this, we'll now install <strong>SyntaxNet</strong>, which does the heavy lifting for our NLP. SyntaxNet is an open source framework for TensorFlow (<a href="https://www.tensorflow.org/"><span class="URLPACKT">https://www.tensorflow.org/</span></a>) that provides base functionality. Google trained a SyntaxNet model with English and named it <strong>Parsey McParseface</strong>, which will be included in our installation. We'll be able to either train our own, better or more specific, models in English or train in other languages altogether.</p>
<p>Training data will pose a challenge, as always, so we'll start with just using the pre-trained English model, Parsey McParseface.</p>
<p>So, let's grab the package and configure it, as shown in the following command line:</p>
<pre><strong>$ git clone --recursive https://github.com/tensorflow/models.git</strong>
<strong>$ cd models/research/syntaxnet/tensorflow</strong>
<strong>$ ./configure</strong></pre>
<p>Finally, let's test the system as follows:</p>
<pre><strong>$ cd ..</strong>
<strong>$ bazel test ...</strong></pre>
<p>This will take a while. Have patience. If you followed all the instructions closely, all the tests will pass. There may be some errors that appeared on our computer as follows:</p>
<ul>
<li>If you find that <kbd>bazel</kbd> can't download a package, you can try to use the following command and run the test command again:</li>
</ul>
<pre>      <strong>$ bazel clean --expunge</strong></pre>
<ul>
<li>If you encounter some failed tests, we suggest that you add the following line into your <kbd>.bazelrc</kbd> in <kbd>home</kbd> directory in order to receive more error information to debug:</li>
</ul>
<pre><strong>      test --test_output=errors</strong></pre>
<ul>
<li>If you encounter the error <kbd>Tensor already registered</kbd>, you need to follow the solution on the Github issue: <a href="https://github.com/tensorflow/models/issues/2355"><span class="URLPACKT">https://github.com/tensorflow/models/issues/2355</span></a>.</li>
</ul>
<p>Now, let's perform a more run-of-the-mill test. Let's provide an English sentence and see how it is parsed:</p>
<pre><strong>$ echo 'Faaris likes to feed the kittens.' | bash  <br/>./syntaxnet/demo.sh</strong></pre>
<p>We are feeding in a sentence via the echo statement and piping it into the <kbd>syntaxnet</kbd> demo script that accepts standard input from the console. Note that to make the example more interesting, I will use an uncommon name, for example, <kbd>Faaris</kbd>. Running this command will produce a great deal of debugging information, shown as follows. I cut out stack traces with ellipses (<kbd>...</kbd>):</p>
<pre>    <strong>I syntaxnet/term_frequency_map.cc:101] Loaded 46 terms from <br/> syntaxnet/models/parsey_mcparseface/label-map.</strong>
    <strong>I syntaxnet/embedding_feature_extractor.cc:35] Features: input.digit <br/> input.hyphen; input.prefix(length="2") input(1).prefix(length="2") <br/> input(2).prefix(length="2") input(3).prefix(length="2") input(-<br/> 1).prefix(length="2")...</strong>
    <strong>I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: <br/> other;prefix2;prefix3;suffix2;suffix3;words</strong>
    <strong>I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: <br/> 8;16;16;16;16;64</strong>
    <strong>I syntaxnet/term_frequency_map.cc:101] Loaded 46 terms from <br/> syntaxnet/models/parsey_mcparseface/label-map.</strong>
    <strong>I syntaxnet/embedding_feature_extractor.cc:35] Features: <br/> stack.child(1).label stack.child(1).sibling(-1).label stack.child(-<br/> 1)....</strong>
    <strong>I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: <br/> labels;tags;words</strong>
    <strong>I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: <br/> 32;32;64</strong>
    <strong>I syntaxnet/term_frequency_map.cc:101] Loaded 49 terms from <br/> syntaxnet/models/parsey_mcparseface/tag-map.</strong>
    <strong>I syntaxnet/term_frequency_map.cc:101] Loaded 64036 terms from <br/> syntaxnet/models/parsey_mcparseface/word-map.</strong>
    <strong>I syntaxnet/term_frequency_map.cc:101] Loaded 64036 terms from <br/> syntaxnet/models/parsey_mcparseface/word-map.</strong>
    <strong>I syntaxnet/term_frequency_map.cc:101] Loaded 49 terms from <br/> syntaxnet/models/parsey_mcparseface/tag-map.</strong>
    <strong>INFO:tensorflow:Building training network with parameters: <br/> feature_sizes: [12 20 20] domain_sizes: [   49    51 64038]</strong>
    <strong>INFO:tensorflow:Building training network with parameters: <br/> feature_sizes: [2 8 8 8 8 8] domain_sizes: [    5 10665 10665  8970  <br/> 8970 64038]</strong>
    <strong>I syntaxnet/term_frequency_map.cc:101] Loaded 46 terms from <br/> syntaxnet/models/parsey_mcparseface/label-map.</strong>
    <strong>I syntaxnet/embedding_feature_extractor.cc:35] Features: <br/> stack.child(1).label stack.child(1).sibling(-1).label stack.child(-<br/> 1)....</strong>
    <strong>I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: <br/> labels;tags;words</strong>
    <strong>I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: <br/> 32;32;64</strong>
    <strong>I syntaxnet/term_frequency_map.cc:101] Loaded 49 terms from <br/> syntaxnet/models/parsey_mcparseface/tag-map.</strong>
    <strong>I syntaxnet/term_frequency_map.cc:101] Loaded 64036 terms from <br/> syntaxnet/models/parsey_mcparseface/word-map.</strong>
    <strong>I syntaxnet/term_frequency_map.cc:101] Loaded 49 terms from <br/> syntaxnet/models/parsey_mcparseface/tag-map.</strong>
    <strong>I syntaxnet/term_frequency_map.cc:101] Loaded 46 terms from <br/> syntaxnet/models/parsey_mcparseface/label-map.</strong>
    <strong>I syntaxnet/embedding_feature_extractor.cc:35] Features: input.digit <br/> input.hyphen; input.prefix(length="2") input(1).prefix(length="2") <br/> input(2).prefix(length="2") input(3).prefix(length="2") input(-<br/> 1).prefix(length="2")...</strong>
    <strong>I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: <br/> other;prefix2;prefix3;suffix2;suffix3;words</strong>
    <strong>I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: <br/> 8;16;16;16;16;64</strong>
    <strong>I syntaxnet/term_frequency_map.cc:101] Loaded 64036 terms from <br/> syntaxnet/models/parsey_mcparseface/word-map.</strong>
    <strong>INFO:tensorflow:Processed 1 documents</strong>
    <strong>INFO:tensorflow:Total processed documents: 1</strong>
    <strong>INFO:tensorflow:num correct tokens: 0</strong>
    <strong>INFO:tensorflow:total tokens: 7</strong>
    <strong>INFO:tensorflow:Seconds elapsed in evaluation: 0.12, eval metric: <br/> 0.00%</strong>
    <strong>INFO:tensorflow:Processed 1 documents</strong>
    <strong>INFO:tensorflow:Total processed documents: 1</strong>
    <strong>INFO:tensorflow:num correct tokens: 1</strong>
    <strong>INFO:tensorflow:total tokens: 6</strong>
    <strong>INFO:tensorflow:Seconds elapsed in evaluation: 0.47, eval metric: <br/> 16.67%</strong>
    <strong>INFO:tensorflow:Read 1 documents</strong>
    <strong>Input: Faaris likes to feed the kittens .</strong>
    <strong>Parse:</strong>
    <strong>likes VBZ ROOT</strong>
    <strong> +-- Faaris NNP nsubj</strong>
    <strong> +-- feed VB xcomp</strong>
    <strong> |   +-- to TO aux</strong>
    <strong> |   +-- kittens NNS dobj</strong>
    <strong> |       +-- the DT det</strong>
    <strong> +-- . . punct</strong></pre>
<p>The final section, starting with <kbd>Input:</kbd>, is the most interesting part, and the output we will consume when we use this foundation programmatically. Notice how the sentence is broken down into parts of speech and entity-action-object pairs? Some of the word designations we see are—<kbd>nsubj</kbd>, <kbd>xcomp</kbd>, <kbd>aux</kbd>, <kbd>dobj</kbd>, <kbd>det</kbd>, and <kbd>punct</kbd>. Some of these designations are obvious, while others are not. If you are into deep dive, we suggest perusing the Stanford dependency hierarchy at <a href="https://nlp-ml.io/jg/software/pac/standep.html"><span class="URLPACKT">https://nlp-ml.io/jg/software/pac/standep.html</span></a>.</p>
<p>Let's try another sentence before we proceed:</p>
<pre><strong>Input: Stop speaking so loudly and be quiet !</strong>
<strong>Parse:</strong>
<strong>Stop VB ROOT</strong>
<strong>+-- speaking VBG xcomp</strong>
<strong>|   +-- loudly RB advmod</strong>
<strong>|       +-- so RB advmod</strong>
<strong>|       +-- and CC cc</strong>
<strong>|       +-- quiet JJ conj</strong>
<strong>|           +-- be VB cop</strong>
<strong>+-- ! . punct</strong></pre>
<p>Again, here, we will find the model performs pretty well in dissecting the phrase. Try some of your own.</p>
<p>Next, let's actually train a model. Training SyntaxNet is fairly trivial as it is a compiled system. So far, we've piped in data via standard input (STDIO), but we can also pipe in a corpus of text. Remember the protocol buffer library we installed? We will use it now to edit the source file—<kbd>syntaxnet/models/parsey_mcparseface/context.pbtxt</kbd>.</p>
<p>Additionally, we will change the source to other training sources, or our own, as shown in the following piece of code:</p>
<pre style="padding-left: 60px"> input { 
  name: 'wsj-data' 
  record_format: 'conll-sentence' 
  Part { 
    file_pattern: './wsj.conll' 
   } 
 } 
 input { 
  name: 'wsj-data-tagged' 
  record_format: 'conll-sentence' 
  Part { 
    file_pattern: './wsj-tagged.conll' 
   } 
 } </pre>
<p>This is how we will train the set; however, it will be pretty challenging to do something better than the natively trained model, Parsey McParseface. So let's train on an interesting dataset using a new model—a <strong>Convolutional neural network</strong> (<strong>CNN</strong>) to process text.</p>
<p>I'm a little biased in favor of my alma mater, so we'll use movie review data that Cornell University's department of computer science compiled. The dataset is available at</p>
<p><span class="URLPACKT"><a href="http://www.cs.cornell.edu/people/pabo/movie-review-data/">http://www.cs.cornell.edu/people/pabo/movie-review-data/</a></span>.</p>
<p>We'll first download and process the movie reviews dataset, then train on it, and finally evaluate based on it.</p>
<p>All our code is available at— <a href="https://github.com/dennybritz/cnn-text-classification-tf">https://github.com/dennybritz/cnn-text-classification-tf</a></p>
<p>The code was inspired by Yoon Kim's paper on the subject, CNNs for sentence classification, implemented and maintained by Google's Denny Britz. Now, we will walk through the code to see how Danny Britz implemented the network</p>
<p>We start on figure 1 with the usual helpers. The only new entrant here is the data helper that downloads and prepares this particular dataset, as shown in the following figure:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img height="523" width="667" class=" image-border" src="assets/ddac5b61-96db-4f10-9eaa-72db394f6813.png"/></div>
<p>We start defining parameters. The training parameters will be very familiar by now—these define the batch size that gets processed on each sweep and how many epochs or full runs we'll undertake. We will also define how often we evaluate progress (100 steps here) and how often we save checkpoints for the model (to allow evaluation and recontinuation). ). Next, we have the code to load and prepare the dataset in figure 2, as follows:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img height="498" width="645" src="assets/4e737d91-9797-4669-b073-43c45a94b20d.png"/></div>
<p>Then, we will take a look at the training part of the code:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="608" width="666" class=" image-border" src="assets/03caa6cb-ff5f-420b-b0c4-b414d66c788a.png"/></div>
<p class="NormalPACKT">Figure 3 shows us instantiating our CNN—a Natural Language CNN—with some of the parameters we defined earlier. We also set up the code to enable the TensorBoard visualization.</p>
<p>Figure 4 shows more items we're capturing for TensorBoard—loss, accuracy for the training, and evaluation sets:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img height="382" width="667" class=" image-border" src="assets/32d4bb99-086c-46c6-9ae2-074920af7b60.png"/></div>
<p>Next, in figure 5, we will define the training and evaluation methods, which are very similar to those we used for image processing. We will receive a set of training data and labels and house them in a dictionary. Then, we will run our TensorFlow session on the dictionary of data, capturing the performance metrics returned.</p>
<p>We will set up the methods at the top and then loop through the training data in batches, applying the training and evaluation methods to each batch of data.</p>
<p>At select intervals, we will also save checkpoints for optional evaluation:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img height="586" width="393" class=" image-border" src="assets/0482e7b5-a255-4640-8aaf-252d7682cdfd.png"/></div>
<p>We can run this and end up with a trained model, after a good hour of training on a CPU-only machine. The trained model will be stored as a checkpoint file, which can then be fed into the evaluation program shown in figure 6:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img height="601" width="545" class=" image-border" src="assets/09400684-0fbf-4b9a-8faf-00671388e1a6.png"/></div>
<p>The evaluation program is just an example of usage, but let's go through it. We will start with the typical imports and parameter settings. Here, we will also take the checkpoint directory as an input and we will load some test data; however, you should use your own data.</p>
<p>Next, let's examine the following figure:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img height="597" width="600" class=" image-border" src="assets/47ccb93f-c1e1-4522-9e0a-65caecb20d66.png"/></div>
<p>We will start with the checkpoint file by just loading it up and recreating a TensorFlow session from it. This allows us to evaluate against the model we just trained, and reuse it over and over.</p>
<p>Next, we will run the test data in batches. In regular use, we will not use a loop or batches, but we have a sizeable set of test data, so we'll do it as a loop.</p>
<p>We will simply run the session against each set of test data and keep the returned predictions (negative versus positive.) The following is some sample positive review data:</p>
<pre> <strong>insomnia loses points when it surrenders to a formulaic bang-bang , <br/> shoot-em-up scene at the conclusion . but the performances of pacino <br/> , williams , and swank keep the viewer wide-awake all the way through <br/> .</strong>
    <strong>what might have been readily dismissed as the tiresome rant of an <br/> aging filmmaker still thumbing his nose at convention takes a <br/> surprising , subtle turn at the midway point .</strong>
    <strong>at a time when commercialism has squeezed the life out of whatever <br/> idealism american moviemaking ever had , godfrey reggio's career <br/> shines like a lonely beacon .</strong>
    <strong>an inuit masterpiece that will give you goosebumps as its uncanny <br/> tale of love , communal discord , and justice unfolds .</strong>
    <strong>this is popcorn movie fun with equal doses of action , cheese , ham <br/> and cheek ( as well as a serious debt to the road warrior ) , but it <br/> feels like unrealized potential</strong>
    <strong>it's a testament to de niro and director michael caton-jones that by <br/> movie's end , we accept the characters and the film , flaws and all .</strong>
    <strong>performances are potent , and the women's stories are ably intercut <br/> and involving .</strong>
    <strong>an enormously entertaining movie , like nothing we've ever seen <br/> before , and yet completely familiar .</strong>
    <strong>lan yu is a genuine love story , full of traditional layers of <br/> awakening and ripening and separation and recovery .</strong>
    <strong>your children will be occupied for 72 minutes .</strong>
    <strong>pull[s] off the rare trick of recreating not only the look of a <br/> certain era , but also the feel .</strong>
    <strong>twohy's a good yarn-spinner , and ultimately the story compels .</strong>
    <strong>'tobey maguire is a poster boy for the geek generation . '</strong>
    <strong> . . . a sweetly affecting story about four sisters who are coping , <br/> in one way or another , with life's endgame .</strong>
    <strong>passion , melodrama , sorrow , laugther , and tears cascade over the <br/> screen effortlessly . . .</strong>
    <strong>road to perdition does display greatness , and it's worth seeing . <br/> but it also comes with the laziness and arrogance of a thing that <br/> already knows it's won .</strong></pre>
<p>Similarly, we have negative data. They are all in the <kbd>data</kbd> folder as <kbd>rt-polarity.pos</kbd> and <kbd>rt-polarity.neg</kbd>.</p>
<p>Here is the network architecture we used:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img height="368" width="675" class=" image-border" src="assets/8ecb8737-7f33-43b1-ab6f-aa7dc5bc8f68.png"/></div>
<p>It is very similar to the architecture we used for images. In fact, the entire effort looks very similar, and it is. The beauty of many of these techniques is its generalizability.</p>
<p>Let's examine the output of training first, which is as follows:</p>
<pre><strong>$ ./train.py</strong>
<strong>...</strong>
<strong>2017-06-15T04:42:08.793884: step 30101, loss 0, acc 1</strong>
<strong>2017-06-15T04:42:08.934489: step 30102, loss 1.54599e-07, acc 1</strong>
<strong>2017-06-15T04:42:09.082239: step 30103, loss 3.53902e-08, acc 1</strong>
<strong>2017-06-15T04:42:09.225435: step 30104, loss 0, acc 1</strong>
<strong>2017-06-15T04:42:09.369348: step 30105, loss 2.04891e-08, acc 1</strong>
<strong>2017-06-15T04:42:09.520073: step 30106, loss 0.0386909, acc <br/>0.984375</strong>
<strong>2017-06-15T04:42:09.676975: step 30107, loss 8.00917e-07, acc 1</strong>
<strong>2017-06-15T04:42:09.821703: step 30108, loss 7.83049e-06, acc 1</strong>
<strong>...</strong>
<strong>2017-06-15T04:42:23.220202: step 30199, loss 1.49012e-08, acc 1</strong>
<strong>2017-06-15T04:42:23.366740: step 30200, loss 5.67226e-05, acc 1</strong>
    
<strong>Evaluation:</strong>
<strong>2017-06-15T04:42:23.781196: step 30200, loss 9.74802, acc 0.721</strong>
<strong>...</strong>
<strong>Saved model checkpoint to /Users/saif/Documents/BOOK/cnn-text-<br/>classification-tf/runs/1465950150/checkpoints/model-30200</strong></pre>
<p>Now let's look at the evaluation step:</p>
<pre><strong>$ ./eval.py –eval_train --checkpoint_dir==./runs/1465950150/checkpoints/</strong>
    
<strong>Parameters:</strong>
<strong>ALLOW_SOFT_PLACEMENT=True</strong>
<strong>BATCH_SIZE=64</strong>
<strong>CHECKPOINT_DIR=/Users/saif/Documents/BOOK/cnn-text-classification-<br/>tf/runs/1465950150/checkpoints/</strong>
<strong>LOG_DEVICE_PLACEMENT=False</strong>
    
<strong>Loading data...</strong>
<strong>Vocabulary size: 18765</strong>
<strong>Test set size 10662</strong>
<strong>Evaluating...</strong>
<strong>Total number of test examples: 10662</strong>
<strong>Accuracy: 0.973832</strong> </pre>
<p>That is pretty good accuracy on the dataset we have. The next step will be to apply the trained model to regular use. Some interesting experiments may be to obtain movie review data from another source, perhaps IMDB or Amazon. As the data will not necessarily be tagged, we can use % positive as a metric of general agreement across sites.</p>
<p>We can then use the model in the field. Consider you were a product manufacturer. You could track, in real time, all reviews from myriad sources and filter for just highly negative reviews. Then, your field-representatives could try and address such issues. The possibilities are endless, so we propose an interesting project you could undertake, combining the two items we've learned.</p>
<p>Write a twitter stream reader that takes each tweet and extracts the subject of the tweet. For a specific set of subjects, say companies, evaluate whether the tweet is positive or negative. Create running metrics on percent positive and negative, which evaluates the subject on different time scales.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Skills learned</h1>
                </header>
            
            <article>
                
<p>You should have learned the following skills in this chapter:</p>
<ul>
<li>Setting up more advanced TensorFlow libraries, including those requiring Bazel-driven compilation</li>
<li>Working with text data</li>
<li>Applying RNNs and CNNs to text instead of images</li>
<li>Evaluating text against saved models</li>
<li>Using prebuilt libraries to extract sentence structure details</li>
<li>Classifying text into buckets based on positive and negative sentiment</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>Excellent! We just took our knowledge of neural networks and applied it to text to understand language. This is quite a feat because full automation leads to vast scale. Even if particular evaluations are not correct, statistically, we'll have a powerful tool in our hands, again, built using the same building blocks.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    </body></html>