<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Setting Up Spark for Deep Learning Development</h1>
                </header>
            
            <article>
                
<p>In this chapter, the following recipes will be covered:</p>
<ul>
<li>Downloading an Ubuntu Desktop image</li>
<li>Installing and configuring Ubuntu with VMWare Fusion on macOS</li>
<li>Installing and configuring Ubuntu with Oracle VirtualBox on Windows</li>
<li>Installing and configuring Ubuntu Desktop for Google Cloud Platform</li>
<li>Installing and configuring Spark and prerequisites on Ubuntu Desktop</li>
<li>Integrating Jupyter notebooks with Spark</li>
<li>Starting and configuring a Spark cluster</li>
<li>Stopping a Spark cluster</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introduction</h1>
                </header>
            
            <article>
                
<p>Deep learning<span> </span>is the focused study of machine learning algorithms that deploy neural networks as their main method of learning. Deep learning has exploded onto the scene just within the last couple of years. Microsoft, Google, Facebook, Amazon, Apple, Tesla and many other companies are all utilizing deep learning models in their apps, websites, and products. At the same exact time, Spark, an in-memory compute engine running on top of big data sources, has made it easy to process volumes of information at record speeds and ease. In fact, Spark has now become the leading big data development tool for data engineers, machine learning engineers, and data scientists.</p>
<p>Since deep learning models perform better with more data, the synergy between Spark and deep learning allowed for a perfect marriage. Almost as important as the code used to execute deep learning algorithms is the work environment that enables optimal development. Many talented minds are eager to develop neural networks to help answer important questions in their research. Unfortunately, one of the greatest barriers to the development of deep learning models is access to the necessary technical resources required to learn on big data. The purpose of this chapter is to create an ideal virtual development environment for deep learning on Spark.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Downloading an Ubuntu Desktop image</h1>
                </header>
            
            <article>
                
<p><span>Spark can be set up for all types of operating systems, whether they reside on-premise or in the cloud. For our purposes, Spark will be installed on a Linux-based virtual machine with Ubuntu as the operating system. There are several advantages to using Ubuntu as the go-to virtual machine, not least of which is cost. Since they are based on open source software, Ubuntu operating systems are free to use and do not require licensing. Cost is always a consideration and one of the main goals of this publication is to minimize the financial footprint required to get started with deep learning on top of a Spark framework.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p class="mce-root">There are some minimum recommendations required for downloading the image file:</p>
<ul class="p-list">
<li class="p-list__item is-ticked">Minimum of 2 GHz dual-core processor</li>
<li class="p-list__item is-ticked">Minimum of 2 GB system memory</li>
<li class="p-list__item is-ticked">Minimum of 25 GB of free hard drive space</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p><span>Follow the steps in the recipe to download an Ubuntu Desktop image:</span></p>
<ol>
<li><span>In order to create a virtual machine of Ubuntu Desktop, it is necessary to first download the file from the official website: <a href="https://www.ubuntu.com/download/desktop">https://www.ubuntu.com/download/desktop.</a></span></li>
<li>
<p>As of this writing, Ubuntu <span>Desktop </span>16.04.3 is the most recent available version for download.</p>
</li>
</ol>
<ol start="3">
<li>
<p>Access the following file in a <kbd>.iso</kbd> format once the download is complete:</p>
<p><kbd>ubuntu-16.04.3-desktop-amd64.iso</kbd></p>
</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p><span>Virtual environments provide an optimal development workspace by isolating the relationship to the physical or host machine. Developers may be using all types of machines for their host environments such as a MacBook running macOS, a Microsoft Surface running Windows or even a virtual machine on the cloud with Microsoft Azure or AWS; however, to ensure consistency within the output of the code executed, a virtual environment within Ubuntu Desktop will be deployed that can be used and shared among a wide variety of host platforms.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p><span>There are several options f</span>or desktop virtualization software, depending on whether the host environment is on a Windows or a macOS. <span>There are two common software applications for virtualization when using macOS:</span></p>
<ul>
<li><span>VMWare Fusion</span></li>
<li><span>Parallels</span></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p>To learn more about Ubuntu D<span>esktop</span>, you can visit <a href="https://www.ubuntu.com/desktop">https://www.ubuntu.com/desktop</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Installing and configuring Ubuntu with VMWare Fusion on macOS</h1>
                </header>
            
            <article>
                
<p><span>This section will focus on building a virtual machine using an Ubuntu operating system with <strong>VMWare Fusion</strong>.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>A previous installation of VMWare Fusion is required on your system. If you do not currently have this, you can download a trial version from the following website:</p>
<p><a href="https://www.vmware.com/products/fusion/fusion-evaluation.html">https://www.vmware.com/products/fusion/fusion-evaluation.html</a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p><span>Follow the steps in the recipe to configure Ubuntu with VMWare Fusion on macOS:</span></p>
<ol>
<li>Once VMWare Fusion is up and running, click on the <em>+</em> button on the upper-left-hand side to begin the configuration process and select <span class="packt_screen">New...,</span> as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1273 image-border" src="assets/de3baeba-f285-420c-bb37-c88f4fe56c6b.png" style="width:15.33em;height:14.17em;"/></div>
<ol start="2">
<li>Once the selection has been made, select the option to <span class="packt_screen">Install from Disk or Image</span>, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/01d7eef1-bcf5-4e26-bbf6-112b89a9ed07.png" style="width:41.58em;height:34.58em;"/></div>
<ol start="3">
<li>Select the operating system's <kbd>iso</kbd> file that was downloaded from the Ubuntu D<span>esktop </span>website, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/c8da4a79-082f-40e7-91f7-4dc24cfc3723.png" style="width:40.67em;height:34.08em;"/></div>
<ol start="4">
<li>The next step will ask whether you want to choose <span class="packt_screen">Linux Easy Install</span>. It is recommended to do so, as well as to incorporate a <span class="packt_screen">Display Name</span>/<span class="packt_screen">P</span><span class="packt_screen">assword</span> combination for the Ubuntu environment, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/ad3cc8d3-194b-4985-b259-de865c1cd1b2.png" style="width:37.92em;height:31.50em;"/></div>
<ol start="5">
<li>The configuration process is almost complete. A <span class="packt_screen">Virtual Machine Summary</span> is displayed with the option to <span class="packt_screen">Customize Settings</span> to increase the <span class="packt_screen">Memory</span> and <span class="packt_screen">Hard Disk,</span> as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1622 image-border" src="assets/81476499-034d-4a51-9dc7-0694f7c89a21.png" style="width:38.75em;height:32.25em;"/></div>
<ol start="6">
<li>Anywhere from 20 to 40 GB hard disk space is sufficient for the virtual machine; however, bumping up the memory to either 2 GB or even 4 GB will assist with the performance of the virtual machine when executing Spark code in later chapters. Update the memory by selecting <span class="packt_screen">Processors</span> and <span class="packt_screen">Memory</span> under the <span class="packt_screen">Settings</span> of the virtual machine and increasing the <span class="packt_screen">Memory</span> to the desired amount, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1571 image-border" src="assets/ac19e635-36e1-493e-99ec-7e8c0f63c90d.png" style="width:42.33em;height:23.25em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>The setup allows for manual configuration of the settings necessary to get Ubuntu <span>Desktop</span><span> </span>up and running successfully on VMWare Fusion. The memory and hard drive storage can be increased or decreased based on the needs and availability of the host machine.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>All that is remaining is to fire up the virtual machine for the first time, which initiates the installation process of the system onto the virtual machine. Once all the setup is complete and the user has logged in, the Ubuntu virtual machine should be available for development, as seen in the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1524 image-border" src="assets/58e6f288-6ea4-45fa-995f-0000b1aaf28e.png" style="width:161.67em;height:135.50em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p><span>Aside from VMWare Fusion, there is also another product that offers similar functionality on a Mac. It is called Parallels Desktop for Mac. To learn more about VMWare and Parallels, and decide which program is a better fit for your development, visit the following websites:</span></p>
<ul>
<li><span><a href="https://www.vmware.com/products/fusion.html">https://www.vmware.com/products/fusion.html</a> to download and install VMWare Fusion for Mac</span></li>
<li><span><a href="https://parallels.com">https://parallels.com</a> to download and install the Parallels Desktop for Mac</span></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Installing and configuring Ubuntu with Oracle VirtualBox on Windows</h1>
                </header>
            
            <article>
                
<p><span>Unlike with macOS, there are several options to virtualize systems within Windows. This mainly has to do with the fact that virtualization on Windows is very common as most developers are using Windows as their host environment and need virtual environments for testing purposes without affecting any of the dependencies that rely on Windows.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p><span>VirtualBox from Oracle is a common virtualization product and is free to use. </span><span>Oracle VirtualBox provides a straightforward process to get an Ubuntu Desktop virtual machine up and running on top of a Windows environment.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p><span>Follow the steps in this recipe to configure Ubuntu with <strong>VirtualBox</strong> on Windows:</span></p>
<ol>
<li>Initiate an <span class="packt_screen">Oracle VM VirtualBox Manager</span>. Next, create a new virtual machine by selecting the <span class="packt_screen">New</span> icon and specify the <span class="packt_screen">Name</span>, <span class="packt_screen">Type</span>, and <span class="packt_screen">Version</span> of the machine, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1570 image-border" src="assets/bf279c58-86ff-4159-97af-87ede0451a29.png" style="width:54.42em;height:20.17em;"/></div>
<ol start="2">
<li>Select <span class="packt_screen">Expert Mode</span> as several of the configuration steps will get consolidated, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1623 image-border" src="assets/e7276b57-d427-46ff-8ee4-ab5fccf0dc49.png" style="width:29.42em;height:27.00em;"/></div>
<p style="padding-left: 60px">Ideal memory size should be set to at least <kbd>2048</kbd> MB, or preferably <kbd>4096</kbd> MB, depending on the resources available on the host machine.</p>
<ol start="3">
<li>Additionally, set an optimal hard disk size for an Ubuntu virtual machine performing deep learning algorithms to at least 20 GB, if not more, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1625 image-border" src="assets/771301d8-e257-4669-9ea2-da6a1fe610b6.png" style="width:33.25em;height:30.50em;"/></div>
<ol start="4">
<li>Point the virtual machine manager to the <span class="packt_screen">start-up disk</span> location where the Ubuntu <kbd>iso</kbd> file was downloaded to and then <span class="packt_screen">Start</span> the creation process, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1624 image-border" src="assets/b8ba0256-a82f-4945-be82-ebd713d814d9.png" style="width:33.25em;height:20.17em;"/></div>
<ol start="5">
<li>After allotting some time for the installation, select the Start icon to complete the virtual machine and get it ready for development as seen in the following screenshot:</li>
</ol>
<div class="mce-root CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1525 image-border" src="assets/accc7615-2469-412b-815a-dc5e57ca3773.png" style="width:33.33em;height:23.67em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p><span>The setup allows for manual configuration of the settings necessary to get Ubuntu Desktop up and running successfully on Oracle VirtualBox. As was the case with VMWare Fusion, the memory and hard drive storage can be increased or decreased based on the needs and availability of the host machine.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>Please note that some machines that run Microsoft Windows are not set up by default for virtualization and users may receive an initial error indicating the VT-x is not enabled. This can be reversed and virtualization may be enabled in the BIOS during a reboot.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p>To learn more about Oracle VirtualBox and decide whether or not it is a good fit, visit the following website and select <span class="packt_screen">Windows hosts</span> to begin the download process: <a href="https://www.virtualbox.org/wiki/Downloads">https://www.virtualbox.org/wiki/Downloads</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Installing and configuring Ubuntu Desktop for Google Cloud Platform</h1>
                </header>
            
            <article>
                
<p>Previously, we saw how Ubuntu Desktop could be set up locally using VMWare Fusion. In this section, we will learn how to do the same on <strong>Google Cloud Platform</strong>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p><span>The only requirement is a Google account username. Begin by logging in to your Google Cloud Platform using your Google account. Google provides a free 12-month subscription with $300 credited to your account. The setup will ask for your bank details; however, Google will not charge you for anything without explicitly letting you know first. Go ahead and verify your bank account and you are good to go.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p><span>Follow the steps in the recipe to configure Ubuntu Desktop for Google Cloud Platform:</span></p>
<ol>
<li><span>Once logged in to your</span> <span class="packt_screen">Google Cloud Platform</span><span>, access a dashboard that looks like the one in the following screenshot:</span></li>
</ol>
<div class="mce-root CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1278 image-border" src="assets/20aa4814-55f9-4f4d-9983-1f90bcacf666.png" style="width:53.25em;height:26.50em;"/></div>
<div class="mce-root CDPAlignCenter CDPAlign packt_figref">Google Cloud Platform Dashboard</div>
<ol start="2">
<li class="mce-root"><span>First, click on the product services button in the top-left-hand corner of your screen. In the drop-down menu, under</span> <span class="packt_screen">Compute</span><span>, click on</span> <span class="packt_screen">VM instances,</span> <span>as shown in the following screenshot:</span></li>
</ol>
<div class="mce-root CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1526 image-border" src="assets/76ecccfc-6e47-4c0b-9f1f-7184d9a438da.png" style="width:51.75em;height:38.75em;"/></div>
<ol start="3">
<li>
<p class="CDPAlignLeft CDPAlign"><span>Create a new instance and name it. We are naming it</span> <kbd>ubuntuvm1</kbd><span> in our case. Google Cloud automatically creates a project while launching an instance and the instance will be launched under a project ID. The project may be renamed if required.</span></p>
</li>
</ol>
<ol start="4">
<li>After clicking on <strong><span class="packt_screen">Create Instance</span></strong>, select the zone/area you are located in.</li>
<li>Select <strong><span class="packt_screen">Ubuntu 16.04LTS</span></strong> under the boot disk as this is the operating system that will be installed in the cloud. Please note that LTS stands for version, and will have <span class="packt_screen">long-term support</span> from Ubuntu’s developers.</li>
<li>Next, under the boot disk options, select <span class="packt_screen">SSD persistent disk</span> and increase the size to 50 GB for some added storage space for the instance, as shown in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1566 image-border" src="assets/83579b58-9f04-47bf-a163-122c32d5c7ab.png" style="width:33.58em;height:42.83em;"/></div>
<ol start="7">
<li>Next, set <span class="packt_screen">Access scopes</span> to <span class="packt_screen"><strong>Allow full access to all Cloud APIs</strong></span>.</li>
<li>Under firewall, please check to <strong><span class="packt_screen">allow HTTP traffic</span></strong> as well as <strong><span class="packt_screen">allow HTTPS traffic</span></strong>, as shown in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1279 image-border" src="assets/78a55da5-aaab-47a9-9b2a-ecce5f968e63.png" style="width:48.33em;height:43.83em;"/></div>
<div class="mce-root CDPAlignCenter CDPAlign packt_figref">Selecting options  Allow HTTP traffic and HTTPS Traffic</div>
<ol start="9">
<li>Once the instance is configured as shown in this section, go ahead and create the instance by clicking on the <span class="packt_screen">Create</span> button.</li>
</ol>
<div class="packt_tip"><span>After clicking on the <span class="packt_screen">Create</span></span> <span>button, you will notice that the instance gets created with a unique internal as well as external IP address. We will require this at a later stage. SSH refers to secure shell tunnel, which is basically an encrypted way of communicating in client-server architectures. Think of it as data going to and from your laptop, as well as going to and from Google's cloud servers, through an encrypted tunnel.</span></div>
<ol start="10">
<li> <span>Click on the newly created instance. From the drop-down menu, click on</span> <strong><span class="packt_screen">open in browser window</span></strong><span>, as shown in the following screenshot:</span></li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1528 image-border" src="assets/ce7e2d0d-b7ab-43e3-bc6f-b704754b2e87.png" style="width:59.33em;height:20.83em;"/></div>
<ol start="11">
<li><span>You will see that Google opens up a shell/terminal in a new window, as shown in the following screenshot:</span></li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1529 image-border" src="assets/0bc13f24-6ab6-4142-af80-ec149762f03f.png" style="width:34.17em;height:14.92em;"/></div>
<ol start="12">
<li><span>Once the shell is open, you should have a window that looks like the following screenshot:</span></li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1569 image-border" src="assets/0f75c9ed-6771-467c-90aa-a142fda0531d.png" style="width:41.25em;height:19.75em;"/></div>
<ol start="13">
<li>Type the following commands in the Google cloud shell:</li>
</ol>
<pre style="padding-left: 60px">$ sudo apt-get update<br/>$ sudo apt-get upgrade<br/>$ sudo apt-get install gnome-shell<br/>$ sudo apt-get install ubuntu-gnome-desktop<br/>$ sudo apt-get install autocutsel<br/>$ sudo apt-get install gnome-core<br/>$ sudo apt-get install gnome-panel<br/>$ sudo apt-get install gnome-themes-standard</pre>
<ol start="14">
<li><span>When presented with a prompt to continue or not, type</span> <kbd>y</kbd> <span>and select <span class="packt_screen">ENTER</span>, as shown in the following screenshot:</span></li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/5f678a2c-6ce3-4ce1-a8f2-d4e8e1d25159.png" style="width:42.08em;height:2.25em;"/></div>
<ol start="15">
<li>Once done with the preceding steps, type the following commands to set up the <kbd>vncserver</kbd> and allow connections to the local shell:</li>
</ol>
<pre style="padding-left: 60px">$ sudo apt-get install tightvncserver<br/>$ touch ~/.Xresources</pre>
<ol start="16">
<li>Next, launch the server by typing the following command:</li>
</ol>
<pre style="padding-left: 60px">$ tightvncserver</pre>
<ol start="17">
<li><span>This will prompt you to enter a password, which will later be used to log in to the Ubuntu Desktop virtual machine. This password is limited to eight characters and needs to be set and verified, as shown in the following screenshot:</span></li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/3fd3e60e-3169-458d-b65c-9d7fd18d986f.png" style="width:37.67em;height:9.33em;"/></div>
<ol start="18">
<li>A startup script is automatically generated by the shell, as shown in the following screenshot. This startup script can be accessed and edited by copying and pasting its <kbd><span>PATH</span></kbd> in the following manner:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/bf39c16f-7c13-4754-9580-00e19e8cd583.png" style="width:48.67em;height:10.92em;"/></div>
<ol start="19">
<li>In our case, the command to view and edit the script is:</li>
</ol>
<pre style="padding-left: 60px">:~$ vim /home/amrith2kmeanmachine/.vnc/xstartup</pre>
<p style="padding-left: 60px">This <kbd><span>PATH</span></kbd> may be different in each case. Ensure you set the right <kbd><span>PATH</span></kbd>. The <kbd>vim</kbd> command opens up the script in the text editor on a Mac.</p>
<div class="packt_infobox"><span>The local shell generated a startup script as well as a log file. The startup script needs to be opened and edited in a text editor, which will be discussed next.</span></div>
<ol start="20">
<li><span>After typing the</span> <kbd>vim</kbd> <span>command, the screen with the startup script should look something like this screenshot:</span></li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1530 image-border" src="assets/7977693a-2615-449d-8586-da3e72be7ef3.png" style="width:44.75em;height:33.83em;"/></div>
<ol start="21">
<li><span>Type <kbd>i</kbd> to enter <kbd>INSERT</kbd> mode. Next, delete all the text in the startup script. It should then look like the following screenshot:</span></li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1531 image-border" src="assets/1a731d52-da18-4838-b240-ed8541ce3ca5.png" style="width:46.33em;height:35.25em;"/></div>
<ol start="22">
<li>Copy paste the following code into the startup script:</li>
</ol>
<pre style="padding-left: 60px">#!/bin/sh<br/>autocutsel -fork<br/>xrdb $HOME/.Xresources<br/>xsetroot -solid grey<br/>export XKL_XMODMAP_DISABLE=1<br/>export XDG_CURRENT_DESKTOP="GNOME-Flashback:Unity"<br/>export XDG_MENU_PREFIX="gnome-flashback-"<br/>unset DBUS_SESSION_BUS_ADDRESS<br/>gnome-session --session=gnome-flashback-metacity --disable-acceleration-check --debug &amp;</pre>
<ol start="23">
<li>The script should appear in the editor, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1532 image-border" src="assets/5d563f4a-e5cd-4c69-b378-d830fbdc2d16.png" style="width:46.25em;height:34.83em;"/></div>
<ol start="24">
<li>Press <span class="packt_screen">Esc</span> to exit out of <kbd>INSERT</kbd> mode and type <kbd>:wq</kbd> to write and quit the file.</li>
<li>Once the startup script has been configured, type the following command in the Google shell to kill the server and save the changes:</li>
</ol>
<pre style="padding-left: 60px"><span>$ </span>vncserver<span> -</span>kill :<span>1</span></pre>
<ol start="26">
<li><span>This command should produce a process ID that looks like the one in the following screenshot:</span></li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1568 image-border" src="assets/3f1637f0-1ff1-44bc-9977-12b159852754.png" style="width:33.92em;height:3.92em;"/></div>
<ol start="27">
<li>Start the server again by typing the following command:</li>
</ol>
<pre style="padding-left: 60px"><span>$ </span>vncserver<span> -geometry 1024x640</span></pre>
<p style="padding-left: 60px">The next series of steps will focus on securing the shell tunnel into the Google Cloud instance from the local host. Before typing anything on the local shell/terminal, ensure that Google Cloud is installed. If not already installed, do so by following the instructions in this quick-start guide located at the following website:</p>
<p style="padding-left: 60px"><a href="https://cloud.google.com/sdk/docs/quickstart-mac-os-x">https://cloud.google.com/sdk/docs/quickstart-mac-os-x</a></p>
<ol start="28">
<li>Once Google Cloud is installed, open up the terminal on your machine and type the following commands to connect to the Google Cloud compute instance:</li>
</ol>
<pre style="padding-left: 60px">$ gcloud compute ssh \<br/>YOUR INSTANCE NAME HERE \<br/>--project YOUR PROJECT NAME HERE \<br/>--zone YOUR TIMEZONE HERE \<br/>--ssh-flag "-L 5901:localhost:5901"</pre>
<ol start="29">
<li><span>Ensure that the instance name, project ID, and zone are specified correctly in the preceding commands. On pressing <span class="packt_screen">ENTER</span>, the output on the local shell changes to what is shown in the following screenshot:</span></li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1567 image-border" src="assets/224843c1-1ecf-4dd6-adbe-cd86313046a1.png" style="width:36.75em;height:43.33em;"/></div>
<ol start="30">
<li><span>Once you see the name of your instance followed by <kbd>":~$"</kbd>, it means that a connection has successfully been established between the local host/laptop and the Google Cloud instance. </span>After successfully SSHing into the instance, we require software called <strong>VNC Viewer</strong> <span>to view and interact with the Ubuntu Desktop that has now been successfully set up on the Google Cloud Compute engine. The following few steps will discuss how this is achieved.</span></li>
</ol>
<ol start="31">
<li><span>VNC Viewer may be downloaded using the following link:</span></li>
</ol>
<p style="padding-left: 90px"><a href="https://www.realvnc.com/en/connect/download/viewer/">https://www.realvnc.com/en/connect/download/viewer/</a></p>
<ol start="32">
<li><span>Once installed, click to open VNC Viewer and in the search bar, type in </span><kbd>localhost::5901</kbd><span>, as shown in the following screenshot:</span></li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1563 image-border" src="assets/3b2c57ec-d2d4-4125-9d39-531aade0352f.png" style="width:50.00em;height:26.92em;"/></div>
<ol start="33">
<li><span>Next, click on </span><span class="packt_screen"><strong>continue</strong><span> </span></span><span>when prompted with the following screen:</span></li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1562 image-border" src="assets/59f9d2d6-3490-451c-bd76-ec7a39ace528.png" style="width:45.83em;height:25.75em;"/></div>
<ol start="34">
<li><span>This will prompt you to enter your password for the virtual machine. Enter the password that you set earlier while launching the</span><span> </span><kbd>tightvncserver</kbd><span> </span><span>command for the first time, as shown in the following screenshot:</span></li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1564 image-border" src="assets/0180764b-79ed-4f45-8b9f-3e8f0fd0beb4.png" style="width:23.50em;height:18.92em;"/></div>
<ol start="35">
<li><span>You will finally be taken into the desktop of your Ubuntu virtual machine on Google Cloud</span><span> </span>Compute<span>. Your Ubuntu Desktop screen must now look something like the following screenshot when viewed on VNC Viewer:</span></li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1560 image-border" src="assets/b8b46dba-ef51-4461-8370-582f5e3ac544.png" style="width:51.25em;height:33.33em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p><span>You have now successfully set up VNC Viewer for interactions with the Ubuntu virtual machine/desktop. Anytime the Google Cloud instance is not in use, it is recommended to suspend or shut down the instance so that additional costs are not being incurred. The cloud approach is optimal for developers who may not have access to physical resources with high memory and storage.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>While we discussed Google Cloud as a cloud option for Spark,  it is possible to leverage Spark on the following cloud platforms as well:</p>
<ul>
<li>Microsoft Azure</li>
<li>Amazon Web Services</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p>In order to learn more about Google Cloud Platform and sign up for a free subscription, visit the following website:</p>
<p><a href="https://cloud.google.com/">https://cloud.google.com/</a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Installing and configuring Spark and prerequisites on Ubuntu Desktop</h1>
                </header>
            
            <article>
                
<p>Before Spark can get up and running, there are some necessary prerequisites that need to be installed on a newly minted Ubuntu <span>Desktop</span>. This section will focus on installing and configuring the following on Ubuntu D<span>esktop</span>:</p>
<ul>
<li>Java 8 or higher</li>
<li>Anaconda</li>
<li>Spark</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>The only requirement for this section is having administrative rights to install applications onto the Ubuntu D<span>esktop</span>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p><span>This section walks through the steps in the recipe to install Python 3, Anaconda, and Spark on Ubuntu Desktop:</span></p>
<ol>
<li><span>Install Java on Ubuntu through the <span class="packt_screen">terminal</span> application, which can be found by searching for the app and then locking it to the launcher on the left-hand side, as seen in the following screenshot:</span></li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1559 image-border" src="assets/24db8263-019c-4cf5-a627-c589a21012c3.png" style="width:38.25em;height:14.83em;"/></div>
<ol start="2">
<li>Perform an initial test for Java on the virtual machine by executing the following command at the terminal:</li>
</ol>
<pre style="padding-left: 60px">java -version</pre>
<ol start="3">
<li><span>Execute the following four commands at the terminal to install Java:</span></li>
</ol>
<pre style="padding-left: 60px">sudo apt-get install software-properties-common <br/>$ sudo add-apt-repository ppa:webupd8team/java<br/>$ sudo apt-get update<br/>$ sudo apt-get install oracle-java8-installer</pre>
<ol start="4">
<li><span>After accepting the necessary license agreements for Oracle, perform a secondary test of Java on the virtual machine by executing <kbd>java -version</kbd> once again in the terminal. A successful installation for Java will display the following outcome in the terminal:</span></li>
</ol>
<pre style="padding-left: 60px">$ java -version<br/>java version "1.8.0_144"<br/>Java(TM) SE Runtime Environment (build 1.8.0_144-b01)<br/>Java HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)</pre>
<ol start="5">
<li>Next, install the most recent version of Anaconda. <span>Current versions of Ubuntu Desktop come preinstalled with Python. </span>While it is convenient that Python comes preinstalled with Ubuntu, the installed version is for <span class="packt_screen">Python 2.7</span>, as seen in the following output:</li>
</ol>
<pre style="padding-left: 60px">$ python --version<br/>Python 2.7.12</pre>
<ol start="6">
<li>The current version of Anaconda is v4.4 and the current version of Python 3 is v3.6. Once downloaded, view the Anaconda installation file by accessing the <kbd>Downloads</kbd> <span>folder using the following command:</span></li>
</ol>
<pre style="padding-left: 60px">$ cd Downloads/<br/>~/Downloads$ ls<br/>Anaconda3-4.4.0-Linux-x86_64.sh</pre>
<ol start="7">
<li><span>Once in the <kbd>Downloads</kbd> folder, initiate the installation for Anaconda by executing the following command:</span></li>
</ol>
<pre style="padding-left: 60px">~/Downloads$ bash Anaconda3-4.4.0-Linux-x86_64.sh <br/>Welcome to Anaconda3 4.4.0 (by Continuum Analytics, Inc.)<br/>In order to continue the installation process, please review the license agreement.<br/>Please, press ENTER to continue</pre>
<div class="packt_tip">Please note that the version of Anaconda, as well as any other software installed, may differ as newer updates are released to the public. The version of Anaconda that we are using in this chapter and in this book can be downloaded from <a href="https://repo.continuum.io/archive/Anaconda3-4.4.0-Linux-x86.sh">https://repo.continuum.io/archive/Anaconda3-4.4.0-Linux-x86.sh</a></div>
<ol start="8">
<li>Once the Anaconda installation is complete, restart the <span class="packt_screen">Terminal</span> application to confirm that Python 3 is now the default Python environment through Anaconda by executing <kbd>python --version</kbd> in the terminal:</li>
</ol>
<pre style="padding-left: 60px">$ python --version<br/>Python 3.6.1 :: Anaconda 4.4.0 (64-bit)</pre>
<ol start="9">
<li>The Python 2 version is still available under Linux, but will require an explicit call when executing a script, as seen in the following command:</li>
</ol>
<pre style="padding-left: 60px">~$ python2 --version<br/>Python 2.7.12</pre>
<ol start="10">
<li>Visit the following website to begin the Spark download and installation process:</li>
</ol>
<p style="padding-left: 90px"><a href="https://spark.apache.org/downloads.html">https://spark.apache.org/downloads.html</a></p>
<ol start="11">
<li><span>Select the download link. The following file will be downloaded to the</span> <kbd>Downloads</kbd> <span>folder in Ubuntu:</span></li>
</ol>
<p style="padding-left: 60px"><kbd>spark-2.2.0-bin-hadoop2.7.tgz</kbd></p>
<ol start="12">
<li>View the file at the terminal level by executing the following commands:</li>
</ol>
<pre style="padding-left: 60px">$ cd Downloads/<br/>~/Downloads$ ls<br/>spark-2.2.0-bin-hadoop2.7.tgz</pre>
<ol start="13">
<li>Extract the <kbd>tgz</kbd> file by executing the following command:</li>
</ol>
<pre style="padding-left: 60px">~/Downloads$ tar -zxvf spark-2.2.0-bin-hadoop2.7.tgz</pre>
<ol start="14">
<li>Another look at the <span class="packt_screen">Downloads</span> directory using <kbd>ls</kbd> shows both the <kbd>tgz</kbd> file and the extracted folder:</li>
</ol>
<pre style="padding-left: 60px">~/Downloads$ ls<br/>spark-2.2.0-bin-hadoop2.7 spark-2.2.0-bin-hadoop2.7.tgz</pre>
<ol start="15">
<li>Move the extracted folder from the <kbd>Downloads</kbd> folder to the <kbd>Home</kbd> folder by executing the following command:</li>
</ol>
<pre style="padding-left: 60px">~/Downloads$ mv spark-2.2.0-bin-hadoop2.7 ~/<br/>~/Downloads$ ls<br/>spark-2.2.0-bin-hadoop2.7.tgz<br/>~/Downloads$ cd<br/>~$ ls<br/>anaconda3 Downloads Pictures Templates<br/>Desktop examples.desktop Public Videos<br/>Documents Music spark-2.2.0-bin-hadoop2.7</pre>
<ol start="16">
<li>Now, the <kbd>spark-2.2.0-bin-hadoop2.7</kbd> folder has been moved to the <span class="packt_screen"><strong>Home</strong></span> folder, which can be viewed when selecting the <span class="packt_screen"><strong>Files</strong></span> icon on the left-hand side toolbar, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1565 image-border" src="assets/e0cfa68f-3713-472f-adfd-1d929b47b819.png" style="width:40.08em;height:20.17em;"/></div>
<ol start="17">
<li>Spark is now installed. Initiate Spark from the terminal by executing the following script at the terminal level:</li>
</ol>
<pre style="padding-left: 60px">~$ cd ~/spark-2.2.0-bin-hadoop2.7/<br/>~/spark-2.2.0-bin-hadoop2.7$ ./bin/pyspark</pre>
<ol start="18">
<li>Perform a final test to ensure Spark is up and running at the terminal by executing the following command to ensure that the <kbd>SparkContext</kbd> is driving the cluster in the local environment:</li>
</ol>
<pre style="padding-left: 60px">&gt;&gt;&gt; <strong>sc</strong><br/>&lt;SparkContext master=local[*] appName=PySparkShell&gt;</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>This section explains the reasoning behind the installation process for Python, Anaconda, and Spark.</p>
<ol>
<li><span>Spark runs on the</span><span> </span><strong>Java virtual machine</strong><span> </span><span>(</span><strong>JVM</strong><span>), the Java</span><span> </span><strong>Software Development Kit</strong><span> </span><span>(</span><strong>SDK</strong><span>) is a prerequisite installation</span><span> </span>for<span> </span><span>Spark to run on an Ubuntu virtual machine.</span></li>
</ol>
<div class="packt_tip"><span>In order for Spark to run on a local machine or in a cluster, a minimum version of Java 6 is required for installation.</span></div>
<ol start="2">
<li><span>Ubuntu recommends the</span><span> </span><kbd>sudo apt install</kbd><span> </span><span>method for Java as it ensures that packages downloaded are up to date. </span></li>
<li>Please note that if Java is not currently installed, the output in the terminal will show the following message:
<ol start="4"/>
</li>
</ol>
<pre style="padding-left: 60px">The program 'java' can be found in the following packages:<br/>* default-jre<br/>* gcj-5-jre-headless<br/>* openjdk-8-jre-headless<br/>* gcj-4.8-jre-headless<br/>* gcj-4.9-jre-headless<br/>* openjdk-9-jre-headless<br/>Try: sudo apt install &lt;selected package&gt;</pre>
<ol start="4">
<li><span>While Python 2 is fine, it is considered legacy Python. Python 2 is facing an end of life date in 2020; therefore, it is recommended that all new Python development be performed with Python 3, as will be the case in this publication. Up until recently, Spark was only available with Python 2. That is no longer the case. Spark works with both Python 2 and 3. </span>A convenient way to install Python 3, as well as many dependencies and libraries, is through Anaconda. Anaconda is a free and open source distribution of Python, as well as R. Anaconda manages the installation and maintenance of many of the most common packages used in Python for data science-related tasks.</li>
<li>
<p>During the installation process for Anaconda, it is important to confirm the following conditions: </p>
<ul>
<li>Anaconda is installed in the<span> </span><kbd>/home/username/Anaconda3</kbd><span> </span>location</li>
<li>The Anaconda installer prepends the Anaconda3 install location to a<span> </span><kbd>PATH</kbd><span> </span>in <kbd>/home/username/.bashrc</kbd></li>
</ul>
</li>
</ol>
<ol start="6">
<li>After Anaconda has been installed, download Spark.<span> </span><span>Unlike Python, Spark does not come preinstalled on Ubuntu and therefore, will need to be downloaded and installed.</span></li>
<li>
<p>For the purposes of development with deep learning, the following preferences will be selected for Spark:</p>
<ul>
<li><strong>Spark release</strong>:<span> </span><strong>2.2.0</strong><span> </span>(Jul 11 2017)</li>
<li><strong>Package type</strong>: Prebuilt for Apache Hadoop 2.7 and later</li>
<li><strong>Download type</strong>: Direct download</li>
</ul>
</li>
<li>Once Spark has been successfully installed, the output from executing Spark at the command line should look something similar to that shown in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1557 image-border" src="assets/3c3ad567-d964-46d1-a678-5269c0d0f49b.png" style="width:47.25em;height:35.67em;"/></div>
<ol start="9">
<li>Two important features to note when initializing Spark are that it is under the<span> </span><kbd>Python 3.6.1</kbd><span> </span>|<span> </span><kbd>Anaconda 4.4.0 (64-bit)</kbd> | framework and that the Spark logo is version 2.2.0.</li>
<li>Congratulations! Spark is successfully installed on the local Ubuntu virtual machine. But, not everything is complete. Spark development is best when Spark code can be executed within a Jupyter notebook, especially for deep learning. Thankfully, Jupyter has been installed with the Anaconda distribution performed earlier in this section.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>You may be asking why we did not just use <kbd>pip install pyspark</kbd> to use Spark in Python. Previous versions of Spark required going through the installation process that we did in this section. Future versions of Spark, starting with 2.2.0 will begin to allow installation directly through the <kbd>pip</kbd> approach. We used the full installation method in this section to ensure that you will be able to get Spark installed and fully-integrated, in case you are using an earlier version of Spark.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p><span>To learn more about Jupyter notebooks and their integration with Python, visit the following website:</span></p>
<p><a href="http://jupyter.org">http://jupyter.org</a></p>
<p>To learn more about <span>Anaconda and download a version for Linux, visit the following website: </span></p>
<p><a href="https://www.anaconda.com/download/">https://www.anaconda.com/download/</a><span>.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Integrating Jupyter notebooks with Spark</h1>
                </header>
            
            <article>
                
<p><span>When learning Python for the first time, it is useful to use Jupyter notebooks as an </span><span><strong>interactive developing environment</strong></span><span> </span>(<span><strong>IDE</strong></span>). T<span>his is one of the main reasons why Anaconda is so powerful. It fully integrates all of the dependencies between Python and Jupyter notebooks.</span><span> </span><span>The same can be done with PySpark and Jupyter notebooks. While Spark is written in Scala, PySpark allows for the translation of code to occur within Python instead.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>Most of the work in this section will just require accessing the <kbd>.bashrc</kbd> script from the terminal.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p><span>PySpark is not configured to work within Jupyter notebooks by default, but a slight tweak of the </span><kbd>.bashrc</kbd><span> script can remedy this issue. We will walk through these steps in this section:</span></p>
<ol>
<li>Access the<span> </span><kbd>.bashrc</kbd><span> </span>script by executing the following command:</li>
</ol>
<pre style="padding-left: 60px">$ nano .bashrc</pre>
<ol start="2">
<li>Scrolling all the way to the end of the script should reveal the last command modified, which should be the<span> </span><kbd>PATH</kbd><span> </span>set by Anaconda during the installation earlier in the previous section. The <kbd>PATH</kbd> should appear as seen in the following:</li>
</ol>
<pre style="padding-left: 60px"># added by Anaconda3 4.4.0 installer<br/>export PATH="/home/asherif844/anaconda3/bin:$PATH"</pre>
<ol start="3">
<li>Underneath, the<span> </span><kbd>PATH</kbd><span> </span>added by the Anaconda installer can include a custom function that helps communicate the Spark installation with the Jupyter notebook installation from Anaconda3. For the purposes of this chapter and remaining chapters, we will name that function<span> </span><kbd>sparknotebook</kbd>. The configuration should appear as the following for <kbd>sparknotebook()</kbd>:</li>
</ol>
<pre style="padding-left: 60px">function sparknotebook()<br/>{<br/>export SPARK_HOME=/home/asherif844/spark-2.2.0-bin-hadoop2.7<br/>export PYSPARK_PYTHON=python3<br/>export PYSPARK_DRIVER_PYTHON=jupyter<br/>export PYSPARK_DRIVER_PYTHON_OPTS="notebook"<br/>$SPARK_HOME/bin/pyspark<br/>}</pre>
<ol start="4">
<li>The updated<span> </span><kbd>.bashrc</kbd><span> </span>script should look like the following once saved:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1556 image-border" src="assets/8e10315b-22c1-42d2-a4cf-634a382cae47.png" style="width:47.50em;height:28.42em;"/></div>
<ol start="5">
<li>Save and exit from the<span> </span><kbd>.bashrc</kbd><span> </span>file. It is recommended to communicate that the<span> </span><kbd>.bashrc</kbd><span> </span>file has been updated by executing the following command and restarting the terminal application:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px">$ source .bashrc</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>Our goal in this section is to integrate Spark directly into a Jupyter notebook so that we are not doing our development at the terminal and instead utilizing the benefits of developing within a notebook. This section explains how the Spark integration within a Jupyter notebook takes place.</p>
<ol>
<li>We will create a command function, <kbd>sparknotebook</kbd>, that we can call from the terminal to open up a Spark session through Jupyter notebooks from the Anaconda installation. This requires two settings to be set in the <kbd>.bashrc</kbd> file:
<ol>
<li>PySpark Python be set to python 3</li>
<li>PySpark driver for python to be set to Jupyter</li>
</ol>
</li>
<li>The<span> </span><kbd>sparknotebook</kbd><span> </span>function can now be accessed directly from the terminal by executing the following command:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px">$ sparknotebook</pre>
<ol start="3">
<li>The function should then initiate a brand new Jupyter notebook session through the default web browser. A new Python script within Jupyter notebooks with<span> </span>a<span> </span><kbd>.ipynb</kbd><span> </span><span>extension can be created by clicking on the </span><span class="packt_screen">New</span><span> button on the right-hand side and by selecting</span><span> </span><span class="packt_screen">Python 3</span><span> </span><span>under</span><span> </span><span class="packt_screen">Notebook:</span><span> </span><span>as seen in the following screenshot:</span></li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1555 image-border" src="assets/759bfb12-f3d8-470b-a1b5-b5d6cfdb3508.png" style="width:47.25em;height:28.92em;"/></div>
<ol start="4">
<li>Once again, just as was done at the terminal level for Spark, a simple script of<span> </span><kbd>sc</kbd><span> </span>will be executed within the notebook to confirm that Spark is up and running through Jupyter:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1554 image-border" src="assets/1fca9542-b5e1-4e76-8c72-63d72fcaa4ec.png" style="width:42.58em;height:13.75em;"/></div>
<ol start="5">
<li>Ideally, the<span> </span><span class="packt_screen">Version</span>,<span> </span><span class="packt_screen">Master</span>, and<span> </span><span class="packt_screen">AppName</span><span> </span>should be identical to the earlier output when<span> </span><kbd>sc</kbd><span> </span>was executed at the terminal. If this is the case, then PySpark has been successfully installed and configured to work with Jupyter notebooks.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>It is important to note that if we were to call a Jupyter notebook through the terminal without specifying <kbd>sparknotebook</kbd>, our Spark session will never be initiated and we will receive an error when executing the <kbd>SparkContext</kbd> script.</p>
<p>We can access a traditional Jupyter notebook by executing the following at the terminal:</p>
<pre>jupyter-notebook</pre>
<p>Once we start the notebook, we can try and execute the same script for <kbd>sc.master</kbd> as we did previously, but this time we will receive the following error:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/fcbadbb7-4201-41b4-8440-6208053013ee.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p>There are many managed offerings online of companies offering Spark through a notebook interface where the installation and configuration of Spark with a notebook have already been managed for you. These are the following:</p>
<ul>
<li>Hortonworks (<a href="https://hortonworks.com/">https://hortonworks.com/</a>)</li>
<li>Cloudera (<a href="https://www.cloudera.com/">https://www.cloudera.com/</a>)</li>
<li>MapR (<a href="https://mapr.com/">https://mapr.com/</a>)</li>
<li>DataBricks (<a href="https://mapr.com/">https://databricks.com/</a>)</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Starting and configuring a Spark cluster</h1>
                </header>
            
            <article>
                
<p><span>For most chapters, one of the first things that we will do is to initialize and configure our Spark cluster.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>Import the following before initializing cluster.</p>
<ul>
<li><kbd>from pyspark.sql import SparkSession</kbd></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>This section walks through the steps to initialize and configure a Spark cluster.</p>
<ol>
<li>Import <kbd>SparkSession</kbd> using the following script:</li>
</ol>
<pre>from pyspark.sql import SparkSession</pre>
<ol start="2">
<li>Configure <kbd>SparkSession</kbd> with a variable named <kbd>spark</kbd> using the following script:</li>
</ol>
<pre>spark = SparkSession.builder \<br/>    .master("local[*]") \<br/>    .appName("GenericAppName") \<br/>    .config("spark.executor.memory", "6gb") \<br/>.getOrCreate()</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>This section explains how the <kbd>SparkSession</kbd> works as an entry point to develop within Spark.</p>
<ol>
<li>Staring with Spark 2.0, it is no longer necessary to create a <kbd>SparkConf</kbd> and <kbd>SparkContext</kbd> to begin development in Spark. Those steps are no longer needed as importing <kbd>SparkSession</kbd> will handle initializing a cluster.  Additionally, it is important to note that <kbd>SparkSession</kbd> is part of the <kbd>sql</kbd> module from <kbd>pyspark</kbd>.</li>
<li>We can assign properties to our <kbd>SparkSession</kbd>:
<ol>
<li><kbd>master</kbd>: assigns the Spark master URL to run on our <kbd>local</kbd> machine with the maximum available number of cores.  </li>
<li><kbd>appName</kbd>: assign a name for the application</li>
<li> <kbd>config</kbd>: assign <kbd>6gb</kbd> to the <kbd>spark.executor.memory</kbd></li>
<li><kbd>getOrCreate</kbd>: ensures that a <kbd>SparkSession</kbd> is created if one is not available and retrieves an existing one if it is available</li>
</ol>
</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p><span>For development purposes, while we are building an application on smaller datasets, we can just use </span><kbd>master("local")</kbd><span>.  If we were to deploy on a production environment, we would want to specify </span><kbd>master("local[*]")</kbd><span> to ensure we are using the maximum cores available and get optimal performance.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p>To learn more about <kbd>SparkSession.builder</kbd>, visit the following website:</p>
<p><a href="https://spark.apache.org/docs/2.2.0/api/java/org/apache/spark/sql/SparkSession.Builder.html">https://spark.apache.org/docs/2.2.0/api/java/org/apache/spark/sql/SparkSession.Builder.html</a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Stopping a Spark cluster</h1>
                </header>
            
            <article>
                
<p>Once we are done developing on our cluster, it is ideal to shut it down and preserve resources.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>This section walks through the steps to stop the <kbd>SparkSession</kbd>.</p>
<ol>
<li>Execute the following script:</li>
</ol>
<p><kbd>spark.stop()</kbd></p>
<ol start="2">
<li>Confirm that the session has closed by executing the following script:</li>
</ol>
<p><kbd>sc.master</kbd></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>This section explains how to confirm that a Spark cluster has been shut down.</p>
<ol start="1">
<li>If the cluster has been shut down, you will receive the error message seen in the following screenshot when executing another Spark command in the notebook:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1553 image-border" src="assets/803973af-d603-4362-a9bb-770ad84e903c.png" style="width:161.50em;height:67.33em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>Shutting down Spark clusters may not be as critical when working in a local environment; however, it will prove costly when Spark is deployed in a cloud environment where you are charged for compute power.</p>
<p> </p>


            </article>

            
        </section>
    </body></html>