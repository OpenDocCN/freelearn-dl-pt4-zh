- en: Productization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter focuses on how to *productize* a deep learning model. We use the
    word *productize* to define the creation of a software product from a deep learning
    model that can be used by other people and applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are interested in models that use new data when it becomes available, continuously
    learning patterns from new data and, consequently, making better predictions.
    We study two strategies to deal with new data: one that re-trains an existing
    model, and another that creates a completely new model. Then, we implement the
    latter strategy in our Bitcoin prices prediction model so that it can continuously
    predict new Bitcoin prices.'
  prefs: []
  type: TYPE_NORMAL
- en: This chapter also provides an exercise of how to deploy a model as a web application.
    By the end of this chapter, we will be able to deploy a working web-application
    (with a functioning HTTP API) and modify it to our heart's content.
  prefs: []
  type: TYPE_NORMAL
- en: We use a web application as an example of how to deploy deep learning models
    because of its simplicity and prevalence (after all, web application are quite
    common), but many other possibilities are available.
  prefs: []
  type: TYPE_NORMAL
- en: 'By the end of this chapter, you will be able to:'
  prefs: []
  type: TYPE_NORMAL
- en: Handle new data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploy a model as a web application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling New Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Models can be trained once in a set of data and can then be used to make predictions.
    Such static models can be very useful, but it is often the case that we want our
    model to continuously learn from new data—and to continuously get better as it
    does so.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will discuss two strategies on how to re-train a deep learning
    model and how to implement them in Python.
  prefs: []
  type: TYPE_NORMAL
- en: Separating Data and Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When building a deep learning application, the two most important areas are
    data and model. From an architectural point of view, we suggest that these two
    areas be separate. We believe that is a good suggestion because each of these
    areas include functions inherently separated from each other. Data is often required
    to be collected, cleaned, organized, and normalized; and models need to be trained,
    evaluated, and able to make predictions. Both of these areas are dependent, but
    are better dealt with separately.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a matter of following that suggestion, we will be using two classes to help
    us build our web application: `CoinMarketCap()` and `Model()` :'
  prefs: []
  type: TYPE_NORMAL
- en: '`CoinMarketCap()` : This is a class designed for fetching Bitcoin prices from
    the following website: [http://www.coinmarketcap.com](https://coinmarketcap.com/).
    This is the same place where our original Bitcoin data comes from. This class
    makes it easy to retrieve that data on a regular schedule, returning a Pandas
    DataFrame with the parsed records and all available historical data. `CoinMarketCap()`
    is our data component.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Model()` : This class implements all the code we have written so far into
    a single class. That class provides facilities for interacting with our previously
    trained models, and also allows for the making of predictions using de-normalized
    data— which is much easier to understand. The `Model()` class is our model component.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These two classes are used extensively throughout our example application and
    define the data and model components.
  prefs: []
  type: TYPE_NORMAL
- en: Data Component
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `CoinMarketCap()` class creates methods for retrieving and parsing data.
    It contains one relevant method, `historic()` , which is detailed in the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '*Snippet 1*: `historic()` method from the `CoinMarketCap()` class.'
  prefs: []
  type: TYPE_NORMAL
- en: This method collects data from the CoinMarketCap website,parses it, and returns
    a Pandas DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: The `historic()` class returns a Pandas DataFrame, ready to be used by the `Model()`
    class.
  prefs: []
  type: TYPE_NORMAL
- en: When working in other models, consider creating a program component (for example,
    a Python class) that fulfils the same functions the `CoinMarketCap()` class does.
    That is, create a component that fetches data from wherever it is available, parses
    that data, and makes it available in a usable format for your modeling component.
  prefs: []
  type: TYPE_NORMAL
- en: The `CoinMarketCap()` class uses the parameter `ticker` to determine what cryptocurrency
    to collect. CoinMarketCap has many other cryptocurrencies available, including
    very popular ones like Ethereum (ethereum) and Bitcoin Cash (bitcoin-cash). Use
    the ticker parameter to change the cryptocurrency and train a different model
    than using the Bitcoin model created in this book.
  prefs: []
  type: TYPE_NORMAL
- en: Model Component
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `Model()` class is where we implement the application''s model component.
    That class contains file methods that implement all the different modeling topics
    from this book. These are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`build()` : Builds an LSTM model using Keras. This function works as a simple
    wrapper for a manually created model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`train()` : Trains model using data that the class was instantiated with.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`evaluate()` : Makes an evaluation of the model using a set of loss functions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`save()` : Saves the model as a file locally.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`predict()` : Makes and returns predictions based on an input sequence of weeks
    ordered observations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We use these methods throughout this chapter to work, train, evaluate, and issue
    predictions with our model. The`Model()` class is an example of how to wrap essential
    Keras functions into a web application. The preceding methods are implemented
    almost exactly as in preceded chapters, but with syntactic sugar added for enhancing
    their interfaces.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, the method `train()` is implemented in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '*Snippet 2*: `train()` method from the `Model()` class. This method trains
    a model available in self.model using data from self.`X` and self.`Y`.'
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding snippet, you will be able to notice that the `train()` method
    resembles the solution to *Activities 6* and 7 from C*hapter 6*, *Model Evaluation
    and Optimization*. The general idea is that each of the processes from the Keras
    workflow (build or design, train, evaluate, and predict) can easily be turned
    into distinct parts of a program. In our case, we made them into methods that
    can be invoked from the `Model() class`. This organizes our program and provides
    a series of constraints (such as on the model architecture or certain API parameters)
    which help us deploy our model in a stable environment.
  prefs: []
  type: TYPE_NORMAL
- en: In the next sections, we explore common strategies for dealing with new data.
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with New Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The core idea of machine learning models—neural networks included—is that they
    can learn patterns from data. Imagine that a model was trained with a certain
    dataset and it is now issuing predictions. Now, imagine that new data is available.
    What strategies can we employ so that a model can take advantage of the newly
    available data to learn new patterns and improve its predictions?
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we discuss two strategies: re-training an old model and training
    a new model.'
  prefs: []
  type: TYPE_NORMAL
- en: Re-Training an Old Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With this strategy, we re-train an existing model with new data. Using this
    strategy, one can continuously adjust the model parameters to adapt to new phenomena.
    However, data used in later training periods may be significantly different to
    other, earlier data. Such differences may cause significant changes to the model
    parameters, making it learn new patterns and forget old patterns. This phenomenon
    is generally referred to as *catastrophic forgetting*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Catastrophic forgetting is a common phenomenon affecting neural networks. Deep
    learning researchers have been trying to tackle this problem for many years. DeepMind,
    a Google-owned deep learning research group from the United Kingdom, has made
    notable advancements in finding a solution. The article *Overcoming Catastrophic
    Forgetting in Neural Networks*, by et. al. is a good reference of such work. The
    paper is available at: [https://arxiv. org/pdf/1612.00796.pdf](https://arxiv.org/pdf/1612.00796.pdf).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The same interface used for training (`model.fit()` ) for the fist time can
    be used for training with new data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '*Snippet 3*: Snippet that implements a TensorBoard callback in our LSTM model'
  prefs: []
  type: TYPE_NORMAL
- en: In Keras, when models are trained, their weight information is kept—this is
    the model's state. When one uses the `model.save()` method, that state is also
    saved. And when one invokes the method `model.fit()` , the model is re-trained
    with the new dataset, using the previous state as a starting point.
  prefs: []
  type: TYPE_NORMAL
- en: 'In typical Keras models, this technique can be used without further issues.
    However, when working with LSTM models, this technique has one key limitation:
    the shape of both train and validation data must be the same. For example, our
    LSTM model (`bitcoin_lstm_v0`) uses 76 weeks to predict one week into the future.
    If we attempt to re-train the network with 77 weeks in the coming week, the model
    raises an exception with information regarding the incorrect shape of data.'
  prefs: []
  type: TYPE_NORMAL
- en: One way of dealing with this is to arrange data in the format expected by the
    model. In our case, we would need to configure our model to predict a future week
    using 40 weeks. Using this solution, we fist train the model with the fist 40
    weeks of 2017, then continue to re-train it over the following weeks until we
    reach week 50.
  prefs: []
  type: TYPE_NORMAL
- en: 'We use the `Model()` class to perform this operation in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '*Snippet 4*: Snippet that implements a re-training technique'
  prefs: []
  type: TYPE_NORMAL
- en: This technique tends to be fast to train, and also tends to work well with series
    that are large. The next technique is easier to implement and works well in smaller
    series.
  prefs: []
  type: TYPE_NORMAL
- en: Training a New Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another strategy is to create and train a new model every time new data is available.
    This approach tends to reduce catastrophic forgetting, but training time increases
    as data increases. Its implementation is quite simple.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the Bitcoin model as an example, let''s now assume that we have old data
    for 49 weeks of 2017, and that after a week, new data is available. We represent
    this with the variables `old_data` and `new_data` in the following quotes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '*Snippet 5*: Snippet that implements a strategy for training a new model when
    new data is available'
  prefs: []
  type: TYPE_NORMAL
- en: This approach is very simple to implement and tends to work well for small datasets.
    This will be the preferred solution for our Bitcoin price-predictions application.
  prefs: []
  type: TYPE_NORMAL
- en: Activity:Dealing with New Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this activity, we re-train our model every time new data is available.
  prefs: []
  type: TYPE_NORMAL
- en: First, we start by importing `cryptonic`. Cryptonic is a simple software application
    developed for this book that implements all the steps up to this section using
    Python classes and modules. Consider Cryptonic as a template of how you could
    develop similar applications.
  prefs: []
  type: TYPE_NORMAL
- en: '`cryptonic` is provided as a Python module alongside this activity. First,
    we will start a Jupyter Notebook instance, and then we will load the `cryptonic`
    package.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using your terminal, navigate to the directory *Chapter_7/activity_8* and execute
    the following code to start a Jupyter Notebook instance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Open the URL provided by the application in your browser and open the Jupyter
    Notebook named `Activity_8_Re_training_a_model_dynamically.ipynb`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, we will load both classes from `cryptonic: Model()` and`CoinMarketCap()`
    . These classes facilitate the process of manipulating our model and also the
    process of getting data from the website CoinMarketCap ([https://coinmarketcap.com/](https://coinmarketcap.com/)).'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the Jupyter Notebook instance, navigate to the header **Fetching Real-Time
    Data**. We will now be fetching updated historical data from `CoinMarketCap`.
    Simply call the method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The variable `historic_data` is now populated with a Pandas DataFrame that contains
    data up to today or yesterday. This is great and makes it easier to retrain our
    model when more data is available.
  prefs: []
  type: TYPE_NORMAL
- en: The data contains practically the same variables from our earlier dataset. However,
    much of the data comes from an earlier period. Recent Bitcoin prices have gained
    a lot of volatility compared to the prices of a few years ago. Before using this
    data in our model, let's make sure to filter it to dates after January 1, 2017.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the Pandas API, filter the data for only the dates available in 2017:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: You should be able to do this by using the date variable as the filtering index.
    Make sure the data is filtered before you continue.
  prefs: []
  type: TYPE_NORMAL
- en: The class `Model()` compiles all the code we have written so far in all of our
    activities. We will use that class to build, train, and evaluate our model in
    this activity.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the Model() class, we now train a model using the preceding filtered
    data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The preceding steps showcase the complete workflow when using the `Model()`
    class for training a model.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we'll focus on re-training our model every time more data is available.
    This re-adjusts the weights of the network to new data.
  prefs: []
  type: TYPE_NORMAL
- en: In order to do this, we have configured our model to predict a week using 40
    weeks. We now want to use the remaining 10 full weeks to create overlapping periods
    of 40 weeks that include one of those 10 weeks at a time, and re-train the model
    for every one of those periods.
  prefs: []
  type: TYPE_NORMAL
- en: 'Navigate to the header **Re-Train Old Model** in the Jupyter Notebook. Now,
    complete the range function and the **model_data** filtering parameters, using
    an index to split the data in overlapping groups of seven days. Then, re-train
    our model and collect the results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The variables `A`, `B`, `C`, and `D` are placeholders. Use integers to create
    overlapping groups of seven days in which the overlap is of one day.
  prefs: []
  type: TYPE_NORMAL
- en: After you have re-trained your model, go ahead and invoke the `M.predict(denormalized=True)`
    function and appreciate the results.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we'll focus on creating and training a new model every time new data is
    available. In order to do this, we now assume that we have old data for 49 weeks
    of 2017, and after a week, we now have new data. We represent this with the variables
    `old_data` and `new_data`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Navigate to the header **Training a New Model** and split the data between
    the variables `old_data` and `new_data`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, train the model with `old_data` first:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This strategy is about building the model from scratch and training it when
    new data is available. Go ahead and implement that in the following cells.
  prefs: []
  type: TYPE_NORMAL
- en: We now have all the pieces that we need in order to train our model dynamically.
    In the next section, we will deploy our model as a web application, making its
    predictions available in the browser via an HTTP API.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we learned about two strategies for training a model when
    new data is available:'
  prefs: []
  type: TYPE_NORMAL
- en: Re-training an old model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training a new model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The latter creates a new model that is trained with the full set of data, except
    the observations in the test set. The former trains a model once on available
    data, then continues to create overlapping batches to re-train that same model
    every time new data is available.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying a Model as a Web Application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will deploy our model as a web application. We will use
    an example web application—called "`cryptonic`"—to deploy our model, exploring
    its architecture so that we can make modifications in the future. The intention
    is to have you use this application as a starter for more complex applications;
    a starter that is fully working and can be expanded as you see fit.
  prefs: []
  type: TYPE_NORMAL
- en: Aside from familiarity with Python, this topic assumes familiarity with creating
    web applications. Specifically, we assume that you have some knowledge about web
    servers, routing, the HTTP protocol, and caching. You will be able to locally
    deploy the demonstrated cryptonic application without extensive knowledge of these
    topics, but learning these topics will make any future development much easier.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, Docker is used to deploy our web applications, so basic knowledge of
    that technology is also useful.
  prefs: []
  type: TYPE_NORMAL
- en: Application Architecture and Technologies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to deploy our web applications, we will use the tools and technologies
    described on Table 1\. Flask is key because it helps us create an HTTP interface
    to our model, allowing us to access an HTTP endpoint (such as /`predict`) and
    receive data back in a universal format. The other components are used because
    they are popular choices when developing web applications:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Tool or Technology**  | **Description**  | **Role**  |'
  prefs: []
  type: TYPE_TB
- en: '| Docker  | Docker is a technology used for working with applications packaged
    in the form of'
  prefs: []
  type: TYPE_NORMAL
- en: containers. Docker is an increasingly popular
  prefs: []
  type: TYPE_NORMAL
- en: technology for building web applications.
  prefs: []
  type: TYPE_NORMAL
- en: '| Packages Python application and UI.'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Flask  | Flask is a micro-framework for building web applications in Python.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Creates application routes'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Vue.js  | JavaScript framework that works by dynamically changing templates
    on the'
  prefs: []
  type: TYPE_NORMAL
- en: frontend based on data inputs from the
  prefs: []
  type: TYPE_NORMAL
- en: backend.
  prefs: []
  type: TYPE_NORMAL
- en: '| Renders a user interface.  |'
  prefs: []
  type: TYPE_TB
- en: '| Nginx  | Web server easily configurable to route traffic to Dockerized applications
    and handle SSL'
  prefs: []
  type: TYPE_NORMAL
- en: certificates for an HTTPS connection.
  prefs: []
  type: TYPE_NORMAL
- en: '| Routes traffic between user and Flask application.'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Redis  | Key-value database. It''s a popular choice for implementing caching
    systems due to its'
  prefs: []
  type: TYPE_NORMAL
- en: simplicity and speed.
  prefs: []
  type: TYPE_NORMAL
- en: '| Cache API requests.  |'
  prefs: []
  type: TYPE_TB
- en: '*Table 1*: Tools and technologies used for deploying a deep learning web application'
  prefs: []
  type: TYPE_NORMAL
- en: 'These components fit together, as shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4882144f-5d91-4ae6-9e85-a5da11185a70.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: System architecture for the web application built in this project'
  prefs: []
  type: TYPE_NORMAL
- en: A user visits the web application using their browser. That traffic is then
    routed by `Nginx` to the Docker container containing the Flask application (by
    default, running on port 5000). The Flask application has instantiated our Bitcoin
    model at startup. If a model has been given, it uses that model without training;
    if not, it creates a new model and trains it from scratch using data from CoinMarketCap.
  prefs: []
  type: TYPE_NORMAL
- en: After having a model ready, the application verifies if the request has been
    cached on Redis—if yes, it returns the cached data. If no cache exists, then it
    will go ahead and issue predictions which are rendered in the UI.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying and Using Cryptonic
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`cryptonic` is developed as a Dockerized application. In Docker terms, that
    means that the application can be built as a Docker image and then deployed as
    a Docker container in either a development or a production environment.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Docker uses files called `Dockerfile` for describing the rules for how to build
    an image and what happens when that image is deployed as a container. Cryptonic''s
    Dockerfile is available in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '*Snippet 6*: Docker file for the cryptonic image'
  prefs: []
  type: TYPE_NORMAL
- en: 'A Docker file can be used to build a Docker image with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '*Snippet 7*: Docker command for building a Docker image locally'
  prefs: []
  type: TYPE_NORMAL
- en: This command will make the image `cryptonic:latest` available to be deployed
    as a container. The building process can be repeated on a production server, or
    the image can be directly deployed and then run as a container.
  prefs: []
  type: TYPE_NORMAL
- en: 'After an image has been built and is available, one can run the cryptonic application
    by using the command docker run, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '*Snippet 8*: Example executing the docker run command in the terminal'
  prefs: []
  type: TYPE_NORMAL
- en: The `--publish` flag binds port 5000 on localhost to port 5000 on the Docker
    container, and `--detach` runs the container as a daemon in the background.
  prefs: []
  type: TYPE_NORMAL
- en: In case you have trained a different model and would like to use that instead
    of training a new model, you can alter the `MODEL_NAME` environment variable on
    the docker-compose. yml, as shown in Snippet 9\. That variable should contain
    the filename of the model you have trained and want served (for example, `bitcoin_lstm_v1_trained.h5`)—it
    should also be a Keras model. If you do that, make sure to also mount a local
    directory into the / models folder. The directory that you decide to mount must
    have your model file.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `cryptonic` application also includes a number of environment variables
    that you may find useful when deploying your own model:'
  prefs: []
  type: TYPE_NORMAL
- en: '`MODEL_NAME`: Allows one to provide a trained model to be used by the application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`BITCOIN_START_DATE`: Determines which day to use as the starting day for the
    Bitcoin series. Bitcoin prices have a lot more variance in recent years than earlier
    ones. This parameter filters the data to only years of interest. The default is
    January 1, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`PERIOD_SIZE`: Sets the period size in terms of days. The default is 7.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`EPOCHS`: Configures the number of epochs that the model trains on every run.
    The default is 300.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These variables can be configured in the `docker-compose.yml` file, as shown
    in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '*Snippet 9*: `docker-compose.yml` file including environment variables'
  prefs: []
  type: TYPE_NORMAL
- en: 'The easiest way to deploy cryptonic is to use the `docker-compose.yml` file
    from Snippet 9\. This file contains all the specifications necessary for the application
    to run, including instructions on how to connect with the Redis cache, and what
    environment variables to use. After navigating to the location of the `docker-compose.yml
    file`, cryptonic can then be started with the command `docker-compose up`, as
    shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '*Snippet 10*: Starting a Docker application with docker-compose. The flag -d
    executes the application in the background.'
  prefs: []
  type: TYPE_NORMAL
- en: 'After being deployed, cryptonic can be accessed on port `5000` via a web browser.
    The application has a simple user interface with a time-series plot depicting
    real historical prices (in other words, observed) and predicted future prices
    from the deep learning model (in other words, predicted). One can also read, in
    the text, both the RMSE and the MAPE calculated using the `Model().evaluate()`
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c4f9e7fd-36c2-4123-a2f4-1b7bfb335b64.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Screenshot of the deployed cryptonic application'
  prefs: []
  type: TYPE_NORMAL
- en: Aside from its user interface (developed using `Vue.js`), the application has
    an HTTP API that makes predictions when invoked.
  prefs: []
  type: TYPE_NORMAL
- en: 'The API has the endpoint /`predict`, which returns a JSON object containing
    the de-normalized Bitcoin prices prediction for a week into the future:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '*Snippet 11*: Example JSON output from the /predict endpoint'
  prefs: []
  type: TYPE_NORMAL
- en: The application can now be deployed in a remote server and used to continuously
    predict Bitcoin prices.
  prefs: []
  type: TYPE_NORMAL
- en: Activity:Deploying a Deep Learning Application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this activity, we deploy our model as a web application locally. This allows
    us to connect to the web application using a browser or to use another application
    through the application''s HTTP API. Before we continue, make sure that you have
    the following applications installed and available in your computer:'
  prefs: []
  type: TYPE_NORMAL
- en: Docker (Community Edition) 17.12.0-ce or later
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker Compose (docker-compose) 1.18.0 or later
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Both of the components above can be downloaded and installed in all major systems
    from the website: [http://docker.com/.](https://www.docker.com/) These are essential
    for completing this activity. Make sure these are available in your system before
    moving forward.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using your terminal, navigate to the cryptonic directory and build the docker images
    for all the required components:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Those two commands build the two images that we will use in this application:
    cryptonic (containing the Flask application) and cryptonic-cache (containing the
    Redis cache).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'After building the images, identify the `docker-compose.yml` file and open
    it in a text editor. Change the parameter `BITCOIN_START_DATE` to a date other
    than 2017- 01-01:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'As a final step, deploy your web application locally using docker-compose,
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: You should see a log of activity on your terminal, including training epochs
    from your model.
  prefs: []
  type: TYPE_NORMAL
- en: 'After the model has been trained, you can visit your application on `http://
    localhost:5000` and make predictions on `http://localhost:5000/predict`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/b5aed7a8-3696-433f-8f2d-21b8f41ec65f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Screenshot of the cryptonic application deployed locally'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter concludes our journey into creating a deep learning model and deploying
    it as a web application. Our very last steps included deploying a model that predicts
    Bitcoin prices built using Keras and using a TensorFlow engine. We finished our
    work by packaging the application as a Docker container and deploying it so that
    others can consume the predictions of our model—as well as other applications
    via its API.
  prefs: []
  type: TYPE_NORMAL
- en: 'Aside from that work, you have also learned that there is much that can be
    improved. Our Bitcoin model is only an example of what a model can do (particularly
    LSTMs). The challenge now is two fold: how can you make that model perform better
    as time passes? And, what features can you add to your web application to make
    your model more accessible? Good luck and keep learning!'
  prefs: []
  type: TYPE_NORMAL
