["```py\ngit clone https://github.com/PacktPublishing/Python-Deep-Learning-Projects\ncd Chapter10/\n```", "```py\ncurl https://get.docker.com | sh\n```", "```py\n#Dockerfile for our env setup\nFROM tensorflow/tensorflow:latest\n\nRUN apt-get update -y --fix-missing\nRUN apt-get install -y ffmpeg\nRUN apt-get install -y build-essential cmake pkg-config \\\n                    libjpeg8-dev libtiff5-dev libjasper-dev libpng12-dev \\\n                    libavcodec-dev libavformat-dev libswscale-dev libv4l-dev \\\n                    libxvidcore-dev libx264-dev \\\n                    libgtk-3-dev \\\n                    libatlas-base-dev gfortran \\\n                    libboost-all-dev \\\n                    python3 python3-dev python3-numpy\n\nRUN apt-get install -y wget vim python3-tk python3-pip\n\nWORKDIR /\nRUN wget -O opencv.zip https://github.com/Itseez/opencv/archive/3.2.0.zip \\\n    && unzip opencv.zip \\\n    && wget -O opencv_contrib.zip https://github.com/Itseez/opencv_contrib/archive/3.2.0.zip \\\n    && unzip opencv_contrib.zip\n\n# install opencv3.2\nRUN cd /opencv-3.2.0/ \\\n   && mkdir build \\\n   && cd build \\\n   && cmake -D CMAKE_BUILD_TYPE=RELEASE \\\n            -D INSTALL_C_EXAMPLES=OFF \\\n            -D INSTALL_PYTHON_EXAMPLES=ON \\\n            -D OPENCV_EXTRA_MODULES_PATH=/opencv_contrib-3.2.0/modules \\\n            -D BUILD_EXAMPLES=OFF \\\n            -D BUILD_opencv_python2=OFF \\\n            -D BUILD_NEW_PYTHON_SUPPORT=ON \\\n            -D CMAKE_INSTALL_PREFIX=$(python3 -c \"import sys; print(sys.prefix)\") \\\n            -D PYTHON_EXECUTABLE=$(which python3) \\\n            -D WITH_FFMPEG=1 \\\n            -D WITH_CUDA=0 \\\n            .. \\\n    && make -j8 \\\n    && make install \\\n    && ldconfig \\\n    && rm /opencv.zip \\\n    && rm /opencv_contrib.zip\n\n# Install dlib 19.4\nRUN wget -O dlib-19.4.tar.bz2 http://dlib.net/files/dlib-19.4.tar.bz2 \\\n    && tar -vxjf dlib-19.4.tar.bz2\n\nRUN cd dlib-19.4 \\\n    && cd examples \\\n    && mkdir build \\\n    && cd build \\\n    && cmake .. \\\n    && cmake --build . --config Release \\\n    && cd /dlib-19.4 \\\n    && pip3 install setuptools \\\n    && python3 setup.py install \\\n    && cd $WORKDIR \\\n    && rm /dlib-19.4.tar.bz2\n\nADD $PWD/requirements.txt /requirements.txt\nRUN pip3 install -r /requirements.txt\n\nCMD [\"/bin/bash\"]\n```", "```py\ndocker build -t hellorahulk/facerecognition -f Dockerfile\n```", "```py\ncurl -O http://dlib.net/\n```", "```py\nfiles/shape_predictor_68_face_landmarks.dat.bz2\nbzip2 -d shape_predictor_68_face_landmarks.dat.bz2\ncp shape_predictor_68_face_landmarks.dat facenet/\n```", "```py\ncurl -L -O https://www.dropbox.com/s/hb75vuur8olyrtw/Resnet-185253.pb\ncp Resnet-185253.pb pre-model/\n```", "```py\nimport sys\nimport dlib\nfrom skimage import io\n\n# Create a HOG face detector using the built-in dlib class\nface_detector = dlib.get_frontal_face_detector()\n\n# Load the image into an array\nfile_name = 'sample_face_image.jpeg'\nimage = io.imread(file_name)\n\n# Run the HOG face detector on the image data.\n# The result will be the bounding boxes of the faces in our image.\ndetected_faces = face_detector(image, 1)\n\nprint(\"Found {} faces.\".format(len(detected_faces)))\n\n# Loop through each face we found in the image\nfor i, face_rect in enumerate(detected_faces):\n # Detected faces are returned as an object with the coordinates \n # of the top, left, right and bottom edges\n  print(\"- Face #{} found at Left: {} Top: {} Right: {} Bottom: {}\".format(i+1, face_rect.left(), face_rect.top(), face_rect.right(), face_rect.bottom()))\n```", "```py\nFound 1 faces. \n-Face #1 found at Left: 365 Top: 365 Right: 588 Bottom: 588\n```", "```py\nimport sys\nimport dlib\nimport cv2\nimport openface\n\npredictor_model = \"shape_predictor_68_face_landmarks.dat\"\n\n# Create a HOG face detector , Shape Predictor and Aligner\nface_detector = dlib.get_frontal_face_detector()\nface_pose_predictor = dlib.shape_predictor(predictor_model)\nface_aligner = openface.AlignDlib(predictor_model)\n\n# Take the image file name from the command line\nfile_name = 'sample_face_image.jpeg'\n\n# Load the image\nimage = cv2.imread(file_name)\n\n# Run the HOG face detector on the image data\ndetected_faces = face_detector(image, 1)\n\nprint(\"Found {} faces.\".format(len(detected_faces))\n\n# Loop through each face we found in the image\nfor i, face_rect in enumerate(detected_faces):\n\n  # Detected faces are returned as an object with the coordinates \n  # of the top, left, right and bottom edges\n  print(\"- Face #{} found at Left: {} Top: {} Right: {} Bottom: {}\".format(i, face_rect.left(), face_rect.top(), face_rect.right(), face_rect.bottom()))\n\n # Get the the face's pose\n  pose_landmarks = face_pose_predictor(image, face_rect)\n\n # Use openface to calculate and perform the face alignment\n  alignedFace = face_aligner.align(534, image, face_rect, landmarkIndices=openface.AlignDlib.OUTER_EYES_AND_NOSE)\n\n # Save the aligned image to a file\n  cv2.imwrite(\"aligned_face_{}.jpg\".format(i), alignedFace)\n```", "```py\ndef _create_embeddings(embedding_layer, images, labels, images_placeholder, phase_train_placeholder, sess):\n    \"\"\"\n    Uses model to generate embeddings from :param images.\n    :param embedding_layer: \n    :param images: \n    :param labels: \n    :param images_placeholder: \n    :param phase_train_placeholder: \n    :param sess: \n    :return: (tuple): image embeddings and labels\n    \"\"\"\n    emb_array = None\n    label_array = None\n    try:\n        i = 0\n        while True:\n            batch_images, batch_labels = sess.run([images, labels])\n            logger.info('Processing iteration {} batch of size: {}'.format(i, len(batch_labels)))\n            emb = sess.run(embedding_layer,\n                           feed_dict={images_placeholder: batch_images, phase_train_placeholder: False})\n\n            emb_array = np.concatenate([emb_array, emb]) if emb_array is not None else emb\n            label_array = np.concatenate([label_array, batch_labels]) if label_array is not None else batch_labels\n            i += 1\n\n    except tf.errors.OutOfRangeError:\n        pass\n\n    return emb_array, label_array\n```", "```py\ndocker run -v $PWD:/facerecognition \\\n-e PYTHONPATH=$PYTHONPATH:/facerecognition \\\n-it hellorahulk/facerecognition python3 /facerecognition/facenet/preprocess.py \\\n--input-dir /facerecognition/data \\\n--output-dir /facerecognition/output/intermediate \\\n--crop-dim 180\n```", "```py\ndocker run -v $PWD:/facerecognition \\\n-e PYTHONPATH=$PYTHONPATH:/facerecognition \\\n-it hellorahulk/facerecognition \\\npython3 /facerecognition/facenet/train_classifier.py \\\n--input-dir /facerecognition/output/intermediate \\\n--model-path /facerecognition/pre-model/Resnet-185253.pb \\\n--classifier-path /facerecognition/output/classifier.pkl \\\n--num-threads 16 \\\n--num-epochs 25 \\\n--min-num-images-per-class 10 \\\n--is-train\n```", "```py\ndocker run -v $PWD:/facerecognition \\\n-e PYTHONPATH=$PYTHONPATH:/facerecognition \\\n-it hellorahulk/facerecognition \\\npython3 /facerecognition/facenet/train_classifier.py \\\n--input-dir /facerecognition/output/intermediate \\\n--model-path /facerecognition/pre-model/Resnet-185253.pb \\\n--classifier-path /facerecognition/output/classifier.pkl \\\n--num-threads 16 \\\n--num-epochs 2 \\\n--min-num-images-per-class 10 \\\n```"]