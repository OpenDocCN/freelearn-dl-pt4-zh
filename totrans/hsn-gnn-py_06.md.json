["```py\nimport numpy as np\nD = np.array([\n    [3, 0, 0, 0],\n    [0, 1, 0, 0],\n    [0, 0, 2, 0],\n    [0, 0, 0, 2]\n])\n```", "```py\nnp.linalg.inv(D)\narray([[0.33333333, 0.        , 0.        , 0.        ],\n       [0.        , 1.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.5       , 0.        ],\n       [0.        , 0.        , 0.        , 0.5       ]])\n```", "```py\nnp.linalg.inv(D + np.identity(4))\narray([[0.25      , 0.        , 0.        , 0.        ],\n       [0.        , 0.5       , 0.        , 0.        ],\n       [0.        , 0.        , 0.33333333, 0.        ],\n       [0.        , 0.        , 0.        , 0.33333333]])\n```", "```py\nA = np.array([\n    [1, 1, 1, 1],\n    [1, 1, 0, 0],\n    [1, 0, 1, 1],\n    [1, 0, 1, 1]\n])\nprint(np.linalg.inv(D + np.identity(4)) @ A)\n[[0.25       0.25       0.25       0.25      ]\n [0.5        0.5        0.         0.        ]\n [0.33333333 0.         0.33333333 0.33333333]\n [0.33333333 0.         0.33333333 0.33333333]]\nprint(A @ np.linalg.inv(D + np.identity(4)))\n[[0.25       0.5        0.33333333 0.33333333]\n [0.25       0.5        0.         0.        ]\n [0.25       0.         0.33333333 0.33333333]\n [0.25       0.         0.33333333 0.33333333]]\n```", "```py\n    from torch_geometric.datasets import Planetoid\n    from torch_geometric.utils import degree\n    from collections import Counter\n    import matplotlib.pyplot as plt\n    ```", "```py\n    dataset = Planetoid(root=\".\", name=\"Cora\")\n    data = dataset[0]\n    ```", "```py\n    degrees = degree(data.edge_index[0]).numpy()\n    ```", "```py\n    numbers = Counter(degrees)\n    ```", "```py\n    fig, ax = plt.subplots()\n    ax.set_xlabel('Node degree')\n    ax.set_ylabel('Number of nodes')\n    plt.bar(numbers.keys(), numbers.values())\n    ```", "```py\n    import torch\n    import torch.nn.functional as F\n    from torch_geometric.nn import GCNConv\n    ```", "```py\n    def accuracy(pred_y, y):\n        return ((pred_y == y).sum() / len(y)).item()\n    ```", "```py\n    class GCN(torch.nn.Module):\n        \"\"\"Graph Convolutional Network\"\"\"\n        def __init__(self, dim_in, dim_h, dim_out):\n            super().__init__()\n            self.gcn1 = GCNConv(dim_in, dim_h)\n            self.gcn2 = GCNConv(dim_h, dim_out)\n    ```", "```py\n        def forward(self, x, edge_index):\n            h = self.gcn1(x, edge_index)\n            h = torch.relu(h)\n            h = self.gcn2(h, edge_index)\n            return F.log_softmax(h, dim=1)\n    ```", "```py\n        def fit(self, data, epochs):\n            criterion = torch.nn.CrossEntropyLoss()\n            optimizer = torch.optim.Adam(self.parameters(),\n                                        lr=0.01,\n                                        weight_decay=5e-4)\n            self.train()\n            for epoch in range(epochs+1):\n                optimizer.zero_grad()\n                out = self(data.x, data.edge_index)\n                loss = criterion(out[data.train_mask], data.y[data.train_mask])\n                acc = accuracy(out[data.train_mask].argmax(dim=1), data.y[data.train_mask])\n                loss.backward()\n                optimizer.step()\n                if(epoch % 20 == 0):\n                    val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n                    val_acc = accuracy(out[data.val_mask].argmax(dim=1), data.y[data.val_mask])\n                    print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc: {acc*100:>5.2f}% | Val Loss: {val_loss:.2f} | Val Acc: {val_acc*100:.2f}%')\n    ```", "```py\n        @torch.no_grad()\n        def test(self, data):\n            self.eval()\n            out = self(data.x, data.edge_index)\n            acc = accuracy(out.argmax(dim=1)[data.test_mask], data.y[data.test_mask])\n            return acc\n    ```", "```py\n    gcn = GCN(dataset.num_features, 16, dataset.num_classes)\n    print(gcn)\n    gcn.fit(data, epochs=100)\n    ```", "```py\n    GCN(\n      (gcn1): GCNConv(1433, 16)\n      (gcn2): GCNConv(16, 7)\n    )\n    Epoch   0 | Train Loss: 1.963 | Train Acc:  8.57% | Val Loss: 1.96 | Val Acc: 9.80%\n    Epoch  20 | Train Loss: 0.142 | Train Acc: 100.00% | Val Loss: 0.82 | Val Acc: 78.40%\n    Epoch  40 | Train Loss: 0.016 | Train Acc: 100.00% | Val Loss: 0.77 | Val Acc: 77.40%\n    Epoch  60 | Train Loss: 0.015 | Train Acc: 100.00% | Val Loss: 0.76 | Val Acc: 76.40%\n    Epoch  80 | Train Loss: 0.018 | Train Acc: 100.00% | Val Loss: 0.75 | Val Acc: 76.60%\n    Epoch 100 | Train Loss: 0.017 | Train Acc: 100.00% | Val Loss: 0.75 | Val Acc: 77.20%\n    ```", "```py\n    acc = gcn.test(data)\n    print(f'GCN test accuracy: {acc*100:.2f}%')\n    GCN test accuracy: 79.70%\n    ```", "```py\n    from torch_geometric.datasets import WikipediaNetwork\n    import torch_geometric.transforms as T\n    dataset = WikipediaNetwork(root=\".\", name=\"chameleon\", transform = T.RandomNodeSplit(num_val=200, num_test=500))\n    data = dataset[0]\n    ```", "```py\n    print(f'Dataset: {dataset}')\n    print('-------------------')\n    print(f'Number of graphs: {len(dataset)}')\n    print(f'Number of nodes: {data.x.shape[0]}')\n    print(f'Number of unique features: {dataset.num_features}')\n    print(f'Number of classes: {dataset.num_classes}')\n    ```", "```py\nDataset: WikipediaNetwork()\n-------------------\nNumber of graphs: 1\nNumber of nodes: 2277\nNumber of unique features: 2325\nNumber of classes: 5\n```", "```py\nimport pandas as pd\ndf = pd.read_csv('wikipedia/chameleon/musae_chameleon_target.csv')\n```", "```py\n    values = np.log10(df['target'])\n    ```", "```py\n    data.y = torch.tensor(values)\n    tensor([2.2330, 3.9079, 3.9329,  ..., 1.9956, 4.3598, 2.4409], dtype=torch.float64)\n    ```", "```py\nimport seaborn as sns\nfrom scipy.stats import norm\ndf['target'] = values\nsns.distplot(df['target'], fit=norm)\n```", "```py\n    class GCN(torch.nn.Module):\n        def __init__(self, dim_in, dim_h, dim_out):\n            super().__init__()\n            self.gcn1 = GCNConv(dim_in, dim_h*4)\n            self.gcn2 = GCNConv(dim_h*4, dim_h*2)\n            self.gcn3 = GCNConv(dim_h*2, dim_h)\n            self.linear = torch.nn.Linear(dim_h, dim_out)\n    ```", "```py\n    def forward(self, x, edge_index):\n        h = self.gcn1(x, edge_index)\n        h = torch.relu(h)\n        h = F.dropout(h, p=0.5, training=self.training)\n        h = self.gcn2(h, edge_index)\n        h = torch.relu(h)\n        h = F.dropout(h, p=0.5, training=self.training)\n        h = self.gcn3(h, edge_index)\n        h = torch.relu(h)\n        h = self.linear(h)\n        return h\n    ```", "```py\n        def fit(self, data, epochs):\n            optimizer = torch.optim.Adam(self.parameters(),\n                                          lr=0.02,\n                                          weight_decay=5e-4)\n            self.train()\n            for epoch in range(epochs+1):\n                optimizer.zero_grad()\n                out = self(data.x, data.edge_index)\n                loss = F.mse_loss(out.squeeze()[data.train_mask], data.y[data.train_mask].float())\n                loss.backward()\n                optimizer.step()\n                if epoch % 20 == 0:\n                    val_loss = F.mse_loss(out.squeeze()[data.val_mask], data.y[data.val_mask])\n                    print(f\"Epoch {epoch:>3} | Train Loss: {loss:.5f} | Val Loss: {val_loss:.5f}\")\n    ```", "```py\n        @torch.no_grad()\n        def test(self, data):\n            self.eval()\n            out = self(data.x, data.edge_index)\n            return F.mse_loss(out.squeeze()[data.test_mask], data.y[data.test_mask].float())\n    ```", "```py\n    gcn = GCN(dataset.num_features, 128, 1)\n    print(gcn)\n    gcn.fit(data, epochs=200)\n    GCN(\n      (gcn1): GCNConv(2325, 512)\n      (gcn2): GCNConv(512, 256)\n      (gcn3): GCNConv(256, 128)\n      (linear): Linear(in_features=128, out_features=1, bias=True)\n    )\n    Epoch   0 | Train Loss: 12.05177 | Val Loss: 12.12162\n    Epoch  20 | Train Loss: 11.23000 | Val Loss: 11.08892\n    Epoch  40 | Train Loss: 4.59072 | Val Loss: 4.08908\n    Epoch  60 | Train Loss: 0.82827 | Val Loss: 0.84340\n    Epoch  80 | Train Loss: 0.63031 | Val Loss: 0.71436\n    Epoch 100 | Train Loss: 0.54679 | Val Loss: 0.75364\n    Epoch 120 | Train Loss: 0.45863 | Val Loss: 0.73487\n    Epoch 140 | Train Loss: 0.40186 | Val Loss: 0.67582\n    Epoch 160 | Train Loss: 0.38461 | Val Loss: 0.54889\n    Epoch 180 | Train Loss: 0.33744 | Val Loss: 0.56676\n    Epoch 200 | Train Loss: 0.29155 | Val Loss: 0.59314\n    ```", "```py\n    loss = gcn.test(data)\n    print(f'GCN test loss: {loss:.5f}')\n    GCN test loss: 0.43005\n    ```", "```py\n    from sklearn.metrics import mean_squared_error, mean_absolute_error\n    ```", "```py\n    out = gcn(data.x, data.edge_index)\n    y_pred = out.squeeze()[data.test_mask].detach().numpy()\n    mse = mean_squared_error(data.y[data.test_mask], y_pred)\n    mae = mean_absolute_error(data.y[data.test_mask], y_pred)\n    ```", "```py\n    print('=' * 43)\n    print(f'MSE = {mse:.4f} | RMSE = {np.sqrt(mse):.4f} | MAE = {mae:.4f}')\n    print('=' * 43)\n    ===========================================\n    MSE = 0.4300 | RMSE = 0.6558 | MAE = 0.5073\n    ===========================================\n    ```", "```py\nfig = sns.regplot(x=data.y[data.test_mask].numpy(), y=y_pred)\n```"]