- en: Cruise Control - Automation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will create a production system, from training to serving
    a model. Our system will have the ability to distinguish between 37 different
    species of dogs and cat. A user can upload an image to our system to receive the
    results. The system can also receive feedback from the user and automatically
    train itself every day to improve results.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter will focus on several areas:'
  prefs: []
  type: TYPE_NORMAL
- en: How to apply transfer learning to a new dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to serve a production model with TensorFlow Serving
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a system with crowd-sourced labeling of the dataset and automatic fine-tuning
    the model on user data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An overview of the system
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following diagram provides an overview of our system:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f70d3bc2-a815-4a92-8c76-8ac66ffc649f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In this system, we will use an initial dataset to train a convolutional neural
    network model on a training server. Then, the model will be served in a production
    server with TensorFlow Serving. On the production server, there will be a Flask
    server that allows users to upload a new image and correct the label if the model
    goes wrong. At a defined time in the day, the training server will combine all
    the user-labeled images with the current dataset to automatically fine-tune the
    model and send it to the production server. Here is the wireframe of the web interface
    that allows users to upload and receive the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9972d10a-5ab1-456c-849f-1490e4f346ff.png)'
  prefs: []
  type: TYPE_IMG
- en: Setting up the project
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will fine-tune a VGG model that has been trained on `ImageNet`
    data with 1,000 classes. We have provided an initial project with a pretrained
    VGG model and some utility files. You can go ahead and download the code from
    [https://github.com/mlwithtf/mlwithtf/tree/master/chapter_09](https://github.com/mlwithtf/mlwithtf/tree/master/chapter_09).
  prefs: []
  type: TYPE_NORMAL
- en: 'In the folder `chapter-09`, you will have the following structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'There are two files that you should understand:'
  prefs: []
  type: TYPE_NORMAL
- en: '`VGG16.npz` is the pre-trained model that is exported from the Caffe model.
    [Chapter 11](1cae2bb8-19d3-4640-aae6-d31d66afb605.xhtml), *Going Further - 21
    Problems* will show you how to create this file from the Caffe model. In this
    chapter, we will use this as the initial values for our model. You can download
    this file from the `README.md` in the `chapter_09` folder.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`production` is the Flask server that we created to serve as a web interface
    for users to upload and correct the model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`debug_print.py` contains some methods that we will use during this chapter
    to understand the network structure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`samples_data` contains some images of cats, dogs, and cars that we will use
    throughout the chapter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loading a pre-trained model to speed up the training
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, let's focus on loading the pre-trained model in TensorFlow.
    We will use the VGG-16 model proposed by K. Simonyan and A. Zisserman from the
    University of Oxford.
  prefs: []
  type: TYPE_NORMAL
- en: 'VGG-16 is a very deep neural network with lots of convolution layers followed
    by max-pooling and fully connected layers. In the `ImageNet` challenge, the top-5
    classification error of the VGG-16 model on the validation set of 1,000 image
    classes is 8.1% in a single-scale approach:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/98634c06-1c4f-4443-a69b-1a6df6d9436b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'First, create a file named `nets.py` in the `project` directory. The following
    code defines the graph for the VGG-16 model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, there are a few things that you should note:'
  prefs: []
  type: TYPE_NORMAL
- en: '`_conv2d`, `_max_pool`, `_fully_connected` and `_softmax` are methods that
    define the convolution, max pooling, fully connected, and softmax layers, respectively.
    We will implement these methods shortly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the `preprocess` name scope, we define a constant tensor, `mean`, which is
    subtracted from the input image. This is the mean vector that the VGG-16 model
    is trained on in order to make the image zero mean.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We then define the convolution, max pooling, and fully connected layers with
    the parameters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the `fc8` layers, we don't apply ReLU activation to the outputs and we send
    the outputs to a `softmax` layer to compute the probability over 1,000 classes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, we will implement `_conv2d`, `_max_pool`, `_fully_connected`, and `_softmax`
    in the `nets.py` file.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code is the code for the `_conv2d` and `_max_pool` methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Most of the preceding code is self-explanatory if you have read [Chapter 4](ff9f54f4-c5eb-4ea8-bc0c-da5021479d77.xhtml),
    *Cats and Dogs*, but there are some lines that deserve a bit of explanation:'
  prefs: []
  type: TYPE_NORMAL
- en: '`k_h` and `k_w` are the height and weights of the kernel'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`c_o` means channel outputs, which is the number of feature maps of the convolution
    layers'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`s_h` and `s_w` are the stride parameters for the `tf.nn.conv2d` and `tf.nn.max_pool`
    layers'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tf.get_variable` is used instead of `tf.Variable` because we will need to
    use `get_variable` again when we load the pre-trained weights'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Implementing the `fully_connected` layers and `softmax` layers are quite easy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Using the `_fully_connected` method, we first check the number of dimensions
    of the input data in order to reshape the input data into the correct shape. Then,
    we create `weights` and `biases` variables with the  `get_variable` method. Finally,
    we check the `relu` parameter to decide whether we should apply `relu` to the
    output with the `tf.nn.relu_layer` or `tf.nn.xw_plus_b`. `tf.nn.relu_layer` will
    compute `relu(matmul(x, weights) + biases)`. `tf.nn.xw_plus_b` but will only compute
    `matmul(x, weights) + biases`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The final method in this section is used to load the pre-trained `caffe` weights
    into the defined variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to understand this method, we must know how the data is stored in
    the pre-trained model, `VGG16.npz`. We have created a simple code to print all
    the variables in the pre-trained model. You can put the following code at the
    end of `nets.py` and run it with Python `nets.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Here are a few lines of the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, `op_name` is the name of the layers, and we can access the `weights`
    and `biases` of each layer with `data_dict[op_name]`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at `load_caffe_weights`:'
  prefs: []
  type: TYPE_NORMAL
- en: We use it with `tf.variable_scope` with `reuse=True` in the parameters so that
    we can get the exact variables for `weights` and `biases` that were defined in
    the graph. After that, we run the assign method to set the data for each variable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `get_variable` method will give `ValueError` if the variable name is not
    defined. Therefore, we will use the `ignore_missing` variable to decide whether
    we should raise an error or not.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing the pre-trained model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have already created a VGG16 neural network. In this section, we will try
    to use the pre-trained model to perform the classifications of cars, cats, and
    dogs to check whether the model has been loaded successfully.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `nets.py` file, we need to replace the current `__main__` code with
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, there are several things that you should note:'
  prefs: []
  type: TYPE_NORMAL
- en: We use the `debug_print`.`print_variables` helper method to visualize all the
    variables by printing the variable names and shapes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We define a placeholder named `inputs` with the shape `[None, 224, 224, 3]`,
    which is the required input size of the VGG16 model:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: In `tf.Session()`, we call the `load_caffe_weights` method with `ignore_missing=False`
    to ensure that we can load all the weights and biases of the pre-trained model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The image is loaded and resized with the `imread` and `imresize` methods from
    `scipy`. Then, we use the `sess.run` method with the `feed_dict` dictionary and
    receive the predictions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following results are the predictions for `car.jpg`, `cat.jpg`, and `dog.jpg`
    in the `samples_data` that we provided at the beginning of the chapter:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The preceding results are the exact labels of these images. This means that
    we have successfully loaded the pre-trained VGG16 model in TensorFlow. In the
    next section, we will show you how to fine-tune the model on our dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Training the model for our dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will work through the process of creating the dataset, fine-tuning
    the model, and exporting the model for production.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to the Oxford-IIIT Pet dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Oxford-IIIT Pet dataset contains 37 species of dogs and cats. Each class
    has 200 images with large variations in scale, pose, and lighting. The ground
    truth data has annotations for species, head position, and pixel segmentation
    for each image. In our application, we only use the species name as the class
    name for the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/682fb671-be0e-4fa6-8895-23a01be38c5b.png)'
  prefs: []
  type: TYPE_IMG
- en: Dataset Statistics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following are the dataset for dogs and cats breed:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Dog breeds:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '| **Breed** | **Total** |'
  prefs: []
  type: TYPE_TB
- en: '| American Bulldog | 200 |'
  prefs: []
  type: TYPE_TB
- en: '| American Pit Bull Terrier  | 200 |'
  prefs: []
  type: TYPE_TB
- en: '| Basset Hound | 200 |'
  prefs: []
  type: TYPE_TB
- en: '| Beagle  | 200 |'
  prefs: []
  type: TYPE_TB
- en: '| Boxer  | 199 |'
  prefs: []
  type: TYPE_TB
- en: '| Chihuahua | 200 |'
  prefs: []
  type: TYPE_TB
- en: '| English Cocker Spaniel | 196 |'
  prefs: []
  type: TYPE_TB
- en: '| English Setter  | 200 |'
  prefs: []
  type: TYPE_TB
- en: '| German Shorthaired | 200 |'
  prefs: []
  type: TYPE_TB
- en: '| Great Pyrenees  | 200 |'
  prefs: []
  type: TYPE_TB
- en: '| Havanese | 200 |'
  prefs: []
  type: TYPE_TB
- en: '| Japanese Chin   | 200 |'
  prefs: []
  type: TYPE_TB
- en: '| Keeshond | 199 |'
  prefs: []
  type: TYPE_TB
- en: '| Leonberger  | 200 |'
  prefs: []
  type: TYPE_TB
- en: '| Miniature Pinscher | 200 |'
  prefs: []
  type: TYPE_TB
- en: '| Newfoundland  | 196 |'
  prefs: []
  type: TYPE_TB
- en: '| Pomeranian | 200 |'
  prefs: []
  type: TYPE_TB
- en: '| Pug | 200 |'
  prefs: []
  type: TYPE_TB
- en: '| Saint Bernard | 200 |'
  prefs: []
  type: TYPE_TB
- en: '| Samoyed | 200 |'
  prefs: []
  type: TYPE_TB
- en: '| Scottish Terrier | 199 |'
  prefs: []
  type: TYPE_TB
- en: '| Shiba Inu | 200 |'
  prefs: []
  type: TYPE_TB
- en: '| Staffordshire Bull Terrier | 189 |'
  prefs: []
  type: TYPE_TB
- en: '| Wheaten Terrier | 200 |'
  prefs: []
  type: TYPE_TB
- en: '| Yorkshire Terrier | 200 |'
  prefs: []
  type: TYPE_TB
- en: '| **Total** | **4978** |'
  prefs: []
  type: TYPE_TB
- en: 'Cat breeds:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '| **Breed** | **Count** |'
  prefs: []
  type: TYPE_TB
- en: '| Abyssinian | 198 |'
  prefs: []
  type: TYPE_TB
- en: '| Bengal | 200 |'
  prefs: []
  type: TYPE_TB
- en: '| Birman | 200 |'
  prefs: []
  type: TYPE_TB
- en: '| Bombay | 184 |'
  prefs: []
  type: TYPE_TB
- en: '| British Shorthair | 200 |'
  prefs: []
  type: TYPE_TB
- en: '| Egyptian Mau | 190 |'
  prefs: []
  type: TYPE_TB
- en: '| Maine Coon | 200 |'
  prefs: []
  type: TYPE_TB
- en: '| Persian | 200 |'
  prefs: []
  type: TYPE_TB
- en: '| Ragdoll | 200 |'
  prefs: []
  type: TYPE_TB
- en: '| Russian Blue | 200 |'
  prefs: []
  type: TYPE_TB
- en: '| Siamese | 199 |'
  prefs: []
  type: TYPE_TB
- en: '| Sphynx | 200 |'
  prefs: []
  type: TYPE_TB
- en: '| **Total** | **2371** |'
  prefs: []
  type: TYPE_TB
- en: 'Total pets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '| **Family** | **Count** |'
  prefs: []
  type: TYPE_TB
- en: '| Cat | 2371 |'
  prefs: []
  type: TYPE_TB
- en: '| Dog | 4978 |'
  prefs: []
  type: TYPE_TB
- en: '| **Total** | **7349** |'
  prefs: []
  type: TYPE_TB
- en: Downloading the dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can get the dataset from the website of the University of Oxford at [http://www.robots.ox.ac.uk/~vgg/data/pets/](http://www.robots.ox.ac.uk/~vgg/data/pets/).
    We need to download the dataset and ground truth data as `images.tar.gz` and `annotations.tar.gz`.
    We store the TAR files in the `data/datasets` folder and extract all the `.tar`
    files. Make sure that the `data` folder has the following structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Preparing the data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before starting the training process, we need to pre-process the dataset into
    a simpler format, which we will use in the further automatic fine-tuning.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we make a Python package with named scripts in the `project` folder.
    Then, we create a Python file named `convert_oxford_data.py` and add the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: In this code, we use `tf.app.flags.FLAGS` to parse arguments so that we can
    customize the script easily. We also create two `helper` methods to make a directory
    and read images.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we add the following code to convert the Oxford dataset into our preferred
    format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can run the `scripts` with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The script reads the Oxford-IIIT dataset ground truth `data` and creates a
    new `dataset` in `data/train_data` with the following structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s discuss these a bit:'
  prefs: []
  type: TYPE_NORMAL
- en: '`labels.txt` contains a list of 37 species in our dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`trainval.txt` contains a list of the images that we will use in the training
    process, with the format `<class_id> <image_path>`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`test.txt` contains a list of the images that we will use to check the accuracy
    of the model. The format of `test.txt` is the same as `trainval.txt`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`trainval` and `test` folders contain 37 sub-folders, which are the names of
    each class and contains all the images of each class.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up input pipelines for training and testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: TensorFlow allows us to create a reliable input pipeline for quick and easy
    training. In this section, we will implement `tf.TextLineReader` to read the train
    and test text files. We will use `tf.train.batch` to read and preprocess images
    in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to create a new Python file named `datasets.py` in the `project`
    directory and add the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: In the `load_files` method, we use the `tf.TextLineReader` to read each line
    of the text file, such as `trainval.txt, test.txt`. `tf.TextLineReader` needs
    a queue of strings to read, so we use `tf.train.string_input_producer` to store
    the filenames. After that, we pass the line variable into `tf.decode_cvs` in order
    to get the `label` and `filename`. The image can be easily read with `tf.image.decode_jpeg`.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we can load the image, we can move forward and create `image` batches
    and `label` batches for `training`.
  prefs: []
  type: TYPE_NORMAL
- en: 'In `datasets.py`, we need to add a new method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We first load the `image` and `label` with the `load_files` method. Then, we
    pass the image through a new preprocessing method, which we will implement shortly.
    Finally, we pass the `image` and `label` into `tf.train.shuffle_batch` for training
    and `tf.train.batch` for testing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'There are two different approaches to preprocessing in training and testing.
    In training, we need to augment data to create more training data from the current
    dataset. There are a few techniques that are used in the preprocessing method:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The images in the dataset can have different image resolutions, but we only
    need 224x224 images. Therefore, we need to resize the image to a reasonable size
    before performing `random_crop`. The following diagram describes how cropping
    works. The `_aspect_preserving_resize` method will be implemented shortly:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/062d0bd1-3f15-4966-8b71-b3603ad59f01.png)'
  prefs: []
  type: TYPE_IMG
- en: After cropping the image, we pass the image through `tf.image.random_flip_left_right`,
    `tf.image.random_brightness` and `tf.image.random_contrast` to distort the image
    and create a new training sample.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the testing routine, we only need to resize the image with `_aspect_preserving_resize`
    and `tf.image.resize_image_with_crop_or_pad`. `tf.image.resize_image_with_crop_or_pad`
    allows us to crop centrally or pad the image to the target `width` and `height`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, we need to add the last two methods into `datasets.py`, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Up to this section, we had to do a lot of work to prepare the `dataset` and
    `input` pipelines. In the following section, we will define the model for our
    `dataset`, `loss`, `accuracy` and `training` operations to perform the `training`
    routine.
  prefs: []
  type: TYPE_NORMAL
- en: Defining the model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Our application will need to classify `37` classes of dogs and cats. The VGG16
    Model supports 1,000 different classes. In our application, we will reuse all
    layers up to the `fc7` layer and train the last layer from scratch. In order to
    make the model output `37` classes, we need to modify the inference method in
    `nets.py` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: We add a new parameter, `is_training`, to the method. After the `fc7` layer,
    we add a `tf.nn.dropout` layer if the inference is training. This dropout layer
    can help the model regularize better with unseen data and avoid overfitting.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of outputs in the `fc8` layer is changed from 1,000 to 37\. Besides,
    the name of the `fc8` layer must be changed to another name; in this case, we
    choose `fc8-pets`. If we don't change the name of the `fc8` layer, `load_caffe_weights`
    will still find the new layers and assign the original weights, which is not the
    same size as our new `fc8` layer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `softmax` layer at the end of the inference method is also removed because
    the `loss` function that we will use later only needs unnormalized outputs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Defining training operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will define all the operations in a new Python file named `models.py`. First,
    let''s create some operations to compute `loss` and `accuracy`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: In these methods, `logits` is the output of the model and `labels` is the ground
    truth data from the `dataset`. In the `compute_loss` method, we use `tf.nn.sparse_softmax_cross_entropy_with_logits`
    so we don't need to normalize the `logits` with `softmax` methods. Besides, we
    don't need to make the `labels` a one-hot vector. In the `compute_accuracy` method,
    we compare the max value in `logits` with `tf.argmax` and compare it with the
    `labels` to get the `accuracy`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we are going to define the operations for the `learning_rate` and the
    `optimizer`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: In the `train` method, we configure the `optimizer` to only `compute` and apply
    `gradients` to some variables defined in the `train_vars` string. This allows
    us to only update the `weights` and `biases` for the last layer, `fc8`, and freeze
    other layers. `train_vars` is a string that contains a list of variables split
    by commas, for example, `models/fc8-pets/weights:0,models/fc8-pets/biases:0`.
  prefs: []
  type: TYPE_NORMAL
- en: Performing the training process
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now we are ready to train the model. Let''s create a Python file named `train.py`
    in the `scripts` folder. First, we need to define some parameters for the `training`
    routines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'These variables are self-explanatory. Next, we need to define some operations
    for `training`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: These operations are created by calling our defined methods in `datasets.py`,
    `nets.py`, and `models.py`. In this code, we create an input pipeline for training
    and another pipeline for testing. After that, we create a new `variable_scope`
    named `models` and create `logits` and `test_logits` with the `nets.inference`
    method. You must make sure that `scope.reuse_variables` is added because we want
    to reuse the `weights` and `biases` from training in testing. Finally, we create
    a `saver` and some directories to save the checkpoints every `save_steps`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The last part of the `training` routine is the `training` loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The `training` loop is easy to understand. First, we load the pre-trained `VGG16`
    model with `ignore_missing` set to `True` because we replaced the name of the `fc8`
    layer before. Then, we loop for `max_steps` steps, print the `loss` every `output_steps`,
    and print the `test_accuracy` every `eval_steps`. Every `save_steps`, we check
    and save the checkpoint if the current test accuracy is higher than the previous.
    We still need to create `models.export_model` to export the model for serving
    after `training`. However, you may want to check whether the `training` routine
    works before moving forward. Let''s comment out the following line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, run the `training` script with this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is some output in the console. First, our script loads the pre-trained
    model. Then, it will output the `loss`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Now, let's stop the `training` and uncomment the `export_model` method. We need
    the `models.export_model` method to export the latest model that has the highest
    test accuracy to the `export_dir` folder with the name `export_name` and the version
    `export_version`.
  prefs: []
  type: TYPE_NORMAL
- en: Exporting the model for production
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'In the `export_model` method, we need to create a new graph to run in production.
    In production, we don''t need all the variables, as in `training`, and we don''t
    need an input pipeline. However, we need to export the model with the `export_saved_model`
    method, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'With this method, we can create a metagraph of the model for serving in production.
    We will cover how to serve the model in a later section. Now, let''s run the `scripts`
    to automatically train and export after 3,000 steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'On our system, with Core i7-4790 CPU and one TITAN-X GPU, the training routine
    takes 20 minutes to finish. Here are a few of the last outputs in our console:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Great! We have a model with 92.18% test accuracy. We also have the exported
    model as a `.pb` file. The `export_dir` folder will have the following structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Serving the model in production
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In production, we need to create an endpoint so our users can send the image
    and receive the result. In TensorFlow, we can easily serve our model with TensorFlow
    Serving. In this section, we will install TensorFlow Serving and create a Flask
    app that allows users to upload their images via a web interface.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up TensorFlow Serving
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In your production server, you need to install TensorFlow Serving and its prerequisites.
    You can visit the official website of TensorFlow Serving at [https://tensorflow.github.io/serving/setup](https://tensorflow.github.io/serving/setup).
    Next, we will use the standard TensorFlow Model Server provided in TensorFlow
    Serving to serve the model. First, we need to build the `tensorflow_model_server`
    with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Copy all the files from `/home/ubuntu/models/pet_model` in your training server
    into your production server. In our setup, we choose `/home/ubuntu/productions`
    as our folder to store all the production models. The `productions` folder will
    have the following structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'We will use `tmux` to keep the model server running. Let''s install `tmux`
    with this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Run a `tmux` session with this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'In the `tmux` session, let''s change directory to the `tensorflow_serving`
    directory and run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the console should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the model is running on host `0.0.0.0` and port `9000`. In the
    next section, we will create a simple Python client to send an image to this server
    via gRPC.
  prefs: []
  type: TYPE_NORMAL
- en: You should also note that the current serving is only using CPU on the production
    server. Building TensorFlow Serving with GPUs is beyond the scope of this chapter.
    If you prefer serving with GPUs, you may want to read [Appendix A](8022db02-d24f-4620-9da7-ae53df279306.xhtml)*,
    Advanced Installation*, which explains how to build TensorFlow and TensorFlow
    Serving with GPU support.
  prefs: []
  type: TYPE_NORMAL
- en: Running and testing the model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the project repository, we have already provided a package named `production`.
    In that package, we need to copy the `labels.txt` file into our `dataset`, create
    a new Python file, `client.py`, and add the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'In this code, we create a `process_image` method that will read the image from
    an image path and use some TensorFlow methods to create a tensor and send it to
    the model server with gRPC. We also create an `Output` class so that we can easily
    return it to the `caller` method. At the end of the method, we print the output
    and the total time so that we can debug it more easily. We can run this Python
    file to see if the `process_image` works:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the correct result. However, the time to process is almost 15 seconds
    for each image. The reason is that we are using TensorFlow Serving in CPU mode.
    As we mentioned earlier, you can build TensorFlow Serving with GPU support in
    [Appendix A](8022db02-d24f-4620-9da7-ae53df279306.xhtml), *Advanced Installation*.
    If you follow that tutorial, you will have the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: The time to process in the first calling time is 493 ms. However, the later
    calling time will be only about 23 ms, which is so much quicker than the CPU version.
  prefs: []
  type: TYPE_NORMAL
- en: Designing the web server
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will set up a Flask server to allow users to upload their
    images and set the correct label if our model is mistaken. We have provided the
    code needed in the production package. Implementing a Flask server with database
    support is beyond the scope of this chapter. In this section, we will describe
    all the main points about Flask so you can follow and understand better.
  prefs: []
  type: TYPE_NORMAL
- en: The main flow that allows users to upload and correct labels can be described
    in the following wireframe.
  prefs: []
  type: TYPE_NORMAL
- en: 'This flow is implemented with the following routes:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Route** | **Method** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `/` | GET | This route returns a web form for users to upload the image.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `/upload_image` | POST | This route gets the image from POST data, saves
    it to the upload directory, and calls `process_image` in our `client.py` to recognize
    the image and save the result to the database. |'
  prefs: []
  type: TYPE_TB
- en: '| `/results<result_id>` | GET | This route returns the result of the corresponding
    row in the database. |'
  prefs: []
  type: TYPE_TB
- en: '| `/results<result_id>` | POST | This route saves the label from, user to the
    database so that we can fine-tune the model later. |'
  prefs: []
  type: TYPE_TB
- en: '| `/user-labels` | GET | This route returns a list of all the user-labeled
    images. In the fine-tune process, we will call this route to get the list of labeled
    images. |'
  prefs: []
  type: TYPE_TB
- en: '| `/model` | POST | This route allows the fine-tune process from the training
    server to serve a new trained model. This route receives a link of the zipped
    model, a version number, a checkpoint name, and a model name. |'
  prefs: []
  type: TYPE_TB
- en: '| `/model` | GET | This route returns the latest model in the database. The
    fine-tune process will call this to know which is the latest model and fine-tune
    from it. |'
  prefs: []
  type: TYPE_TB
- en: 'We should run this server in a `tmux` session with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Testing the system
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, we can access the server via `http://0.0.0.0:5000`.
  prefs: []
  type: TYPE_NORMAL
- en: First, you will see a form to choose and submit an image.
  prefs: []
  type: TYPE_NORMAL
- en: The website will be redirected to the `/results` page with the corresponding
    image and its results. The user label field is empty. There is also a short form
    at the end so that you can submit the corrected label of the model.
  prefs: []
  type: TYPE_NORMAL
- en: Automatic fine-tune in production
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After running the system for a while, we will have some user-labeled images.
    We will create a fine-tune process to automatically run every day and fine-tune
    the latest model with new data.
  prefs: []
  type: TYPE_NORMAL
- en: Let's create a file named `finetune.py` in the scripts folder.
  prefs: []
  type: TYPE_NORMAL
- en: Loading the user-labeled data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, we will add the code to download all user-labeled images from the production
    server:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'In `download_user_data`, we call the `/user-labels` endpoint to get the list
    of user-labeled images. The JSON has the following format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: In this JSON, `label` is the label that the user has chosen, and URL is the
    link to download the image from. For every image, we will download it into the
    `tmp` folder and use `imread` and `imsave` from `scipy` to make sure that the
    image is in JPEG format. We also create a `trainval.txt` and `test.txt` file,
    as in the training dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Performing a fine-tune on the model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to fine-tune the model, we need to know which one is the latest model
    and its corresponding checkpoint to restore `weights` and `biases`. Therefore,
    we call the `/model` endpoint to get the checkpoint name and a version number:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'The response JSON should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will implement the code to fine-tune the model. Let''s start with some
    parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we will implement the fine-tune loop. In the following code, we call
    `download_user_data` to download all the user-labeled images and pass `user_dir`
    into `input_pipeline` so that it will load the new images:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Other parts are quite similar to the training loop. However, instead of loading
    the weights from the `caffe` model, we use the checkpoint of the latest model
    and run the test a few times to get its test accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: 'At the end of the fine-tune loop, we need a new method named `archive_and_send_file`
    to make an archive from the `exported` model and send the link to the production
    server:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: You should note that we create a link with the `source_api` parameter, which
    is the link to the training server, `http://1.53.110.161:8181`. We will set up
    a simple Apache Server to support this function. However, in reality, we suggest
    that you upload the archived model to cloud storage such as Amazon S3\. Now, we
    will show you the simplest way with Apache.
  prefs: []
  type: TYPE_NORMAL
- en: 'We need to install Apache with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, in `/etc/apache2/ports.conf`, on line 6, we need to add this code to make
    `apache2` listen on port `8181`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, add the following code at the beginning of `/etc/apache2/sites-available/000-default.conf`
    to support downloading from the `/home/ubuntu/models` directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we need to restart the `apache2` server:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: Up to now, we have set up all the code to perform fine-tuning. Before running
    the fine-tuning for the first time, we need to send a `POST` request to the `/model`
    endpoint with the information about our first model because we have already copied
    the model to the production server.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `project` repository, let''s run the `finetune` script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'The last few lines in the console will look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, the new model has a test accuracy of 91%. The model is also
    exported and archived to `/home/ubuntu/models/pet-model/2.zip`. The code is also
    calling the `/model` endpoint to post the link to the production server. In the
    logging of the Flask app in the production server, we will get the following results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'This means that our Flask app had downloaded the `2.zip` file from the training
    server and extracted the content to `/home/ubuntu/productions/2`. In the `tmux`
    session for TensorFlow Serving, you will also get the following results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: This output indicates that the TensorFlow model server has successfully loaded
    `version 2` of the `pet-model` and unloaded `version 1`. This also means that
    we have served the new model, which was trained on the training server and sent
    to the production server via the `/model` endpoint.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up cronjob to run every day
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Finally, we need to set up the fine-tuning to run every day and automatically
    upload the new model to the server. We can achieve this easily by creating a `crontab`
    in the training server.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to run the `crontab` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we can just add the following line to define the time that we want `finetune.py`
    to run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: As we defined, the Python command will run at 3 a.m. every day.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we have implemented a complete real-life production, from
    training to serving a deep learning model. We also created a web interface in
    a Flask app so that users can upload their images and receive results. Our model
    can automatically be fine-tuned every day to improve the quality of the system.
    There are a few things that you can consider to improve the overall system:'
  prefs: []
  type: TYPE_NORMAL
- en: The model and checkpoints should be saved in cloud storage.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Flask app and TensorFlow Serving should be managed by another, better process
    management system, such as Supervisor.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There should be a web interface so that the team can approve the labels that
    users select. We shouldn't rely completely on users to decide the training set.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TensorFlow Serving should be built with GPU support to achieve the best performance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
