- en: '8'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Limitations of Coding with LLMs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter will help you learn about how **large language models** ( **LLMs**
    ) lack a perfect understanding of the nuances of human languages and find complex
    coding tasks beyond their abilities. We’ll be examining the inconsistencies and
    unpredictabilities of LLM chatbots. This chapter will also help you to integrate
    the LLM code into your code base. Hopefully, you’ll be informed and inspired by
    research into improving the state of the field, including moving toward constructing
    more complex code.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, you’ll have the opportunity to learn the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Inherent limitations of LLMs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Challenges in integrating LLMs into coding workflows
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Future research directions to address limitations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this chapter, you may want to have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Access to an LLM/chatbot, such as GPT-4 or Gemini; each requires logins. For
    GPT-4, you’d need an OpenAI account and for Gemini, you’d need a Google account.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An internet browser for all the additional reading to get deeper into this.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, we’ll get into the first section of the chapter, which talks about the
    inherent limitations of all LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: Inherent limitations of LLMs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: LLMs have shown remarkable capabilities in generating code, but they also possess
    inherent limitations that can significantly impact the quality and reliability
    of the output.
  prefs: []
  type: TYPE_NORMAL
- en: Core limitations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here are some of the limitations that LLMs have:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Lack of true understanding** : While LLMs can generate syntactically correct
    code, they lack a deep understanding of the underlying concepts, algorithms, and
    problem domains. This can lead to suboptimal or incorrect solutions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hallucinations** : LLMs can generate plausible-sounding but incorrect or
    nonsensical code, often referred to as “hallucinations.” This can be particularly
    problematic in critical applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dependency on training data** : The quality of LLM-generated code is heavily
    reliant on the quality and diversity of the training data. Biases or limitations
    in the training data can be reflected in the generated code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Difficulty with complex logic** : LLMs often struggle with tasks requiring
    intricate logical reasoning or problem-solving, leading to suboptimal or incorrect
    code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lack of contextual understanding** : While LLMs can process information sequentially,
    they often lack a comprehensive understanding of the broader context, which can
    lead to inconsistencies or errors in code generation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Limited context window or memory** : In the context windows of LLMs, the
    amount of information that can be entered in one prompt (query) or that can be
    delivered in a response is limited. These context windows are quickly increasing,
    but they now have big hardware requirements.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Limited debugging capabilities** : LLMs are generally poor at debugging their
    own generated code, making it necessary for human intervention to identify and
    correct errors.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Old training data** : LLMs cannot update their training data, so can be answering
    based on the past.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are also specific limitations in code generation, which are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Code quality and efficiency** : LLM-generated code can often be inefficient
    or suboptimal in terms of performance and resource utilization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security vulnerabilities** : There’s a risk of generating code with security
    vulnerabilities due to the LLM’s lack of security expertise.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Maintainability** : LLM-generated code can be difficult to maintain due to
    its potential complexity and lack of adherence to coding standards.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reproducibility** : Generating the same code output multiple times can be
    challenging, as LLMs are stochastic systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ Prompt_Drive]'
  prefs: []
  type: TYPE_NORMAL
- en: Other limitations to LLMs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Apart from the preceding, there might also be ethical and legal limitations.
    LLMs might inadvertently generate biased code or replicate existing code snippets
    verbatim from its training data, leading to potential issues with **intellectual
    property** ( **IP** ) or unintended ethical implications [Parth Santpurkar, Technical
    Reviewer for the book].
  prefs: []
  type: TYPE_NORMAL
- en: There is more on ethics and biases in [*Chapter 5*](B21009_05.xhtml#_idTextAnchor115)
    ; [*Chapter 6*](B21009_06.xhtml#_idTextAnchor137) goes over legal considerations
    and [*Chapter 7*](B21009_07.xhtml#_idTextAnchor180) attempts to handle most security
    threats with countermeasures.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating LLM performance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: LLM outputs are very difficult to evaluate, but there are many methods to do
    so. Some methods are neural network-based, and some are statistical analysis methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'What metrics can be used to evaluate LLMs and how do you calculate them? Here’s
    a very brief intro to some of them:'
  prefs: []
  type: TYPE_NORMAL
- en: Is the generated code syntactically and semantically correct compared to a ground
    truth? Does the LLM-generated code solve the problem it was asked to?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How similar is the generated code to the expected solution in terms of functionality
    and logic?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does the LLM generate incorrect code?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Contextual relevancy** : For **retrieval-augmented generation** ( **RAG**
    ) models, does the LLM extract and use the most relevant information from the
    provided context?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Summarization** : Does the LLM give you concise and correct code snippets
    or documentation that is based on the source material?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**CodeBLEU (Bilingual Evaluation Understudy)** : This compares outputs with
    ground truth code using precision for each matching *n* -gram ( *n* consecutive
    words). BLEU itself is not so effective for code, so CodeBLEU has been for code
    synthesis [CodeBLEU].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**METEOR** : A metric that combines unigram matching, stemming, and synonymy
    to capture semantic similarity, which might be beneficial for code evaluation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[confident_ai, Stevens, CodeBLEU]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Learn more about metrics here: [https://www.confident-ai.com/blog/llm-evaluation-metrics-everything-you-need-for-llm-evaluation](https://www.confident-ai.com/blog/llm-evaluation-metrics-everything-you-need-for-llm-evaluation)
    .'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also see what Jane Huang says about LLM metrics and best practices:
    [https://medium.com/data-science-at-microsoft/evaluating-llm-systems-metrics-challenges-and-best-practices-664ac25be7e5](https://medium.com/data-science-at-microsoft/evaluating-llm-systems-metrics-challenges-and-best-practices-664ac25be7e5)
    .'
  prefs: []
  type: TYPE_NORMAL
- en: 'Learn about CodeBLEU, by Ren et al., here: [https://arxiv.org/abs/2009.10297](https://arxiv.org/abs/2009.10297)
    .'
  prefs: []
  type: TYPE_NORMAL
- en: Overcoming inherent limitations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s see what can already be done to improve LLM work and results.
  prefs: []
  type: TYPE_NORMAL
- en: Search the web
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'LLMs are trained with data up to a point, then they are tested and deployed.
    So, their data is always out of date and always needs to be re-trained as the
    world changes. However, Gemini does search the internet and Serper is a low-cost
    API that helps LLMs, such as GPT-4, by searching the web for the latest information.
    Get Serper here: [https://serper.dev/](https://serper.dev/) . It’s very quick
    and easy to sign up for an API key and start using it on your agents. Serper comes
    with 2,500 free queries.'
  prefs: []
  type: TYPE_NORMAL
- en: AI agents
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An **intelligent agent** is something that operates in an environment, has a
    state, has sensors (with perception), and performs actions autonomously to achieve
    goals. A thermostat, a human, and a state are all examples of intelligent agents
    [Wiki_Agent].
  prefs: []
  type: TYPE_NORMAL
- en: Creating AI agents from LLMs can help to reduce some of the problems of LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: When you input a prompt to get some code from GPT-4o, run it in an IDE, find
    it has an error, and enter another prompt to GPT-4o to correct this error, you
    are behaving like an agent, and feeding back the weaknesses to be improved.
  prefs: []
  type: TYPE_NORMAL
- en: 'This can be automated: when applications behave like agents, they are called
    *agentic* .'
  prefs: []
  type: TYPE_NORMAL
- en: The AI agent does the whole running of the code, feedback, re-query process,
    and iterations itself.
  prefs: []
  type: TYPE_NORMAL
- en: This way, the LLM agent can work to remove its own errors. If a human is checking,
    this process can be more exact, but the iterations will be slower.
  prefs: []
  type: TYPE_NORMAL
- en: 'Devin is an agent that is a virtual software engineer and can be prompted to
    give you code. Unfortunately, as of writing, in July 2024, Cognition has not released
    Devin to the public; you’ll have to join the waiting list: [https://www.cognition.ai/blog/introducing-devin](https://www.cognition.ai/blog/introducing-devin)
    .'
  prefs: []
  type: TYPE_NORMAL
- en: If you have an agentic application that employs a few different LLMs as agents,
    then the blind spots and weaknesses of one LLM can be improved by other LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Agents and especially multi-agent applications can make the performance of
    LLMs much greater. Even agents powered by weaker LLMs can perform better than
    the latest and best LLMs in the world (at any point). Here is a study on multi-agent
    systems and how they improve the performance of LLMs: [https://arxiv.org/html/2402.05120v1](https://arxiv.org/html/2402.05120v1)
    . LLMs can also debate and vote.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Even human reasoning is vastly superior when in groups, rather than a single
    person reasoning alone [Mercier]; this is collective intelligence. Debate and
    being forced to provide good arguments and evidence greatly improve the chances
    of uncovering truth or avoiding mistakes. Groups of humans and AI agent groups
    share benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: Error correction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Diversity of experience or data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Knowledge sharing: members can learn from each other'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'More computational power: more speed'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So, working in groups can be very beneficial; this is probably why humans operate
    in groups of up to billions! Will there ever be groups of billions of AI agents?
  prefs: []
  type: TYPE_NORMAL
- en: 'Agents can be employed in groups to code, and one of these is called **ChatDev**
    . ChatDev is a virtual software company with a CEO, a developer, an architect,
    and a project manager. These are all agents that work together to make users the
    software requested in a prompt. Find out more about ChatDev here: [https://chatdev.toscl.com/](https://chatdev.toscl.com/)
    and here: [https://medium.com/@meirgotroot/chatdev-review-the-good-the-bad-and-the-ugly-469b5cb691d4](mailto:https://medium.com/@meirgotroot/chatdev-review-the-good-the-bad-and-the-ugly-469b5cb691d4)
    .'
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft has developed a multi-agent application for automating complex LLM
    workflows; it’s called **AutoGen** .
  prefs: []
  type: TYPE_NORMAL
- en: 'In both AutoGen and ChatDev, the agents talk to each other and collaborate
    to produce a better solution. See a comparison between ChatDev and AutoGen here:
    [https://www.ikangai.com/autogen-vs-chatdev-pioneering-multi-agent-systems-in-the-llm-landscape/](https://www.ikangai.com/autogen-vs-chatdev-pioneering-multi-agent-systems-in-the-llm-landscape/)
    .'
  prefs: []
  type: TYPE_NORMAL
- en: AutoGPT is an open source AI agent that you can query. It will break up the
    goal you give it into sub-tasks, and use tools such as the internet in an automatic
    loop ( [https://en.wikipedia.org/wiki/Auto-GPT](https://en.wikipedia.org/wiki/Auto-GPT)
    ).
  prefs: []
  type: TYPE_NORMAL
- en: 'Make your own AI agents with MetaGPT: [https://play.google.com/store/apps/details?id=com.metagpt.app&hl=en_US&pli=1](https://play.google.com/store/apps/details?id=com.metagpt.app&hl=en_US&pli=1)
    .'
  prefs: []
  type: TYPE_NORMAL
- en: AI agents are a key field of research at the moment, and the field shows a lot
    of promise. Much can be written about this topic, but we need to move on to the
    topics of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: We’ve looked at inherent limitations, and we can learn about how difficult it
    can be to insert code into coding workflows in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Challenges in integrating LLMs into coding workflows
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, we should look at what the challenges are with LLM-generated code and
    workflows. Here are some of them:'
  prefs: []
  type: TYPE_NORMAL
- en: Code quality and reliability, security risks, and dependency management have
    already been mentioned.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Explainability** : Understanding the logic behind LLM-generated code can
    be difficult, making debugging and maintenance challenging'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Contextual understanding** : The LLM understands a small context but not
    the whole code base or project, so its use may lead to incompatibility with the
    other code or not generate co de that’s in the same style'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Code snippet length** : LLMs may struggle to understand and process long
    code snippets, leading to incomplete or inaccurate responses'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Specialized domains** : LLMs trained on general-purpose datasets might lack
    the deep domain-specific knowledge required for certain coding tasks, such as
    medical imaging or financial modeling'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fixing complex errors** : While good at finding errors in code, LLMs usually
    don’t detect all errors and may also not identify and fix subtle or complex errors'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Performance considerations** : An LLM might not prioritize code efficiency
    or optimization, potentially generating code that is suboptimal in terms of execution
    speed or resource usage'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Algorithm selection** : Choosing the most appropriate algorithms and data
    structures for a given task can be challenging for LLMs, as they might not have
    a deep understanding of algorithmic complexity or trade-offs'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Relevant workflow example
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A common workflow involving LLM-generated code is **automated code generation
    for software development** . This involves using an LLM to generate initial code
    snippets based on user requirements or code comments, followed by human review,
    testing, and integration into the main code base.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a bit more detail on the integration process for LLM-generated code:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Code review and refinement** : The generated code undergoes a thorough review
    by human experts to ensure it aligns with coding standards, best practices, and
    project requirements. This may involve refactoring, debugging, and optimization.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Unit testing** : The integrated code undergoes rigorous unit testing to verify
    its functionality and correctness. This helps identify and address potential issues
    early in the development process.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Integration testing** : The integrated code is tested in conjunction with
    other components of the system to ensure seamless integration and compatibility.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Version control** : The integrated code is properly managed using version
    control systems (e.g., Git or SVN) to track changes, facilitate collaboration,
    and enable rollback if necessary.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Continuous integration and continuous delivery (CI/CD)** : The integrated
    code is incorporated into the CI/CD pipeline to automate testing, deployment,
    and monitoring.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Monitoring and maintenance** : The performance and behavior of the integrated
    code are closely monitored to identify and address any issues that may arise.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[ Liu_2024]'
  prefs: []
  type: TYPE_NORMAL
- en: Security risks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The preceding process didn’t mention security as a stage because security must
    be a concern throughout the process. We’ll briefly mention risks and measures
    to secure your systems, but [*Chapter 7*](B21009_07.xhtml#_idTextAnchor180) has
    much more on security.
  prefs: []
  type: TYPE_NORMAL
- en: There are various security risks; here are some that LLM-generated code may
    bring.
  prefs: []
  type: TYPE_NORMAL
- en: Risks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'While LLM-generated code offers potential benefits, it also presents several
    risks:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Code quality and** **reliability risks** :'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Incorrect or inefficient code** : LLMs may generate code that is functionally
    incorrect, inefficient, or suboptimal'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security vulnerabilities** : Generated code could introduce security vulnerabilities
    if not carefully reviewed'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lack of adherence to coding standards** : Code might not conform to established
    coding standards, leading to maintainability issues'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Operational risks** :'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dependency issues** : The generated code might introduce dependencies that
    are incompatible with the existing environment'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Integration challenges** : Integrating LLM-generated code into existing systems
    can be complex and error-prone'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Security measures
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Here are measures to secure your systems against the preceding risks:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Pre-integration security** :'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**LLM model security** : Ensure the LLM model used is secure and doesn’t expose
    sensitive data. Consider using models with robust security measures in place.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data privacy** : Protect sensitive data used to train the LLM and generate
    code. Implement data anonymization and encryption techniques.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Code vulnerability scanning** : Conduct thorough vulnerability scans on the
    generated code before integration to identify potential security risks.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Integration and** **post-integration security** :'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Code review and security audit** : Employ security experts to review the
    integrated code for vulnerabilities and compliance with security standards'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Secure coding practices** : Adhere to strict secure coding practices throughout
    the integration process'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security testing** : Conduct comprehensive security testing, including penetration
    testing, to identify and address weaknesses'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monitoring and threat detection** : Implement *continuous* monitoring and
    threat detection mechanisms to identify and respond to potential security incidents'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Specific** **security measures** :'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Input validation and sanitization** : Validate and sanitize all inputs to
    the LLM to prevent injection attacks and other vulnerabilities'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Access control** : Implement strict access controls to protect the LLM and
    the integrated code from unauthorized access'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Encryption** : Encrypt sensitive data both at rest and in transit'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Incident response plan** : Develop a comprehensive incident response plan
    to address security breaches effectively'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 7*](B21009_07.xhtml#_idTextAnchor180) has much more information on
    security, so we won’t repeat that here. [*Chapter 6*](B21009_06.xhtml#_idTextAnchor137)
    goes deep into the legal side of LLM code, so we won’t repeat that here either.'
  prefs: []
  type: TYPE_NORMAL
- en: IP concerns
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The issue of IP with respect to LLM-generated code is complex and evolving.
    Here are some potential issues:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Copyright issues** :'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Copyright infringement** : If the LLM was trained on copyrighted code, there’s
    a risk of the generated code infringing on those copyrights. This is particularly
    complex due to the nature of training data and the potential for unintentional
    copying.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ownership of generated code** : Who owns the copyright to the generated code?
    The LLM provider, the user, or a shared ownership model? This is an area with
    limited legal precedent.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Patent issues** :'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Patent infringement** : If the generated code implements a patented invention,
    it could constitute patent infringement'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Patent eligibility** : Whether or not generated code can be patented is a
    complex legal question, as it involves determining if the code represents an inventive
    step'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Trade** **secret issues** :'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Disclosure of trade secrets** : If the LLM was trained on proprietary code
    or data, there’s a risk of inadvertently disclosing trade secrets through the
    generated code'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Other concerns** :'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fair use** : The doctrine of fair use might be applicable in some cases,
    but its application to LLM-generated code is still unclear'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Licensing** : Understanding the licensing terms of the LLM and any underlying
    data is crucial to avoid IP issues'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: It’s important to note that the legal landscape in this area is rapidly changing,
    and it’s advisable to consult with legal experts to assess specific risks and
    develop appropriate strategies to mitigate them.
  prefs: []
  type: TYPE_NORMAL
- en: Again, check out [*Chapter 6*](B21009_06.xhtml#_idTextAnchor137) for much more
    on legal concerns.
  prefs: []
  type: TYPE_NORMAL
- en: Where to learn more about IP concerns of LLM-generated code
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Check out these prominent legal sites for developments in LLM-generated code,
    a.k.a. AI-generated code:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Harvard Law** **Review** : [https://harvardlawreview.org/](https://harvardlawreview.org/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stanford Law** **Review** : [https://www.stanfordlawreview.org/](https://www.stanfordlawreview.org/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Columbia Law** **Review** : [https://columbialawreview.org/](https://columbialawreview.org/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**American Intellectual Property Law Association (AIPLA)** : [https://www.aipla.org/](https://www.aipla.org/)
    ( e.g., [https://www.aipla.org/detail/event/2024/04/23/default-calendar/aipla-cle-webinar-copyright-implications-in-generative-ai](https://www.aipla.org/detail/event/2024/04/23/default-calendar/aipla-cle-webinar-copyright-implications-in-generative-ai)
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**International Trademark Association (** **INTA)** : [https://www.inta.org/](https://www.inta.org/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**European Patent Office (EPO)** : [https://www.epo.org/](https://www.epo.org/)
    ( e.g. [https://www.epo.org/en/about-us/statistics/patent-index-2023/insight-artificial-intelligence](https://www.epo.org/en/about-us/statistics/patent-index-2023/insight-artificial-intelligence)
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**United States Patent and Trademark Office (** **USPTO)** : [https://www.uspto.gov/](https://www.uspto.gov/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**World Intellectual Property Office (WIPO)** : [https://www.wipo.int/](https://www.wipo.int/)
    ( e.g., [https://www.wipo.int/export/sites/www/about-ip/en/frontier_technologies/pdf/generative-ai-factsheet.pdf](https://www.wipo.int/export/sites/www/about-ip/en/frontier_technologies/pdf/generative-ai-factsheet.pdf)
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**LexisNexis** : [https://www.lexisnexis.com/](https://www.lexisnexis.com/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Thomson** **Reuters** : [https://legal.thomsonreuters.com/en/search-results#q=LLM%20code&t=Legal&sort=relevancy](https://legal.thomsonreuters.com/en/search-results#q=LLM%20code&t=Legal&sort=relevancy)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We cannot talk about the challenges of integrating LLM-generated code into workflows
    without mentioning dependency management, the backbone of code integration.
  prefs: []
  type: TYPE_NORMAL
- en: Dependency management
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Dependency management** is the process of identifying, controlling, and managing
    the external software components (libraries, frameworks, or tools) that a software
    project relies on. These external components are called **dependencies** .'
  prefs: []
  type: TYPE_NORMAL
- en: If these dependencies are not looked after and fail to work as expected, then
    the whole application may well stop working and disrupt the lives of many or all
    of its users. These failures can be very embarrassing and bad for business. If
    you have fewer dependencies, there will be less risk and maintenance.
  prefs: []
  type: TYPE_NORMAL
- en: Importance in LLM-generated code integration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When integrating code generated by LLMs, dependency management becomes even
    more critical for several reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Unpredictable dependencies** : LLMs might introduce dependencies that were
    not anticipated, leading to compatibility issues or security risks'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Version conflicts** : Different dependencies may have conflicting version
    requirements, causing build failures or runtime errors'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security vulnerabilities** : Outdated or compromised dependencies can expose
    the entire application to security threats'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Performance impact** : Inefficient or bloated dependency trees can degrade
    application performance'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Maintainability** : Proper dependency management is essential for understanding
    and modifying the code base in the future'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The best practices for dependency management are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Dependency analysis** : Thoroughly analyze the dependencies introduced by
    the LLM-generated code to identify potential conflicts or issues'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Version control** : Use a robust version control system to track changes
    in dependencies and revert to previous versions if necessary'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dependency management tools** : Employ tools such as npm, Apache Maven, Gradle,
    or pip to manage dependencies effectively'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Regular updates** : Keep dependencies up to date with the latest versions
    to benefit from bug fixes and security patches'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dependency vulnerability scanning** : Regularly scan dependencies for known
    vulnerabilities and address them promptly'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dependency minimization** : Strive to minimize the number of dependencies
    to reduce complexity and potential issues'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By following the preceding practices, you can mitigate the risks associated
    with LLM-generated code and ensure the stability and security of your applications
    and systems [ QwietAI , Sonatype].
  prefs: []
  type: TYPE_NORMAL
- en: Hopefully, automated tools for checking and correcting these things will soon
    be developed. Maybe they will use LLMs as part of their operations
  prefs: []
  type: TYPE_NORMAL
- en: That’s all we’re going to talk about regarding dependency management. Next,
    we must cover explainability, because we want to ensure the code is understandable,
    does what we intend, and we can tell others about how it works, if need be.
  prefs: []
  type: TYPE_NORMAL
- en: Explainability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sensibly, there is a movement toward having more explainable and transparent
    code, but using LLMs for code, often black-box code, might make this more difficult
    if we do it the wrong way. These AI-generated segments might deviate from established
    coding conventions, introduce unforeseen dependencies, or make assumptions incompatible
    with the existing code base. AI code that is explainable is called **XAI** .
  prefs: []
  type: TYPE_NORMAL
- en: AI or a human, integrating code generated by a different author, who doesn’t
    know everything about how the other scripts, functions, classes, and decorators
    of the code are written can follow a different approach and make different assumptions,
    so could introduce complexities that are hard to follow. This is even worse if
    the additional code doesn’t make sense given the overall software architecture.
  prefs: []
  type: TYPE_NORMAL
- en: 'Issues when using LLM-generated code may include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Hidden assumptions and biases** : LLMs might incorporate hidden biases or
    assumptions from their training data, which can manifest in the generated code.
    These biases can be difficult to identify and can lead to unexpected behaviors
    or errors.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lack of traceability** : Understanding the origin of specific code segments
    within the LLM-generated output can be challenging. This makes it difficult to
    pinpoint the source of errors or to modify the code effectively.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dynamic behavior** : LLMs can generate code that exhibits dynamic behavior,
    making it difficult to predict how the code will function under different conditions.
    This can lead to unexpected outcomes and challenges in debugging.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Overreliance on comments** : While comments can improve code readability,
    excessive reliance on comments to explain LLM-generated code can be misleading.
    Comments might not accurately reflect the code’s actual behavior, especially if
    the code itself is complex or ambiguous.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These challenges underscore the importance of *rigorous* testing, code reviews,
    and careful integration when incorporating LLM-generated code into software systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a good source to study XAI more: [ACM_DL].'
  prefs: []
  type: TYPE_NORMAL
- en: Since we have an understanding of the challenges of integrating LLM-generated
    code into coding workflows, we can move on to thinking about the future and how
    researchers may work to ameliorate the LLM limitations.
  prefs: []
  type: TYPE_NORMAL
- en: Future research directions to address limitations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What might our human-machine civilization do to LLMs to remove and mitigate
    more of their limitations and drive technological advancements?
  prefs: []
  type: TYPE_NORMAL
- en: Let’s consider a few ideas here.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If we could enable LLMs to constantly take in new data and re-train frequently
    (e.g., every day), they would not be out of date for long and could go through
    many iterations of improvement in short time spans.
  prefs: []
  type: TYPE_NORMAL
- en: Novel architectures
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Exploring new neural network architectures and hybrid models can lead to breakthroughs
    in LLM capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: New hardware devices and coding and testing practices have always been important
    for machine learning advancement, but what really drives AI power is new neural
    network architecture.
  prefs: []
  type: TYPE_NORMAL
- en: The neural network gave us the ability to train software to make its own decisions
    and be more adaptable, rather than every scenario being programmed and hardcoded
    in.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before deep learning, neural networks were weak and couldn’t solve complex
    problems: object detection, translation, object descriptions, and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: Before LLMs, the public couldn’t query an AI in a natural language (English,
    French, Japanese, etc.) to gain knowledge quickly and get text generation, AI
    art, AI music, AI movies, and AI-generated code.
  prefs: []
  type: TYPE_NORMAL
- en: Each new generation of ML architecture gives the world new abilities.
  prefs: []
  type: TYPE_NORMAL
- en: Likely, some of the proposed new ML architectures will lead to advancements
    that the world can greatly benefit from.
  prefs: []
  type: TYPE_NORMAL
- en: Computational efficiency
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Optimizing model size and computational requirements can make LLMs more accessible
    and scalable.
  prefs: []
  type: TYPE_NORMAL
- en: To approximate anything like human thinking and understand the context of a
    query or topic, LLMs take many billions of parameters (neural network training
    weights); the latest LLM from Meta, Llama 3.1, has a version with 405 billion
    parameters. GPT-4o has over 200 billion parameters. These models have enormous
    memory requirements (800 GB for Llama 3.1 400B), so average people cannot use
    these most powerful models. They use far too much money, space, energy, and time
    to order the hardware. The human brain, indeed the brain of any animal, is vastly
    more efficient when using energy and space, if not memory, directly. If we can
    make LLMs more efficient in these dimensions, then we can greatly democratize
    LLMs for the people. That would speed up technological development and help people
    not working for huge tech companies to have enough income to afford to live.
  prefs: []
  type: TYPE_NORMAL
- en: Ways to reduce the burden include using flash attention, lower precision, and
    the aforementioned architectural innovations [HuggingFace_Optimizing, Snowflake].
    Flash attention is an attention algorithm that is more memory-efficient and also
    uses GPU memory in a better way.
  prefs: []
  type: TYPE_NORMAL
- en: 'Quantization or lower precision involves using less precise numbers; so, instead
    of using 16-bit numbers, the model can be stored in 8-bit numbers. 8-bit numbers
    are 2 8 = 256 digits in a number (such as RGB values in a picture: 0 to 255) and
    16-bit is 2^16, which is 65,536 different values in a number. So, if you’re storing
    the model with only 8-bit precision, you’ll save a lot of computation, time, and
    energy, but the model will be less precise. This is why there are Llama 8b and
    Llama 70b models; they are smaller and can run on more average computer hardware.'
  prefs: []
  type: TYPE_NORMAL
- en: Pruning can also reduce model size and inference time without significant performance
    degradation.
  prefs: []
  type: TYPE_NORMAL
- en: More specialized architectures, such as rotary embeddings, Alibi, Grouped-Query
    Attention, and Multi-Query Attention, can improve LLM efficiencies. You can learn
    more about those from [HuggingFace_Optimizing]. This is beyond the scope of this
    chapter; Hugging Face has more information on architectures.
  prefs: []
  type: TYPE_NORMAL
- en: With LLMs, inference is when you give the LLM a prompt and get a response [Gemini,
    Symbli].
  prefs: []
  type: TYPE_NORMAL
- en: If LLMs could be more efficient with energy usage, they wouldn’t take as much
    money to train, thus democratizing LLM training. There is work to make lighter
    LLMs that can be used on smaller and more mobile devices, so this issue is known.
  prefs: []
  type: TYPE_NORMAL
- en: More efficient LLMs could be able to understand the contexts of the scripts,
    classes, functions, and decorators better.
  prefs: []
  type: TYPE_NORMAL
- en: If code operated more quickly, then vulnerabilities could be found more quickly.
  prefs: []
  type: TYPE_NORMAL
- en: Efficiency and better contextual awareness could also help with dependency understanding.
  prefs: []
  type: TYPE_NORMAL
- en: Specialized training
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you want an LLM with a great ability to give deep insights into the code
    needed for a specific problem or application, it’ll perform better with specific
    training on those problems and solutions. This is because it’ll be more familiar
    with that field of work and its best practices.
  prefs: []
  type: TYPE_NORMAL
- en: Hopefully, training LLMs will become more efficient and therefore cheaper and
    easier.
  prefs: []
  type: TYPE_NORMAL
- en: More security training may benefit the LLM and its users. This can be done with
    security datasets; datasets specifically designed to teach about vulnerabilities
    and best practices.
  prefs: []
  type: TYPE_NORMAL
- en: The LLM might be able to be trained with dependencies, the code libraries and
    versions that are needed, and the target hardware and use.
  prefs: []
  type: TYPE_NORMAL
- en: That’s all for continuous learning, new architectures, efficiencies, and specialized
    training; now, it’s time for a chapter summary.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We thought and learned about the limitations of LLMs in this chapter, including
    the lack of understanding, lack of context, high computational requirements, dependency
    on their training data, and security risks. We’ve also touched on some metrics
    for judging LLM performance.
  prefs: []
  type: TYPE_NORMAL
- en: We tried to overcome these limitations and looked at a few promising alleys
    for how to create greater LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter also covered IP concerns, how LLMs need to be explainable, and
    where to learn more about these issues.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn about collaboration and knowledge sharing
    in LLM-powered coding because this is how you make real changes to the world,
    help people, and get your name known more.
  prefs: []
  type: TYPE_NORMAL
- en: Bibliography
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*ACM_DL* : “Investigating Explainability of Generative AI for Code through
    Scenario-based Design,” Jiao Sun, Q. Vera Liao, Michael Muller, Mayank Agarwal,
    Stephanie Houde, Karthik Talamadulupa, and Justin D. Weisz, [https://dl.acm.org/doi/fullHtml/10.1145/3490099.3511119](https://dl.acm.org/doi/fullHtml/10.1145/3490099.3511119)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*CodeBLEU* : “CodeBLEU: a Method for Automatic Evaluation of Code Synthesis,”
    Shuo Ren, Daya Guo, Shuai Lu, Long Zhou, Shujie Liu, Duyu Tang, Neel Sundaresan,
    Ming Zhou, Ambrosio Blanco, and Shuai Ma, [https://arxiv.org/abs/2009.10297](https://arxiv.org/abs/2009.10297)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*confident_ai* : “LLM Evaluation Metrics: The Ultimate LLM Evaluation Guide,”
    Jeffrey Ip, [https://www.confident-ai.com/blog/llm-evaluation-metrics-everything-you-need-for-llm-evaluation](https://www.confident-ai.com/blog/llm-evaluation-metrics-everything-you-need-for-llm-evaluation)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Gemini: Gemini,* *Alphabet* : https://gemini.google.com/'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**HuggingFace_Optimizing** : “Optimizing your LLM in production,” Patrick von
    Platen, https://huggingface.co/blog/optimize-llm'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Liu_2024* : “Large Language Models for Networking: Workflow, Advances and
    Challenges,” Chang Liu, Xiaohui Xie, Xinggong Zhang, and Yong Cui, [https://arxiv.org/html/2404.12901v1](https://arxiv.org/html/2404.12901v1)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Mercier* : “The Enigma of Reason,” Hugo Mercier and Dan Sperber, https://www.hup.harvard.edu/books/9780674237827'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Prompt_Drive* : “What Are the Limitations of Large Language Models (LLMs)?”
    Jay, [https://promptdrive.ai/llm-limitations/](https://promptdrive.ai/llm-limitations/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*QwietAI* : “AppSec 101 – Dependency Management,” QweitAI, https://qwiet.ai/appsec-101-dependency-management/#:~:text=Dependency%20Management%20Tools,-The%20software%20development&text=These%20tools%20are%20the%20backbone,ensure%20compatibility%20across%20the%20board
    .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Snowflake* : “Achieve Low-Latency and High-Throughput Inference with Meta’s
    Llama 3.1 405B using Snowflake’s Optimized AI Stack,” Aurick Qiao, Reza Yazdani,
    Hao Zhang, Jeff Rasley, Flex Wang, Gabriele Oliaro, Yuxiong He, and Samyam Rajbhandari,
    [https://www.snowflake.com/engineering-blog/optimize-llms-with-llama-snowflake-ai-stack](https://www.snowflake.com/engineering-blog/optimize-llms-with-llama-snowflake-ai-stack)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Sonatype* : “What are Software Dependencies?” Sonatype, https://www.sonatype.com/resources/articles/what-are-software-dependencies'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Stevens* : “What is Semantic Similarity: An Explanation in the Context of
    Retrieval Augmented Generation (RAG),” Ingrid Stevens, [https://ai.gopubby.com/what-is-semantic-similarity-an-explanation-in-the-context-of-retrieval-augmented-generation-rag-78d9f293a93b](https://ai.gopubby.com/what-is-semantic-similarity-an-explanation-in-the-context-of-retrieval-augmented-generation-rag-78d9f293a93b)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Symbli* : “A Guide to LLM Inference Performance Monitoring,” Kartik Talamadupula'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: https://symbl.ai/developers/blog/a-guide-to-llm-inference-performance-monitoring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Wiki_Agent* : “Intelligent Agent,” Wikipedia, https://en.wikipedia.org/wiki/Intelligent_agent'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
