<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Hidden Markov Models</h1>
                </header>
            
            <article>
                
<p class="mce-root">In the previous chapter, we discussed Markov chains, which are helpful in modelling a sequence of observations across time. In this chapter, we are going to study the <strong>Hidden Markov Model</strong> (<strong>HMM</strong>), which is also used to model sequential data but is much more flexible than Markov chains.</p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li class="h1">Markov models</li>
<li><span>The HMM</span></li>
<li><span>Evaluation of an HMM</span></li>
<li><span>Extensions of HMM</span></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Markov models</h1>
                </header>
            
            <article>
                
<p>The Markov model is a stochastic model in which the state of the random variable at the next instance of time depends only on the outcome of the random variable at the current time. The simplest kind of Markov model is a Markov chain, which we discussed in <a href="c8b01245-1f2b-4b5e-837f-bdcc1d87343e.xhtml" target="_blank">Chapter 1</a>, <em>Introduction to Markov Process</em>. </p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root CDPAlignLeft CDPAlign"><span>Suppose we have a set of sequential observations (<em>x<sub>1</sub>,. . ., x<sub>n</sub>)</em></span><span><span> obeying the Markov property, then we can state the joint probability distribution for</span><span> <em>N </em></span><span>observations as the following:</span></span></p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/5c66bf6e-6ea7-484b-994a-be9b41ebd265.png" style="width:22.67em;height:4.00em;"/></div>
<div>
<div class="CDPAlignCenter CDPAlign"><img src="assets/6f36b56b-0134-419b-b19c-8b86f17fb3fe.png" style="color: #333333;font-size: 1em;border: 1em solid black;text-align: center;width:36.67em;height:3.67em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Graphical representation of a first-order Markov chain in which the distribution of the current observation is conditioned on the value of the previous observation</div>
<p class="mce-root"><span>The preceding representation of the Markov chain is different from the representations we saw earlier. In this representation, the observations are presented as nodes and the edges represent conditional probability between two observations, namely <em>Pr(x<sub>n</sub>|x<sub>n-1</sub>)</em></span><span>. This is how probabilistic graphical models are generally represented, where nodes represent random variables and edges represent a conditional probability distribution between these two variables. This graphical representation gives us insight into the causal relationships between random variables. </span></p>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">State space models</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span>We can see that a simple Markov chain is very restrictive and does not work well for situations where we anticipate that several successive observations will provide important information required to predict the next observation. Fortunately, a Markov chain can be tweaked to support these cases as well:</span></p>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/7034d32a-d9eb-416a-93ee-7b3c690948ce.png" style="width:34.08em;height:6.08em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Second-order Markov chain in which the distribution of the current observation is conditioned on the values of the last two observations</div>
<p>Let's consider a Markov chain where the probability of the next state not only depends on the current state but also on the last state. This type of Markov chain is called a <strong>second-order Markov chain</strong> and the joint probability distribution can be represented as follows:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/f3e9a95b-56cb-46be-8cd9-eee411ac53a3.png" style="width:27.08em;height:3.50em;"/></div>
<div>
<p class="p1">Using the d-separation property, we see that the conditional distribution of <em>X<sub>n</sub></em><span class="s1"> </span>given <em>X<sub>n-1</sub></em><span class="s2"> </span>and <em>X<sub>n-2</sub></em><span class="s2"> </span>is independent of all observations, <em>X<sub>1</sub>, . . ., X<sub>n-3</sub></em>.</p>
<p class="p1">Similarly, we can extend this to an <em>M<sup>th</sup></em><span class="s1">-</span>order Markov chain in which the conditional distribution for a particular observation depends on the previous <em>M</em> observations. However, we are now paying the price of a large number of parameters for increased flexibility.</p>
<p class="p1">Suppose that the observations are discrete variables having <em>K</em> states. Then the conditional distribution, <em>Pr(X<sub>n</sub>|X<sub>n-1</sub>)</em>,<em> </em>in a first-order Markov chain will be specified by a set of <em>K-1</em> parameters for each of the <em>K</em> states of <em>X<sub>n-1</sub></em>, giving a total of <em>K(K-1)</em> parameters. If we extend this to an <em>M<sup>th</sup></em>-order Markov chain, where joint distribution is built up from conditionals, <em>Pr(x<sub>n</sub>|x<sub>n-M</sub>, . . ., x<sub>n-1</sub>)</em>, the number of parameters in such a model would have <em>K<sup>M-1</sup>(K-1)</em>. Because this grows exponentially with <em>M</em>, it will often render this approach impractical for larger values of <em>M</em>. <span>But, what if we want to build a model for sequential data that is not bounded by any order of Markov assumption, and yet it can be represented by a limited number of parameters?</span></p>
</div>
<div>
<p>Such models can be created by introducing latent (or hidden) variables. Latent variables allow us to create a rich class of models constructed out of simple components. Let's assume that for each observation, <em>x<sub>n</sub></em>, we have a latent variable, <em>z<sub>n </sub></em>(which may or may not have the same dimensionality as the observed variable). If these latent variables form a first-order Markov chain, this type of model can be called a <strong>state space model</strong>, which is represented in the following diagram:</p>
</div>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-487 image-border" src="assets/ab40bbf5-fbfa-40e5-b890-c60f1245c51f.png" style="width:26.92em;height:9.25em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">State space model representing a distribution, where each observation is conditioned upon a latent variable</div>
<p>Using the d-separation property, we can see that there is always a path between any two observed variables, <em>x<sub>n</sub></em> and <em>x<sub>m</sub></em>, via latent variables and this path can never be blocked. So the <em>Pr(x<sub>n+1</sub>|x<sub>1</sub>, . . ., x<sub>n</sub>)</em> distribution for observation <em>x<sub>n+1</sub></em> given all previous observations does not exhibit any conditional independence properties, and thus the prediction for <em>x<sub>n+1</sub></em> depends on all previous observations.</p>
<p>As the latent variables form a Markov chain, they satisfy the following conditional distribution:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/081d9b87-ab89-4b8c-95c1-9640bdf73bc2.png" style="width:10.25em;height:1.83em;"/></div>
<p class="CDPAlignLeft CDPAlign">Thus, the joint distribution of this model can be stated as follows:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/2e6929df-c3e3-46b5-a85f-47bbd6b4565d.png" style="width:34.17em;height:3.58em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The HMM</h1>
                </header>
            
            <article>
                
<p>An HMM is a specific case of state space model in which the latent variables are discrete and multinomial variables. From the graphical representation, we can also consider an HMM to be a double stochastic process consisting of a hidden stochastic Markov process (of latent variables) that we cannot observe directly, and another stochastic process that produces a sequence of the observation given the first process.</p>
<p>Before moving on to the parameterization, let's consider an example of coin-tossing to get an idea of how it works. Assume that we have two unfair<em> </em>coins, <em>M<sub>1</sub></em> and <em>M<sub>2</sub></em>, with <em>M<sub>1</sub></em> having a higher probability (70%) of getting heads and <em>M<sub>2</sub></em> having a higher probability (80%) of getting tails. Someone sequentially flips these two coins, however, we do not know which one. We can only observe the outcome, which can either be heads (<em>H</em>) or tails (<em>T</em>):</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/ce6640f8-df25-4556-8bb7-6022359b457b.png" style="width:14.00em;height:1.25em;"/></div>
<p class="mce-root">We can consider the unfair coin selected to be the latent variable, and the outcome of the coin toss to be the observed data. To predict the next outcome sequence of observation, we would at least require information such as which coin was selected at first, the next coin to flip given the previous one, and the probability of getting <em>H</em> or <em>T</em> given the coin. Assuming that both of the coins have equal priority of getting selected at first and each coin is equally likely to get selected given the previous coin selected, we can create the following state diagram:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-489 image-border" src="assets/09da993d-b970-4820-ab7b-79f5e77e25f1.png" style="width:19.50em;height:16.17em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">State diagram for coin toss HMM</div>
<p><span>In the previous diagram, <strong>z<sub>1</sub></strong> </span><span>and <strong>z<sub>2</sub></strong></span><span> represent states of the latent variable </span>coin selected <em>(</em><strong>z<sub>1</sub></strong><em> </em>representing coin <strong>M<sub>1</sub></strong> getting selected, and<span> <strong>z<sub>2</sub></strong></span><span> </span>representing coin <strong>M<sub>2</sub></strong><em><sub> </sub></em>being selected). T<span>he arcs represent transition probabilities of moving from one state of latent variable to the other and the straight lines represent the probabilities of the observed variable (toss outcome) given the latent variable (coin selected).</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Parameterization of HMM</h1>
                </header>
            
            <article>
                
<p>In the previous section, we saw an example of an HMM to get an idea of how the model works. Let's now formally parameterize an HMM.</p>
<p>As the latent variables of an HMM are discrete multinomial variables, we can use the 1-of-K encoding scheme to represent it, where the <em>z<sub>n</sub></em> variable is represented by a K-dimensional vector of binary variables, <em>z<sub>nk</sub> ∈ {0,1}</em>, such that <em>z<sub>nk</sub> = 1</em> and <em>z<sub>nj</sub> = 0</em> for <em>j ≠ k</em> if the <em>z<sub>n</sub></em> variable is in the <em>k</em> state.</p>
<p>With this in mind, we can create a matrix with the transition probability matrix <em>A</em>, where <em>A<sub>ij</sub></em> = <em>Pr(Z<sub>nj </sub>= 1| z<sub>n-1</sub>, i = 1)</em>. As the <em>A<sub>ij</sub></em> represent <span>the probability of moving from state <em>i</em></span><span> to state <em>j</em></span>, it holds the property of <img class="fm-editor-equation" src="assets/4ad55b94-7a14-470d-8994-feb70fc80bcb.png" style="width:2.50em;height:1.67em;"/> and can be expressed using the <em>K(K-1)</em> parameters<span>.</span> Thus we can represent the conditional probability distribution as follows:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/3e8acc3f-3118-4382-8647-1bc598a13328.png" style="width:18.33em;height:4.08em;"/></div>
<p>The transition matrix is generally represented using a state-transition diagram, as we saw in <a href="https://cdp.packtpub.com/hands_on_markov_models_with_python/wp-admin/post.php?post=25&amp;action=edit#post_24" target="_blank">Chapter 1</a><span>, </span><em>Introduction to Markov Process</em>. But we can take the same representation and unfold it across time to get a <em>lattice</em> or <em>trellis</em> diagram, as presented in the following image. We will be using this representation of HMM in the following sections for learning parameters and making inferences from the model:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/36f8e635-07bc-4c8a-8b27-b0cee3c2a0a3.png" style="width:41.33em;height:15.75em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Trellis diagram for an HMM with latent variables with three states</div>
<p class="p1">As the initial latent node, <em>z<sub>1</sub></em>, does not have a parent node, it has a marginal distribution, <em>Pr(z<sub>1</sub>)</em>, which can be represented by a vector of probabilities, <em>π</em>, such that <em>π<sub>k</sub> = Pr(z<sub>1k</sub> = 1)</em> with <img class="fm-editor-equation" src="assets/afb5fed2-f1d9-48ac-9595-db3ef99d4465.png" style="width:3.50em;height:2.42em;"/>. Thus, the probability of <em>Pr(z<sub>1</sub>|π</em>) can be expressed as follows:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/28e79bdb-aea8-45be-9822-d4ca7b68eb50.png" style="width:9.92em;height:3.83em;"/></div>
<div>
<p class="mce-root">The third and final parameter required to parameterize an HMM is the conditional probability of the observed variable given the latent variable, namely the emission probability. It is represented by the conditional distribution, <em>Pr(x<span><sub>n</sub>| z<sub>n</sub>, Φ</span>)</em>, which is governed by some parameters, <em>Φ</em>. I<span>f the observed variable, <em>x<sub>n</sub></em>, is discrete, the emission probability may take the form of a conditional probability table (multinomial HMM). Similarly, i</span><span>f the observed variable, <em>x<sub>n</sub></em>, is continuous, then this distribution might be a Gaussian distribution (Gaussian HMM) where <img class="fm-editor-equation" src="assets/e188d3e6-22f0-4a60-abad-ca3b1d67a157.png" style="width:4.50em;height:1.17em;"/> denotes the set of parameters governing the distribution, namely the mean and variance. </span></p>
<p><span>Thus, the joint probability distribution over both the latent and observed variables can be stated as follows:</span></p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/f28a70f1-1d0d-49c6-872b-48f4785f4fd3.png" style="width:29.58em;height:3.75em;"/></div>
<p>Here, <em>X = {x<sub>1</sub>, ..., x<sub>N</sub>}</em>, <em>Z<span> = {z<sub>1</sub>, ..., z<sub>N</sub>}</span></em> and <em>θ = {A, π, Φ}</em> denotes the set of parameters governing the model.</p>
</div>
<div class="packt_infobox">An HMM model is called a <strong>homogenous model</strong> when all the conditional distributions governing the latent variables share the same transition matrix, <em>A</em>, and all the emission probabilities share the same parameters, <em>Φ</em>. </div>
<p>Now, let's try to code a simple multinomial HMM. We will start by defining a simple <kbd>MultinomialHMM</kbd> class and keep on adding methods as we move forward:</p>
<pre><span>import numpy as np<br/><br/>class </span>MultinomialHMM:<br/> <span>def </span><span>__init__</span>(<span>self</span><span>, </span>num_states<span>, </span>observation_states<span>, </span>prior_probabilities<span>,<br/></span><span> </span>transition_matrix<span>, </span>emission_probabilities):<br/> <span>"""<br/></span><span> Initialize Hidden Markov Model<br/></span><span><br/></span><span> Parameters<br/></span><span> -----------<br/></span><span> num_states: int<br/></span><span> Number of states of latent variable<br/></span><span> observation_states: 1-D array<br/></span><span> An array representing the set of all observations<br/></span><span> prior_probabilities: 1-D array<br/></span><span> An array representing the prior probabilities of all the states<br/></span><span> of latent variable</span><span><br/></span><span>        transition_matrix: 2-D array<br/></span><span>            A matrix representing the transition probabilities of change of<br/></span><span>            state of latent variable<br/></span><span>        emission_probabilities: 2-D array<br/></span><span>            A matrix representing the probability of a given observation<br/></span><span>            given the state of the latent variable<br/></span><span>        """<br/>        # As latent variables form a Markov chain, we can use<br/>        # use the previous defined MarkovChain class to create it<br/></span><span>        </span><span>self</span>.latent_variable_markov_chain = MarkovChain(<br/>            <span>transition_matrix</span>=transition_matrix<span>,<br/></span><span>            </span><span>states</span>=[<span>'z{index}'</span>.format(<span>index</span>=index) <span>for </span>index <span>in </span><span>range</span>(num_states)]<span>,<br/></span><span>        </span>)<br/>        <span>self</span>.observation_states = observation_states<br/>        <span>self</span>.prior_probabilities = np.atleast_1d(prior_probabilities)<br/>        <span>self</span>.transition_matrix = np.atleast_2d(transition_matrix)<br/>        <span>self</span>.emission_probabilities = np.atleast_2d(emission_probabilities)</pre>
<p>Using the <kbd>MultinomialHMM</kbd> class, we can define the HMM coin that we discussed previously as follows:</p>
<pre>coin_hmm = MultinomialHMM(<span>num_states</span>=<span>2</span><span>,<br/></span><span>                          </span><span>observation_states</span>=[<span>'H'</span><span>, </span><span>'T'</span>]<span>,<br/></span><span>                          </span><span>prior_probabilities</span>=[<span>0.5</span><span>, </span><span>0.5</span>]<span>,<br/></span><span>                          </span><span>transition_matrix</span>=[[<span>0.5</span><span>, </span><span>0.5</span>]<span>, </span>[<span>0.5</span><span>, </span><span>0.5</span>]]<span>,<br/></span><span>                          </span><span>emission_probabilities</span>=[[<span>0.8</span><span>, </span><span>0.2</span>]<span>, </span>[<span>0.3</span><span>, </span><span>0.7</span>]])</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Generating an observation sequence</h1>
                </header>
            
            <article>
                
<p>For a given HMM parameterized by <em>{A,<span> </span>π,<span> </span>Φ}</em>, we can generate a sequence of observations, <em>{x<sub>1</sub>, ..., x<sub>N</sub>}</em>, using the following steps:</p>
<ol>
<li>Set <em>n = 1</em></li>
<li>Choose an initial state of the latent variable, <em>z<sub>1</sub></em>, according to the prior distribution, <em>π</em></li>
<li>Choose an observation, <em>x<sub>1</sub></em>, for the given value of <em>z<sub>1</sub></em>, by sampling the emission-probability distribution governed by <em>Φ</em></li>
<li>Transit to the next state of the latent variable, <em>z<sub>n+1</sub></em>, according to the state-transition probability matrix, <em>A</em></li>
<li>Set <em>n = n + 1 </em>and repeat step 3 if <em>n ≤ N</em>, otherwise terminate</li>
</ol>
<p>We can add a method to generate samples in the previously defined <kbd>MultinomialHMM</kbd> class, as follows:</p>
<pre><span>def </span><span>observation_from_state</span>(<span>self</span><span>, </span>state):<br/>    <span>"""<br/></span><span>    Generate observation for a given state in accordance with<br/></span><span>    the emission probabilities<br/></span><span><br/></span><span>    Parameters<br/></span><span>    ----------<br/></span><span>    state: int<br/></span><span>        Index of the current state<br/></span><span>    """<br/></span><span>    </span>state_index = <span>self</span>.latent_variable_markov_chain.index_dict[state]<br/>    <span>return </span>np.random.choice(<span>self</span>.observation_states<span>,<br/></span><span>                            </span><span>p</span>=<span>self</span>.emission_probabilities[state_index<span>, </span>:])<br/><br/><span>def </span><span>generate_samples</span>(<span>self</span><span>, </span>no=<span>10</span>):<br/>    <span>"""<br/></span><span>    Generate samples from the hidden Markov model<br/></span><span><br/></span><span>    Parameters<br/></span><span>    ----------<br/></span><span>    no: int<br/></span><span>        Number of samples to be drawn<br/></span><span><br/></span><span>    Returns<br/></span><span>    -------<br/></span><span>    observations: 1-D array<br/></span><span>        An array of sequence of observations<br/></span><span><br/></span><span>    state_sequence: 1-D array<br/></span><span>        An array of sequence of states<br/></span><span>    """<br/></span><span>    </span>observations = []<br/>    state_sequence = []<br/><br/>    initial_state = np.random.choice(<span>self</span>.latent_variable_markov_chain.states<span>,<br/></span><span>                                     </span><span>p</span>=<span>self</span>.prior_probabilities)<br/><br/>    state_sequence.append(initial_state)<br/>    observations.append(<span>self</span>.observation_from_state(initial_state))<br/><br/>    current_state = initial_state<br/>    <span>for </span>i <span>in </span><span>range</span>(<span>2</span><span>, </span>no):<br/>        next_state = <span>self</span>.latent_variable_markov_chain.next_state(current_state)<br/>        state_sequence.append(next_state)<br/>        observations.append(<span>self</span>.observation_from_state(next_state))<br/>        current_state = next_state<br/><br/>    <span>return </span>observations<span>, </span>state_sequence</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>We can use the <kbd>generate_samples</kbd> method on our HMM coin example to generate an observation sequence:</p>
<pre>&gt;&gt;&gt; coin_hmm.generate_samples()<br/>(['T', 'H', 'H', 'T', 'T', 'H', 'H', 'H', 'H'], ['z1', 'z0', 'z0', 'z1', 'z1', 'z0', 'z1', 'z1', 'z1'])</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Installing Python packages</h1>
                </header>
            
            <article>
                
<p><span>HMM can also have a Gaussian distribution for the emission probability. Just like <kbd>MultinomialHMM</kbd>, we can also sample from <kbd>GaussianHMM</kbd>. In the next code example, we use the <kbd>GaussianHMM</kbd> class provided in the </span><kbd>hmmlearn</kbd><span> library to see how the samples are generated from this type of model:</span></p>
<pre>source activate hmm<br/>conda install scikit-learn<br/>pip install hmmlearn</pre>
<p>Once the Python packages are installed, we can use the following code to generate samples from <kbd>Gaussian HMM</kbd>:</p>
<pre><span>from </span>hmmlearn.hmm <span>import </span>GaussianHMM<br/><span>import </span>numpy <span>as </span>np<br/><span>import </span>matplotlib.pyplot <span>as </span>plt<br/><br/></pre>
<pre><span class="n">startprob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">])</span>
<span class="c1"># The transition matrix, note that there are no transitions possible</span>
<span class="c1"># between component 1 and 3</span>
<span class="n">transmat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
                     <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
                     <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
                     <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">]])</span>
<span class="c1"># The means of each component</span>
<span class="n">means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.0</span><span class="p">,</span>  <span class="mf">0.0</span><span class="p">],</span>
                  <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">11.0</span><span class="p">],</span>
                  <span class="p">[</span><span class="mf">9.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">],</span>
                  <span class="p">[</span><span class="mf">11.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">]])</span>
<span class="c1"># The covariance of each component</span>
<span class="n">covars</span> <span class="o">=</span> <span class="o">.</span><span class="mi">5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="c1"># Build an HMM instance and set parameters</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">hmm</span><span class="o">.</span><span class="n">GaussianHMM</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">covariance_type</span><span class="o">=</span><span class="s2">"full"</span><span class="p">)</span>

<span class="c1"># Instead of fitting it from the data, we directly set the estimated</span>
<span class="c1"># parameters, the means and covariance of the components</span>
<span class="n">model</span><span class="o">.</span><span class="n">startprob_</span> <span class="o">=</span> <span class="n">startprob</span>
<span class="n">model</span><span class="o">.</span><span class="n">transmat_</span> <span class="o">=</span> <span class="n">transmat</span>
<span class="n">model</span><span class="o">.</span><span class="n">means_</span> <span class="o">=</span> <span class="n">means</span>
<span class="n">model</span><span class="o">.</span><span class="n">covars_</span> <span class="o">=</span> <span class="n">covars<br/><br/></span>X<span>, </span>state_sequence = model.sample(<span>n_samples</span>=<span>100</span>)<br/><br/>plt.plot(X[:<span>, </span><span>0</span>]<span>, </span>X[:<span>, </span><span>1</span>]<span>, </span><span>".-"</span><span>, </span><span>label</span>=<span>"observations"</span><span>, </span><span>ms</span>=<span>6</span><span>,<br/></span><span>         </span><span>mfc</span>=<span>"orange"</span><span>, </span><span>alpha</span>=<span>0.7</span>)<br/><span>for </span>i<span>, </span>m <span>in </span><span>enumerate</span>(means):<br/>    plt.text(m[<span>0</span>]<span>, </span>m[<span>1</span>]<span>, </span><span>'Component %i' </span>% (i + <span>1</span>)<span>,<br/></span><span>             </span><span>size</span>=<span>12</span><span>, </span><span>horizontalalignment</span>=<span>'center'</span><span>,<br/></span><span>             </span><span>bbox</span>=<span>dict</span>(<span>alpha</span>=<span>.7</span><span>, </span><span>facecolor</span>=<span>'w'</span>))<br/>plt.legend(<span>loc</span>=<span>'best'</span>)<br/>plt.show()</pre>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-488 image-border" src="assets/fded911f-78d0-4b3b-a756-2c15392d329b.png" style="width:32.75em;height:24.58em;"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref"><span>Sampling from an HMM with a four-state latent variable, z, and a</span> <span>Gaussian emission model, p(x|z)</span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Evaluation of an HMM</h1>
                </header>
            
            <article>
                
<p>In the previous section, we discussed generating an observation sequence of a given HMM. But, in reality, most of the time we are not interested in generating the observation sequence, mostly because we don't know the parameters of the HMM to generate observations in the first place.</p>
<p class="mce-root"/>
<p>For a given HMM representation, in most of the applications, we are always trying to address the following three problems:</p>
<ul>
<li><strong>Evaluation of the model</strong>: Given the parameters of the model and the observation sequence, estimating the probability of the sequence</li>
<li><strong>Predicting the optimal sequence</strong><span><span>: Given the parameters of the model and the observation sequence, estimating the most probable sequence of the state sequence that had produced these observations</span></span></li>
<li><strong>Parameter-learning</strong><span>: Given a sequence of observations, estimating the parameters of the HMM model that generated it</span></li>
</ul>
<p>In this section, we'll discuss the first problem, the evaluation of the model, and in the following chapters, we will discuss the other two problems in detail. As we will see in the later chapters, evaluating the model forms the basis for solving the other two problems. Thus, solving this problem efficiently is the first stepping stone toward parameter-learning and inference.</p>
<p>Let's formally describe the problem of model evaluation. Given an HMM parameterized by <em>θ = {A, π, Φ}</em> and an observation sequence, <em>X = {x<sub>1</sub>, ..., x<sub>N</sub>}</em>, we need to compute the probability of <em>Pr(X|θ)</em>. From our discussions in the previous section, we can say that we can compute <em>Pr(X|θ)</em> by marginalizing the joint-probability distribution <em>Pr(X, Z|θ)</em>, where <em>Z = {z<sub>1</sub>, ..., z<sub>N</sub>}</em>, with respect to <em>Z:</em></p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/bf84a382-52f0-44a7-8f9b-dbfbf4dfc8fe.png" style="width:11.83em;height:2.42em;"/></div>
<p>In the previous section, we saw that the following is true:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/f3c9df46-6db1-4419-87a4-27c7d9cf0d74.png" style="width:35.08em;height:5.42em;"/></div>
<p class="mce-root">Thus the <em>Pr(X, Z|θ)</em> probability can be stated as follows:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/14fcbdbb-0a0a-4a54-a16a-4ae0eafe7249.png" style="width:34.83em;height:2.67em;"/></div>
<p>For a model with <em>K</em> states and an observation length of <em>N</em>, there are <em>K<sup>T</sup></em> possible state sequences. Each term in the summation requires <em>2N</em> operations. As a result, the evaluation becomes a mathematical operation of the order of <em>2N X K<sup>T</sup></em>. For example, if we consider a model with five states, <em>K = 5</em>, and an observation sequence of length <em>N = 100</em>, the number of required operations is of the order of 10<sup>72</sup>, which makes this method of evaluation intractable even for a very small HMM.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Extensions of HMM</h1>
                </header>
            
            <article>
                
<p>In the previous sections, we discussed HMM, sampling from it and evaluating the probability of a given sequence given its parameters. In this section, we are going to discuss some of its variations.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Factorial HMMs</h1>
                </header>
            
            <article>
                
<p>Let's consider the problem of modelling of several objects in a sequence of images. If there are <em>M</em> objects with <em>K</em> different positions and orientations in the image, there are be <em>K<sup>M</sup></em> possible states for the system underlying an image. An HMM would require <em>K<sup>M</sup></em> distinct states to model the system. This way of representing the system is not only inefficient but also difficult to interpret. We would prefer that our HMM could capture the state space by using <em>M</em> different <em>K</em>-dimensional variables.</p>
<p>A factorial HMM is such a representation. In this model, there are multiple independent Markov chains of latent variables and the distribution of the observed variable at any given time is conditional on the states of all the corresponding latent variables in that given time. The graphical model of the system can be represented as follows:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-490 image-border" src="assets/855f8b95-963e-4e71-89ff-1554067981f6.png" style="width:18.92em;height:13.08em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">A factorial HMM comprising two Markov chains</div>
<p class="p1">The motivation for considering factorial HMM can be seen by noting that in order to represent, say, 10 bits of information at a given time step, a standard HMM would need <em>K = 2<sup>10</sup> = 1024</em> latent states, whereas a factorial HMM could make use of 10 binary latent chains. However, this presents additional complexity in training, as we will see in the later chapters.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Tree-structured HMM</h1>
                </header>
            
            <article>
                
<p>In the previous section, we discussed factorial HMM, in which the latent variables formed independent Markov chains. This independence assumption about the latent variables can be relaxed by introducing some coupling between them. One way to couple latent variables is to order them such that <img class="fm-editor-equation" src="assets/5deeb537-39a8-40d7-b5e3-a2170aae1970.png" style="width:2.17em;height:1.75em;"/> depends on <img class="fm-editor-equation" src="assets/22d1629a-e9a1-4f2a-a8cd-32fadc0b78e5.png" style="width:1.58em;height:1.75em;"/> for all <em>1 ≤ l ≤ m</em>. Furthermore, if all the output variables and the latent variables depend on some random input variable, <em>x<sub>n</sub></em>, we obtain a tree-structured HMM represented as follows:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-491 image-border" src="assets/8702cf40-118a-4e62-9291-5358b5805598.png" style="width:26.17em;height:21.50em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Graphical representation of a tree-structured HMM</div>
<p>The architecture of this model can be interpreted as a probabilistic decision tree. Let's considered at first-time slice <em>n=1</em>, and try to understand how this model would generate data. Based on the value of <em>x<sub>1</sub></em>, the top node, <img class="fm-editor-equation" src="assets/e7a75457-434e-4c4a-b294-da1e2f2c5b9c.png" style="width:1.42em;height:1.50em;"/>, can take <em>K</em> values (assuming that the hidden variables have <em>K</em> states). This partitions the <em>x</em> space into <em>K</em> decision groups. The next node, <img class="fm-editor-equation" src="assets/3c6d4a75-fd66-406f-a0fe-b874f461124b.png" style="width:2.08em;height:2.17em;"/>, further partitions into <em>K</em> subregions, and so on. The output, <em>y<sub>1</sub></em>, is generated from the input, <em>x<sub>1</sub></em>, and K-way decisions at each node. At the next time slice, the same thing is going to happen, expect that each decision in the tree depends on the decision taken at that node in the previous time slice. Therefore, this model can be interpreted as a probabilistic decision tree with Markovian dynamics.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we got a detailed introduction to Markov model and HMM. We talked about parameterizing an HMM, generating samples from it, and their code. We discussed estimating the probability of observation, which would form the basis of inference, which we'll cover in the next chapter. We also talked about various extensions of HMMs.</p>
<p>In the next chapter, we will take an in-depth look at inference in HMMs.</p>


            </article>

            
        </section>
    </body></html>