<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Summary and Next Steps in Your Deep Learning Career</h1>
                </header>
            
            <article>
                
<p>This has been a fantastic journey and you've been quite productive as a member of the team! We hope that you've enjoyed our practical approach to teaching <em>Python Deep Learning Projects</em>. Furthermore, it was our intention to provide you with thought-provoking and exciting experiences that will further your intuition and form the technical foundation for your career in deep learning engineering.</p>
<p>Each chapter was structured similarly to participating as a member of our Intelligence Factory team, where, by going through the material, we achieved the following:</p>
<ul>
<li>Saw the big picture of the real-world use case and identified the success criteria</li>
<li>Got focused and into the code, loaded dependencies and data, and built, trained, and evaluated our models</li>
<li>Expanded back out to the big picture to confirm that we achieved our goal</li>
</ul>
<p>We love solving problems and building smart solutions, insights, and people! Let's review some key learning, summarize some of our intuition, and look at what could be next in your deep learning career. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Python deep learning – building the foundation – two projects</h1>
                </header>
            
            <article>
                
<p><span>The foundation of a common working environment enables us to work together, and empowers our learning of cool and powerful deep learning technologies in the fields of <strong>computer vision</strong> (<strong>CV</strong>) and <strong>natural language processing</strong> (<strong>NLP</strong>). The first two chapters in this book provide the establishing experience that you will use time and again in your professional career as a data scientist.</span></p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 1 – Building the Deep Learning Environment</h1>
                </header>
            
            <article>
                
<p>The main goal in this chapter was to standardize the toolset for our work together to achieve consistently accurate results. We want to establish a process for building applications using <span>deep learning </span>algorithms that can scale for production. Towards the end, we identified the components of our common deep learning environment, and initially set up a local <span>deep learning </span>environment, which expanded to a cloud-based environment. Throughout the projects that followed, you gained experience with Ubuntu, Anaconda, Python, TensorFlow, Keras, and <strong>Google Cloud Platform</strong> (<strong>GCP</strong>), to highlight but a few core technologies. These will continue to be of value to you in your deep learning engineering career!</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 2 – Training NN for Prediction Using Regression</h1>
                </header>
            
            <article>
                
<p>In <a href="027b6171-1cf7-4589-b9a2-e417dbe53d8b.xhtml" target="_blank">Chapter 2</a>, <em>Training NN for Prediction Using Regression</em>, we identified our first business use case—one that would become a theme for a number of projects: that of a restaurant chain seeking to automate some of its processes. Specifically, in this chapter, the business use case was to build a deep learning classifier using a <strong>multi-layer perceptron</strong> (<strong>MLP</strong>), the basic building block in deep learning, to accurately classify handwritten digits of a customer's phone number. If you recall, the goal was to accurately classify (digitize) the handwritten phone number on an iPad so that the patron could receive a text that their table was ready.</p>
<p>We built a two-layer (minimally deep) neural network in TensorFlow and trained it on the classic MNIST dataset. This project provided us the opportunity to address overfitting, underfitting, hyperparameter tuning, and activation functions in our exploration of the model's performance. What we found particularly interesting was the impact of the business use case on interpreting the utility of the model's performance. Our accuracy with this simple model initially seemed adequate, until we thought about what a single digit error in a phone number would mean to the accurate delivery of a text to the right patron. In this context, we quickly understood we would need to do much better. Fortunately, we had an opportunity later in the book to take a second run at the problem, and in <a href="acee9abb-ee8f-4b59-8e5e-44ed24ad05c2.xhtml" target="_blank">Chapter 8</a>, <em>Handwritten Digits Classification Using ConvNets</em>, we employed a more complex deep learning model that performed much better! </p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Python deep learning – NLP – 5 projects</h1>
                </header>
            
            <article>
                
<p>A third of our <em>Python Deep Learning Projects</em> are in the field of computational linguistics. Unstructured text data is everywhere, and is being generated at an astonishing rate. We split up the approaches and technologies employed into five parts, to adequately handle the breadth of information. Let's review how the projects in <a href="4dcd4b65-934b-4a8a-a252-9af7513a4787.xhtml" target="_blank">Chapters 3</a>, <em>Word Representation Using word2vec</em>, through <a href="acee9abb-ee8f-4b59-8e5e-44ed24ad05c2.xhtml" target="_blank">Chapter 8</a>, <em>Handwritten Digits Classification Using ConvNets</em>, relate and build on one another.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 3 – Word Representations Using word2vec</h1>
                </header>
            
            <article>
                
<p>Core to computational linguistics is an effective representation of words and the features they embody. word2vec was used to transform the words into dense vectors (that is, tensors), creating embedding representations for the corpus. We then created a <strong>convolutional neural network</strong> (<strong>CNN</strong>) to build a language model for sentiment analysis. To help us frame this task we envisioned the hypothetical use case of our restaurant chain client asking us to make sense of the response texts that they were receiving from their patrons getting the notification that their table was ready. Particularly interesting was the realization that CNNs can be applied to more than just image data! We also took this project as an opportunity to explore data visualization with <strong>t-distributed stochastic neighbor embedding</strong> (<strong>t-SNE</strong>) and TensorBoard.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 4 – Build an NLP Pipeline for Building Chatbots</h1>
                </header>
            
            <article>
                
<p>We dive deeper into computational linguistics in this project by exploring the deep learning techniques (building blocks) for language models. word2vec models like ours in <a href="https://cdp.packtpub.com/python_deep_learning_projects/wp-admin/post.php?post=39&amp;action=edit#post_26" target="_blank">Chapter 3</a><span>, </span><em>Word Representation Using word2vec</em>, are made possible by NLP pipelines. <span>Our task was to create a natural language pipeline that would power a chatbot for open-domain question-answering.</span><span class="Apple-converted-space"> We pictured our</span><span> (hypothetical) restaurant chain as having a website with their menu, history, location, hours, and other information, and that they would like the added ability for a website visitor to ask a question in a query box, and for our deep-learning NLP chatbot to find the relevant information and present that back.</span></p>
<p class="mce-root"/>
<p>The NLP pipeline tokenized the corpus, tagged parts of speech, determined the relationship between words with dependency parsing, and conducted <strong>named entity recognition</strong> (<strong>NER</strong>). This prepared us to use TF-IDF to vectorize the features in the document to create a simple FAQ-type chatbot. We enhanced this with NER and the implementation of Rasa NLU. We were then able t<span>o build a bot that understood the context (intent) of a piece of text, and could also extract the entities, because we created an NLP pipeline that could perform intent classification, along with NER extraction, to allow it to provide an accurate response.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 5 – Sequence-to-Sequence Models for Building Chatbots</h1>
                </header>
            
            <article>
                
<p>This chapter builds directly on<span> </span><a href="c6f638a5-96bf-4488-9e14-4fbc9b969a42.xhtml" target="_blank"/><a href="c6f638a5-96bf-4488-9e14-4fbc9b969a42.xhtml" target="_blank">C<span>hapter 4</span></a><span>, <em>Build NLP Pipeline for Building Chatbots</em> </span>to build a more advanced chatbot for our hypothetical restaurant chain to automate the process of fielding call in orders. We combined our learning on a number of technologies to make a chatbot that is more contextually aware and robust. We avoided some of the limitations of CNNs in chatbots by building a <strong>recurrent neural network</strong> (<strong>RNN</strong>) model with <strong>long short-term memory</strong> (<strong>LSTM</strong>) units, specifically designed to capture the signal represented in sequences of characters or words.</p>
<p>We implemented<span> a language model, with an encoder-decoder RNN based on the LSTM unit, for a simple sequence-to-sequence question-answer task. This model was able to handle inputs and outputs of different sizes, preserve the state of information, and adequately handle complex context. An additional learning of ours was that of the importance of obtaining a sufficient amount of the right training data as the outputs of the model are put up against a very high standard for speech interpretability. However, w</span>ith the right training data, it would be possible to use this model to achieve the hypothetical restaurant chain's goal of building a robust chatbot (in combination with other computational linguistic technologies we've explored) that could automate the over-the-phone <span>process of </span>ordering <span>food</span>.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 6 – Generative Language Model for Content Creation</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span>In this project, we not only take the next step in our computational linguistics journey; we take a profound leap to generate new content! We defined the business use case goal of providing a deep learning solution that generates new content that can be used in movie scripts, song lyrics, and music. We asked ourselves: h</span>ow can we leverage our experience in solving problems for restaurant chains and apply it to different industries? Upon reflection on what we learned in past projects regarding the inputs and outputs of the models, we gained confidence that novel content was just another type of output. We demonstrated that we could take an image as input, and output a class label (<a href="027b6171-1cf7-4589-b9a2-e417dbe53d8b.xhtml" target="_blank">Chapter 2</a>,<span> </span><em>Training NN for Prediction Using Regression</em>). We trained a model to take inputs of text and output sentiment classifications (<a href="4dcd4b65-934b-4a8a-a252-9af7513a4787.xhtml" target="_blank">Chapter 3</a>,<span> </span><em>Word Representation Using word2vec</em>), and we built a NLP pipeline for an open-domain question-answering chatbot, where we took text as input, and identified text in a corpus to present the appropriate output (<a href="c6f638a5-96bf-4488-9e14-4fbc9b969a42.xhtml" target="_blank">Chapter 4</a>,<span> </span><em>Build NLP Pipeline for Building Chatbots</em>). We then expanded that chatbot functionality to be able to serve a restaurant with an automated ordering system (<a href="856ccfef-cfe1-462f-9998-73f2b5168ae7.xhtml" target="_blank">Chapter 5</a>,<span> </span><em>Sequence-to-Sequence Models for Building Chatbots</em>).</p>
<p class="mce-root">In this chapter, we implemented a generative model to generate content using the<span> </span><strong>long short-term memory</strong> (<strong>LSTM</strong>), variational autoencoders, and<span> <strong>g</strong></span><strong>enerative adversarial networks</strong><span> </span>(<strong>GANs</strong>). We effectively implemented models, for both text and music, that can generate song lyrics, scripts, and music for artists and various creative businesses.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 7 – Building Speech Recognition with DeepSpeech2</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span>This project on building speech recognition with DeepSpeech2 is the capstone in the <em>Natural Language Processing</em> section of the <em>Python Deep Learning Projects</em> book. So far, we've explored chatbots, natural language processing, and speech recognition with RNNs (both uni- and bi-directional, with and without LSTM components) and CNNs. We've seen the power of these technologies to provide intelligence to existing business processes, as well as to create entirely new and smart systems. This is exciting work at the cutting edge of applied AI using deep learning!</span></p>
<p class="mce-root"/>
<p class="mce-root">The goal of this project was to build and train an <strong>automatic speech recognition</strong> (<strong>ASR</strong>) system to take in and convert an audio call to text, which could then be used as the input for a text-based chatbot that was capable of parsing the input and responding appropriately. <span>We made a deep dive into speech data, performing feature engineering to allow us to extract various kinds of features from the data, to then build a speech recognition system which can detect a users voice. In the end, w</span><span class="s1">e demonstrated mastery by building a system, <span>using the DeepSpeech2 model,</span> that recognizes English speech. We w</span><span class="s1">orked with speech and spectograms to build</span><span class="s1"><span class="Apple-converted-space"> an </span>end-to-end speech recognition system using t</span><span class="s1"><span class="Apple-converted-space">he <strong>c</strong></span><strong>onnectionist temporal classification</strong> (<strong>CTC</strong>) loss function, b</span><span class="s1">atch normalization, and<span> </span>SortaGrad<span> </span>for the RNNs.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deep learning – computer vision – 6 projects</h1>
                </header>
            
            <article>
                
<p>The following six Python deep learning projects, focusing on CV, represent the largest portion of the content of this book. We've already seen how some of the deep learning technologies we explore in detail, with reference to CV, have some applicability to other types of data, and in particular, to text-based data. In no small part, that is because of the enormous utility of CNNs in feature extraction and hierarchical representation. There is no magic tool that is perfect for all jobs—being a deep learning engineer in data science is no exception. But you should not underestimate the familiarity you'll get with CNNs, as you'll find yourself using them time and again, across many different datasets and business use cases. Being a data scientist without CNN skills is like being a carpenter without a hammer. The obvious caveat is that not everything in data science is the equivalent of a nail!</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 8 – Handwritten Digit Classification Using ConvNets</h1>
                </header>
            
            <article>
                
<p>This chapter reminds us of the first deep neural net we created in <a href="027b6171-1cf7-4589-b9a2-e417dbe53d8b.xhtml" target="_blank">Chapter 2</a>, <em>Training NN for Prediction Using Regression</em>, and the business use case to which it was applied. The purpose of that chapter was to provide a foundation for our understanding of deep neural networks and how they operate. The complexity of the math underlying deep learning was highlighted when we compared the model architecture with the more advanced techniques afforded when we build deeper and more robust models. Complexity isn't cool just because it's complex; in this case, it's cool because of the improvement in realized performance utility that it provides. </p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>We spent a considerable amount of time examining the convolution operation, pooling, and dropout regularization. These are the levers you'll adjust in tuning your models in your career, so getting a solid understanding of them early is essential. In reference to the business use case, we see the value of deploying a more complex model, in that the performance gain supports the parent product implementation. The error rate obtained in <a href="https://cdp.packtpub.com/python_deep_learning_projects/wp-admin/post.php?post=39&amp;action=edit#post_25" target="_blank">Chapter 2</a><span>, </span><em>Training NN for Prediction Using Regression</em>, was such that, in the worse case, not a single text would have been appropriately delivered to the right patron at the hypothetical restaurant chain (and in the best case, it was still dismal and effectively not functional). The CNN model on the same dataset produces results that mean that, in the new worst-case scenario, 90% of the patrons would receive the text notifications, and in the best case, 99% would get the text! </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 9 – Object Detection Using OpenCV and TensorFlow</h1>
                </header>
            
            <article>
                
<p class="mce-root">Let's think about what we accomplished in <a href="acee9abb-ee8f-4b59-8e5e-44ed24ad05c2.xhtml" target="_blank">Chapter 8</a>, <em>Handwritten Digits Classification Using ConvNets</em>, where we were able to train an image classifier, with a CNN, to accurately classify handwritten digits in an image. The data was less complicated than it could have been, because each image only had one handwritten digit in it, and our goal was to accurately assign a class label to the image. What would have happened if each image had multiple handwritten digits in it, or different types of objects? What if we had a video? What if we want to identify <em>where</em> the digits are in the image? These questions represent the challenges that real-world data embodies, and drives our data science innovation toward new models and capabilities.</p>
<p>Object detection and classification is no trivial task for a computer, particularly at scale and hitting speed requirements. We employed data inputs in<span> </span>this project that were much more informationally complex than what we've had in previous projects, and the outcomes, when we got them right, were that much more impressive. We found that the deep learning package YOLOv2 performed very well, and saw our model architecture get deeper and more complex with good results.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 10 – Building Facial Recognition Using OpenFace</h1>
                </header>
            
            <article>
                
<p>In <a href="d3a16c16-a745-4cd4-ae4b-4afcec887ada.xhtml" target="_blank">Chapter 9</a>, <em>Object Detection Using OpenCV and TensorFlow</em>, we demonstrated mastery in the skills needed to build a deep learning object detection and classification model. Building on that, we set our objective at a refinement of that classification operation: is the object identical to another? In our case, we were looking to build a facial recognition system of the kind that we see in spy movies, and now in high tech security systems. Facial recognition is a combination of two major operations: face detection, followed by face classification. </p>
<p class="mce-root">Using OpenFace in this project, we built a model that looked at a picture and identified all the possible faces in it, then performed face extraction to understand the quality of the part of the image containing faces. We then performed feature extraction on the face, identifying parts of the image that gave us the basis for comparison with another data point (a labeled image of the person's face).<span> This Python deep learning project demonstrates the exciting potential for this technology, and the future for the engineers that excel at working on these applications.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 11 – Automated Image Captioning</h1>
                </header>
            
            <article>
                
<p><span>In <a href="d3a16c16-a745-4cd4-ae4b-4afcec887ada.xhtml" target="_blank">Chapter 9</a>, <em>Object Detection Using OpenCV and TensorFlow</em>, we learned how to detect and classify objects in an image, and in <a href="78e388c6-e8f4-49f4-84d6-ab7c20fd6b71.xhtml" target="_blank">Chapter 10</a>, <em>Building Face Recognition Using FaceNet</em>, we learned how to detect, classify, and identify objects as being the same thing (for example, identifying the same person from two different facial images). In this project, we did something even more complicated and cool! We combined the current state-of-the-art techniques that we've learned so far in our Python deep learning projects, in both CV and<em> </em>NLP, to form a complete image description approach. This model</span> was capable of <span>constructing computer-generated natural language descriptions of any image provided. </span></p>
<p><span>The clever idea that made this possible was to replace the encoder (the RNN layer) in an encoder-decoder architecture with a deep </span><span>CNN, trained to classify objects in images. Normally, the CNN's last layer is the </span>softmax layer,<span> which assigns the probability that each object might be in the image. But when we remove that softmax layer from the CNN, we can feed the CNN's rich encoding of the image into the decoder (the language generation component of the RNN) designed to produce phrases. We can then train the whole system directly on images and their captions, maximizing the likelihood that the descriptions it produces best match the training descriptions for each image. This deep learning technology is the backbone of many intelligence factory solutions!</span></p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 12 – Pose Estimation on 3D Models Using ConvNets</h1>
                </header>
            
            <article>
                
<p>Data that we apply to our models are representations of the real world. This is the fundamental truth that unites computational linguistics and CV. With respect to CV, we need to remember that 2D images represent a 3D world, in the same way that video represents 4D, with the added aspects of time and movement. Recalling this obvious fact lets us ask ever more interesting questions and develop deep learning technologies with increasing utility. Our hypothetical use case was to enable visual effects specialists to easily estimate the pose of actors (particularly the shoulders, neck, and head) on frames of a video. Our task was to build the intelligence for this application.</p>
<p><span>We successfully built a deep CNN/VGG16 model in Keras on <strong>frames labeled in cinema</strong> (<strong>FLIC</strong>) images. We got hands-on experience in preparing the images for modeling. We successfully implemented transfer learning, and understood that doing so will save us a lot of time. We defined some key hyperparameters, as well as understanding why we did what we did. Finally, we tested the modified VGG16 model performance on unseen data, and determined that we succeeded in achieving our goals.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 13 – Image Translation Using GANs for Style Transfer</h1>
                </header>
            
            <article>
                
<p>GANs are just downright cool. When we look back at the skills and intuition we've built throughout these projects, we had an interesting idea. Could we predict missing information? Or, stated in a different way: can we create data that should be in an image, but that's not there? If we can take text input and generate novel text output, and if we can take a 2D image and generate or predict a 3D positional output, then it would seem possible that, if we have a 2D image that's missing some information, maybe we ought to be able to generate the missing information? So, in this chapter, we built a neural network that fills in the missing part of a handwritten digit. We previously built a digit classifier for a hypothetical restaurant chain client. Error rates could be attributable to the digits not being accurately captured, and the resulting image having incompletely drawn digits. <span>We focused our efforts on the new part of the model creation—the generation/reconstruction of the missing sections of a digit with the help of neural inpainting with GANs. We then</span> reconstructed the missing parts of the handwritten numbers, so that the classifier received clear handwritten numbers for conversion into digits.<span> </span><span>With this, the classifier was able to do a much more accurate job of classifying the handwritten digits (and our mythical restaurant patrons were able to receive their notification texts and get seated promptly).</span></p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Python deep learning – autonomous agents – 1 project</h1>
                </header>
            
            <article>
                
<p>The final project in our book is unlike anything we've done so far, and deserves its own treatment. Robotic process automation and optimization, and autonomous agents, such as drones and vehicles, require our deep learning models to learn from environmental cues in a reinforcement learning paradigm. Unlike previous projects, where we've been primarily focused on <span>solving supervised learning problems,</span> in this chapter, we learned to build and train a deep reinforcement learning model capable of playing games. </p>
<p>We employed a deep Q-learning and deep <strong>state-action-reward-state-action</strong><span> </span>(<strong>SARSA</strong>) learning model. Unlike programming simple models by defining heuristics, deep learning models mapping A-B in a supervised learning environment, or determining decision boundaries in cluster analysis in unsupervised learning, it is the rules of the game or environment (as expressed in the delivery of reinforcement) that provide the feedback for training in reinforcement learning. The deep learning model, also called the agent in reinforcement-learning terms, interacts with the game environment and learns how to play the game, seeking to maximize rewards after several attempts at playing.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 14 – Develop an Autonomous Agent with Deep Reinforcement Learning</h1>
                </header>
            
            <article>
                
<p>In this project, we built a deep reinforcement learning model to successfully play the game of<span> </span>CartPole-v1, from OpenAI Gym. Demonstrating mastery here first, we could then extend it to other complex games, such as those by Atari.</p>
<p>We learned how to interact with the Gym toolkit, Q-learning, and SARSA learning; how to code the reinforcement learning model and define hyperparameters; and how to build the training loop and test the model. We found that our SARSA model performed quite a bit better than the Q-learning model. Further training and tuning of hyperparameters, and our own capture of reinforcement units (better scores by our models), should shape our behavior to build better models that ultimately result in the nearly perfect performance of our agent! </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Next steps – AI strategy and platforms</h1>
                </header>
            
            <article>
                
<p>Throughout this book, you've gained experiences that form the technical foundations for professional work in deep learning projects. However, the scope of the book was such that our focus could only be on a subset of the entire production-scale data science pipeline. We spent our time in the context of a business use case to ground our thinking on the domain and success criteria, but quickly dove into deep-learning model training, evaluation, and validation. These components, comprising the bulk of the training in our projects, are certainly the core of a data science pipeline for an enterprise, but cannot function in a vacuum. Additional considerations and training in AI strategy and data science platforms are the natural next steps in your education and career. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">AI strategy</h1>
                </header>
            
            <article>
                
<p>AI strategy is about gaining knowledge from the client that empowers you to determine the following:</p>
<ul>
<li>The client's grand vision for an intelligence-based competitive advantage</li>
<li>How to translate that vision into an effective production-scale data science pipeline:
<ul>
<li>Take into account the current and near-term digital maturity of the client</li>
<li>Processes of data ingestion, analysis, and transformation</li>
<li>Technology and engineering resources and constraints</li>
<li>The analytics team's <span>current </span>capabilities</li>
<li>Model selection, customization, training, evaluation, validation, and serving</li>
</ul>
</li>
<li>Achievement of KPIs and ROI that meets the objectives of the client's leadership</li>
</ul>
<p>AI strategy consulting uncovers goals and expectations, while aligning outcomes with machine learning and deep learning technologies. Building an AI solution architecture must take all of this into account to be successful. You should look to mentors in the industry, read available case studies, and keep this in mind as your career advances, and you are called in to provide guidance and opinions earlier and earlier in the solution-building process.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deep learning platforms – TensorFlow Extended (TFX)</h1>
                </header>
            
            <article>
                
<p>Data science platforms, designed to meet the demands for production-scale deployment, require significant engineering support. At the Intelligence Factory and Skejul, we've built deep learning platforms that take in live feeds of constantly updating data to produce intelligence-based outputs within milliseconds, to be delivered via a cloud-based web application using API gateways. It's extraordinarily complex and rewarding, once you get all the pieces to come together!</p>
<p>One technology that will aid in your deep learning and data science career is TFX. This is Google's TensorFlow-based production-scale machine learning platform. The first few lines from their abstract from the article <br/>
<em>TFX: A TensorFlow-Based Production-Scale Machine Learning Platform</em> (<a href="https://ai.google/research/pubs/pub46484" target="_blank">https://ai.google/research/pubs/pub46484</a>) summarize the potential of the TFX and similar platforms:</p>
<div class="packt_quote">"Creating and maintaining a platform for reliably producing and deploying machine learning models requires careful orchestration of many components—a learner for generating models based on training data, modules for analyzing and validating both data as well as models, and finally infrastructure for serving models in production. This becomes particularly challenging when data changes over time and fresh models need to be produced continuously."<a href="http://stevenwhang.com/tfx_paper.pdf"/></div>
<p>Data science platform engineering that's based on a smartly crafted AI strategy is our next step in training, and we look forward to the opportunity to share those experiences with you too!</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Conclusion and thank you!</h1>
                </header>
            
            <article>
                
<p>We want to thank you for choosing our book, <em>Python Deep Learning Projects</em>, as part of your data science education! It's our hope that you found the projects and the business use cases intriguing and informative, and that you feel more professionally prepared than when you started. We look forward to the opportunity to engage with you via our respective blogs, on social media, and possibly even at conferences or on working together on delivering AI-based solutions to clients around the world.</p>
<p>We've been happy to have you in our weekly AI team<span> meetings in these projects. </span>Now that we've learned a bunch of stuff, and had some fun with really cool and powerful data science technologies, let's go out to do great work based on these Python deep learning projects!</p>


            </article>

            
        </section>
    </body></html>