<html><head></head><body>
  <div id="_idContainer350">
   <h1 class="chapter-number" id="_idParaDest-208">
    <a id="_idTextAnchor211">
    </a>
    <span class="koboSpan" id="kobo.1.1">
     11
    </span>
   </h1>
   <h1 id="_idParaDest-209">
    <a id="_idTextAnchor212">
    </a>
    <span class="koboSpan" id="kobo.2.1">
     Emerging Applications
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.3.1">
     Graph deep learning has demonstrated remarkable versatility across a wide array of domains, extending far beyond its well-known applications in
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.4.1">
      natural language processing
     </span>
    </strong>
    <span class="koboSpan" id="kobo.5.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.6.1">
      NLP
     </span>
    </strong>
    <span class="koboSpan" id="kobo.7.1">
     ), recommendation
    </span>
    <a id="_idIndexMarker772">
    </a>
    <span class="koboSpan" id="kobo.8.1">
     systems, and
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.9.1">
      computer vision
     </span>
    </strong>
    <span class="koboSpan" id="kobo.10.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.11.1">
      CV
     </span>
    </strong>
    <span class="koboSpan" id="kobo.12.1">
     ), as
    </span>
    <a id="_idIndexMarker773">
    </a>
    <span class="koboSpan" id="kobo.13.1">
     we saw in
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.14.1">
      Chapters 8
     </span>
    </em>
    <span class="koboSpan" id="kobo.15.1">
     ,
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.16.1">
      9
     </span>
    </em>
    <span class="koboSpan" id="kobo.17.1">
     , and
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.18.1">
      10
     </span>
    </em>
    <span class="koboSpan" id="kobo.19.1">
     , respectively.
    </span>
    <span class="koboSpan" id="kobo.19.2">
     Here, we explore the diverse landscape of applications where graph-based approaches have made significant impacts or show
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.20.1">
      promising potential.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.21.1">
     As we delve into these applications, we’ll see how graph deep learning techniques adapt to different contexts, often providing novel solutions to long-standing challenges.
    </span>
    <span class="koboSpan" id="kobo.21.2">
     In urban planning, for example, these methods have been used to optimize public transportation networks and predict traffic flow, contributing to the development of smarter, more efficient cities.
    </span>
    <span class="koboSpan" id="kobo.21.3">
     In the realm of materials science, researchers are leveraging graph-based models to predict material properties and design new compounds with specific characteristics, potentially accelerating innovation in fields such as renewable energy and
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.22.1">
      advanced manufacturing.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.23.1">
     The applications that we’ll examine in this chapter not only showcase the breadth of graph deep learning’s impact but also highlight the transferable nature of these techniques.
    </span>
    <span class="koboSpan" id="kobo.23.2">
     Many of the approaches developed for one domain often find unexpected applications in others, fostering cross-pollination of ideas and methodologies.
    </span>
    <span class="koboSpan" id="kobo.23.3">
     As we cover each application, we’ll discuss the unique challenges they present, the specific graph deep learning techniques employed, and the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.24.1">
      results achieved.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.25.1">
     By the end of this chapter, you’ll have a comprehensive understanding of the far-reaching implications of graph deep learning across various industries and scientific disciplines, including
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.26.1">
      the following:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <span class="koboSpan" id="kobo.27.1">
      Biology
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.28.1">
       and healthcare
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.29.1">
      Social
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.30.1">
       network analysis
      </span>
     </span>
    </li>
    <li>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.31.1">
       Financial services
      </span>
     </span>
    </li>
    <li>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.32.1">
       Cybersecurity
      </span>
     </span>
    </li>
    <li>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.33.1">
       Energy systems
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.34.1">
       Internet of
      </span>
     </strong>
     <span class="No-Break">
      <strong class="bold">
       <span class="koboSpan" id="kobo.35.1">
        Things
       </span>
      </strong>
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.36.1">
       (
      </span>
     </span>
     <span class="No-Break">
      <strong class="bold">
       <span class="koboSpan" id="kobo.37.1">
        IoT
       </span>
      </strong>
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.38.1">
       )
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.39.1">
      Legal governance
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.40.1">
       and compliance
      </span>
     </span>
    </li>
   </ul>
   <h1 id="_idParaDest-210">
    <a id="_idTextAnchor213">
    </a>
    <span class="koboSpan" id="kobo.41.1">
     Biology and healthcare
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.42.1">
     Graph-structured data is
    </span>
    <a id="_idIndexMarker774">
    </a>
    <span class="koboSpan" id="kobo.43.1">
     ubiquitous in biology and healthcare, from molecular interactions to brain
    </span>
    <a id="_idIndexMarker775">
    </a>
    <span class="koboSpan" id="kobo.44.1">
     connectomes.
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.45.1">
      Graph neural networks
     </span>
    </strong>
    <span class="koboSpan" id="kobo.46.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.47.1">
      GNNs
     </span>
    </strong>
    <span class="koboSpan" id="kobo.48.1">
     ) have emerged as powerful tools for learning on these complex
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.49.1">
      relational structures.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-211">
    <a id="_idTextAnchor214">
    </a>
    <span class="koboSpan" id="kobo.50.1">
     Protein-protein interaction networks
    </span>
   </h2>
   <p>
    <strong class="bold">
     <span class="koboSpan" id="kobo.51.1">
      Protein-protein interaction
     </span>
    </strong>
    <span class="koboSpan" id="kobo.52.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.53.1">
      PPI
     </span>
    </strong>
    <span class="koboSpan" id="kobo.54.1">
     ) networks
    </span>
    <a id="_idIndexMarker776">
    </a>
    <span class="koboSpan" id="kobo.55.1">
     represent
    </span>
    <a id="_idIndexMarker777">
    </a>
    <span class="koboSpan" id="kobo.56.1">
     physical contact between proteins in a cell.
    </span>
    <span class="koboSpan" id="kobo.56.2">
     These interactions are crucial for understanding cellular processes and developing new therapeutics.
    </span>
    <span class="koboSpan" id="kobo.56.3">
     GNNs can effectively model and analyze PPI networks to do
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.57.1">
      the following:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.58.1">
       Predict new interactions
      </span>
     </strong>
     <span class="koboSpan" id="kobo.59.1">
      : GNNs can learn patterns in known interactions to infer novel PPIs.
     </span>
     <span class="koboSpan" id="kobo.59.2">
      For example, Gainza et al.
     </span>
     <span class="koboSpan" id="kobo.59.3">
      (2020) (
     </span>
     <a href="https://doi.org/10.1093/bioinformatics/btab154">
      <span class="koboSpan" id="kobo.60.1">
       https://doi.org/10.1093/bioinformatics/btab154
      </span>
     </a>
     <span class="koboSpan" id="kobo.61.1">
      ) developed a GNN model that predicts PPIs by learning geometric and chemical features of protein surfaces.
     </span>
     <span class="koboSpan" id="kobo.61.2">
      Another
     </span>
     <a id="_idIndexMarker778">
     </a>
     <span class="koboSpan" id="kobo.62.1">
      instance is the
     </span>
     <strong class="bold">
      <span class="koboSpan" id="kobo.63.1">
       Subgraph Neural Networks for Link Prediction (
      </span>
     </strong>
     <strong class="bold">
      <span class="koboSpan" id="kobo.64.1">
       SEAL) model
      </span>
     </strong>
     <span class="koboSpan" id="kobo.65.1">
      by Zhang and Chen (2018) (
     </span>
     <a href="https://arxiv.org/pdf/1802.09691">
      <span class="koboSpan" id="kobo.66.1">
       https://arxiv.org/pdf/1802.09691
      </span>
     </a>
     <span class="koboSpan" id="kobo.67.1">
      ), which achieved state-of-the-art
     </span>
     <a id="_idIndexMarker779">
     </a>
     <span class="koboSpan" id="kobo.68.1">
      performance in PPI prediction on the
     </span>
     <strong class="bold">
      <span class="koboSpan" id="kobo.69.1">
       Human Protein Reference Database
      </span>
     </strong>
     <span class="koboSpan" id="kobo.70.1">
      (
     </span>
     <strong class="bold">
      <span class="koboSpan" id="kobo.71.1">
       HPRD
      </span>
     </strong>
     <span class="koboSpan" id="kobo.72.1">
      ).
     </span>
     <span class="koboSpan" id="kobo.72.2">
      It learns from local enclosing subgraphs around protein pairs to
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.73.1">
       predict interactions.
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.74.1">
       Identify functional modules
      </span>
     </strong>
     <span class="koboSpan" id="kobo.75.1">
      : By clustering proteins based on learned embeddings, GNNs can discover functional protein complexes.
     </span>
     <span class="koboSpan" id="kobo.75.2">
      Xing et al.
     </span>
     <span class="koboSpan" id="kobo.75.3">
      (
     </span>
     <a href="https://doi.org/10.1093/bioinformatics/btac088">
      <span class="koboSpan" id="kobo.76.1">
       https://doi.org/10.1093/bioinformatics/btac088
      </span>
     </a>
     <span class="koboSpan" id="kobo.77.1">
      ) used a
     </span>
     <strong class="bold">
      <span class="koboSpan" id="kobo.78.1">
       graph attention network
      </span>
     </strong>
     <span class="koboSpan" id="kobo.79.1">
      (
     </span>
     <strong class="bold">
      <span class="koboSpan" id="kobo.80.1">
       GAT
      </span>
     </strong>
     <span class="koboSpan" id="kobo.81.1">
      ) to identify
     </span>
     <a id="_idIndexMarker780">
     </a>
     <span class="koboSpan" id="kobo.82.1">
      disease-related
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.83.1">
       protein modules.
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.84.1">
       Predict protein functions
      </span>
     </strong>
     <span class="koboSpan" id="kobo.85.1">
      : GNNs can propagate known functional annotations through PPI networks to predict functions of unannotated proteins.
     </span>
     <span class="koboSpan" id="kobo.85.2">
      For
     </span>
     <a id="_idIndexMarker781">
     </a>
     <span class="koboSpan" id="kobo.86.1">
      instance, the
     </span>
     <strong class="bold">
      <span class="koboSpan" id="kobo.87.1">
       DeepGOPlus model
      </span>
     </strong>
     <span class="koboSpan" id="kobo.88.1">
      by Kulmanov and Hoehndorf (
     </span>
     <a href="https://doi.org/10.1093/bioinformatics/btaa763">
      <span class="koboSpan" id="kobo.89.1">
       https://doi.org/10.1093/bioinformatics/btaa763
      </span>
     </a>
     <span class="koboSpan" id="kobo.90.1">
      ) combines sequence information with PPI
     </span>
     <a id="_idIndexMarker782">
     </a>
     <span class="koboSpan" id="kobo.91.1">
      networks for
     </span>
     <a id="_idIndexMarker783">
     </a>
     <span class="koboSpan" id="kobo.92.1">
      improved
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.93.1">
       function prediction.
      </span>
     </span>
    </li>
   </ul>
   <h2 id="_idParaDest-212">
    <a id="_idTextAnchor215">
    </a>
    <span class="koboSpan" id="kobo.94.1">
     Drug discovery and development
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.95.1">
     Graph-based models are
    </span>
    <a id="_idIndexMarker784">
    </a>
    <span class="koboSpan" id="kobo.96.1">
     revolutionizing various
    </span>
    <a id="_idIndexMarker785">
    </a>
    <span class="koboSpan" id="kobo.97.1">
     stages of the drug
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.98.1">
      discovery pipeline:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.99.1">
       Molecular property prediction
      </span>
     </strong>
     <span class="koboSpan" id="kobo.100.1">
      : GNNs can learn from molecular graphs to predict properties such as solubility, toxicity, and binding affinity.
     </span>
     <span class="koboSpan" id="kobo.100.2">
      The
     </span>
     <strong class="bold">
      <span class="koboSpan" id="kobo.101.1">
       message passing neural network
      </span>
     </strong>
     <span class="koboSpan" id="kobo.102.1">
      (
     </span>
     <strong class="bold">
      <span class="koboSpan" id="kobo.103.1">
       MPNN
      </span>
     </strong>
     <span class="koboSpan" id="kobo.104.1">
      ) by
     </span>
     <a id="_idIndexMarker786">
     </a>
     <span class="koboSpan" id="kobo.105.1">
      Gilmer et al.
     </span>
     <span class="koboSpan" id="kobo.105.2">
      (
     </span>
     <a href="https://arxiv.org/abs/1704.01212">
      <span class="koboSpan" id="kobo.106.1">
       https://arxiv.org/abs/1704.01212
      </span>
     </a>
     <span class="koboSpan" id="kobo.107.1">
      ) pioneered
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.108.1">
       this approach.
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.109.1">
       De novo drug design
      </span>
     </strong>
     <span class="koboSpan" id="kobo.110.1">
      : Generative GNN models can create novel molecular structures with desired properties.
     </span>
     <span class="koboSpan" id="kobo.110.2">
      For example, the
     </span>
     <strong class="bold">
      <span class="koboSpan" id="kobo.111.1">
       GraphAF model
      </span>
     </strong>
     <span class="koboSpan" id="kobo.112.1">
      by Shi et al.
     </span>
     <span class="koboSpan" id="kobo.112.2">
      (
     </span>
     <a href="https://arxiv.org/abs/2001.09382">
      <span class="koboSpan" id="kobo.113.1">
       https://arxiv.org/abs/2001.09382
      </span>
     </a>
     <span class="koboSpan" id="kobo.114.1">
      ) uses
     </span>
     <a id="_idIndexMarker787">
     </a>
     <span class="koboSpan" id="kobo.115.1">
      a flow-based approach to generate molecules atom
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.116.1">
       by atom.
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.117.1">
       Drug-target interaction prediction
      </span>
     </strong>
     <span class="koboSpan" id="kobo.118.1">
      : GNNs can model both drugs and proteins as graphs to predict their interactions.
     </span>
     <span class="koboSpan" id="kobo.118.2">
      The work by Nguyen et al.
     </span>
     <span class="koboSpan" id="kobo.118.3">
      (
     </span>
     <a href="https://doi.org/10.1093/bioinformatics/btaa921">
      <span class="koboSpan" id="kobo.119.1">
       https://doi.org/10.1093/bioinformatics/btaa921
      </span>
     </a>
     <span class="koboSpan" id="kobo.120.1">
      ) uses
     </span>
     <a id="_idIndexMarker788">
     </a>
     <span class="koboSpan" id="kobo.121.1">
      the
     </span>
     <strong class="bold">
      <span class="koboSpan" id="kobo.122.1">
       GraphDTA model
      </span>
     </strong>
     <span class="koboSpan" id="kobo.123.1">
      for
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.124.1">
       this task.
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.125.1">
       Polypharmacy side-effect prediction
      </span>
     </strong>
     <span class="koboSpan" id="kobo.126.1">
      : GNNs can model drug-drug interactions in knowledge graphs to predict the adverse effects of drug combinations.
     </span>
     <span class="koboSpan" id="kobo.126.2">
      The
     </span>
     <strong class="bold">
      <span class="koboSpan" id="kobo.127.1">
       Decagon model
      </span>
     </strong>
     <span class="koboSpan" id="kobo.128.1">
      by
     </span>
     <a id="_idIndexMarker789">
     </a>
     <span class="koboSpan" id="kobo.129.1">
      Zitnik et al.
     </span>
     <span class="koboSpan" id="kobo.129.2">
      (
     </span>
     <a href="https://doi.org/10.1093/bioinformatics/bty294">
      <span class="koboSpan" id="kobo.130.1">
       https://doi.org/10.1093/bioinformatics/bty294
      </span>
     </a>
     <span class="koboSpan" id="kobo.131.1">
      ) is a
     </span>
     <a id="_idIndexMarker790">
     </a>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.132.1">
       prominent example.
      </span>
     </span>
    </li>
   </ul>
   <h2 id="_idParaDest-213">
    <a id="_idTextAnchor216">
    </a>
    <span class="koboSpan" id="kobo.133.1">
     Disease prediction and progression modeling
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.134.1">
     Graph-based
    </span>
    <a id="_idIndexMarker791">
    </a>
    <span class="koboSpan" id="kobo.135.1">
     models can
    </span>
    <a id="_idIndexMarker792">
    </a>
    <span class="koboSpan" id="kobo.136.1">
     integrate diverse biomedical data for improved disease prediction
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.137.1">
      and understanding:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.138.1">
       Electronic Health Record (EHR) analysis
      </span>
     </strong>
     <span class="koboSpan" id="kobo.139.1">
      : Patient records can be modeled as temporal graphs, with GNNs capturing complex relationships between diagnoses, medications, and lab tests.
     </span>
     <span class="koboSpan" id="kobo.139.2">
      The
     </span>
     <strong class="bold">
      <span class="koboSpan" id="kobo.140.1">
       GRAM model
      </span>
     </strong>
     <span class="koboSpan" id="kobo.141.1">
      by
     </span>
     <a id="_idIndexMarker793">
     </a>
     <span class="koboSpan" id="kobo.142.1">
      Choi et al.
     </span>
     <span class="koboSpan" id="kobo.142.2">
      (
     </span>
     <a href="https://pubmed.ncbi.nlm.nih.gov/33717639">
      <span class="koboSpan" id="kobo.143.1">
       https://pubmed.ncbi.nlm.nih.gov/33717639
      </span>
     </a>
     <span class="koboSpan" id="kobo.144.1">
      ) uses a graph-based attention mechanism on medical ontologies to improve
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.145.1">
       risk prediction.
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.146.1">
       Disease gene prediction
      </span>
     </strong>
     <span class="koboSpan" id="kobo.147.1">
      : GNNs can integrate protein interactions, gene expression, and known disease associations to identify novel disease genes.
     </span>
     <span class="koboSpan" id="kobo.147.2">
      The model by Li et al.
     </span>
     <span class="koboSpan" id="kobo.147.3">
      (
     </span>
     <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8275341">
      <span class="koboSpan" id="kobo.148.1">
       https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8275341
      </span>
     </a>
     <span class="koboSpan" id="kobo.149.1">
      ) uses a
     </span>
     <a id="_idIndexMarker794">
     </a>
     <span class="koboSpan" id="kobo.150.1">
      heterogeneous
     </span>
     <strong class="bold">
      <span class="koboSpan" id="kobo.151.1">
       graph convolutional network
      </span>
     </strong>
     <span class="koboSpan" id="kobo.152.1">
      (
     </span>
     <strong class="bold">
      <span class="koboSpan" id="kobo.153.1">
       GCN
      </span>
     </strong>
     <span class="koboSpan" id="kobo.154.1">
      ) for
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.155.1">
       this task.
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.156.1">
       Cancer subtype classification
      </span>
     </strong>
     <span class="koboSpan" id="kobo.157.1">
      : Graph models can integrate multi-omics data (for example, gene expression, mutations, copy number variations) to improve cancer subtype prediction.
     </span>
     <span class="koboSpan" id="kobo.157.2">
      The work of Zhang et al.
     </span>
     <span class="koboSpan" id="kobo.157.3">
      (
     </span>
     <a href="https://doi.org/10.1016/j.engappai.2023.106717">
      <span class="koboSpan" id="kobo.158.1">
       https://doi.org/10.1016/j.engappai.2023.106717
      </span>
     </a>
     <span class="koboSpan" id="kobo.159.1">
      ) uses a multi-view GCN for
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.160.1">
       this purpose.
      </span>
     </span>
    </li>
   </ul>
   <h2 id="_idParaDest-214">
    <a id="_idTextAnchor217">
    </a>
    <span class="koboSpan" id="kobo.161.1">
     Brain connectomics analysis
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.162.1">
     GNNs are particularly
    </span>
    <a id="_idIndexMarker795">
    </a>
    <span class="koboSpan" id="kobo.163.1">
     well suited
    </span>
    <a id="_idIndexMarker796">
    </a>
    <span class="koboSpan" id="kobo.164.1">
     for analyzing brain
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.165.1">
      connectivity data:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.166.1">
       Brain disorder classification
      </span>
     </strong>
     <span class="koboSpan" id="kobo.167.1">
      : GNNs can learn from structural or functional connectomes to classify
     </span>
     <a id="_idIndexMarker797">
     </a>
     <span class="koboSpan" id="kobo.168.1">
      neurological and psychiatric disorders.
     </span>
     <span class="koboSpan" id="kobo.168.2">
      The
     </span>
     <strong class="bold">
      <span class="koboSpan" id="kobo.169.1">
       BrainGNN model
      </span>
     </strong>
     <span class="koboSpan" id="kobo.170.1">
      by Li et al.
     </span>
     <span class="koboSpan" id="kobo.170.2">
      (
     </span>
     <a href="https://doi.org/10.1016/j.media.2021.102233">
      <span class="koboSpan" id="kobo.171.1">
       https://doi.org/10.1016/j.media.2021.102233
      </span>
     </a>
     <span class="koboSpan" id="kobo.172.1">
      ) uses a hierarchical GNN for autism spectrum
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.173.1">
       disorder classification.
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.174.1">
       Cognitive state prediction
      </span>
     </strong>
     <span class="koboSpan" id="kobo.175.1">
      : Graph models can map brain connectivity patterns to cognitive states or behaviors.
     </span>
     <span class="koboSpan" id="kobo.175.2">
      The work of Wang et al.
     </span>
     <span class="koboSpan" id="kobo.175.3">
      (
     </span>
     <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7935029">
      <span class="koboSpan" id="kobo.176.1">
       https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7935029
      </span>
     </a>
     <span class="koboSpan" id="kobo.177.1">
      ) uses a dynamic GCN to predict cognitive
     </span>
     <a id="_idIndexMarker798">
     </a>
     <span class="koboSpan" id="kobo.178.1">
      states
     </span>
     <a id="_idIndexMarker799">
     </a>
     <span class="koboSpan" id="kobo.179.1">
      from
     </span>
     <strong class="bold">
      <span class="koboSpan" id="kobo.180.1">
       functional magnetic resonance imaging
      </span>
     </strong>
     <span class="koboSpan" id="kobo.181.1">
      (
     </span>
     <span class="No-Break">
      <strong class="bold">
       <span class="koboSpan" id="kobo.182.1">
        fMRI
       </span>
      </strong>
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.183.1">
       ) data.
      </span>
     </span>
    </li>
   </ul>
   <h2 id="_idParaDest-215">
    <a id="_idTextAnchor218">
    </a>
    <span class="koboSpan" id="kobo.184.1">
     Genomics and gene regulatory networks
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.185.1">
     Graph deep
    </span>
    <a id="_idIndexMarker800">
    </a>
    <span class="koboSpan" id="kobo.186.1">
     learning approaches
    </span>
    <a id="_idIndexMarker801">
    </a>
    <span class="koboSpan" id="kobo.187.1">
     are advancing our understanding of gene regulation and
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.188.1">
      genomic architecture:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.189.1">
       Enhancer-promoter interaction prediction
      </span>
     </strong>
     <span class="koboSpan" id="kobo.190.1">
      : GNNs can model the 3D structure of chromatin to predict long-range regulatory interactions.
     </span>
     <span class="koboSpan" id="kobo.190.2">
      The model by Sun et al.
     </span>
     <span class="koboSpan" id="kobo.190.3">
      (
     </span>
     <a href="https://genomebiology.biomedcentral.com/articles/10.1186/s13059-023-02916-x">
      <span class="koboSpan" id="kobo.191.1">
       https://genomebiology.biomedcentral.com/articles/10.1186/s13059-023-02916-x
      </span>
     </a>
     <span class="koboSpan" id="kobo.192.1">
      ) uses GCNs on Hi-C data for
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.193.1">
       this task.
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.194.1">
       Variant effect prediction
      </span>
     </strong>
     <span class="koboSpan" id="kobo.195.1">
      : GNNs can model the impact of genetic variants on gene regulation and phenotypes.
     </span>
     <span class="koboSpan" id="kobo.195.2">
      The
     </span>
     <strong class="bold">
      <span class="koboSpan" id="kobo.196.1">
       ExPecto model
      </span>
     </strong>
     <span class="koboSpan" id="kobo.197.1">
      by
     </span>
     <a id="_idIndexMarker802">
     </a>
     <span class="koboSpan" id="kobo.198.1">
      Zhou et al.
     </span>
     <span class="koboSpan" id="kobo.198.2">
      (
     </span>
     <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6094955">
      <span class="koboSpan" id="kobo.199.1">
       https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6094955
      </span>
     </a>
     <span class="koboSpan" id="kobo.200.1">
      ) uses a deep learning approach that incorporates regulatory grammar to predict variant effects on
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.201.1">
       gene expression.
      </span>
     </span>
    </li>
   </ul>
   <p>
    <span class="koboSpan" id="kobo.202.1">
     Graph deep learning methods are making significant impacts across various domains in biology and healthcare.
    </span>
    <span class="koboSpan" id="kobo.202.2">
     By effectively modeling complex relational data, these approaches are advancing our understanding of biological systems and improving
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.203.1">
      clinical decision-making.
     </span>
    </span>
   </p>
   <h1 id="_idParaDest-216">
    <a id="_idTextAnchor219">
    </a>
    <span class="koboSpan" id="kobo.204.1">
     Social network analysis
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.205.1">
     Social networks provide rich
    </span>
    <a id="_idIndexMarker803">
    </a>
    <span class="koboSpan" id="kobo.206.1">
     relational data that can be naturally represented as graphs, with users as
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.207.1">
      nodes
     </span>
    </em>
    <span class="koboSpan" id="kobo.208.1">
     and connections between users as
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.209.1">
      edges
     </span>
    </em>
    <span class="koboSpan" id="kobo.210.1">
     .
    </span>
    <span class="koboSpan" id="kobo.210.2">
     Graph deep learning techniques have emerged as powerful tools for analyzing and extracting insights from social
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.211.1">
      network data.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-217">
    <a id="_idTextAnchor220">
    </a>
    <span class="koboSpan" id="kobo.212.1">
     Community detection
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.213.1">
     Community
    </span>
    <a id="_idIndexMarker804">
    </a>
    <span class="koboSpan" id="kobo.214.1">
     detection aims to identify clusters or groups of densely connected users within a social network, as shown in
    </span>
    <span class="No-Break">
     <em class="italic">
      <span class="koboSpan" id="kobo.215.1">
       Figure 11
      </span>
     </em>
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.216.1">
      .1
     </span>
    </em>
    <span class="koboSpan" id="kobo.217.1">
     .
    </span>
    <span class="koboSpan" id="kobo.217.2">
     Traditional community detection algorithms, such as modularity optimization or spectral clustering, often struggle with large-scale networks.
    </span>
    <span class="koboSpan" id="kobo.217.3">
     GNNs offer a promising alternative by learning node embeddings that capture both local and global
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.218.1">
      network structures:
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer348">
     <span class="koboSpan" id="kobo.219.1">
      <img alt="Figure 11.1 – Community detection" src="image/B22118_11_01.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.220.1">
     Figure 11.1 – Community detection
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.221.1">
     For instance, Wang et al.
    </span>
    <span class="koboSpan" id="kobo.221.2">
     (2024) (
    </span>
    <a href="https://doi.org/10.1016/j.neucom.2024.127703">
     <span class="koboSpan" id="kobo.222.1">
      https://doi.org/10.1016/j.neucom.2024.127703
     </span>
    </a>
    <span class="koboSpan" id="kobo.223.1">
     ) proposed
    </span>
    <a id="_idIndexMarker805">
    </a>
    <span class="koboSpan" id="kobo.224.1">
     a
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.225.1">
      graph autoencoder
     </span>
    </strong>
    <span class="koboSpan" id="kobo.226.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.227.1">
      GAE
     </span>
    </strong>
    <span class="koboSpan" id="kobo.228.1">
     ) approach
    </span>
    <a id="_idIndexMarker806">
    </a>
    <span class="koboSpan" id="kobo.229.1">
     for community detection.
    </span>
    <span class="koboSpan" id="kobo.229.2">
     The model uses graph convolutional layers to encode nodes into a low-dimensional latent space, then attempts to reconstruct the graph structure from these embeddings.
    </span>
    <span class="koboSpan" id="kobo.229.3">
     By training on the reconstruction task, the embeddings naturally cluster nodes belonging to the same community.
    </span>
    <span class="koboSpan" id="kobo.229.4">
     The decoder can then be used to assign
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.230.1">
      community labels.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-218">
    <a id="_idTextAnchor221">
    </a>
    <span class="koboSpan" id="kobo.231.1">
     Influence propagation modeling
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.232.1">
     Understanding
    </span>
    <a id="_idIndexMarker807">
    </a>
    <span class="koboSpan" id="kobo.233.1">
     how information and influence spread through social networks is crucial for applications such as viral marketing and public health campaigns.
    </span>
    <span class="koboSpan" id="kobo.233.2">
     GNNs can model complex diffusion dynamics by learning how node attributes and network structure impact
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.234.1">
      propagation patterns.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.235.1">
     The
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.236.1">
      DeepInf model
     </span>
    </strong>
    <span class="koboSpan" id="kobo.237.1">
     by Qiu et al.
    </span>
    <span class="koboSpan" id="kobo.237.2">
     (
    </span>
    <a href="https://dl.acm.org/doi/10.1145/3219819.3220077">
     <span class="koboSpan" id="kobo.238.1">
      https://dl.acm.org/doi/10.1145/3219819.3220077
     </span>
    </a>
    <span class="koboSpan" id="kobo.239.1">
     ) uses a GAT to predict whether a user will be
    </span>
    <a id="_idIndexMarker808">
    </a>
    <span class="koboSpan" id="kobo.240.1">
     influenced to adopt a behavior based on their local network neighborhood.
    </span>
    <span class="koboSpan" id="kobo.240.2">
     The attention mechanism allows the model to focus on the most influential neighbors when
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.241.1">
      making predictions.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-219">
    <a id="_idTextAnchor222">
    </a>
    <span class="koboSpan" id="kobo.242.1">
     User behavior prediction
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.243.1">
     Predicting user
    </span>
    <a id="_idIndexMarker809">
    </a>
    <span class="koboSpan" id="kobo.244.1">
     behaviors and preferences is a key task for recommender systems and targeted advertising.
    </span>
    <span class="koboSpan" id="kobo.244.2">
     GNNs can improve predictions by incorporating social context and
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.245.1">
      network effects.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.246.1">
     For example, the
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.247.1">
      GraphRec model
     </span>
    </strong>
    <span class="koboSpan" id="kobo.248.1">
     by Fan et al.
    </span>
    <span class="koboSpan" id="kobo.248.2">
     (
    </span>
    <a href="https://arxiv.org/abs/1902.07243">
     <span class="koboSpan" id="kobo.249.1">
      https://arxiv.org/abs/1902.07243
     </span>
    </a>
    <span class="koboSpan" id="kobo.250.1">
     ) uses a GCN to
    </span>
    <a id="_idIndexMarker810">
    </a>
    <span class="koboSpan" id="kobo.251.1">
     learn user and item embeddings from a user-item interaction graph for social recommendation.
    </span>
    <span class="koboSpan" id="kobo.251.2">
     The model also incorporates a social aggregation layer to capture influence from a user’s
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.252.1">
      social connections.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-220">
    <a id="_idTextAnchor223">
    </a>
    <span class="koboSpan" id="kobo.253.1">
     Fake news detection
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.254.1">
     The spread of
    </span>
    <a id="_idIndexMarker811">
    </a>
    <span class="koboSpan" id="kobo.255.1">
     misinformation on social media has become a major societal challenge.
    </span>
    <span class="koboSpan" id="kobo.255.2">
     Graph-based deep learning models can help detect fake news by analyzing both content features and
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.256.1">
      propagation patterns.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.257.1">
     For instance, the
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.258.1">
      GCAN model
     </span>
    </strong>
    <span class="koboSpan" id="kobo.259.1">
     by Lu
    </span>
    <a id="_idIndexMarker812">
    </a>
    <span class="koboSpan" id="kobo.260.1">
     and Li (
    </span>
    <a href="https://aclanthology.org/2020.acl-main.48">
     <span class="koboSpan" id="kobo.261.1">
      https://aclanthology.org/2020.acl-main.48
     </span>
    </a>
    <span class="koboSpan" id="kobo.262.1">
     ) uses a graph-aware
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.263.1">
      co-attention network
     </span>
    </strong>
    <span class="koboSpan" id="kobo.264.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.265.1">
      CAN
     </span>
    </strong>
    <span class="koboSpan" id="kobo.266.1">
     ) to jointly
    </span>
    <a id="_idIndexMarker813">
    </a>
    <span class="koboSpan" id="kobo.267.1">
     model news content and user engagement patterns.
    </span>
    <span class="koboSpan" id="kobo.267.2">
     The model learns representations of news articles, user profiles, and user-news interactions to
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.268.1">
      make predictions.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.269.1">
     By capturing complex relational structures and learning rich node representations, GNNs can improve
    </span>
    <a id="_idIndexMarker814">
    </a>
    <span class="koboSpan" id="kobo.270.1">
     performance on a wide range of social network
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.271.1">
      analysis tasks.
     </span>
    </span>
   </p>
   <h1 id="_idParaDest-221">
    <a id="_idTextAnchor224">
    </a>
    <span class="koboSpan" id="kobo.272.1">
     Financial services
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.273.1">
     Graph-based deep
    </span>
    <a id="_idIndexMarker815">
    </a>
    <span class="koboSpan" id="kobo.274.1">
     learning models have emerged as powerful tools for analyzing complex relationships and patterns in financial data.
    </span>
    <span class="koboSpan" id="kobo.274.2">
     By representing financial entities and their interactions as nodes and edges in a graph, these models can capture intricate dependencies that traditional methods
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.275.1">
      often miss.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-222">
    <a id="_idTextAnchor225">
    </a>
    <span class="koboSpan" id="kobo.276.1">
     Fraud detection in transaction networks
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.277.1">
     One of the most
    </span>
    <a id="_idIndexMarker816">
    </a>
    <span class="koboSpan" id="kobo.278.1">
     impactful applications of graph-based deep learning in finance is detecting fraudulent activities in transaction networks.
    </span>
    <span class="koboSpan" id="kobo.278.2">
     Traditional fraud detection systems often rely on rule-based approaches or analyze transactions in isolation.
    </span>
    <span class="koboSpan" id="kobo.278.3">
     However, fraudulent behaviors frequently involve complex patterns of interactions between multiple entities
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.279.1">
      over time.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.280.1">
     GNNs can model entire transaction networks, where nodes represent accounts or users, and edges represent transactions or relationships between entities.
    </span>
    <span class="koboSpan" id="kobo.280.2">
     By propagating and aggregating information across the graph structure, GNNs can identify suspicious patterns that may be invisible when looking at individual
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.281.1">
      transactions alone.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.282.1">
     For instance, a team at Alibaba developed a GNN-based fraud detection system called
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.283.1">
      GraphConsis
     </span>
    </strong>
    <span class="koboSpan" id="kobo.284.1">
     that
    </span>
    <a id="_idIndexMarker817">
    </a>
    <span class="koboSpan" id="kobo.285.1">
     significantly outperformed traditional methods.
    </span>
    <span class="koboSpan" id="kobo.285.2">
     The model represents users, merchants, and devices as nodes in a heterogeneous graph, with edges representing various types of interactions.
    </span>
    <span class="koboSpan" id="kobo.285.3">
     By learning node embeddings that capture both local and global graph structures, GraphConsis can identify coordinated fraud rings and detect subtle anomalies in
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.286.1">
      transaction patterns.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-223">
    <a id="_idTextAnchor226">
    </a>
    <span class="koboSpan" id="kobo.287.1">
     Credit risk assessment
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.288.1">
     Assessing creditworthiness
    </span>
    <a id="_idIndexMarker818">
    </a>
    <span class="koboSpan" id="kobo.289.1">
     is a critical task for financial institutions.
    </span>
    <span class="koboSpan" id="kobo.289.2">
     Graph-based models can enhance credit scoring by incorporating diverse data sources and modeling complex relationships between borrowers, their financial activities, and
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.290.1">
      external factors.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.291.1">
     For example, researchers have proposed multiple graph-based credit scoring models.
    </span>
    <span class="koboSpan" id="kobo.291.2">
     These approaches construct a graph where
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.292.1">
      nodes
     </span>
    </em>
    <span class="koboSpan" id="kobo.293.1">
     represent loan applicants and
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.294.1">
      edges
     </span>
    </em>
    <span class="koboSpan" id="kobo.295.1">
     represent similarities between applicants based on various features.
    </span>
    <span class="koboSpan" id="kobo.295.2">
     The models then use GCNs to propagate credit information across similar applicants, leading to more accurate and robust credit scores.
    </span>
    <span class="koboSpan" id="kobo.295.3">
     Such models can also incorporate domain knowledge as constraints during
    </span>
    <a id="_idIndexMarker819">
    </a>
    <span class="koboSpan" id="kobo.296.1">
     the learning process, ensuring the model’s predictions align with established
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.297.1">
      financial principles.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-224">
    <a id="_idTextAnchor227">
    </a>
    <span class="koboSpan" id="kobo.298.1">
     Stock market prediction using company relationship graphs
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.299.1">
     The stock market i
    </span>
    <a id="_idIndexMarker820">
    </a>
    <span class="koboSpan" id="kobo.300.1">
     s a complex system where companies’ performances are often interrelated due to supply chain relationships, competition, and broader economic factors.
    </span>
    <span class="koboSpan" id="kobo.300.2">
     Graph-based models can capture these intricate relationships to improve stock price prediction and
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.301.1">
      portfolio management.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.302.1">
     A study by researchers introduced the
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.303.1">
      long short-term memory graph convolutional neural network
     </span>
    </strong>
    <span class="koboSpan" id="kobo.304.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.305.1">
      LSTM-GCN
     </span>
    </strong>
    <span class="koboSpan" id="kobo.306.1">
     ) model
    </span>
    <a id="_idIndexMarker821">
    </a>
    <span class="koboSpan" id="kobo.307.1">
     for stock market prediction (
    </span>
    <a href="https://arxiv.org/abs/2303.09406">
     <span class="koboSpan" id="kobo.308.1">
      https://arxiv.org/abs/2303.09406
     </span>
    </a>
    <span class="koboSpan" id="kobo.309.1">
     ).
    </span>
    <span class="koboSpan" id="kobo.309.2">
     This model constructs a dynamic graph of companies, where edges represent value chain relationships and correlations in historical stock prices.
    </span>
    <span class="koboSpan" id="kobo.309.3">
     The LSTM-GCN model then learns to aggregate information from neighboring companies and across time to predict future
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.310.1">
      stock prices.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-225">
    <a id="_idTextAnchor228">
    </a>
    <span class="koboSpan" id="kobo.311.1">
     Anti-money laundering systems
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.312.1">
     Money laundering
    </span>
    <a id="_idIndexMarker822">
    </a>
    <span class="koboSpan" id="kobo.313.1">
     often involves complex networks of transactions designed to obscure the origin of illicit funds.
    </span>
    <span class="koboSpan" id="kobo.313.2">
     Graph-based deep learning models are particularly well suited
    </span>
    <a id="_idIndexMarker823">
    </a>
    <span class="koboSpan" id="kobo.314.1">
     for
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.315.1">
      anti-money laundering
     </span>
    </strong>
    <span class="koboSpan" id="kobo.316.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.317.1">
      AML
     </span>
    </strong>
    <span class="koboSpan" id="kobo.318.1">
     ) applications, as they can analyze entire transaction networks to identify
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.319.1">
      suspicious patterns.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.320.1">
     For example, researchers have developed a GNN-based AML system called
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.321.1">
      GCN-AML
     </span>
    </strong>
    <span class="koboSpan" id="kobo.322.1">
     that operates on Bitcoin
    </span>
    <a id="_idIndexMarker824">
    </a>
    <span class="koboSpan" id="kobo.323.1">
     transaction graphs (
    </span>
    <a href="https://arxiv.org/abs/1908.02591">
     <span class="koboSpan" id="kobo.324.1">
      https://arxiv.org/abs/1908.02591
     </span>
    </a>
    <span class="koboSpan" id="kobo.325.1">
     ).
    </span>
    <span class="koboSpan" id="kobo.325.2">
     The model represents Bitcoin addresses as nodes and transactions as edges in a large-scale graph.
    </span>
    <span class="koboSpan" id="kobo.325.3">
     By applying GCNs to this structure, GCN-AML learns to identify patterns indicative of money laundering activities, such as layering and integration of funds.
    </span>
    <span class="koboSpan" id="kobo.325.4">
     The system demonstrated high accuracy in detecting known money laundering cases while also uncovering
    </span>
    <a id="_idIndexMarker825">
    </a>
    <span class="koboSpan" id="kobo.326.1">
     previously unidentified
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.327.1">
      suspicious activities.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-226">
    <a id="_idTextAnchor229">
    </a>
    <span class="koboSpan" id="kobo.328.1">
     Personalized financial recommendations
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.329.1">
     Graph-based models
    </span>
    <a id="_idIndexMarker826">
    </a>
    <span class="koboSpan" id="kobo.330.1">
     can also enhance personalized financial services by modeling relationships between customers, products, and
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.331.1">
      financial behaviors.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.332.1">
     For instance, a major bank implemented a GNN-based recommendation system for personalized financial product offerings.
    </span>
    <span class="koboSpan" id="kobo.332.2">
     The system constructs a heterogeneous graph incorporating
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.333.1">
      customer nodes
     </span>
    </em>
    <span class="koboSpan" id="kobo.334.1">
     ,
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.335.1">
      product nodes
     </span>
    </em>
    <span class="koboSpan" id="kobo.336.1">
     , and various
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.337.1">
      interaction edges
     </span>
    </em>
    <span class="koboSpan" id="kobo.338.1">
     (for example, past purchases, inquiries, and demographic similarities).
    </span>
    <span class="koboSpan" id="kobo.338.2">
     By learning embeddings that capture both customer preferences and product characteristics, the GNN can generate highly relevant and personalized product recommendations, leading to increased customer satisfaction and product
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.339.1">
      adoption rates.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-227">
    <a id="_idTextAnchor230">
    </a>
    <span class="koboSpan" id="kobo.340.1">
     Systemic risk assessment
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.341.1">
     Regulators and
    </span>
    <a id="_idIndexMarker827">
    </a>
    <span class="koboSpan" id="kobo.342.1">
     central banks are increasingly interested in using graph-based models to assess systemic risks in financial networks, particularly in the wake of the 2008
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.343.1">
      financial crisis.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.344.1">
     For example, researchers have proposed using GNNs to model interbank lending networks and predict systemic risks.
    </span>
    <span class="koboSpan" id="kobo.344.2">
     By representing banks as nodes and their lending relationships as edges, GNNs can learn to identify vulnerable institutions and potential contagion paths in the financial system.
    </span>
    <span class="koboSpan" id="kobo.344.3">
     This approach allows for more dynamic and data-driven systemic risk assessments compared to traditional stress
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.345.1">
      testing methods.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.346.1">
     Graph-based deep learning models offer powerful tools for analyzing the complex, interconnected nature of financial systems.
    </span>
    <span class="koboSpan" id="kobo.346.2">
     As these techniques continue to evolve, we can expect to see even more sophisticated applications that leverage the rich relational structure of financial data to improve decision-making, risk management, and customer experiences
    </span>
    <a id="_idIndexMarker828">
    </a>
    <span class="koboSpan" id="kobo.347.1">
     across the financial
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.348.1">
      services industry.
     </span>
    </span>
   </p>
   <h1 id="_idParaDest-228">
    <a id="_idTextAnchor231">
    </a>
    <span class="koboSpan" id="kobo.349.1">
     Cybersecurity
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.350.1">
     GNNs have emerged
    </span>
    <a id="_idIndexMarker829">
    </a>
    <span class="koboSpan" id="kobo.351.1">
     as a powerful tool for cybersecurity applications, leveraging the inherent graph structure of many security-related datasets to detect threats
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.352.1">
      and anomalies.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-229">
    <a id="_idTextAnchor232">
    </a>
    <span class="koboSpan" id="kobo.353.1">
     Why graphs for cybersecurity?
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.354.1">
     Many cybersecurity
    </span>
    <a id="_idIndexMarker830">
    </a>
    <span class="koboSpan" id="kobo.355.1">
     datasets and problems naturally lend themselves to
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.356.1">
      graph representations:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <span class="koboSpan" id="kobo.357.1">
      Network traffic and communications can be modeled as graphs, with devices as
     </span>
     <em class="italic">
      <span class="koboSpan" id="kobo.358.1">
       nodes
      </span>
     </em>
     <span class="koboSpan" id="kobo.359.1">
      and connections
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.360.1">
       as
      </span>
     </span>
     <span class="No-Break">
      <em class="italic">
       <span class="koboSpan" id="kobo.361.1">
        edges
       </span>
      </em>
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.362.1">
       .
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.363.1">
      System call traces form temporal graphs of
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.364.1">
       process interactions.
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.365.1">
      Social networks used for fraud detection are
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.366.1">
       inherently graph-structured.
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.367.1">
      Software dependency graphs represent relationships between
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.368.1">
       code components.
      </span>
     </span>
    </li>
   </ul>
   <p>
    <span class="koboSpan" id="kobo.369.1">
     By using graph-based models, we can capture and analyze complex relationships and patterns that may be missed by
    </span>
    <a id="_idIndexMarker831">
    </a>
    <span class="koboSpan" id="kobo.370.1">
     traditional
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.371.1">
      machine learning
     </span>
    </strong>
    <span class="koboSpan" id="kobo.372.1">
     (
    </span>
    <span class="No-Break">
     <strong class="bold">
      <span class="koboSpan" id="kobo.373.1">
       ML
      </span>
     </strong>
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.374.1">
      ) approaches.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-230">
    <a id="_idTextAnchor233">
    </a>
    <span class="koboSpan" id="kobo.375.1">
     Network intrusion detection
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.376.1">
     GNNs have shown
    </span>
    <a id="_idIndexMarker832">
    </a>
    <span class="koboSpan" id="kobo.377.1">
     promise for detecting network intrusions and anomalies by analyzing traffic patterns.
    </span>
    <span class="koboSpan" id="kobo.377.2">
     In this application, the following points
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.378.1">
      are relevant:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <em class="italic">
      <span class="koboSpan" id="kobo.379.1">
       Nodes
      </span>
     </em>
     <span class="koboSpan" id="kobo.380.1">
      represent devices or
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.381.1">
       IP addresses.
      </span>
     </span>
    </li>
    <li>
     <em class="italic">
      <span class="koboSpan" id="kobo.382.1">
       Edges
      </span>
     </em>
     <span class="koboSpan" id="kobo.383.1">
      represent network connections or
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.384.1">
       data transfers.
      </span>
     </span>
    </li>
    <li>
     <em class="italic">
      <span class="koboSpan" id="kobo.385.1">
       Node features
      </span>
     </em>
     <span class="koboSpan" id="kobo.386.1">
      may include device type, operating system, and
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.387.1">
       so on.
      </span>
     </span>
    </li>
    <li>
     <em class="italic">
      <span class="koboSpan" id="kobo.388.1">
       Edge features
      </span>
     </em>
     <span class="koboSpan" id="kobo.389.1">
      may include protocol, port numbers, data volume, and
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.390.1">
       so on.
      </span>
     </span>
    </li>
   </ul>
   <p>
    <span class="koboSpan" id="kobo.391.1">
     A GNN can learn to identify suspicious patterns of communication that may indicate an ongoing attack or compromised device.
    </span>
    <span class="koboSpan" id="kobo.391.2">
     For example, a GNN-based
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.392.1">
      intrusion detection system
     </span>
    </strong>
    <span class="koboSpan" id="kobo.393.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.394.1">
      IDS
     </span>
    </strong>
    <span class="koboSpan" id="kobo.395.1">
     ) might
    </span>
    <a id="_idIndexMarker833">
    </a>
    <span class="koboSpan" id="kobo.396.1">
     flag unusual data transfers between nodes that don’t typically communicate or identify
    </span>
    <a id="_idIndexMarker834">
    </a>
    <span class="koboSpan" id="kobo.397.1">
     a node suddenly establishing many
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.398.1">
      new connections:
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer349">
     <span class="koboSpan" id="kobo.399.1">
      <img alt="Figure 11.2 – Intrusion detection using graph learning" src="image/B22118_11_02.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.400.1">
     Figure 11.2 – Intrusion detection using graph learning
    </span>
   </p>
   <h2 id="_idParaDest-231">
    <a id="_idTextAnchor234">
    </a>
    <span class="koboSpan" id="kobo.401.1">
     Malware detection
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.402.1">
     Graph representations
    </span>
    <a id="_idIndexMarker835">
    </a>
    <span class="koboSpan" id="kobo.403.1">
     of program behavior, such as system call graphs or control flow graphs, can be analyzed using GNNs to detect malicious software.
    </span>
    <span class="koboSpan" id="kobo.403.2">
     In this case, note
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.404.1">
      the following:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <em class="italic">
      <span class="koboSpan" id="kobo.405.1">
       Nodes
      </span>
     </em>
     <span class="koboSpan" id="kobo.406.1">
      represent system calls or
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.407.1">
       code blocks.
      </span>
     </span>
    </li>
    <li>
     <em class="italic">
      <span class="koboSpan" id="kobo.408.1">
       Edges
      </span>
     </em>
     <span class="koboSpan" id="kobo.409.1">
      represent temporal ordering or
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.410.1">
       control flow.
      </span>
     </span>
    </li>
    <li>
     <em class="italic">
      <span class="koboSpan" id="kobo.411.1">
       Node features
      </span>
     </em>
     <span class="koboSpan" id="kobo.412.1">
      may include call types, arguments, return values, and
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.413.1">
       so on.
      </span>
     </span>
    </li>
   </ul>
   <p>
    <span class="koboSpan" id="kobo.414.1">
     GNNs can learn to distinguish between benign and malicious behavioral patterns.
    </span>
    <span class="koboSpan" id="kobo.414.2">
     For instance, a GNN might identify sequences of system calls characteristic of ransomware file
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.415.1">
      encryption operations.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.416.1">
     Let’s take an example
    </span>
    <a id="_idIndexMarker836">
    </a>
    <span class="koboSpan" id="kobo.417.1">
     of
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.418.1">
      advanced persistent threat
     </span>
    </strong>
    <span class="koboSpan" id="kobo.419.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.420.1">
      APT
     </span>
    </strong>
    <span class="koboSpan" id="kobo.421.1">
     ) detection.
    </span>
    <span class="koboSpan" id="kobo.421.2">
     APTs are sophisticated, long-term cyber-attacks that are particularly challenging to detect.
    </span>
    <span class="koboSpan" id="kobo.421.3">
     Let’s consider a hypothetical GNN-based APT
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.422.1">
      detection system:
     </span>
    </span>
   </p>
   <ol>
    <li>
     <span class="No-Break">
      <strong class="bold">
       <span class="koboSpan" id="kobo.423.1">
        Graph construction
       </span>
      </strong>
     </span>
     <ul>
      <li>
       <em class="italic">
        <span class="koboSpan" id="kobo.424.1">
         Nodes
        </span>
       </em>
       <span class="koboSpan" id="kobo.425.1">
        represent
       </span>
       <a id="_idIndexMarker837">
       </a>
       <span class="koboSpan" id="kobo.426.1">
        network entities (devices, users,
       </span>
       <span class="No-Break">
        <span class="koboSpan" id="kobo.427.1">
         IP addresses).
        </span>
       </span>
      </li>
      <li>
       <em class="italic">
        <span class="koboSpan" id="kobo.428.1">
         Edges
        </span>
       </em>
       <span class="koboSpan" id="kobo.429.1">
        represent communications or
       </span>
       <span class="No-Break">
        <span class="koboSpan" id="kobo.430.1">
         access events.
        </span>
       </span>
      </li>
      <li>
       <em class="italic">
        <span class="koboSpan" id="kobo.431.1">
         Node features
        </span>
       </em>
       <span class="koboSpan" id="kobo.432.1">
        include device types, installed software, and
       </span>
       <span class="No-Break">
        <span class="koboSpan" id="kobo.433.1">
         user roles.
        </span>
       </span>
      </li>
      <li>
       <em class="italic">
        <span class="koboSpan" id="kobo.434.1">
         Edge features
        </span>
       </em>
       <span class="koboSpan" id="kobo.435.1">
        include communication protocols, data volumes,
       </span>
       <span class="No-Break">
        <span class="koboSpan" id="kobo.436.1">
         and timestamps.
        </span>
       </span>
       <p class="list-inset">
        <span class="koboSpan" id="kobo.437.1">
         Let’s look at
        </span>
        <a id="_idIndexMarker838">
        </a>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.438.1">
          an example:
         </span>
        </span>
       </p>
       <pre class="source-code"><span class="koboSpan" id="kobo.439.1">
def construct_graph(network_data):
    # devices, users, IP addresses
    nodes = create_nodes(network_data)
    # communications, access events
    edges = create_edges(network_data)
    for node in nodes:
        # device type, software, user role
        node.features = extract_node_features(node)
    for edge in edges:
        # protocol, data volume, timestamp
        edge.features = extract_edge_features(edge)
    return Graph(nodes, edges)</span></pre>
      </li>
     </ul>
    </li>
    <li>
     <span class="No-Break">
      <strong class="bold">
       <span class="koboSpan" id="kobo.440.1">
        GNN architecture
       </span>
      </strong>
     </span>
     <ul>
      <li>
       <span class="koboSpan" id="kobo.441.1">
        Use a GAT to
       </span>
       <a id="_idIndexMarker839">
       </a>
       <span class="koboSpan" id="kobo.442.1">
        learn
       </span>
       <span class="No-Break">
        <span class="koboSpan" id="kobo.443.1">
         node embeddings.
        </span>
       </span>
      </li>
      <li>
       <em class="italic">
        <span class="koboSpan" id="kobo.444.1">
         Temporal edges
        </span>
       </em>
       <span class="koboSpan" id="kobo.445.1">
        are handled with a recurrent
       </span>
       <a id="_idIndexMarker840">
       </a>
       <span class="koboSpan" id="kobo.446.1">
        mechanism (for example,
       </span>
       <strong class="bold">
        <span class="koboSpan" id="kobo.447.1">
         gated recurrent unit
        </span>
       </strong>
       <span class="koboSpan" id="kobo.448.1">
        (
       </span>
       <span class="No-Break">
        <strong class="bold">
         <span class="koboSpan" id="kobo.449.1">
          GRU
         </span>
        </strong>
       </span>
       <span class="No-Break">
        <span class="koboSpan" id="kobo.450.1">
         ) cells).
        </span>
       </span>
      </li>
      <li>
       <span class="koboSpan" id="kobo.451.1">
        Multiple GNN layers capture
       </span>
       <span class="No-Break">
        <span class="koboSpan" id="kobo.452.1">
         multi-hop relationships.
        </span>
       </span>
       <p class="list-inset">
        <span class="koboSpan" id="kobo.453.1">
         Here’s how this
        </span>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.454.1">
          could work:
         </span>
        </span>
       </p>
       <pre class="source-code"><span class="koboSpan" id="kobo.455.1">
class APTDetectionGNN(nn.Module):
    def __init__(self, in_features, hidden_features,
                 num_layers):
        super().__init__()
        self.gat_layers = nn.ModuleList([
            GATConv(in_features if i == 0 else hidden_features, 
                    hidden_features
            )for i in range(num_layers)
        ])
        self.gru = nn.GRU(hidden_features, hidden_features)
        self.output = nn.Linear(hidden_features, 1)
    def forward(self, x, edge_index, edge_attr):
        for gat in self.gat_layers:
            x = F.relu(gat(x, edge_index, edge_attr))
        x, _ = self.gru(x.unsqueeze(0))
        return self.output(x.squeeze(0)).squeeze(-1)</span></pre>
      </li>
     </ul>
    </li>
    <li>
     <span class="No-Break">
      <strong class="bold">
       <span class="koboSpan" id="kobo.456.1">
        Training
       </span>
      </strong>
     </span>
     <p class="list-inset">
      <span class="koboSpan" id="kobo.457.1">
       Here is how we will write a model training code for APT incident detection using historical
      </span>
      <span class="No-Break">
       <span class="koboSpan" id="kobo.458.1">
        labeled data.
       </span>
      </span>
     </p>
     <pre class="source-code"><span class="koboSpan" id="kobo.459.1">
def train_model(model, labeled_data, unlabeled_data, 
                num_epochs=10):
    optimizer = torch.optim.Adam(model.parameters())
    
    for epoch in range(num_epochs):
        model.train()
        
        # Supervised learning
        optimizer.zero_grad()
        x, edge_index, edge_attr, y = labeled_data
        out = model(x, edge_index, edge_attr)
        loss = F.binary_cross_entropy_with_logits(out, y)
        loss.backward()
        optimizer.step()
        
        # Print training progress
        if epoch % 2 == 0:
            print(f"Epoch {epoch}, Loss: {loss.item():.4f}")</span></pre>
    </li>
    <li>
     <span class="No-Break">
      <strong class="bold">
       <span class="koboSpan" id="kobo.460.1">
        Detection
       </span>
      </strong>
     </span>
     <ul>
      <li>
       <span class="koboSpan" id="kobo.461.1">
        The GNN
       </span>
       <a id="_idIndexMarker841">
       </a>
       <span class="koboSpan" id="kobo.462.1">
        outputs anomaly scores for
       </span>
       <span class="No-Break">
        <span class="koboSpan" id="kobo.463.1">
         each node.
        </span>
       </span>
      </li>
      <li>
       <span class="koboSpan" id="kobo.464.1">
        Nodes with high anomaly scores are flagged
       </span>
       <span class="No-Break">
        <span class="koboSpan" id="kobo.465.1">
         for investigation.
        </span>
       </span>
      </li>
      <li>
       <span class="koboSpan" id="kobo.466.1">
        Attention weights can be analyzed to explain which connections contributed to the
       </span>
       <span class="No-Break">
        <span class="koboSpan" id="kobo.467.1">
         anomaly score.
        </span>
       </span>
       <p class="list-inset">
        <span class="koboSpan" id="kobo.468.1">
         Let’s take the
        </span>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.469.1">
          following approach:
         </span>
        </span>
       </p>
       <pre class="source-code"><span class="koboSpan" id="kobo.470.1">
def detect_apts(model, graph, threshold=0.5):
    model.eval()
    with torch.no_grad():
        x, edge_index, edge_attr, _ = graph
        anomaly_scores = torch.sigmoid(model(
            x, edge_index, edge_attr))
        suspicious_nodes = (
            anomaly_scores &gt; threshold
        ).nonzero().flatten()
        
        results = []
        for node in suspicious_nodes:
            attention_weights = model.get_attention_ weights(
                node)
            results.append({
                'node': node.item(),
                'score': anomaly_scores[node].item(),
                'attention': attention_weights
            })
        
        return results</span></pre>
       <p class="list-inset">
        <span class="koboSpan" id="kobo.471.1">
         This approach
        </span>
        <a id="_idIndexMarker842">
        </a>
        <span class="koboSpan" id="kobo.472.1">
         could detect subtle APT patterns by connecting seemingly unrelated events, such as unusual login times, atypical system access, and low-volume data exfiltration, into a coherent picture of an ongoing attack.
        </span>
        <span class="koboSpan" id="kobo.472.2">
         The attention weights of the model could then be analyzed to explain which connections contributed to the anomaly score, providing
        </span>
        <a id="_idIndexMarker843">
        </a>
        <span class="koboSpan" id="kobo.473.1">
         valuable insights for
        </span>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.474.1">
          security teams.
         </span>
        </span>
       </p>
      </li>
     </ul>
    </li>
   </ol>
   <h1 id="_idParaDest-232">
    <a id="_idTextAnchor235">
    </a>
    <span class="koboSpan" id="kobo.475.1">
     Energy systems
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.476.1">
     Graph-based deep
    </span>
    <a id="_idIndexMarker844">
    </a>
    <span class="koboSpan" id="kobo.477.1">
     learning models can act as powerful tools for analyzing and optimizing complex energy systems.
    </span>
    <span class="koboSpan" id="kobo.477.2">
     By representing energy networks as graphs, these models can capture intricate relationships and dependencies between different components, enabling more accurate predictions, efficient control strategies, and
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.478.1">
      improved decision-making.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-233">
    <a id="_idTextAnchor236">
    </a>
    <span class="koboSpan" id="kobo.479.1">
     Graph representation of energy systems
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.480.1">
     Energy systems can
    </span>
    <a id="_idIndexMarker845">
    </a>
    <span class="koboSpan" id="kobo.481.1">
     be naturally represented as graphs, where
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.482.1">
      nodes
     </span>
    </em>
    <span class="koboSpan" id="kobo.483.1">
     typically represent physical components such as generators, transformers, transmission lines, and loads, while
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.484.1">
      edges
     </span>
    </em>
    <span class="koboSpan" id="kobo.485.1">
     represent connections and interactions between these components.
    </span>
    <span class="koboSpan" id="kobo.485.2">
     This graph structure allows us to model
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.486.1">
      the following:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <span class="koboSpan" id="kobo.487.1">
      Power flow
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.488.1">
       between components
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.489.1">
      Interdependencies in
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.490.1">
       the network
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.491.1">
      Spatial and
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.492.1">
       temporal relationships
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.493.1">
      System topology
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.494.1">
       and connectivity
      </span>
     </span>
    </li>
   </ul>
   <h2 id="_idParaDest-234">
    <a id="_idTextAnchor237">
    </a>
    <span class="koboSpan" id="kobo.495.1">
     Load forecasting
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.496.1">
     Graph-based deep
    </span>
    <a id="_idIndexMarker846">
    </a>
    <span class="koboSpan" id="kobo.497.1">
     learning models have shown superior performance in predicting electricity demand across power networks.
    </span>
    <span class="koboSpan" id="kobo.497.2">
     By incorporating the grid topology and spatial correlations between loads, these models can capture complex patterns more effectively than traditional time
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.498.1">
      series approaches.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.499.1">
     For example, a GCN-LSTM hybrid model can be used for short-term load forecasting in a city-wide power grid, where each
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.500.1">
      node
     </span>
    </em>
    <span class="koboSpan" id="kobo.501.1">
     represents a substation and
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.502.1">
      edges
     </span>
    </em>
    <span class="koboSpan" id="kobo.503.1">
     represent transmission lines.
    </span>
    <span class="koboSpan" id="kobo.503.2">
     The model aggregates information from neighboring substations and historical load
    </span>
    <a id="_idIndexMarker847">
    </a>
    <span class="koboSpan" id="kobo.504.1">
     data to make
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.505.1">
      accurate predictions.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-235">
    <a id="_idTextAnchor238">
    </a>
    <span class="koboSpan" id="kobo.506.1">
     Fault detection and localization
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.507.1">
     GNNs can analyze
    </span>
    <a id="_idIndexMarker848">
    </a>
    <span class="koboSpan" id="kobo.508.1">
     the propagation of anomalies through power networks, enabling rapid detection and localization
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.509.1">
      of faults.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.510.1">
     For instance, a GAT-based model can be used for identifying faulty components in a transmission network.
    </span>
    <span class="koboSpan" id="kobo.510.2">
     The attention mechanism allows the model to focus on the most relevant neighboring nodes when detecting anomalies, improving accuracy
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.511.1">
      and interpretability.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-236">
    <a id="_idTextAnchor239">
    </a>
    <span class="koboSpan" id="kobo.512.1">
     Optimal power flow
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.513.1">
     GNNs can learn to
    </span>
    <a id="_idIndexMarker849">
    </a>
    <span class="koboSpan" id="kobo.514.1">
     solve complex optimization problems such as
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.515.1">
      optimal power flow
     </span>
    </strong>
    <span class="koboSpan" id="kobo.516.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.517.1">
      OPF
     </span>
    </strong>
    <span class="koboSpan" id="kobo.518.1">
     ) more
    </span>
    <a id="_idIndexMarker850">
    </a>
    <span class="koboSpan" id="kobo.519.1">
     efficiently than
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.520.1">
      traditional methods.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.521.1">
     For example, a GNN-based mode can be trained to approximate OPF solutions, taking into account network constraints and renewable energy uncertainties.
    </span>
    <span class="koboSpan" id="kobo.521.2">
     The model can generate near-optimal solutions in milliseconds, enabling real-time optimization of
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.522.1">
      power dispatch.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-237">
    <a id="_idTextAnchor240">
    </a>
    <span class="koboSpan" id="kobo.523.1">
     Renewable energy forecasting
    </span>
   </h2>
   <p>
    <strong class="bold">
     <span class="koboSpan" id="kobo.524.1">
      Spatial-temporal GNNs
     </span>
    </strong>
    <span class="koboSpan" id="kobo.525.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.526.1">
      STGNNs
     </span>
    </strong>
    <span class="koboSpan" id="kobo.527.1">
     ) are
    </span>
    <a id="_idIndexMarker851">
    </a>
    <span class="koboSpan" id="kobo.528.1">
     particularly
    </span>
    <a id="_idIndexMarker852">
    </a>
    <span class="koboSpan" id="kobo.529.1">
     effective for forecasting renewable energy generation, as they can capture both spatial correlations (for example, between nearby wind farms) and
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.530.1">
      temporal patterns.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.531.1">
     For instance, an STGNN model can be
    </span>
    <a id="_idIndexMarker853">
    </a>
    <span class="koboSpan" id="kobo.532.1">
     used for predicting solar power generation across a network of
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.533.1">
      photovoltaic
     </span>
    </strong>
    <span class="koboSpan" id="kobo.534.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.535.1">
      PV
     </span>
    </strong>
    <span class="koboSpan" id="kobo.536.1">
     ) installations.
    </span>
    <span class="koboSpan" id="kobo.536.2">
     The model can incorporate weather data, historical generation, and spatial relationships between sites to improve
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.537.1">
      forecast accuracy.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-238">
    <a id="_idTextAnchor241">
    </a>
    <span class="koboSpan" id="kobo.538.1">
     Energy storage management
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.539.1">
     Graph-based
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.540.1">
      reinforcement learning
     </span>
    </strong>
    <span class="koboSpan" id="kobo.541.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.542.1">
      RL
     </span>
    </strong>
    <span class="koboSpan" id="kobo.543.1">
     ) models
    </span>
    <a id="_idIndexMarker854">
    </a>
    <span class="koboSpan" id="kobo.544.1">
     can
    </span>
    <a id="_idIndexMarker855">
    </a>
    <span class="koboSpan" id="kobo.545.1">
     optimize the operation of distributed energy storage systems, considering network constraints and
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.546.1">
      market conditions.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.547.1">
     For example, a
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.548.1">
      graph
     </span>
    </strong>
    <strong class="bold">
     <span class="koboSpan" id="kobo.549.1">
      reinforcement learning
     </span>
    </strong>
    <span class="koboSpan" id="kobo.550.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.551.1">
      GRL
     </span>
    </strong>
    <span class="koboSpan" id="kobo.552.1">
     ) agent
    </span>
    <a id="_idIndexMarker856">
    </a>
    <span class="koboSpan" id="kobo.553.1">
     can be used for coordinating a network of battery energy storage systems in a microgrid.
    </span>
    <span class="koboSpan" id="kobo.553.2">
     The agent can learn to charge and discharge batteries optimally, balancing renewable integration, peak shaving, and electricity
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.554.1">
      market participation.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-239">
    <a id="_idTextAnchor242">
    </a>
    <span class="koboSpan" id="kobo.555.1">
     Vulnerability assessment
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.556.1">
     GNNs can analyze the
    </span>
    <a id="_idIndexMarker857">
    </a>
    <span class="koboSpan" id="kobo.557.1">
     resilience of power grids to various disturbances and identify
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.558.1">
      critical components.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.559.1">
     For instance, a GCN-based model can be used for assessing the vulnerability of power grids to cascading failures.
    </span>
    <span class="koboSpan" id="kobo.559.2">
     The model can learn to predict the propagation of failures through the network and identify the most critical nodes for
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.560.1">
      system stability.
     </span>
    </span>
   </p>
   <h1 id="_idParaDest-240">
    <a id="_idTextAnchor243">
    </a>
    <span class="koboSpan" id="kobo.561.1">
     IoT
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.562.1">
     Graph-based deep
    </span>
    <a id="_idIndexMarker858">
    </a>
    <span class="koboSpan" id="kobo.563.1">
     learning models can be used for analyzing the complex interconnected nature of IoT systems.
    </span>
    <span class="koboSpan" id="kobo.563.2">
     By representing IoT devices, sensors, and their interactions as
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.564.1">
      nodes
     </span>
    </em>
    <span class="koboSpan" id="kobo.565.1">
     and
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.566.1">
      edges
     </span>
    </em>
    <span class="koboSpan" id="kobo.567.1">
     in a graph structure, these models can capture important relational information and dependencies that are crucial for various
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.568.1">
      IoT applications.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-241">
    <a id="_idTextAnchor244">
    </a>
    <span class="koboSpan" id="kobo.569.1">
     Device interaction modeling
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.570.1">
     One of the fundamental
    </span>
    <a id="_idIndexMarker859">
    </a>
    <span class="koboSpan" id="kobo.571.1">
     challenges in IoT systems is modeling the complex interactions between heterogeneous devices and sensors.
    </span>
    <span class="koboSpan" id="kobo.571.2">
     GNNs provide an elegant solution to this problem by naturally representing devices as
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.572.1">
      nodes
     </span>
    </em>
    <span class="koboSpan" id="kobo.573.1">
     and their communications or dependencies as
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.574.1">
      edges
     </span>
    </em>
    <span class="koboSpan" id="kobo.575.1">
     in
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.576.1">
      a graph.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.577.1">
     GCNs have been particularly effective for this task.
    </span>
    <span class="koboSpan" id="kobo.577.2">
     In a GCN, each node aggregates information from its neighbors through convolutional operations, allowing the model to learn representations that incorporate both node features and graph structure.
    </span>
    <span class="koboSpan" id="kobo.577.3">
     This enables the GCN to capture complex interaction patterns between
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.578.1">
      IoT devices.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.579.1">
     For example, in a smart home setting, a GCN could model the relationships between various smart appliances, environmental sensors, and user devices.
    </span>
    <span class="koboSpan" id="kobo.579.2">
     The model could learn how the activation of one device (for example, a motion sensor) influences the behavior of others (for example, lights or thermostats).
    </span>
    <span class="koboSpan" id="kobo.579.3">
     This learned representation can then be used for tasks
    </span>
    <a id="_idIndexMarker860">
    </a>
    <span class="koboSpan" id="kobo.580.1">
     such as predicting device states or optimizing overall
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.581.1">
      system performance.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-242">
    <a id="_idTextAnchor245">
    </a>
    <span class="koboSpan" id="kobo.582.1">
     Anomaly detection in sensor networks
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.583.1">
     Detecting anomalies in
    </span>
    <a id="_idIndexMarker861">
    </a>
    <span class="koboSpan" id="kobo.584.1">
     IoT sensor networks is crucial for identifying faults, security breaches, or unusual events.
    </span>
    <span class="koboSpan" id="kobo.584.2">
     Graph-based deep learning models excel at this task by leveraging spatial and temporal correlations between
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.585.1">
      sensor readings.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.586.1">
     GATs have shown promising results in this domain.
    </span>
    <span class="koboSpan" id="kobo.586.2">
     GATs use attention mechanisms to assign different weights to neighboring nodes, allowing the model to focus on the most relevant information for anomaly detection.
    </span>
    <span class="koboSpan" id="kobo.586.3">
     This is particularly useful in large-scale IoT deployments where not all sensor interactions are
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.587.1">
      equally important.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.588.1">
     In practice, a GAT-based anomaly detection system might work
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.589.1">
      as follows:
     </span>
    </span>
   </p>
   <ol>
    <li>
     <span class="koboSpan" id="kobo.590.1">
      Represent sensors as
     </span>
     <em class="italic">
      <span class="koboSpan" id="kobo.591.1">
       nodes
      </span>
     </em>
     <span class="koboSpan" id="kobo.592.1">
      in a graph, with
     </span>
     <em class="italic">
      <span class="koboSpan" id="kobo.593.1">
       edges
      </span>
     </em>
     <span class="koboSpan" id="kobo.594.1">
      based on physical proximity or
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.595.1">
       logical relationships.
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.596.1">
      Use historical sensor readings as
     </span>
     <span class="No-Break">
      <em class="italic">
       <span class="koboSpan" id="kobo.597.1">
        node features
       </span>
      </em>
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.598.1">
       .
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.599.1">
      Apply graph attention layers to learn representations that capture normal
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.600.1">
       behavior patterns.
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.601.1">
      Use these learned representations to identify deviations that may
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.602.1">
       indicate anomalies.
      </span>
     </span>
    </li>
   </ol>
   <p>
    <span class="koboSpan" id="kobo.603.1">
     This approach has been successfully applied to detect anomalies in urban water distribution
    </span>
    <a id="_idIndexMarker862">
    </a>
    <span class="koboSpan" id="kobo.604.1">
     networks,
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.605.1">
      industrial control systems
     </span>
    </strong>
    <span class="koboSpan" id="kobo.606.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.607.1">
      ICSs
     </span>
    </strong>
    <span class="koboSpan" id="kobo.608.1">
     ), and
    </span>
    <a id="_idIndexMarker863">
    </a>
    <span class="koboSpan" id="kobo.609.1">
     smart
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.610.1">
      grid infrastructures.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-243">
    <a id="_idTextAnchor246">
    </a>
    <span class="koboSpan" id="kobo.611.1">
     Predictive maintenance
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.612.1">
     Predictive maintenance
    </span>
    <a id="_idIndexMarker864">
    </a>
    <span class="koboSpan" id="kobo.613.1">
     is a critical
    </span>
    <a id="_idIndexMarker865">
    </a>
    <span class="koboSpan" id="kobo.614.1">
     application in
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.615.1">
      industrial IoT
     </span>
    </strong>
    <span class="koboSpan" id="kobo.616.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.617.1">
      IIoT
     </span>
    </strong>
    <span class="koboSpan" id="kobo.618.1">
     ) settings, where unexpected equipment failures can lead to significant costs and safety risks.
    </span>
    <span class="koboSpan" id="kobo.618.2">
     Graph-based deep learning models can enhance predictive maintenance by incorporating complex interdependencies between different components of
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.619.1">
      industrial systems.
     </span>
    </span>
   </p>
   <p>
    <strong class="bold">
     <span class="koboSpan" id="kobo.620.1">
      Temporal GNNs
     </span>
    </strong>
    <span class="koboSpan" id="kobo.621.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.622.1">
      TGNNs
     </span>
    </strong>
    <span class="koboSpan" id="kobo.623.1">
     ) are
    </span>
    <a id="_idIndexMarker866">
    </a>
    <span class="koboSpan" id="kobo.624.1">
     particularly well suited for this task, as they can model both the spatial relationships between components and their temporal evolution.
    </span>
    <span class="koboSpan" id="kobo.624.2">
     A TGNN for predictive maintenance might achieve
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.625.1">
      the following:
     </span>
    </span>
   </p>
   <ol>
    <li>
     <span class="koboSpan" id="kobo.626.1">
      Represent equipment components as
     </span>
     <em class="italic">
      <span class="koboSpan" id="kobo.627.1">
       nodes
      </span>
     </em>
     <span class="koboSpan" id="kobo.628.1">
      and their physical or functional connections
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.629.1">
       as
      </span>
     </span>
     <span class="No-Break">
      <em class="italic">
       <span class="koboSpan" id="kobo.630.1">
        edges
       </span>
      </em>
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.631.1">
       .
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.632.1">
      Use time series of sensor readings and operational data as dynamic
     </span>
     <span class="No-Break">
      <em class="italic">
       <span class="koboSpan" id="kobo.633.1">
        node features
       </span>
      </em>
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.634.1">
       .
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.635.1">
      Apply GCN
     </span>
     <a id="_idIndexMarker867">
     </a>
     <span class="koboSpan" id="kobo.636.1">
      and
     </span>
     <strong class="bold">
      <span class="koboSpan" id="kobo.637.1">
       recurrent neural network
      </span>
     </strong>
     <span class="koboSpan" id="kobo.638.1">
      (
     </span>
     <strong class="bold">
      <span class="koboSpan" id="kobo.639.1">
       RNN
      </span>
     </strong>
     <span class="koboSpan" id="kobo.640.1">
      ) layers to capture both spatial and
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.641.1">
       temporal patterns.
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.642.1">
      Predict future component states or
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.643.1">
       failure probabilities.
      </span>
     </span>
    </li>
   </ol>
   <p>
    <span class="koboSpan" id="kobo.644.1">
     This approach has been shown to outperform traditional ML methods in predicting equipment failures in manufacturing plants, wind turbines, and
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.645.1">
      aircraft engines.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-244">
    <a id="_idTextAnchor247">
    </a>
    <span class="koboSpan" id="kobo.646.1">
     Smart home applications
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.647.1">
     In smart home
    </span>
    <a id="_idIndexMarker868">
    </a>
    <span class="koboSpan" id="kobo.648.1">
     environments, graph-based deep learning can enhance various applications by modeling complex interactions between devices, users, and
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.649.1">
      the environment.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.650.1">
     For example, a graph-based recommender system for smart home automation might use a heterogeneous graph structure
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.651.1">
      as follows:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <span class="koboSpan" id="kobo.652.1">
      Devices, users, and rooms are represented as different types
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.653.1">
       of
      </span>
     </span>
     <span class="No-Break">
      <em class="italic">
       <span class="koboSpan" id="kobo.654.1">
        nodes
       </span>
      </em>
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.655.1">
       .
      </span>
     </span>
    </li>
    <li>
     <em class="italic">
      <span class="koboSpan" id="kobo.656.1">
       Edges
      </span>
     </em>
     <span class="koboSpan" id="kobo.657.1">
      represent interactions (for example, user-device interactions) or relationships (for example,
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.658.1">
       device locations).
      </span>
     </span>
    </li>
    <li>
     <em class="italic">
      <span class="koboSpan" id="kobo.659.1">
       Node features
      </span>
     </em>
     <span class="koboSpan" id="kobo.660.1">
      include device characteristics, user preferences, and
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.661.1">
       environmental data.
      </span>
     </span>
    </li>
   </ul>
   <p>
    <span class="koboSpan" id="kobo.662.1">
     By applying techniques such as graph embedding or graph convolutional matrix completion, such a system can generate personalized automation rules or device usage recommendations that
    </span>
    <a id="_idIndexMarker869">
    </a>
    <span class="koboSpan" id="kobo.663.1">
     account for the full context of the smart
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.664.1">
      home ecosystem.
     </span>
    </span>
   </p>
   <h1 id="_idParaDest-245">
    <a id="_idTextAnchor248">
    </a>
    <span class="koboSpan" id="kobo.665.1">
     Legal governance and compliance
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.666.1">
     GNNs can be useful
    </span>
    <a id="_idIndexMarker870">
    </a>
    <span class="koboSpan" id="kobo.667.1">
     tools in the legal and compliance sectors, offering innovative solutions to complex challenges.
    </span>
    <span class="koboSpan" id="kobo.667.2">
     By leveraging graph structures to represent intricate relationships between legal entities, documents, and regulations, these techniques are revolutionizing how legal professionals and compliance officers approach
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.668.1">
      their work.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-246">
    <a id="_idTextAnchor249">
    </a>
    <span class="koboSpan" id="kobo.669.1">
     Knowledge graph construction for legal and regulatory data
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.670.1">
     One of the primary applications of deep learning on graphs in the legal domain is the construction and
    </span>
    <a id="_idIndexMarker871">
    </a>
    <span class="koboSpan" id="kobo.671.1">
     utilization of
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.672.1">
      knowledge graphs
     </span>
    </strong>
    <span class="koboSpan" id="kobo.673.1">
     .
    </span>
    <span class="koboSpan" id="kobo.673.2">
     These graphs serve as comprehensive repositories of legal and regulatory information, capturing complex relationships between various entities such as laws, regulations, court cases, and
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.674.1">
      legal concepts:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.675.1">
       Entity extraction and relation mapping
      </span>
     </strong>
     <span class="koboSpan" id="kobo.676.1">
      : Deep learning models, particularly those based on NLP techniques, are employed to automatically extract entities and relationships from legal texts.
     </span>
     <span class="koboSpan" id="kobo.676.2">
      GNNs can then be used to refine and expand these relationships, creating a rich, interconnected network of
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.677.1">
       legal knowledge.
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.678.1">
       Multilingual integration
      </span>
     </strong>
     <span class="koboSpan" id="kobo.679.1">
      : In regions with multiple official languages, such as the
     </span>
     <strong class="bold">
      <span class="koboSpan" id="kobo.680.1">
       European Union
      </span>
     </strong>
     <span class="koboSpan" id="kobo.681.1">
      (
     </span>
     <strong class="bold">
      <span class="koboSpan" id="kobo.682.1">
       EU
      </span>
     </strong>
     <span class="koboSpan" id="kobo.683.1">
      ), deep learning on graphs facilitates the integration of legal information across different languages.
     </span>
     <span class="koboSpan" id="kobo.683.2">
      This enables the creation of multilingual legal knowledge graphs that support cross-border compliance and
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.684.1">
       legal research.
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.685.1">
       Dynamic updating
      </span>
     </strong>
     <span class="koboSpan" id="kobo.686.1">
      : The legal landscape is constantly evolving.
     </span>
     <span class="koboSpan" id="kobo.686.2">
      deep learning models can be trained to continuously update the knowledge graph with new legislation, case law, and regulatory changes, ensuring that the graph remains current
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.687.1">
       and relevant.
      </span>
     </span>
    </li>
   </ul>
   <h2 id="_idParaDest-247">
    <a id="_idTextAnchor250">
    </a>
    <span class="koboSpan" id="kobo.688.1">
     Automated compliance monitoring and risk assessment
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.689.1">
     Deep learning on graphs
    </span>
    <a id="_idIndexMarker872">
    </a>
    <span class="koboSpan" id="kobo.690.1">
     offers powerful tools for automating compliance processes and assessing
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.691.1">
      regulatory risks:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.692.1">
       Pattern recognition in complex regulations
      </span>
     </strong>
     <span class="koboSpan" id="kobo.693.1">
      : GNNs can analyze the structure of regulatory texts represented as graphs, identifying patterns and relationships that might be missed by traditional text analysis methods.
     </span>
     <span class="koboSpan" id="kobo.693.2">
      This capability is particularly useful for understanding the implications of new regulations across different
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.694.1">
       business areas.
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.695.1">
       Real-time compliance checking
      </span>
     </strong>
     <span class="koboSpan" id="kobo.696.1">
      : By representing an organization’s operations and regulatory requirements as a graph, deep learning models can perform real-time compliance checks.
     </span>
     <span class="koboSpan" id="kobo.696.2">
      These models can flag potential violations and suggest corrective actions, significantly reducing the risk
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.697.1">
       of non-compliance.
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.698.1">
       Predictive risk analysis
      </span>
     </strong>
     <span class="koboSpan" id="kobo.699.1">
      : By analyzing historical compliance data and current regulatory trends represented in graph form, deep learning models can predict future compliance risks.
     </span>
     <span class="koboSpan" id="kobo.699.2">
      This allows organizations to proactively address potential issues before they become
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.700.1">
       serious problems.
      </span>
     </span>
    </li>
   </ul>
   <h2 id="_idParaDest-248">
    <a id="_idTextAnchor251">
    </a>
    <span class="koboSpan" id="kobo.701.1">
     Legal document analysis and contract management
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.702.1">
     Deep learning on graphs is transforming how legal documents are analyzed
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.703.1">
      and managed:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.704.1">
       Semantic understanding of legal documents
      </span>
     </strong>
     <span class="koboSpan" id="kobo.705.1">
      : By representing legal documents as graphs of interconnected concepts and clauses, deep learning models can achieve a more nuanced understanding of document content.
     </span>
     <span class="koboSpan" id="kobo.705.2">
      This enables more accurate document classification, comparison, and
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.706.1">
       information retrieval.
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.707.1">
       Automated contract review
      </span>
     </strong>
     <span class="koboSpan" id="kobo.708.1">
      : GNNs can be trained to analyze contract graphs, identifying key clauses, potential risks, and inconsistencies.
     </span>
     <span class="koboSpan" id="kobo.708.2">
      This significantly speeds up the contract review process and
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.709.1">
       improves accuracy.
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.710.1">
       Legal precedent analysis
      </span>
     </strong>
     <span class="koboSpan" id="kobo.711.1">
      : By representing case law as a graph of interconnected decisions, deep learning models can analyze legal precedents more effectively.
     </span>
     <span class="koboSpan" id="kobo.711.2">
      This aids in case preparation and predicting potential outcomes of
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.712.1">
       legal disputes.
      </span>
     </span>
    </li>
   </ul>
   <h2 id="_idParaDest-249">
    <a id="_idTextAnchor252">
    </a>
    <span class="koboSpan" id="kobo.713.1">
     Regulatory intelligence and policy impact assessment
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.714.1">
     Deep learning on graphs is enhancing how organizations understand and respond to
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.715.1">
      regulatory changes:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.716.1">
       Regulatory change management
      </span>
     </strong>
     <span class="koboSpan" id="kobo.717.1">
      : By representing regulatory frameworks as graphs, deep learning models can analyze the impact of changes in one regulation on other related regulations.
     </span>
     <span class="koboSpan" id="kobo.717.2">
      This helps organizations understand the full implications of regulatory changes and adjust their compliance
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.718.1">
       strategies accordingly.
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.719.1">
       Policy impact prediction
      </span>
     </strong>
     <span class="koboSpan" id="kobo.720.1">
      : GNNs can be used to model the potential impacts of proposed regulations or policy changes.
     </span>
     <span class="koboSpan" id="kobo.720.2">
      By analyzing the connections between different
     </span>
     <a id="_idIndexMarker873">
     </a>
     <span class="koboSpan" id="kobo.721.1">
      areas of law and business operations, these models can predict how new policies might affect
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.722.1">
       various stakeholders.
      </span>
     </span>
    </li>
   </ul>
   <h1 id="_idParaDest-250">
    <a id="_idTextAnchor253">
    </a>
    <span class="koboSpan" id="kobo.723.1">
     Summary
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.724.1">
     In this chapter, we investigated the diverse applications of graph deep learning across various domains.
    </span>
    <span class="koboSpan" id="kobo.724.2">
     You learned about how graph-based approaches are revolutionizing fields such as biology and healthcare, social network analysis, financial services, cybersecurity, energy systems, IoT, and legal governance
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.725.1">
      and compliance.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.726.1">
     We also highlighted how GNNs and other graph-based models can capture complex relationships in interconnected data structures, leading to breakthroughs in areas such as drug discovery, fraud detection, network optimization, and predictive maintenance.
    </span>
    <span class="koboSpan" id="kobo.726.2">
     By showcasing the adaptability and transferability of these techniques, we explained the far-reaching impact of graph deep learning in solving complex real-world problems across industries and
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.727.1">
      scientific disciplines.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.728.1">
     In the next chapter, we will look at what lies in the future for graph deep learning and which areas will be deeply impacted by these
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.729.1">
      powerful models.
     </span>
    </span>
   </p>
  </div>
 </body></html>