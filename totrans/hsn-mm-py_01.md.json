["```py\nconda create -n hmm python=3.4\n```", "```py\nactivate hmm\nconda install numpy scipy\n```", "```py\nchmod +x Miniconda.sh\n./Miniconda.sh\n```", "```py\nconda create -n hmm python=3.4\n```", "```py\nsource activate hmm\nconda install numpy scipy\n```", "```py\nimport numpy as np\n\nclass MarkovChain(object):\n    def __init__(self, transition_prob):\n        \"\"\"\n        Initialize the MarkovChain instance.\n\n        Parameters\n        ----------\n        transition_prob: dict\n            A dict object representing the transition probabilities in \n            Markov Chain. Should be of the form: {'state1': {'state1': \n            0.1, 'state2': 0.4}, 'state2': {...}}\n        \"\"\"\n        self.transition_prob = transition_prob\n        self.states = list(transition_prob.keys())\n\n    def next_state(self, current_state):\n        \"\"\"\n        Returns the state of the random variable at the next time \n        instance.\n\n        Parameters\n        ----------\n        current_state: str\n            The current state of the system.\n        \"\"\"\n        return np.random.choice(\n            self.states, p=[self.transition_prob[current_state][next_state] \n                            for next_state in self.states])\n\n    def generate_states(self, current_state, no=10):\n        \"\"\"\n        Generates the next states of the system.\n\n        Parameters\n        ----------\n        current_state: str\n            The state of the current random variable.\n\n        no: int\n            The number of future states to generate.\n        \"\"\"\n        future_states = []\n        for i in range(no):\n            next_state = self.next_state(current_state)\n            future_states.append(next_state)\n            current_state = next_state\n        return future_states\n```", "```py\n>>> transition_prob = {'Sunny': {'Sunny': 0.8, 'Rainy': 0.19, \n 'Snowy': 0.01},\n 'Rainy': {'Sunny': 0.2, 'Rainy': 0.7,\n 'Snowy': 0.1},\n 'Snowy': {'Sunny': 0.1, 'Rainy': 0.2,\n 'Snowy': 0.7}}\n\n>>> weather_chain = MarkovChain(transition_prob=transition_prob)\n>>> weather_chain.next_state(current_state='Sunny')\n'Sunny'\n>>> weather_chain.next_state(current_state='Snowy')\n'Snowy'\n>>> weather_chain.generate_states(current_state='Snowy', no=10)     \n['Snowy', 'Snowy', 'Snowy', 'Rainy', 'Snowy', 'Snowy', 'Rainy',\n 'Rainy', 'Snowy', 'Snowy']\n```", "```py\nimport numpy as np\n\nclass MarkovChain(object):\n    def __init__(self, transition_matrix, states):\n        \"\"\"\n        Initialize the MarkovChain instance.\n\n        Parameters\n        ----------\n        transition_matrix: 2-D array\n            A 2-D array representing the probabilities of change of \n            state in the Markov Chain.\n\n        states: 1-D array \n            An array representing the states of the Markov Chain. It\n            needs to be in the same order as transition_matrix.\n        \"\"\"\n        self.transition_matrix = np.atleast_2d(transition_matrix)\n        self.states = states\n        self.index_dict = {self.states[index]: index for index in \n                           range(len(self.states))}\n        self.state_dict = {index: self.states[index] for index in\n                           range(len(self.states))}\n\n    def next_state(self, current_state):\n        \"\"\"\n        Returns the state of the random variable at the next time \n        instance.\n\n        Parameters\n        ----------\n        current_state: str\n            The current state of the system.\n        \"\"\"\n        return np.random.choice(\n                    self.states, \n                    p=self.transition_matrix[self.index_dict[current_state], :])\n\n    def generate_states(self, current_state, no=10):\n        \"\"\"\n        Generates the next states of the system.\n\n        Parameters\n        ----------\n        current_state: str\n            The state of the current random variable.\n\n        no: int\n            The number of future states to generate.\n        \"\"\"\n        future_states = []\n        for i in range(no):\n            next_state = self.next_state(current_state)\n            future_states.append(next_state)\n            current_state = next_state\n        return future_states\n```", "```py\n>>> transition_matrix = [[0.8, 0.19, 0.01],\n                         [0.2,  0.7,  0.1],\n                         [0.1,  0.2,  0.7]]\n>>> weather_chain = MarkovChain(transition_matrix=transition_matrix,\n                                states=['Sunny', 'Rainy', 'Snowy'])\n>>> weather_chain.next_state(current_state='Sunny')\n'Sunny'\n>>> weather_chain.next_state(current_state='Snowy')\n'Sunny'\n>>> weather_chain.generate_states(current_state='Snowy', no=10)\n['Snowy', 'Rainy', 'Rainy', 'Rainy', 'Rainy', 'Rainy', \n 'Rainy', 'Rainy', 'Sunny', 'Sunny']\n```", "```py\nfrom itertools import combinations\n\ndef is_accessible(self, i_state, f_state):\n    \"\"\"\n    Check if state f_state is accessible from i_state.\n\n    Parameters\n    ----------\n    i_state: str\n        The state from which the accessibility needs to be checked.\n\n    f_state: str\n        The state to which accessibility needs to be checked.\n    \"\"\"\n    reachable_states = [i_state]\n    for state in reachable_states:\n        if state == self.index_dict[f_state]:\n            return True\n        else:\n            reachable_states.append(np.nonzero(\n              self.transition_matrix[self.index_dict[i_state], :])[0])\n    return False\n\ndef is_irreducible(self):\n    \"\"\"\n    Check if the Markov Chain is irreducible.\n    \"\"\"\n    for (i, j) in combinations(self.states, self.states):\n        if not self.is_accessible(i, j):\n            return False\n    return True\n```", "```py\n>>> transition_irreducible = [[0.5, 0.5, 0, 0],\n                              [0.25, 0, 0.5, 0.25],\n                              [0.25, 0.5, 0, 0.25],\n                              [0, 0, 0.5, 0.5]]\n>>> transition_reducible = [[0.5, 0.5, 0, 0],\n                            [0, 1, 0, 0],\n                            [0.25, 0.5, 0, 0],\n                            [0, 0, 0.25, 0.75]]\n>>> markov_irreducible = MarkovChain(transition_matrix=transition_irreducible,\n                                     states=['A', 'B', 'C', 'D'])\n>>> markov_reducible = MarkovChain(transition_matrix=transition_reducible,\n                                   states=['A', 'B', 'C', 'D'])\n>>> markov_irreducible.is_accessible(i_state='A', f_state='D')\nTrue\n>>> markov_irreducible.is_accessible(i_state='B', f_state='D')\nTrue\n>>> markov_irreducible.is_irreducible()\nTrue\n>>> markov_reducible.is_accessible(i_state='A', f_state='D')\nFalse\n>>> markov_reducible.is_accessible(i_state='D', f_state='A')\nTrue\n>>> markov_reducible.is_accessible(i_state='C', f_state='D')\nFalse\n>>> markov_reducible.is_irreducible()\nFalse\n```", "```py\ndef get_period(self, state):\n    \"\"\"\n    Returns the period of the state in the Markov Chain.\n\n    Parameters\n    ----------\n    state: str\n        The state for which the period needs to be computed.\n    \"\"\"\n    return gcd([len(i) for i in all_possible_paths])\n\ndef is_aperiodic(self):\n    \"\"\"\n    Checks if the Markov Chain is aperiodic. \n    \"\"\"\n    periods = [self.get_period(state) for state in self.states]\n    for period in periods:\n        if period != 1:\n            return False\n    return True\n```", "```py\n>>> transition_periodic = [[0, 1, 0, 0, 0],\n                           [0, 0, 1, 0, 0],\n                           [0.5, 0, 0, 0.5, 0],\n                           [0, 0, 0, 0, 1],\n                           [0, 0, 1, 0, 0]]\n>>> transition_aperiodic = [[0, 1, 0, 0, 0],\n                            [0, 0, 1, 0, 0],\n                            [0.5, 0.25, 0, 0.25, 0],\n                            [0, 0, 0, 0, 1],\n                            [0, 0, 0.5, 0.5, 0]]\n>>> markov_periodic = MarkovChain(transition_matrix=transition_periodic,\n                                  states=['A', 'B', 'C', 'D', 'E'])\n>>> markov_aperiodic = MarkovChain(transition_matrix=transition_aperiodic,\n                                   states=['A', 'B', 'C', 'D', 'E'])\n\n>>> markov_periodic.get_period('A')\n3\n>>> markov_periodic.get_period('C')\n3\n>>> markov_aperiodic.is_periodic()\nFalse\n\n>>> markov_aperiodic.get_period('A')\n1\n>>> markov_aperiodic.get_period('B')\n1\n>>> markov_aperiodic.is_periodic()\nTrue\n```", "```py\ndef is_transient(self, state):\n    \"\"\"\n    Checks if a state is transient or not.\n\n    Parameters\n    ----------\n    state: str\n        The state for which the transient property needs to be checked.\n    \"\"\"\n    if all(self.transition_matrix[~self.index_dict[state], self.index_dict[state]] == 0):\n        return True\n    else:\n        return False\n```", "```py\n>>> transient_matrix = [[0, 0.5, 0.5, 0],\n                        [0, 0, 0.25, 0.75],\n                        [0, 0, 0, 1],\n                        [0, 0, 0.5, 0.5]]\n>>> transient_markov = MarkovChain(transition_matrix=transient_matrix,\n                                   states=['A', 'B', 'C', 'D'])\n>>> transient_markov.is_transient('A')\nTrue\n>>> transient_markov.is_transient('B')\nTrue\n>>> transient_markov.is_transient('C')\nFalse\n```", "```py\ndef is_absorbing(self, state):\n \"\"\"\n Checks if the given state is absorbing.\n\n Parameters\n ----------\n state: str\n The state for which we need to check whether it's absorbing\n or not.\n \"\"\"\n state_index = self.index_dict[state]\n if self.transition_matrix[state_index, state_index]\n```", "```py\n>>> absorbing_matrix = [[0, 1, 0],\n                        [0.5, 0, 0.5],\n                        [0, 0, 1]]\n>>> absorbing_chain = MarkovChain(transition_matrix=absorbing_matrix,\n                                  states=['A', 'B', 'C'])\n>>> absorbing_chain.is_absorbing('A')\nFalse\n>>> absorbing_chain.is_absorbing('C')\nTrue\n```"]