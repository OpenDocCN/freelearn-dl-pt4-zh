- en: Creating a Neural Network in Spark
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, the following recipes will be covered:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a dataframe in PySpark
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manipulating columns in a PySpark dataframe
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Converting a PySpark dataframe into an array
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visualizing the array in a scatterplot
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up weights and biases for input into the neural network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Normalizing the input data for the neural network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Validating array for optimal neural network performance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up the activation function with sigmoid
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating the sigmoid derivative function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calculating the cost function in a neural network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predicting gender based on height and weight
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visualizing prediction scores
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Much of this book will focus on building deep learning algorithms with libraries
    in Python, such as TensorFlow and Keras. While these libraries are helpful to
    build deep neural networks without getting deep into the calculus and linear algebra
    of deep learning, this chapter will do a deep dive into building a simple neural
    network in PySpark to make a gender prediction based on height and weight. One
    of the best ways to understand the foundation of neural networks is to build a
    model from scratch, without any of the popular deep learning libraries. Once the
    foundation for a neural network framework is established, understanding and utilizing
    some of the more popular deep neural network libraries will become much simpler.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a dataframe in PySpark
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: dataframes will serve as the framework for any and all data that will be used
    in building deep learning models. Similar to the `pandas` library with Python,
    PySpark has its own built-in functionality to create a dataframe.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are several ways to create a dataframe in Spark. One common way is by
    importing a `.txt`, `.csv`, or `.json` file. Another method is to manually enter
    fields and rows of data into the PySpark dataframe, and while the process can
    be a bit tedious, it is helpful, especially when dealing with a small dataset.
    To predict gender based on height and weight, this chapter will build a dataframe
    manually in PySpark. The dataset used is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/57578186-ff94-4049-a2c3-ea7519eac43f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'While the dataset will be manually added to PySpark in this chapter, the dataset
    can also be viewed and downloaded from the following link:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/asherif844/ApacheSparkDeepLearningCookbook/blob/master/CH02/data/HeightAndWeight.txt](https://github.com/asherif844/ApacheSparkDeepLearningCookbook/blob/master/CH02/data/HeightAndWeight.txt)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we will begin this chapter and future chapters by starting up a Spark
    environment configured with a Jupyter notebook that was created in [chapter 1](a010c7af-0e48-4bac-9146-47ddecc2cc8e.xhtml), *Setting
    up your Spark Environment for Deep Learning,* using the following terminal command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When working with PySpark, a `SparkSession` must first be imported and initialized
    before any dataframe creation can occur:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import a `SparkSession` using the following script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Configure a `SparkSession`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: In this situation, the `SparkSession` `appName` has been named `Neural Network
    Model` and `6gb` has been assigned to the session memory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section explains how we create our Spark cluster and configure our first
    dataframe.
  prefs: []
  type: TYPE_NORMAL
- en: In Spark, we use `.master()` to specify whether we will run our jobs on a distributed
    cluster or locally.  For the purposes of this chapter and the remaining chapters,
    we will be executing Spark locally with one worker thread as specified with `.master('local')`. 
    This is fine for testing and development purposes as we are doing in this chapter;
    however, we may run into performance issues if we deployed this to production. 
    In production, it is recommended to use `.master('local[*]')` to set Spark to
    run on as many worker nodes that are available locally as possible. If we had
    3 cores on our machine and we wanted to set our node count to match that, we would
    then specify `.master('local[3]')`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The `dataframe` variable, `df`, is first created by inserting the row values
    for each column and then by inserting the column header names using the following
    script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'In PySpark, the `show()` function gives the ability to preview the top 20 rows,
    as seen in the following screenshot when using the preceding script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/c40e1c6f-93eb-42c4-881f-51af531af877.png)'
  prefs: []
  type: TYPE_IMG
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `.show()` functionality defaults to 20 rows if not explicitly stated. 
    If we only wanted to show the first 5 rows of a dataframe, we would need to explicitly
    state it as seen in the following script: `df.show(5)`.'
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to learn more about SparkSQL, dataframes, functions, and data sets
    in PySpark, visit the following website:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://spark.apache.org/docs/latest/sql-programming-guide.html](https://spark.apache.org/docs/latest/sql-programming-guide.html)'
  prefs: []
  type: TYPE_NORMAL
- en: Manipulating columns in a PySpark dataframe
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The dataframe is almost complete; however, there is one issue that requires
    addressing before building the neural network. Rather than keeping the gender
    value as a string, it is better to convert the value to a numeric integer for
    calculation purposes, which will become more evident as this chapter progresses.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This section will require  importing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`from pyspark.sql import functions`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This section walks through the steps for the string conversion to a numeric
    value in the dataframe:'
  prefs: []
  type: TYPE_NORMAL
- en: Female --> 0
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Male --> 1
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Convert a column value inside of a dataframe requires importing `functions`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, modify the `gender` column to a numeric value using the following script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, reorder the columns so that `gender` is the last column in the dataframe
    using the following script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section explains how the manipulation of the dataframe is applied.
  prefs: []
  type: TYPE_NORMAL
- en: '`functions from pyspark.sql` have several useful logic applications that can
    be used to apply if-then transformations to columns in a Spark dataframe.  In
    our case, we are converting `Female` t0 0 and `Male` to 1.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The function to convert to numeric is applied to the Spark dataframe using the
    `.withColumn()` transformation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `.select()` feature for a Spark dataframe functions like traditional SQL
    by selecting the columns in the order and manner requested.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A final preview of the dataframe will display the updated dataset, as seen
    in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/f6ab7f97-c69b-4a78-88c8-cfc2c2ce5a36.png)'
  prefs: []
  type: TYPE_IMG
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In addition to the `withColumn()` method for a dataframe, there is also the
    `withColumnRenamed()` method, which is used for renaming columns in a dataframe.
  prefs: []
  type: TYPE_NORMAL
- en: Converting a PySpark dataframe to an array
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order to form the building blocks of the neural network, the PySpark dataframe
    must be converted into an array. Python has a very powerful library, `numpy`,
    that makes working with arrays simple.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `numpy` library should be already available with the installation of the
    `anaconda3` Python package. However, if for some reason the `numpy` library is
    not available, it can be installed using the following command at the terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/08f1438e-fa19-4f98-bfc7-9627bb135aa6.png)'
  prefs: []
  type: TYPE_IMG
- en: '`pip install` or `sudo pip install` will confirm whether the requirements are
    already satisfied by using the requested library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This section walks through the steps to convert the dataframe into an array:'
  prefs: []
  type: TYPE_NORMAL
- en: 'View the data collected from the dataframe using the following script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Store the values from the collection into an array called `data_array` using
    the following script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Execute the following script to access the first row of the array:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, execute the following script to access the final row of the array:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This section explains how the dataframe is converted into an array:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The output of our dataframe can be collected using `collect()` and viewed as
    seen in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/05572b09-0de4-4e0d-b76e-99e90becf5af.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The dataframe is converted into an array and the output of the array from that
    script can be seen in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/07d57776-fbb7-404d-99f0-020887beb1cd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Any set of `height`, `weight`, and `gender` values can be accessed by referencing
    the index of the array. The array has a shape of (29,3) with a length of 29 elements,
    and each element is composed of three items. While the length is 29, the index
    starts at `[0]` and ends at `[28]`.  The outputs for the shape of the array as
    well as the first and last rows of the array can be seen in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/8bf08db5-d187-4caf-9f81-bc626952350b.png)'
  prefs: []
  type: TYPE_IMG
- en: The first and last values of the array can be compared with the original dataframe to
    confirm that the values and order have not changed as a result of the conversion.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In addition to viewing the data points in an array, it is also useful to retrieve
    the minimum and maximum points of each feature in an array:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To retrieve the minimum and maximum values for `height`, `weight`, and `gender`,
    the following script can be used:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The output from the script can be seen in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/b2541062-eef7-4d18-9809-03f49782f645.png)'
  prefs: []
  type: TYPE_IMG
- en: The maximum `height` is `74` inches and minimum `height` is `60` inches. The
    maximum weight is `188` lbs, while the minimum weight is `107` lbs. The minimum
    and maximum values for gender are not as relevant, as we have assigned them numeric
    values of `0` and `1`.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To learn more about numpy, visit the following website:'
  prefs: []
  type: TYPE_NORMAL
- en: '[www.numpy.org](http://www.numpy.org)'
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing an array in a scatterplot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The goal of the neural network that will be developed in this chapter is to
    predict the gender of an individual if the `height` and `weight` are known. A
    powerful method for understanding the relationship between `height`, `weight`,
    and `gender` is by visualizing the data points feeding the neural network. This
    can be done with the popular Python visualization library `matplotlib`.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As was the case with `numpy`, `matplotlib` should be available with the installation
    of the anaconda3 Python package. However, if for some reason `matplotlib` is not
    available, it can be installed using the following command at the terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4bacc6c7-65ac-4896-9954-9698569e33e9.png)'
  prefs: []
  type: TYPE_IMG
- en: '`pip install` or `sudo pip install` will confirm the requirements are already
    satisfied by using the requested library.'
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section walks through the steps to visualize an array through a scatterplot.
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the `matplotlib` library and configure the library to visualize plots
    inside of the Jupyter notebook using the following script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, determine the minimum and maximum values of the *x* and y-axes of the
    scatterplot using the `min()` and `max()` functions from `numpy`, as seen in the
    following script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Execute the following script to plot the `height` and `weight` for each `gender`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This section explains how an array is plotted as a scatterplot:'
  prefs: []
  type: TYPE_NORMAL
- en: The `matplotlib` library is imported into the Jupyter notebook and the `matplotlib`
    library is configured to plot visualizations inline in the cells of the Jupyter
    notebook
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The minimum and maximum values of the x and y-axes are determined to size up
    our plot and give us an optimal looking graph.  The output of the script can be
    seen in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/90dc5c16-1ee5-42d7-b0dd-b11c6e01f0af.png)'
  prefs: []
  type: TYPE_IMG
- en: A `10`-point pixel buffer has been added to each axis to ensure all data points
    are captured without being cut off.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A loop is created to iterate through each row of values and plot the `weight`
    versus the `height`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Additionally, a different style point is assigned to the `Female gender`, `x`,
    and the `Male gender`, `o`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The output of the script to plot the Weight vs Height by Gender can be seen
    in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/d8beca7d-6268-47fd-bc4d-20b73a12615d.png)'
  prefs: []
  type: TYPE_IMG
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The scatterplot gives a quick and easy visual interpretation of what is going
    on with the data. There is an apparent divide between the upper-right quadrant
    and the lower-left quadrant of the scatterplot. All of the data points above 140
    lbs indicate a `Male gender`, with all of the data points below that belong to
    the `Female gender`, as seen in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/64fe80b4-f02e-4d87-9eaa-c6a016a61ca9.png)'
  prefs: []
  type: TYPE_IMG
- en: This scatterplot will help confirm what is to be expected when picking a random
    height and weight to predict the outcome of the gender when the neural network
    is created later on in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To learn more about `matplotlib`, visit the following website:'
  prefs: []
  type: TYPE_NORMAL
- en: '[www.matplotlib.org](http://www.matplotlib.org/)'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up weights and biases for input into the neural network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The framework in PySpark and the data are now complete. It is time to move
    on to building the neural network. Regardless of the complexity of the neural
    network, the development follows a similar path:'
  prefs: []
  type: TYPE_NORMAL
- en: Input data
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add the weights and biases
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sum the product of the data and weights
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply an activation function
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Evaluate the output and compare it to the desired outcome
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This section will focus on setting the weights that create the input which feeds
    into the activation function.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A cursory understanding of the building blocks of a simple neural network is
    helpful in understanding this section and the rest of the chapter.  Each neural
    network has inputs and outputs.  In our case, the inputs are the height and weight
    of the individuals and the output is the gender.  In order to get to the output,
    the inputs are multiplied with values (also known as weights: w1 and w2) and then
    a bias (b) is added to the end.  This equation is known as the summation function,
    z, and is given the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: z = (input1) x (w1) + (input2) x (w2) + b
  prefs: []
  type: TYPE_NORMAL
- en: The weights and the bias are initially just random generated values that can
    be performed with `numpy`. The weights will literally add weight to inputs by
    increasing or decreasing their impact on the output. The bias will serve a slightly
    different role in that it will shift the baseline of the summation (z) upwards
    or downwards, depending on what is needed to meet the prediction. Each value of
    z is then converted into a predicted value between 0 and 1 through an activation
    function.  The activation function is a converter that gives us a value that we
    can convert into a binary output (male/female). The predicted output is then compared
    with the actual output.  Initially, the difference between the predicted and actual
    output will be large as the weights will be random when first starting out.  However,
    a process known as backpropagation is used to minimize the difference between
    the actual and the predicted using a technique known as gradient descent.  Once
    we settle on a negligible difference between the actual and predicted, we store
    the values of w1, w2, and b for the neural network.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section walks through the steps to set up the weights and bias of the neural
    network.
  prefs: []
  type: TYPE_NORMAL
- en: 'Set the randomness of the value generator using the following script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Set the weights and biases using the following script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This section explains how the weights and bias are initialized for use in later
    parts of this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: The weights are generated randomly using `numpy`, and a random seed is set to
    ensure the same random numbers are generated each time
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The weights will be assigned a generic variable of `w1` and `w2`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The bias is also generated randomly using `numpy` and a random seed is set to
    maintain the same random numbers is generated each time
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The bias will be assigned a generic variable of `b`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The values are inserted into a summation function, `z`, which populates an initial
    score that will feed into another function, the activation function, to be discussed
    later on in this chapter
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'At the moment, all three variables are completely random.  The output of `w1`,
    `w2`, and `b` can be seen in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/eb68ecc9-2921-4cee-b951-568f84370ed4.png)'
  prefs: []
  type: TYPE_IMG
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Ultimately, the goal is to get a predicted output that matches the actual output.
    Summing the product of the weights and the values helps achieve part of this process.
    Therefore, a random input of `0.5` and `0.5` would have a summation output of
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Or it would have the following output with our current random values for our
    weights, `w1` and `w2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The variable `z` is assigned as the product summation of the weights with the
    data points. Currently, the weights and biases are completely random. However,
    as mentioned earlier in the section, through a process called backpropagation*,*
    using gradient descent, the weights will be tweaked until a more desirable outcome
    is determined. Gradient descent is simply the process of identifying the optimal
    values for our weights that will give us the best prediction output with the least
    amount of error.  The process of identifying the optimal values involves identifying
    the local minimum of a function. Gradient descent will be discussed later on in
    this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to learn more about weights and biases in an artificial neural network,
    visit the following website:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://en.wikipedia.org/wiki/Artificial_neuron](https://en.wikipedia.org/wiki/Artificial_neuron)'
  prefs: []
  type: TYPE_NORMAL
- en: Normalizing the input data for the neural network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Neural networks work more efficiently when the inputs are normalized. This minimizes
    the magnitude of a particular input affecting the overall outcome over other potential
    inputs that have lower values of magnitude. This section will normalize the `height`
    and `weight` inputs of the current individuals.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The normalization of input values requires obtaining the mean and standard deviation
    of those values for the final calculation.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section walks through the steps to normalize the height and weight.
  prefs: []
  type: TYPE_NORMAL
- en: 'Slice the array into inputs and outputs using the following script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The mean and the standard deviation can be calculated across the 29 individuals
    using the following script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a normalization function to normalize `X` using the following script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section explains how the height and weight are normalized.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `data_array` matrix is split into two matrices:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`X` is composed of the height and the weight'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '`y` is composed of the gender'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The output of both arrays can be seen in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/cbe8d854-b194-462b-a639-64a48deebd85.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The `X` component is the input and is the only part that will undergo the normalization
    process. The *y* component, or the gender, will be disregarded for the moment.
    The normalization process involves extracting the mean and standard deviation
    of both inputs for all 29 individuals. The output of the mean and standard deviations
    for the height and weight can be seen in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/8a23c34c-0387-4848-bd43-9561a6b28e98.png)'
  prefs: []
  type: TYPE_IMG
- en: The mean of the height is ~67 inches and the standard deviation of the height
    is ~3.4 inches. The mean of the weight is ~145 lbs and the standard deviation
    of the weight is ~22 lbs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once they are extracted, the inputs are normalized using the following equation:
    `X_norm = (X - X_mean)/X_std`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The `X` array is normalized using the Python function `normalize()` and the
    `X` array is now assigned to the values of the newly minted normalized set, as
    seen in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/b44ccd64-f096-46ca-9599-4dadb60cb70c.png)'
  prefs: []
  type: TYPE_IMG
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to learn more about normalization in statistics, visit the following
    website:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://en.wikipedia.org/wiki/Normalization_(statistics)](https://en.wikipedia.org/wiki/Normalization_(statistics))'
  prefs: []
  type: TYPE_NORMAL
- en: Validating array for optimal neural network performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A little bit of validation goes a long way in ensuring that our array is normalized
    for optimal performance within our upcoming neural network.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section will require a bit of `numpy` magic using the `numpy.stack()` function.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The following steps walk through validating that our array has been normalized.
  prefs: []
  type: TYPE_NORMAL
- en: 'Execute the following step to print the mean and standard deviation of array
    inputs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Execute the following script to combine height, weight, and gender into one
    array, `data_array`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section explains how the array is validated and constructed for optimal
    future use within the neural network.
  prefs: []
  type: TYPE_NORMAL
- en: 'The new `mean` of the height should be 0 and the `standard deviation` should
    be 1\. This can be seen in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/7540c7bb-c6c1-41b1-8fcd-fdf91baadc9d.png)'
  prefs: []
  type: TYPE_IMG
- en: This is confirmation of a normalized dataset, as it includes a mean of 0 and
    a standard deviation of 1.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The original `data_array` is no longer useful for a neural network because it
    contains the original, non-normalized, input values for `height`, `weight`, and `gender`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Nonetheless, with a little bit of `numpy` magic, `data_array` can be restructured
    to include the normalized `height` and `weight`, along with `gender`.  This is
    done with `numpy.stack()`.   The output of the new array, `data_array`, can be
    seen in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/c337a2fd-0984-4038-a8a7-026525df2a9b.png)'
  prefs: []
  type: TYPE_IMG
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our array is now all set.  Our inputs for height and weight are normalized and
    our output for gender is labeled as 0 or 1.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To learn more about `numpy.stack()`, visit the following website:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://docs.scipy.org/doc/numpy/reference/generated/numpy.stack.html](https://docs.scipy.org/doc/numpy/reference/generated/numpy.stack.html)'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the activation function with sigmoid
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An activation function is used in a neural network to help determine the output,
    whether it is a yes or no, true or false, or in our case 0 or 1 (male/female). 
    At this point, the inputs have been normalized and have been summed with the weights
    and bias: `w1`, `w2`, and `b`. However, the weights and bias are completely random
    at the moment and are not optimized to produce a predicted output that matches
    the actual output. The missing link in building the predicted outcome resides
    with the activation or `sigmoid` function, which is shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9ded16b0-c52c-4fcb-9e53-4677113c656b.png)'
  prefs: []
  type: TYPE_IMG
- en: If the number that is produced out of the summation is very small, it will produce
    an activation of 0\. Likewise, if the number produced out of the summation is
    quite large, it will produce an activation of 1\. This function is useful because
    it restricts the output to a binary outcome, which is quite useful for classification.
    The consequences of these outputs will be discussed and clarified in the remainder
    of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `sigmoid` function is similar to the logistic regression function in that
    it computes a probabilistic outcome between 0 and 1\. Additionally, it gives a
    range of everything in -between. Therefore, a condition could be set to associate
    any value greater than 0.5 to 1 and less than 0.5 to 0.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section walks through the steps of creating and plotting a sigmoid function
    with sample data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create the `sigmoid` function using a Python function, as seen in the following
    script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Create sample `x` values for the `sigmoid` curve using the following script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Additionally, create sample `y` values for the `sigmoid` curve using the following
    script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Plot the `x` and `y` values for these points using the following script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section explains the mathematics behind the sigmoid function.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `sigmoid` function is a specialized version of the logistic regression
    used for classification. The calculation of the logistic regression is expressed
    with the following formula:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/761ff6f1-ac53-4570-bb6e-1263f56ffc26.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The variables for the logistic regression function stand for the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*L* stands the maximum value of the function'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*k* stands for the steepness of the curve'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*x[midpoint]* stands for the midpoint value of the function'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Since the `sigmoid` function has a steepness of value 1, a midpoint of 0, and
    a maximum value of 1, it produces the following function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/69709a0a-e875-4cdf-ab74-9c71a8991598.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can plot a general sigmoid function with x-values ranging from -5 to 5,
    and y-values ranging from 0 to 1 as seen in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/9fd2bcf1-683d-4818-8a0c-1a8f548fdd1f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We created our own `sigmoid` function with Python and plotted it using sample
    data between `-10` and `10`.  Our plot looks very similar to the previous general
    sigmoid plot.  The output of our `sigmoid` function can be seen in the following
    screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/de49da85-78f6-4562-8d09-aa632b62fc92.png)'
  prefs: []
  type: TYPE_IMG
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to learn more about the origin of the `sigmoid` function, visit the
    following website:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://en.wikipedia.org/wiki/Sigmoid_function](https://en.wikipedia.org/wiki/Sigmoid_function)'
  prefs: []
  type: TYPE_NORMAL
- en: Creating the sigmoid derivative function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The sigmoid function is a unique function where the value of the derivative
    of the sigmoid function includes the value of the sigmoid function.  You may be
    asking what's the big deal.  However, since the sigmoid function is already calculated
    it allows for simpler and more efficient processing when performing backpropagation
    over many layers.  Additionally, it is the derivative of the sigmoid function
    that is used in the calculation to derive the optimal `w1`, `w2`, and `b` values
    to derive the most accurate predicted output.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A cursory understanding of derivatives from calculus will assist in understanding
    the sigmoid derivative function.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section walks through the steps to create a sigmoid derivative function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Just like the `sigmoid` function, create the derivative of the `sigmoid` function
    can with Python using the following script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Plot the derivative of the `sigmoid` function alongside the original `sigmoid` function
    using the following script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section explains the math behind the derivative of the sigmoid function
    along with the logic to create the derivative of the sigmoid function with Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'The neural network will require the derivative of the `sigmoid` function to
    predict an accurate output for `gender`. The derivative of the `sigmoid` function
    is calculated using the following formula:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/95d933f9-d2b5-4593-ae6b-3cef9db42678.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can then create the derivative of the sigmoid function, `sigmoid_derivate()`,
    using the original sigmoid function, `sigmoid()`, in Python. We can plot both
    functions side by side as seen in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/22feaa79-5478-49e0-a08c-98b117c41935.png)'
  prefs: []
  type: TYPE_IMG
- en: Sigmoid Derivative tracks the slope of the original Sigmoid function. Early
    on in the plot, when the slope of the Sigmoid is completely horizontal, the Sigmoid
    Derivative is also 0.0.  The same holds true for Sigmoid when the value is approaching
    1 as the slope is also almost completely horizontal. The peak value of the slope
    of Sigmoid is at the midpoint of the x-axis. Consequently, this is also the peak
    value of Sigmoid Derivative.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To get a deeper dive into derivatives, visit the following website:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.khanacademy.org/math/calculus-home/taking-derivatives-calc](https://www.khanacademy.org/math/calculus-home/taking-derivatives-calc)'
  prefs: []
  type: TYPE_NORMAL
- en: Calculating the cost function in a neural network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At this point, it is time to bring together all of the parts highlighted earlier
    on in the chapter to calculate the cost function, which will be used by the neural
    network to determine how well the predicted outcome matched the original or actual
    outcome, given the 29 individual data points that are currently available. The
    purpose of the cost function is to identify the difference between the actual
    value and the predicted value.  Gradient descent is then used to either increase
    or decrease the values for `w1`, `w2`, and `b` to decrease the value of the cost
    function and ultimately achieve our goal of deriving a predicted value that matches
    the actual value.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The formula for the cost function is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: cost(x)=(predicted-actual)²
  prefs: []
  type: TYPE_NORMAL
- en: If the cost function looks familiar, it's because it is really just another
    way of minimizing the squared difference between the actual output and the prediction.
    The purpose of gradient descent or backpropagation in a neural network is to minimize
    the cost function until the value is close to 0\. At that point, the weights and
    bias (`w1`, `w2`, and `b`) will no longer be random insignificant values generated
    by `numpy`, but actual significant weights contributing to a neural network model.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section walks through the steps to calculate the cost function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Set a  learning rate value of `0.1` to incrementally change the weights and
    bias until a final output is selected using the following script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Initiate a Python list called `allCosts` using the following script.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a `for` loop that will iterate through 100,000 scenarios using the following
    script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/94ba5b3d-40e4-4c59-bf85-52850d1f5e9b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Plot the cost values collected over the 100,000 iterations using the following
    script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The final values of the weights and bias can be viewed using the following
    script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section explains how the cost function is used to generate weights and
    bias.
  prefs: []
  type: TYPE_NORMAL
- en: A `for` loop will be implemented that will perform gradient descent on the weights
    and bias to tweak the values until the cost function gets close to 0.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The loop will iterate over the cost function 100,000 times. Each time, a random
    value for `height` and `weight` from the 29 individuals is selected.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A summation value, `z`, is calculated from the random `height` and `weight`,
    and the input is used to calculate a `predictedGender` score with the `sigmoid` function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The cost function is calculated and added to a list that tracks all cost functions
    through the 100,000 iterations, `allCosts`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A series of partial derivatives is calculated with respect to the summation
    value (`z`) as well as the `cost` function (`cost`).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: These calculations are ultimately used to update the weights and bias with respect
    to the cost function until they (`w1`, `w2`, and `b`) return a value that is close
    to 0 for the cost function over the 100,000 iterations.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Ultimately, the goal is for the values to be decreasing for the cost function
    as the iterations increase.  The output of the cost function values over the 100,000
    iterations can be seen in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/3480b8b4-1423-4ddb-aefb-0691ef980ce3.png)'
  prefs: []
  type: TYPE_IMG
- en: Over the course of the iterations, the cost value dropped from ~0.45 to ~0.01.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Additionally, we can view the final output for the values of `w1`, `w2`, and `b` that
    produced the lowest value of the cost function as seen in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/34d2c6f2-b025-4158-ab3c-78821ab39752.png)'
  prefs: []
  type: TYPE_IMG
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The ability to test the final values of the weights and bias is now available
    to compute how well the cost function worked to compute a predicted and how it
    compared to the actual score.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following script will create a loop through each individual and calculate
    a predicted gender score based on the weights (`w1`, `w2`) and the bias (`b`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the script can be seen in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e03197a6-0bf4-4170-bd6e-8396d617aa14.png)'
  prefs: []
  type: TYPE_IMG
- en: All 29 of the actual scores approximately match the predicted scores when rounded.
    While this is good for confirming the model produced matching results on the training
    data, ultimately, the test will be to determine whether the model can make accurate
    gender predictions on new individuals introduced to it.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to learn more about minimizing cost functions or squared (difference)
    error functions using gradient descent, visit the following site:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://en.wikipedia.org/wiki/Gradient_descent](https://en.wikipedia.org/wiki/Gradient_descent)'
  prefs: []
  type: TYPE_NORMAL
- en: Predicting gender based on height and weight
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A predictive model is only useful if it can actually predict based on new information.
    This is the case with a simple logistic or linear regression, or a more complex
    neural network model.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is where the fun begins. The only requirements for this section are to
    pull sample data points for both male and female individuals and use their height
    and weight values to measure the accuracy of the model created in the previous
    section.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section walks through the steps to predict gender based on height and weight.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a Python function called `input_normalize` to input new values for `height` and `weight` and
    output a normalized height and weight, as seen in the following script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Assign a variable called `score` to the function for the values of `70` inches
    for the `height` and `180` lbs for the `weight`, as seen in the following script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Create another Python function, called `predict_gender`, to output a probability
    score, `gender_score`, between 0 and 1, as well as a gender description, by applying
    the summation with `w1`, `w2`, and `b` as well as the `sigmoid` function, as seen
    in the following script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section explains how new inputs for height and weight are used to generate
    a prediction score for gender.
  prefs: []
  type: TYPE_NORMAL
- en: A function is created to input new height and weight values and convert the
    actual values to normalized height and weight values called `inputHeight` and `inputWeight`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A variable, `score`, is used to store the normalized values and another function, `predictGender`,
    is created to input the score values and output a gender score and description
    based on the values of `w1`, `w2`, and `b` that were created in the previous section. 
    These values have already been pre-adjusted using gradient descent to tweak the
    values and minimize the `cost` function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Applying the `score` value to the `predict_gender` function should reveal the
    gender description and score, as seen in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/74e468ef-124b-4aa2-8e77-9e74b610c494.png)'
  prefs: []
  type: TYPE_IMG
- en: It appears that the specifications of `70` inches in `height` and `180` lbs
    in `weight` is a high predictor (99.999%) for Male.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Another test for `50` inches in `height` and `150` lbs in `weight` will likely
    reveal a different gender, as seen in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/8eed7441-e377-4a4a-b906-b893a3847ab6.png)'
  prefs: []
  type: TYPE_IMG
- en: Similarly, this input produces a very low score from the `sigmoid` function
    (0.00000000839) indicating that these features are closely associated with the `Female` gender.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to learn more about testing, training, and validation data sets, visit
    the following website:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://en.wikipedia.org/wiki/Training,_test,_and_validation_sets](https://en.wikipedia.org/wiki/Training,_test,_and_validation_sets)'
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing prediction scores
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While we can individually predict the gender based on an individual with a certain
    height and weight, the entire dataset can be graphed and scored using every data
    point to determine whether the output is going to score a female or a male.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are no dependencies required for this section.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section walks through the steps to visualize all of the predicted points
    in a graph.
  prefs: []
  type: TYPE_NORMAL
- en: 'Compute the minimum and maximum points of the graph  using the following script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Generate *x* and *y* values in increments of 0.05 units and then create an
    array called `xy_data`, as seen in the following script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, a similar script to that used earlier in the chapter is used to generate
    a gender score and populate a graph, as seen in the following script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section explains how the data points are created to generate prediction
    values that will be graphed.
  prefs: []
  type: TYPE_NORMAL
- en: 'The minimum and maximum values of the graph are computed based on the array
    values. The output of the script can be seen in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/368393bd-0b7d-4d20-a2b5-4a2609fa00e2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We generate x and y values for each data point within the minimum and maximum
    values within 0.05 increments and then run each (x,y) point into the prediction
    score to plot the values.  The Female gender score is assigned a red color and
    the Male gender score is assigned a blue color as seen in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/0e791280-c635-4aa2-86cd-7768ac3a8399.png)'
  prefs: []
  type: TYPE_IMG
- en: The graph shows the cutoff between the gender scores depending on the `height` and `weight` selected.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
