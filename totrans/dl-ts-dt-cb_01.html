<html><head></head><body>
<div id="book-content">
<div id="sbo-rt-content"><div id="_idContainer012">
			<h1 id="_idParaDest-20" class="chapter-number"><a id="_idTextAnchor019"/>1</h1>
			<h1 id="_idParaDest-21"><a id="_idTextAnchor020"/>Getting Started with Time Series</h1>
			<p>In this chapter, we introduce the main concepts and techniques used in time series analysis. The chapter begins by defining time series and explaining why the analysis of these datasets is a relevant topic in data science. After that, we describe how to load time series data using the <strong class="source-inline">pandas</strong> library. The chapter dives into the basic components of a time series, such as trend and seasonality. One key concept of time series analysis covered in this chapter is that of stationarity. We will explore several methods to assess stationarity using <span class="No-Break">statistical tests.</span></p>
			<p>The following recipes will be covered in <span class="No-Break">this chapter:</span></p>
			<ul>
				<li>Loading a time series <span class="No-Break">using </span><span class="No-Break"><strong class="source-inline">pandas</strong></span></li>
				<li>Visualizing a <span class="No-Break">time series</span></li>
				<li>Resampling a <span class="No-Break">time series</span></li>
				<li>Dealing with <span class="No-Break">missing values</span></li>
				<li>Decomposing a <span class="No-Break">time series</span></li>
				<li><span class="No-Break">Computing autocorrelation</span></li>
				<li><span class="No-Break">Detecting stationarity</span></li>
				<li>Dealing <span class="No-Break">with heteroskedasticity</span></li>
				<li>Loading and visualizing a multivariate <span class="No-Break">time series</span></li>
				<li>Resampling a multivariate <span class="No-Break">time series</span></li>
				<li>Analyzing the correlation among pairs <span class="No-Break">of variables</span></li>
			</ul>
			<p>By the end of this chapter, you will have a solid foundation in the main aspects of time series analysis. This includes loading and preprocessing time series data, identifying its basic components, decomposing time series, detecting stationarity, and expanding this understanding to a multivariate setting. This knowledge will serve as a building block for the <span class="No-Break">subsequent chapters.</span></p>
			<h1 id="_idParaDest-22"><a id="_idTextAnchor021"/><a id="_idTextAnchor022"/>Technical requirements</h1>
			<p>To work through this chapter, you need to have Python 3.9 installed on your machine. We will work with the <span class="No-Break">following libraries:</span></p>
			<ul>
				<li><span class="No-Break"><strong class="source-inline">pandas</strong></span><span class="No-Break"> (2.1.4)</span></li>
				<li><span class="No-Break"><strong class="source-inline">numpy</strong></span><span class="No-Break"> (1.26.3)</span></li>
				<li><span class="No-Break"><strong class="source-inline">statsmodels</strong></span><span class="No-Break"> (0.14.1)</span></li>
				<li><span class="No-Break"><strong class="source-inline">pmdarima</strong></span><span class="No-Break"> (2.0.4)</span></li>
				<li><span class="No-Break"><strong class="source-inline">seaborn</strong></span><span class="No-Break"> (0.13.2)</span></li>
			</ul>
			<p>You can install these libraries <span class="No-Break">using </span><span class="No-Break"><strong class="source-inline">pip</strong></span><span class="No-Break">:</span></p>
			<pre class="console">
pip install pandas numpy statsmodels pmdarima seaborn</pre>			<p>In our setup, we used <strong class="source-inline">pip</strong> version 23.3.1. The code for this chapter can be found at the following GitHub <span class="No-Break">URL: </span><a href="https://github.com/PacktPublishing/Deep-Learning-for-Time-Series-Data-Cookbook"><span class="No-Break">https://github.com/PacktPublishing/Deep-Learning-for-Time-Series-Data-Cookbook</span></a></p>
			<h1 id="_idParaDest-23"><a id="_idTextAnchor023"/><a id="_idTextAnchor024"/>Loading a time series using pandas</h1>
			<p>In this first <a id="_idIndexMarker000"/>recipe, we start by loading a dataset<a id="_idIndexMarker001"/> in a Python session using <strong class="source-inline">pandas</strong>. Throughout this book, we’ll work with time series using <strong class="source-inline">pandas</strong> data structures. <strong class="source-inline">pandas</strong> is a useful Python package for data analysis and manipulation. Univariate time series can be structured as <strong class="source-inline">pandas</strong> Series objects, where the values of the series have an associated index or timestamp with a <span class="No-Break"><strong class="source-inline">pandas.Index</strong></span><span class="No-Break"> structure<a id="_idTextAnchor025"/>.</span></p>
			<h2 id="_idParaDest-24"><a id="_idTextAnchor026"/>Getting ready</h2>
			<p>We will focus on a dataset related to solar radiation that was collected by the U.S. Department of Agriculture. The data, which contains information about solar radiation (in watts per square meter), spans from October 1, 2007, to October 1, 2013. It was collected at an hourly frequency totaling <span class="No-Break">52,608 observations.</span></p>
			<p>You can download the dataset from the GitHub URL provided in the<em class="italic"> Technical requirements</em> section of this chapter. You can also find the original source at the following <span class="No-Break">URL: </span><a href="https://catalog.data.gov/dataset/data-from-weather-snow-and-streamflow-data-from-four-western-juniper-dominated-experimenta-b9e22"><span class="No-Break">https://catalog.data.gov/dataset/data-from-weather-snow-and-streamflow-data-from-four-western-juniper-dominated-experimenta-b9e2<span id="_idTextAnchor027"/>2</span></a><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-25"><a id="_idTextAnchor028"/>How to do it…</h2>
			<p>The <a id="_idIndexMarker002"/>dataset <a id="_idIndexMarker003"/>is a <strong class="source-inline">.csv</strong> file. In <strong class="source-inline">pandas</strong>, we can load a <strong class="source-inline">.csv</strong> file using the <span class="No-Break"><strong class="source-inline">pd.read_csv</strong></span><span class="No-Break"><strong class="source-inline">()</strong></span><span class="No-Break"> function:</span></p>
			<pre class="source-code">
import pandas as pd
data = pd.read_csv('path/to/data.csv',
                   parse_dates=['Datetime'],
                   index_col='Datetime')
series = data['Incoming Solar']</pre>			<p>In the preceding code, note <span class="No-Break">the following:</span></p>
			<ul>
				<li>First, we import <strong class="source-inline">pandas</strong> using the <strong class="source-inline">import</strong> keyword. Importing this library is a necessary step to make its methods available in a <span class="No-Break">Python session.</span></li>
				<li>The main argument to <strong class="source-inline">pd.read_csv</strong> is the file location. The <strong class="source-inline">parse_dates</strong> argument automatically converts the input variables (in this case, <strong class="source-inline">Datetime</strong>) into a datetime format. The <strong class="source-inline">index_col</strong> argument sets the index of the data to the <span class="No-Break"><strong class="source-inline">Datetime</strong></span><span class="No-Break"> column.</span></li>
				<li>Finally, we subset the <strong class="source-inline">data</strong> object using squared brackets to get the <strong class="source-inline">Incoming Solar</strong> column, which contains the information about solar radiation at each <span class="No-Break">time st<a id="_idTextAnchor029"/>ep.</span></li>
			</ul>
			<h2 id="_idParaDest-26"><a id="_idTextAnchor030"/>How it works…</h2>
			<p>The following table shows a sample of the data. Each row represents the level of the time series at a<a id="_idIndexMarker004"/> <span class="No-Break">particular</span><span class="No-Break"><a id="_idIndexMarker005"/></span><span class="No-Break"> hour.</span></p>
			<table id="table001-1" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
				</colgroup>
				<thead>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Datetime</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Incoming Solar</strong></span></p>
						</td>
					</tr>
				</thead>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">2007-10-01 09:00:00</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">35.4</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">2007-10-01 10:00:00</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">63.8</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">2007-10-01 11:00:00</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">99.4</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">2007-10-01 12:00:00</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">174.5</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">2007-10-01 13:00:00</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">157.9</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">2007-10-01 14:00:00</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">345.8</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">2007-10-01 15:00:00</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">329.8</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">2007-10-01 16:00:00</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">114.6</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">2007-10-01 17:00:00</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">29.9</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">2007-10-01 18:00:00</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">10.9</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">2007-10-01 19:00:00</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.0</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 1.1: Sample of an hourly univariate time series</p>
			<p>The <strong class="source-inline">series</strong> object that contains the time series is a <strong class="source-inline">pandas</strong> Series data structure. This structure contains several methods for time series analysis. We could also create a Series object by calling <strong class="source-inline">pd.Series</strong> with a dataset and the respective time series. The following<a id="_idIndexMarker006"/> is <a id="_idIndexMarker007"/>an example of this: <strong class="source-inline">pd.Series(data=values, index=timestamps)</strong>, where <strong class="source-inline">values</strong> refers to the time series values and <strong class="source-inline">timestamps</strong> represents the respective timestamp of <span class="No-Break">each observation<a id="_idTextAnchor031"/><a id="_idTextAnchor032"/>.</span></p>
			<h1 id="_idParaDest-27"><a id="_idTextAnchor033"/>Visualizing a time series</h1>
			<p>Now, we have<a id="_idIndexMarker008"/> a time series loaded in a Python session. This recipe walks you through the process of visualizing a time series in Python. Our goal is to create a line plot of the time series data, with the dates on the <em class="italic">x</em> axis and the value of the series on the <span class="No-Break"><em class="italic">y</em></span><span class="No-Break"> axi<a id="_idTextAnchor034"/>s.</span></p>
			<h2 id="_idParaDest-28"><a id="_idTextAnchor035"/>Getting ready</h2>
			<p>There are several data visualization libraries in Python. Visualizing a time series is useful to quickly identify patterns such as trends or seasonal effects. A graphic is an easy way to understand the dynamics of the data and to spot any anomalies <span class="No-Break">within it.</span></p>
			<p>In this recipe, we will create a time series plot using two different libraries: <strong class="source-inline">pandas</strong> and <strong class="source-inline">seaborn</strong>. <strong class="source-inline">seaborn</strong> is a popular data visualization <span class="No-Break">Python librar<a id="_idTextAnchor036"/>y.</span></p>
			<h2 id="_idParaDest-29">How to do i<a id="_idTextAnchor037"/>t…</h2>
			<p><strong class="source-inline">pandas</strong> Series objects contain a <strong class="source-inline">plot</strong><strong class="source-inline">()</strong> method for visualizing time series. You can use it <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
series.plot(figsize=(12,6), title='Solar radiation time series')</pre>			<p>The <strong class="source-inline">plot</strong><strong class="source-inline">()</strong> method is called with two arguments. We use the <strong class="source-inline">figsize</strong> argument to change the size of the plot. In this case, we set the width and height of the figure to <strong class="source-inline">12</strong> and <strong class="source-inline">6</strong> inches, respectively. Another argument is <strong class="source-inline">title</strong>, which we set to <strong class="source-inline">Solar radiation time series</strong>. You can check the <strong class="source-inline">pandas</strong> documentation for a complete list of <span class="No-Break">acceptable argument<a id="_idTextAnchor038"/>s.</span></p>
			<p>You use it to plot a <a id="_idIndexMarker009"/>time series using <strong class="source-inline">seaborn</strong> <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
import matplotlib.pyplot as plt
import seaborn as sns
series_df = series.reset_index()
plt.rcParams['figure.figsize'] = [12, 6]
sns.set_theme(style='darkgrid')
sns.lineplot(data=series_df, x='Datetime', y='Incoming Solar')
plt.ylabel('Solar Radiation')
plt.xlabel('')
plt.title('Solar radiation time series')
plt.show()
plt.savefig('assets/time_series_plot.png')</pre>			<p>The preceding code includes the <span class="No-Break">following steps:</span></p>
			<ol>
				<li>Import <strong class="source-inline">seaborn</strong> and <strong class="source-inline">matplotlib</strong>, two data <span class="No-Break">visualization libraries.</span></li>
				<li>Transform the time series into a <strong class="source-inline">pandas</strong> DataFrame object by calling the <strong class="source-inline">reset_index</strong><strong class="source-inline">()</strong> method. This step is required because <strong class="source-inline">seaborn</strong> takes DataFrame objects as the <span class="No-Break">main input.</span></li>
				<li>Configure the figure size using <strong class="source-inline">plt.rcParams</strong> to a width of 12 inches and a height of <span class="No-Break">6 inches.</span></li>
				<li>Set the plot theme to <strong class="source-inline">darkgrid</strong> using the <span class="No-Break"><strong class="source-inline">set_theme</strong></span><span class="No-Break"><strong class="source-inline">()</strong></span><span class="No-Break"> method.</span></li>
				<li>Use the <strong class="source-inline">lineplot</strong><strong class="source-inline">()</strong> method to build the plot. Besides the input data, it takes the name of the column for each of the axes: <strong class="source-inline">Datetime</strong> and <strong class="source-inline">Incoming Solar</strong> for the <em class="italic">x</em> axis and <em class="italic">y</em> <span class="No-Break">axis, respectively.</span></li>
				<li>Configure the plot parameters, namely the <em class="italic">y</em>-axis label (<strong class="source-inline">ylabel</strong>), <em class="italic">x</em>-axis label (<strong class="source-inline">xlabel</strong>), <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">title</strong></span><span class="No-Break">.</span></li>
				<li>Finally, we use<a id="_idIndexMarker010"/> the <strong class="source-inline">show</strong> method to display the plot and <strong class="source-inline">savefig</strong> to store it as a <strong class="source-inline">.</strong><span class="No-Break"><strong class="source-inline">png</strong></span><span class="No-Break"> f<a id="_idTextAnchor039"/>ile.</span></li>
			</ol>
			<h2 id="_idParaDest-30"><a id="_idTextAnchor040"/>How it works…</h2>
			<p>The following figure shows the plot obtained from the <span class="No-Break"><strong class="source-inline">seaborn</strong></span><span class="No-Break"> library:</span></p>
			<div>
				<div id="_idContainer005" class="IMG---Figure">
					<img src="image/B21145_01_001.jpg" alt="Figure 1.1: Time series plot using seaborn" width="723" height="377"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.1: Time series plot using seaborn</p>
			<p>The example time series shows a strong yearly seasonality, where the average level is lower at the start of the year. Apart from some fluctuations and seasonality, the long-term average level of the time series remains stable <span class="No-Break">over time.</span></p>
			<p>We learned about two ways of creating a time series plot. One uses the <strong class="source-inline">plot</strong><strong class="source-inline">()</strong> method that is available in <strong class="source-inline">pandas</strong>, and another one uses <strong class="source-inline">seaborn</strong>, a Python library dedicated <a id="_idIndexMarker011"/>to data visualization. The first one provides a quick way of visualizing your data. But <strong class="source-inline">seaborn</strong> has a more powerful visualization toolkit that you can use to create <span class="No-Break">beautiful pl<a id="_idTextAnchor041"/>ots.</span></p>
			<h2 id="_idParaDest-31"><a id="_idTextAnchor042"/>There’s more…</h2>
			<p>The type of plot created in this recipe is called a line plot. Both <strong class="source-inline">pandas</strong> and <strong class="source-inline">seaborn</strong> can be used to create other types of plots. We encourage you to go through the documentation to learn <span class="No-Break">about th<a id="_idTextAnchor043"/>e<a id="_idTextAnchor044"/>se.</span></p>
			<h1 id="_idParaDest-32"><a id="_idTextAnchor045"/>Resampling a time series</h1>
			<p>Time series<a id="_idIndexMarker012"/> resampling is the process of changing the frequency of a time series, for example, from hourly to daily. This task is a common preprocessing step in time series analysis and this recipe shows how to do it <span class="No-Break">with </span><span class="No-Break"><strong class="source-inline">pan<a id="_idTextAnchor046"/>das</strong></span><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-33"><a id="_idTextAnchor047"/>Getting ready</h2>
			<p>Changing the frequency of a time series is a common preprocessing step before analysis. For example, the time series used in the preceding recipes has an hourly granularity. Yet, our goal may be to study daily variations. In such cases, we can resample the data into a different period. Resampling is also an effective way of handling irregular time series – those that are collected in irregularly <span class="No-Break">spaced per<a id="_idTextAnchor048"/>iods.</span></p>
			<h2 id="_idParaDest-34"><a id="_idTextAnchor049"/>How to do it…</h2>
			<p>We’ll go over two different scenarios where resampling a time series may be useful: when changing the sampling frequency and when dealing with irregular <span class="No-Break">time se<a id="_idTextAnchor050"/>ries.</span></p>
			<p>The following code resamples the time series into a <span class="No-Break">daily granularity:</span></p>
			<pre class="source-code">
series_daily = series.resample('D').sum()</pre>			<p>The daily granularity is specified with the input <strong class="source-inline">D</strong> to the <strong class="source-inline">resample</strong> () method. The values of each corresponding day are summed together using the <span class="No-Break"><strong class="source-inline">sum</strong></span><span class="No-Break"><strong class="source-inline">()</strong></span><span class="No-Break"> me<a id="_idTextAnchor051"/>thod.</span></p>
			<p>Most time series analysis methods work under the assumption that the time series is regular; in other words, it is collected in regularly spaced time intervals (for example, every day). But some time series are naturally irregular. For instance, the sales of a retail product occur at arbitrary timestamps as customers arrive at <span class="No-Break">a store.</span></p>
			<p>Let us simulate sale events with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
import numpy as np
import pandas as pd
n_sales = 1000
start = pd.Timestamp('2023-01-01 09:00')
end = pd.Timestamp('2023-04-01')
n_days = (end – start).days + 1
irregular_series = pd.to_timedelta(np.random.rand(n_sales) * n_days,
                                   unit='D') + start</pre>			<p>The preceding code creates <strong class="source-inline">1000</strong> sale events from <strong class="source-inline">2023-01-01 09:00</strong> to <strong class="source-inline">2023-04-01</strong>. A sample of<a id="_idIndexMarker013"/> this series is shown in the <span class="No-Break">following table:</span></p>
			<table id="table002" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
				</colgroup>
				<thead>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">ID</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Timestamp</strong></span></p>
						</td>
					</tr>
				</thead>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>1</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">2023-01-01 15:18:10</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>2</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">2023-01-01 15:28:15</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>3</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">2023-01-01 16:31:57</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>4</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">2023-01-01 16:52:29</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>5</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">2023-01-01 23:01:24</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>6</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">2023-01-01 23:44:39</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 1.2: Sample of an irregular time series</p>
			<p>Irregular time series can be transformed into a regular frequency by resampling. In the case of sales, we will count how many sales occurred <span class="No-Break">each day:</span></p>
			<pre class="source-code">
ts_sales = pd.Series(0, index=irregular_series)
tot_sales = ts_sales.resample('D').count()</pre>			<p>First, we create a time series of zeros based on the irregular timestamps (<strong class="source-inline">ts_sales</strong>). Then, we resample this dataset into a daily frequency (<strong class="source-inline">D</strong>) and use the <strong class="source-inline">count</strong><strong class="source-inline">()</strong> method to count how many observations occur each day. The <strong class="source-inline">tot_sales</strong> reconstructed time series can be used for other tasks, such as forecasting <span class="No-Break">daily sales.</span></p>
			<h2 id="_idParaDest-35"><a id="_idTextAnchor052"/>How it works…</h2>
			<p>A sample of the reconstructed time series concerning solar radiation is shown in the <span class="No-Break">following table:</span></p>
			<table id="table003" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
				</colgroup>
				<thead>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Datetime</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Incoming Solar</strong></span></p>
						</td>
					</tr>
				</thead>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">2007-10-01</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">1381.5</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">2007-10-02</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">3953.2</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">2007-10-03</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">3098.1</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">2007-10-04</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">2213.9</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 1.3: Solar radiation time series after resampling</p>
			<p>Resampling is a <a id="_idIndexMarker014"/>cornerstone preprocessing step in time series analysis. This technique can be used to change a time series into a different granularity or to convert an irregular time series into a <span class="No-Break">regular one.</span></p>
			<p>The summary statistic is an important input to consider. In the first case, we used <strong class="source-inline">sum</strong> to add the hourly solar radiation values observed each day. In the case of the irregular time series, we used the <strong class="source-inline">count</strong><strong class="source-inline">()</strong> method to count how many events occurred in each period. Yet, you can use other summary statistics according to your needs. For example, using the mean would take the average value of each period to resample the <span class="No-Break">time series.</span><a id="_idTextAnchor053"/></p>
			<h2 id="_idParaDest-36"><a id="_idTextAnchor054"/>There’s more…</h2>
			<p>We resampled to daily granularity. A list of available options is available <span class="No-Break">here: </span><a href="https://pandas.pydata.org/docs/user_guide/timeseries.html#dateoffset-objects"><span class="No-Break">https://pandas.pydata.org/docs/user_guide/timeseries.html#dateoffset-objects</span></a><span class="No-Break">.</span><span class="hidden"><a id="_idTextAnchor055"/><a id="_idTextAnchor056"/></span></p>
			<h1 id="_idParaDest-37"><a id="_idTextAnchor057"/>Dealing with missing values</h1>
			<p>In this recipe, we’ll <a id="_idIndexMarker015"/>cover how to impute time series missing values. We’ll discuss different methods of imputing missing values and the factors to consider when choosing a method. We’ll show an example of how to solve this problem <span class="No-Break">using </span><span class="No-Break"><strong class="source-inline">pandas<a id="_idTextAnchor058"/></strong></span><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-38"><a id="_idTextAnchor059"/>Getting ready</h2>
			<p>Missing values are an issue that plagues all kinds of data, including time series. Observations are often unavailable for various reasons, such as sensor failure or annotation errors. In such cases, data imputation can be used to overcome this problem. Data imputation works by assigning a value based on some rule, such as the mean or some <span class="No-Break">predefined value<a id="_idTextAnchor060"/>.</span></p>
			<h2 id="_idParaDest-39"><a id="_idTextAnchor061"/>How to do it…</h2>
			<p>We start by simulating missing data. The following code removes 60% of observations from a sample of two years of the solar radiation <span class="No-Break">time series:</span></p>
			<pre class="source-code">
import numpy as np
sample_with_nan = series_daily.head(365 * 2).copy()
size_na=int(0.6 * len(sample_with_nan))
idx = np.random.choice(a=range(len(sample_with_nan)),
                       size=size_na,
                       replace=False)
sample_with_nan[idx] = np.nan</pre>			<p>We leverage the <strong class="source-inline">np.random.choice</strong><strong class="source-inline">()</strong> method from <strong class="source-inline">numpy</strong> to select a random sample of the time series. The observations of this sample are changed to a missing <span class="No-Break">value (</span><span class="No-Break"><strong class="source-inline">np.nan</strong></span><span class="No-Break">).</span></p>
			<p>In datasets without temporal order, it is common to impute missing values using central statistics such as the mean or median. This can be done <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
average_value = sample_with_nan.mean()
imp_mean = sample_with_nan.fillna(average_value)</pre>			<p>Time series imputation must take into account the temporal nature of observations. This means that the assigned value should follow the dynamics of the series. A more common approach in time series is to impute missing data with the last known observation. This<a id="_idIndexMarker016"/> approach is implemented in the <span class="No-Break"><strong class="source-inline">ffill</strong></span><span class="No-Break"><strong class="source-inline">()</strong></span><span class="No-Break"> method:</span></p>
			<pre class="source-code">
imp_ffill = sample_with_nan.ffill()</pre>			<p>Another, less common, approach that uses the order of observations <span class="No-Break">is </span><span class="No-Break"><strong class="source-inline">bfill</strong></span><span class="No-Break"><strong class="source-inline">()</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
imp_bfill = sample_with_nan.bfill()</pre>			<p>The <strong class="source-inline">bfill</strong><strong class="source-inline">()</strong> method imputes missing data with the next available observation in <span class="No-Break">the datase<a id="_idTextAnchor062"/>t.</span></p>
			<h2 id="_idParaDest-40"><a id="_idTextAnchor063"/>How it works…</h2>
			<p>The following figure shows the reconstructed time series after imputation with <span class="No-Break">each method:</span></p>
			<div>
				<div id="_idContainer006" class="IMG---Figure">
					<img src="image/B21145_01_002.jpg" alt="Figure 1.2: Imputing missing data with different strategies" width="840" height="560"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.2: Imputing missing data with different strategies</p>
			<p>The <strong class="source-inline">mean</strong> imputation approach misses the time series dynamics, while both <strong class="source-inline">ffill</strong> and <strong class="source-inline">bfill</strong> lead to a reconstructed time series with similar dynamics as the original time series. Usually, <strong class="source-inline">ffill</strong> is preferable because it does not break the temporal order of<a id="_idIndexMarker017"/> observations, that is, using future information to alter (impute) <span class="No-Break">the past.</span></p>
			<h2 id="_idParaDest-41"><a id="_idTextAnchor064"/>There’s more…</h2>
			<p>The imputation process can also be carried out using some conditions, such as limiting the number of imputed observations. You can learn more about this in the documentation pages of these functions, for <span class="No-Break">example, </span><a href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ffill.html"><span class="No-Break">https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ffill.html<span id="_idTextAnchor065"/><span id="_idTextAnchor066"/></span></a><span class="No-Break">.</span></p>
			<h1 id="_idParaDest-42"><a id="_idTextAnchor067"/>Decomposing a time series</h1>
			<p>Time series<a id="_idIndexMarker018"/> decomposition is the process of splitting a time series into its basic components, such as trend or seasonality. This recipe explores different techniques to solve this task and how to choose <span class="No-Break">among th<a id="_idTextAnchor068"/>em.</span></p>
			<h2 id="_idParaDest-43"><a id="_idTextAnchor069"/>Getting ready</h2>
			<p>A time series is composed of three parts – trend, seasonality, and <span class="No-Break">the remainder:</span></p>
			<ul>
				<li>The trend characterizes the long-term change in the level of a time series. Trends can be upward (increase in level) or downward (decrease in level), and they can also change <span class="No-Break">over time.</span></li>
				<li>Seasonality refers to regular variations in fixed periods, such as every day. The solar radiation time series plotted in the preceding recipe shows a clear yearly seasonality. Solar radiation is higher during summer and lower <span class="No-Break">during winter.</span></li>
				<li>The remainder (also called irregular) of the time series is what is left after removing the trend and <span class="No-Break">seasonal components.</span></li>
			</ul>
			<p>Breaking a time series into its components is useful to understand the underlying structure of <span class="No-Break">the data.</span></p>
			<p>We’ll describe the process of time series decomposition with two methods: the classical decomposition approach and a method based on local regression. You’ll also learn how to extend<a id="_idIndexMarker019"/> the latter method to time series with multiple <span class="No-Break">seasonal patte<a id="_idTextAnchor070"/>rns.</span></p>
			<h2 id="_idParaDest-44">How to do<a id="_idTextAnchor071"/> it…</h2>
			<p>There are several approaches for decomposing a time series into its basic parts. The simplest method is known as classical decomposition. This approach is implemented in the <strong class="source-inline">statsmodels</strong> library and can be used <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
from statsmodels.tsa.seasonal import seasonal_decompose
result = seasonal_decompose(x=series_daily,
                            model='additive',
                            period=365)</pre>			<p>Besides the dataset, you need to specify the period and the type of model. For a daily time series with a yearly seasonality, the period should be set to <strong class="source-inline">365</strong>, which is the number of days in a year. The <strong class="source-inline">model</strong> parameter can be either <strong class="source-inline">additive</strong> or <strong class="source-inline">multiplicative</strong>. We’ll go into more detail about this in the <span class="No-Break">next section.</span></p>
			<p>Each component is stored as an attribute of the results in <span class="No-Break">an object:</span></p>
			<pre class="source-code">
result.trend
result.seasonal
result.resid</pre>			<p>Each of these attributes returns a time series with the <span class="No-Break">respective compon<a id="_idTextAnchor072"/>ent.</span></p>
			<p>Arguably, one of the most popular methods for time series decomposition is <strong class="bold">STL</strong> (which stands <a id="_idIndexMarker020"/>for <strong class="bold">Seasonal and Trend decomposition using LOESS</strong>). This method is also available <span class="No-Break">on </span><span class="No-Break"><strong class="source-inline">statsmodels</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
from statsmodels.tsa.seasonal import STL
result = STL(endog=series_daily, period=365).fit()</pre>			<p>In the case of <strong class="source-inline">STL</strong>, you don’t need to specify a model as we did with the <span class="No-Break">classical me<a id="_idTextAnchor073"/>thod.</span></p>
			<p>Usually, time series <a id="_idIndexMarker021"/>decomposition approaches work under the assumption that the dataset contains a single seasonal pattern. Yet, time series collected in high sampling frequencies (such as hourly or daily) can contain multiple seasonal patterns. For example, an hourly time series can show both regular daily and <span class="No-Break">weekly variations.</span></p>
			<p>The <strong class="source-inline">MSTL</strong><strong class="source-inline">()</strong> method (short<a id="_idIndexMarker022"/> for <strong class="bold">Multiple STL</strong>) extends MSTL for time series with multiple seasonal patterns. You can specify the period for each seasonal pattern in a tuple as the input for the <strong class="source-inline">period</strong> argument. An example is shown in the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
from statsmodels.tsa.seasonal import MSTL
result = MSTL(endog=series_daily, periods=(7, 365)).fit()</pre>			<p>In the preceding code, we passed two periods as input: <strong class="source-inline">7</strong> and <strong class="source-inline">365</strong>. These periods attempt to capture weekly and yearly seasonality in a daily <span class="No-Break">time <a id="_idTextAnchor074"/>series.</span></p>
			<h2 id="_idParaDest-45"><a id="_idTextAnchor075"/>How it works…</h2>
			<p>In a given time step <strong class="source-inline">i</strong>, the value of the time series (<strong class="source-inline">Y</strong><span class="subscript">i</span>) can be decomposed using an additive model, <span class="No-Break">as follows:</span></p>
			<p><em class="italic">Y</em><span class="subscript">i </span><em class="italic">= </em><span class="No-Break"><em class="italic">Trend</em></span><span class="No-Break"><span class="subscript">i</span></span><span class="No-Break"><em class="italic">+Seasonality</em></span><span class="No-Break"><span class="subscript">i</span></span><span class="No-Break"><em class="italic">+Remainder</em></span><span class="No-Break"><span class="subscript">i</span></span></p>
			<p>This decomposition can also <span class="No-Break">be multiplicative:</span></p>
			<p><em class="italic">Y</em><span class="subscript">i </span><em class="italic">= </em><span class="No-Break"><em class="italic">Trend</em></span><span class="No-Break"><span class="subscript">i</span></span><span class="No-Break"><em class="italic">×Seasonality</em></span><span class="No-Break"><span class="subscript">i</span></span><span class="No-Break"><em class="italic">×Remainder</em></span><span class="No-Break"><span class="subscript">i</span></span></p>
			<p>The most appropriate approach, additive or multiplicative, depends on the input data. But you can turn a multiplicative decomposition into an additive one by transforming the data with the logarithm function. The logarithm stabilizes the variance, thus making<a id="_idIndexMarker023"/> the series additive regarding <span class="No-Break">its components.</span></p>
			<p>The results of the classical decomposition are shown in the <span class="No-Break">following figure:</span></p>
			<div>
				<div id="_idContainer007" class="IMG---Figure">
					<img src="image/B21145_01_003.jpg" alt="Figure 1.3: Time series components after decomposition with the classical method" width="840" height="560"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.3: Time series components after decomposition with the classical method</p>
			<p>In the classical decomposition, the trend is estimated using a moving average, for example, the average of the last 24 hours (for hourly series). Seasonality is estimated by averaging the values of each period. <strong class="source-inline">STL</strong> is a more flexible method for decomposing a time series. It can handle complex patterns, such as irregular trends or outliers. <strong class="source-inline">STL</strong> leverages <strong class="bold">LOESS</strong>, which stands for <strong class="bold">locally weighted scatterplot smoothing</strong>, to extract<a id="_idIndexMarker024"/> <span class="No-Break">each component.</span></p>
			<h2 id="_idParaDest-46"><a id="_idTextAnchor076"/>There’s more…</h2>
			<p>Decomposition is usually<a id="_idIndexMarker025"/> done for data exploration purposes. But it can also be used as a preprocessing step for forecasting. For example, some studies show that removing seasonality before training a neural network improves <span class="No-Break">forecasting performance.</span></p>
			<h2 id="_idParaDest-47"><a id="_idTextAnchor077"/>See also</h2>
			<p>You can learn more about this in the <span class="No-Break">following references:</span></p>
			<ul>
				<li>Hewamalage, Hansika, Christoph Bergmeir, and Kasun Bandara. “Recurrent neural networks for time series forecasting: Current status and future directions.” <em class="italic">International Journal of Forecasting</em> 37.1 (<span class="No-Break">2021): 388-427.</span></li>
				<li>Hyndman, Rob J., and George Athanasopoulos. <em class="italic">Forecasting: Principles and Practice</em>. <span class="No-Break">OTex<a id="_idTextAnchor078"/><a id="_idTextAnchor079"/>ts, 2018.</span></li>
			</ul>
			<h1 id="_idParaDest-48"><a id="_idTextAnchor080"/>Computing autocorrelation</h1>
			<p>This recipe guides <a id="_idIndexMarker026"/>you through the process of computing autocorrelation. Autocorrelation is a measure of the correlation between a time series and itself at different lags, and it is helpful to understand the structure of time series, specifically, to quantify how past values affect <span class="No-Break">t<a id="_idTextAnchor081"/>he future.</span></p>
			<h2 id="_idParaDest-49"><a id="_idTextAnchor082"/>Getting ready</h2>
			<p>Correlation is a statistic that measures the linear relationship between two random variables. Autocorrelation extends this notion to time series data. In time series, the value observed in a given time step will be similar to the values observed before it. The autocorrelation function quantifies the linear relationship between a time series and a lagged version of itself. A lagged time series refers to a time series that is shifted over a number <span class="No-Break">of<a id="_idTextAnchor083"/> periods.</span></p>
			<h2 id="_idParaDest-50"><a id="_idTextAnchor084"/>How to do it…</h2>
			<p>We can compute the autocorrelation function <span class="No-Break">using </span><span class="No-Break"><strong class="source-inline">statsmodels</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
from statsmodels.tsa.stattools import acf
acf_scores = acf(x=series_daily, nlags=365)</pre>			<p>The inputs to the function are a time series and the number of lags to analyze. In this case, we compute autocorrelation up to <strong class="source-inline">365</strong> lags, a full year <span class="No-Break">of data.</span></p>
			<p>We can also use <strong class="source-inline">statsmodels</strong> to compute the partial autocorrelation function. This measure extends the autocorrelation by controlling for the correlation of the time series at <span class="No-Break">shorter lags:</span></p>
			<pre class="source-code">
from statsmodels.tsa.stattools import pacf
pacf_scores = pacf(x=series_daily, nlags=365)</pre>			<p>The <strong class="source-inline">statsmodels</strong> library<a id="_idIndexMarker027"/> also provides functions to plot the results of <span class="No-Break">autocorrelation analysis:</span></p>
			<pre class="source-code">
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
plot_acf(series_daily, lags=365)
plot_pacf(series_daily<a id="_idTextAnchor085"/>, lags=365)</pre>			<h2 id="_idParaDest-51"><a id="_idTextAnchor086"/>How it works…</h2>
			<p>The following figure shows the autocorrelation of the daily solar radiation time series up to <span class="No-Break"><strong class="source-inline">365</strong></span><span class="No-Break"> lags.</span></p>
			<div>
				<div id="_idContainer008" class="IMG---Figure">
					<img src="image/B21145_01_004.jpg" alt="Figure 1.4: Autocorrelation scores up to 365 lags. The oscillations indicate seasonality" width="840" height="620"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.4: Autocorrelation scores up to 365 lags. The oscillations indicate seasonality</p>
			<p>The oscillations in this plot are due to the yearly seasonal pattern. The analysis of autocorrelation is a<a id="_idIndexMarker028"/> useful approach to <span class="No-Break">detecting seasonality.</span></p>
			<h2 id="_idParaDest-52"><a id="_idTextAnchor087"/>There’s more…</h2>
			<p>The autocorrelation at each seasonal lag is usually large and positive. Besides, sometimes autocorrelation decays slowly along the lags, which indicates the presence of a trend. You can learn more about this from the following <span class="No-Break">URL: </span><a href="https://otexts.com/fpp3/components.html"><span class="No-Break">https://otexts.com/fpp3/components.html</span></a><span class="No-Break">.</span></p>
			<p>The partial autocorrelation function is an important tool for identifying the order of autoregressive models. The idea is to select the number of lags whose partial autocorrelation <span class="No-Break">is s<a id="_idTextAnchor088"/><a id="_idTextAnchor089"/>ignificant.</span></p>
			<h1 id="_idParaDest-53"><a id="_idTextAnchor090"/>Detecting stationarity</h1>
			<p>Stationarity is a central<a id="_idIndexMarker029"/> concept in time series analysis and an important assumption made by many time series models. This recipe walks you through the process of testing a time series <span class="No-Break">for st<a id="_idTextAnchor091"/>ationarity.</span></p>
			<h2 id="_idParaDest-54"><a id="_idTextAnchor092"/>Getting ready</h2>
			<p>A time series is stationary if its statistical properties do not change. It does not mean that the series does not change over time, just that the way it changes does not itself change over time. This includes the level of the time series, which is constant under stationary conditions. Time series patterns such as trend or seasonality break stationarity. Therefore, it may help to deal with these issues before modeling. As we described in the <em class="italic">Decomposing a time series</em> recipe, there is evidence that removing seasonality improves the forecasts of deep <span class="No-Break">learning models.</span></p>
			<p>We can stabilize the mean level of the time series by differencing. Differencing is the process of taking the difference between consecutive observations. This process works in <span class="No-Break">two steps:</span></p>
			<ol>
				<li>Estimate the number of differencing steps required <span class="No-Break">for stationarity.</span></li>
				<li>Apply the required number of <span class="No-Break">differencing<a id="_idTextAnchor093"/> operations.</span></li>
			</ol>
			<h2 id="_idParaDest-55"><a id="_idTextAnchor094"/>How to do it…</h2>
			<p>We can estimate the <a id="_idIndexMarker030"/>required differencing steps with statistical tests, such as the augmented Dickey-Fuller test, or the KPSS test. These are implemented in the <strong class="source-inline">ndiffs</strong><strong class="source-inline">()</strong> function, which is available in the <span class="No-Break"><strong class="source-inline">pmdarima</strong></span><span class="No-Break"> library:</span></p>
			<pre class="source-code">
from pmdarima.arima import ndiffs
ndiffs(x=series_daily, test='adf')</pre>			<p>Besides the time series, we pass <strong class="source-inline">test='adf'</strong> as an input to set the method to the augmented Dickey-Fuller test. The output of this function is the number of differencing steps, which in this case is <strong class="source-inline">1</strong>. Then, we can differentiate the time series using the <span class="No-Break"><strong class="source-inline">diff</strong></span><span class="No-Break"><strong class="source-inline">()</strong></span><span class="No-Break"> method:</span></p>
			<pre class="source-code">
series_changes = series_daily.diff()</pre>			<p>Differencing can also be applied over seasonal periods. In such cases, seasonal differencing involves computing the difference between consecutive observations of the same <span class="No-Break">seasonal period:</span></p>
			<pre class="source-code">
from pmdarima.arima import nsdiffs
nsdiffs(x=series_changes, test='ch', m=365)</pre>			<p>Besides the data and the test (<strong class="source-inline">ch</strong> for Canova-Hansen), we also specify the number of periods. In this case, this parameter is set to <strong class="source-inline">365</strong> (number of day<a id="_idTextAnchor095"/>s in <span class="No-Break">a year).</span></p>
			<h2 id="_idParaDest-56"><a id="_idTextAnchor096"/>How it works…</h2>
			<p>The differenced time <a id="_idIndexMarker031"/>series is shown in the <span class="No-Break">following figure.</span></p>
			<div>
				<div id="_idContainer009" class="IMG---Figure">
					<img src="image/B21145_01_005.jpg" alt="Figure 1.5: Sample of the series of changes between consecutive periods after differencing" width="713" height="504"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.5: Sample of the series of changes between consecutive periods after differencing</p>
			<p>Differencing works as a preprocessing step. First, the time series is differenced until it becomes stationary. Then, a forecasting model is created based on the differenced time series. The forecasts provided by the model can be transformed to the original scale by reverting the <span class="No-Break">differencing<a id="_idTextAnchor097"/> operations.</span></p>
			<h2 id="_idParaDest-57"><a id="_idTextAnchor098"/>There’s more…</h2>
			<p>In this recipe, we <a id="_idIndexMarker032"/>focused on two particular methods for testing stationarity. You can check other options in the function <span class="No-Break">documentation: </span><a href="https://alkaline-ml.com/pmdarima/modules/generated/pmdarima.arima.ndiffs.html"><span class="No-Break">https://alkaline-ml.com/pmdarima/modules/generated/pmdarima.ari<span id="_idTextAnchor099"/><span id="_idTextAnchor100"/>ma.ndiffs.html</span></a><span class="No-Break">.</span></p>
			<h1 id="_idParaDest-58"><a id="_idTextAnchor101"/>Dealing with heteroskedasticity</h1>
			<p>In this recipe, we <a id="_idIndexMarker033"/>delve into the variance of time series. The variance of a time series is a measure of how spread out the data is and how this dispersion evolves over time. You’ll learn how to handle data with a <span class="No-Break">cha<a id="_idTextAnchor102"/>nging variance.</span></p>
			<h2 id="_idParaDest-59"><a id="_idTextAnchor103"/>Getting ready</h2>
			<p>The variance of time series can change over time, which also violates stationarity. In such cases, the time series is referred to as heteroskedastic and usually shows a long-tailed distribution. This means the data is left- or right-skewed. This condition is problematic because it impacts the training of neural networks an<a id="_idTextAnchor104"/>d <span class="No-Break">other models.</span></p>
			<h2 id="_idParaDest-60"><a id="_idTextAnchor105"/>How to do it…</h2>
			<p>Dealing with non-constant variance is a two-step process. First, we use statistical tests to check whether a time series is heteroskedastic. Then, we use transformations such as the logarithm to stabiliz<a id="_idTextAnchor106"/>e <span class="No-Break">the variance.</span></p>
			<p>We can detect heteroskedasticity using statistical tests such as the White test or the Breusch-Pagan test. The following code implements these tests based on the <span class="No-Break"><strong class="source-inline">statsmodels</strong></span><span class="No-Break"> library:</span></p>
			<pre class="source-code">
import statsmodels.stats.api as sms
from statsmodels.formula.api import ols
series_df = series_daily.reset_index(drop=True).reset_index()
series_df.columns = ['time', 'value']
series_df['time'] += 1
olsr = ols('value ~ time', series_df).fit()
_, pval_white, _, _ = sms.het_white(olsr.resid, olsr.model.exog)
_, pval_bp, _, _ = sms.het_breuschpagan(olsr.resid, olsr.model.exog)</pre>			<p>The preceding code follows <span class="No-Break">these steps:</span></p>
			<ol>
				<li>Import the <strong class="source-inline">statsmodels</strong> modules <strong class="source-inline">ols</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">stats</strong></span><span class="No-Break">.</span></li>
				<li>Create a DataFrame based on the values of the time series and the row they were collected at (<strong class="source-inline">1</strong> for the <span class="No-Break">first observation).</span></li>
				<li>Create a linear model that relates the values of the time series with the <span class="No-Break"><strong class="source-inline">time</strong></span><span class="No-Break"> column.</span></li>
				<li>Run <strong class="source-inline">het_white</strong> (White) and <strong class="source-inline">het_breuschpagan</strong> (Breusch-Pagan) to apply the <span class="No-Break">variance tests.</span></li>
			</ol>
			<p>The output of the<a id="_idIndexMarker034"/> tests is a p-value, where the null hypothesis posits that the time series has constant variance. So, if the p-value is below the significance value, we reject the null hypothesis and <span class="No-Break">assume het<a id="_idTextAnchor107"/>eroskedasticity.</span></p>
			<p>The simplest way to deal with non-constant variance is by transforming the data using the logarithm. This operation can be implemented <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
import numpy as np
class LogTransformation:
    @staticmethod
    def transform(x):
        xt = np.sign(x) * np.log(np.abs(x) + 1)
        return xt
    @staticmethod
    def inverse_transform(xt):
        x = np.sign(xt) * (np.exp(np.abs(xt)) - 1)
        return x</pre>			<p>The preceding code is a Python class called <strong class="source-inline">LogTransformation</strong>. It contains two methods: <strong class="source-inline">transform</strong><strong class="source-inline">()</strong> and <strong class="source-inline">inverse_transform</strong><strong class="source-inline">()</strong>. The first transforms the data using the logarithm and the second reverts <span class="No-Break">that operation.</span></p>
			<p>We apply the <strong class="source-inline">transform</strong><strong class="source-inline">()</strong> method to the time series <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
series_log = LogTransformation.transform(series_daily)</pre>			<p>The log is a particular case of Box-Cox transformation that is available in the <strong class="source-inline">scipy</strong> library. You can implement this method <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
series_transformed, lmbda = stats.boxcox(series_daily)</pre>			<p>The <strong class="source-inline">stats.boxcox</strong><strong class="source-inline">()</strong> method estimates a transformation parameter, <strong class="source-inline">lmbda</strong>, which can be used to rever<a id="_idTextAnchor108"/>t <span class="No-Break">the operation.</span></p>
			<h2 id="_idParaDest-61"><a id="_idTextAnchor109"/>How it works…</h2>
			<p>The transformations <a id="_idIndexMarker035"/>outlined in this recipe stabilize the variance of a time series. They also bring the data distribution closer to the <strong class="source-inline">Normal</strong> distribution. These transformations are especially useful for neural networks as they help avoid saturation areas. In neural networks, saturation occurs when the model becomes insensitive to different inputs, thus compromising the <a id="_idTextAnchor110"/><span class="No-Break">training process.</span></p>
			<h2 id="_idParaDest-62"><a id="_idTextAnchor111"/>There’s more…</h2>
			<p>The Yeo-Johnson power transformation is similar to the Box-Cox transformation but allows for negative values in the time series. You can learn more about this method with the following <span class="No-Break">link: </span><a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.yeojohnson.html"><span class="No-Break">https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.yeojohnson.html</span></a><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-63"><a id="_idTextAnchor112"/>See also</h2>
			<p>You can learn more about the importance of the logarithm transformation in the <span class="No-Break">following reference:</span></p>
			<p>Bandara, Kasun, Christoph Bergmeir, and Slawek Smyl. “Forecasting across time series databases using recurrent neural networks on groups of similar series: A clustering approach.” <em class="italic">Expert Systems with Applications</em> 14<a id="_idTextAnchor113"/>0 (<a id="_idTextAnchor114"/><span class="No-Break">2020): 112896.</span></p>
			<h1 id="_idParaDest-64"><a id="_idTextAnchor115"/>Loading and visualizing a multivariate time series</h1>
			<p>So far, we’ve<a id="_idIndexMarker036"/> learned how to analyze univariate time series. Yet, multivariate time series are also relevant in real-world problems. This recipe explores how to load a multivariate time series. Before, we used the <strong class="source-inline">pandas</strong> Series structure to handle univariate time series. Multivariate time series are better structured as <strong class="source-inline">pandas</strong> <a id="_idTextAnchor116"/><span class="No-Break">DataFrame objects.</span></p>
			<h2 id="_idParaDest-65"><a id="_idTextAnchor117"/>Getting ready</h2>
			<p>A multivariate time series contains multiple variables. The concepts underlying time series analysis are extended to cases where multiple variables evolve over time and are interrelated with each other. The relationship between the different variables can be difficult to model, especially when the number of these variables <span class="No-Break">is large.</span></p>
			<p>In many real-world applications, multiple variables can influence each other and exhibit a temporal dependency. For example, in weather modeling, the incoming solar radiation is correlated with other meteorological variables, such as air temperature or humidity. Considering these variables with a single multivariate model can be fundamental for modeling the dynamics of the data and getting <span class="No-Break">better predictions.</span></p>
			<p>We’ll continue to study the solar radiation dataset. This time series is extended by including extra <span class="No-Break">meteorolog<a id="_idTextAnchor118"/>ical information.</span></p>
			<h2 id="_idParaDest-66"><a id="_idTextAnchor119"/>How to do it…</h2>
			<p>We’ll start by reading a multivariate time series. Like in the <em class="italic">Loading a time series using pandas</em> recipe, we resort to <strong class="source-inline">pandas</strong> and read a <strong class="source-inline">.csv</strong> file into a DataFrame <span class="No-Break">data structure:</span></p>
			<pre class="source-code">
import pandas as pd
data = pd.read_csv('path/to/multivariate_ts.csv',
                   parse_dates=['datetime'],
                   index_col='datetime')</pre>			<p>The <strong class="source-inline">parse_dates</strong> and <strong class="source-inline">index_col</strong> arguments ensure that the index of the DataFrame is a <strong class="source-inline">DatetimeIndex</strong> object. This is important so that <strong class="source-inline">pandas</strong> treats this object as a time series. After loading the time series, we can transform and visualize it using <a id="_idIndexMarker037"/>the <span class="No-Break"><strong class="source-inline">plot</strong></span><span class="No-Break"><strong class="source-inline">()</strong></span><span class="No-Break"> method:</span></p>
			<pre class="source-code">
data_log = LogTransformation.transform(data)
sample = data_log.tail(1000)
mv_plot = sample.plot(figsize=(15, 8),
                      title='Multivariate time series',
                      xlabel='',
                      ylabel='Value')
mv_plot.legend(fancybox=True, framealpha=1)</pre>			<p>The preceding code follows <span class="No-Break">these steps:</span></p>
			<ol>
				<li>First, we transform the data using <span class="No-Break">the logarithm.</span></li>
				<li>We take the last 1,000 observations to make the visualization <span class="No-Break">less cluttered.</span></li>
				<li>Finally, we use the <strong class="source-inline">plot</strong><strong class="source-inline">()</strong> method to create a visualization. We also call <strong class="source-inline">legend</strong> to configure the <a id="_idTextAnchor120"/>legend of <span class="No-Break">the plot.</span></li>
			</ol>
			<h2 id="_idParaDest-67"><a id="_idTextAnchor121"/>How it works…</h2>
			<p>A sample of the multivariate time series is displayed in the <span class="No-Break">following figure:</span></p>
			<div>
				<div id="_idContainer010" class="IMG---Figure">
					<img src="image/B21145_01_006.jpg" alt="Figure 1.6: Multivariate time series plot" width="1247" height="719"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.6: Multivariate time series plot</p>
			<p>The process of loading<a id="_idIndexMarker038"/> a multivariate time series works like the univariate case. The main difference is that a multivariate time series is stored in Python as a DataFrame object rather than a <span class="No-Break">Series one.</span></p>
			<p>From the preceding plot, we can notice that different variables follow different distributions and have distinct average and <a id="_idTextAnchor122"/><a id="_idTextAnchor123"/><span class="No-Break">dispersion levels.</span></p>
			<h1 id="_idParaDest-68"><a id="_idTextAnchor124"/>Resampling a multivariate time series</h1>
			<p>This recipe revisits <a id="_idIndexMarker039"/>the topic of resampling but focuses on multivariate time series. We’ll explain why resampling can be a bit tricky for multivariate time series due to the eventual need to use distinct summary statistics for <a id="_idTextAnchor125"/><span class="No-Break">different variables.</span></p>
			<h2 id="_idParaDest-69"><a id="_idTextAnchor126"/>Getting ready</h2>
			<p>When resampling a multivariate time, you may need to apply different summary statistics depending on the variable. For example, you may want to sum up the solar radiation observed at each hour to get a sense of how much power you could generate. Yet, taking the average, instead of the sum, is more sensible when summarizing wind speed because this variabl<a id="_idTextAnchor127"/>e is <span class="No-Break">not cumulative.</span></p>
			<h2 id="_idParaDest-70"><a id="_idTextAnchor128"/>How to do it…</h2>
			<p>We can pass a Python dictionary that details which statistic should be applied to each variable. Then, we can pass this dictionary to the <strong class="source-inline">agg</strong> <strong class="source-inline">()</strong> method, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
stat_by_variable = {
    'Incoming Solar': 'sum',
    'Wind Dir': 'mean',
    'Snow Depth': 'sum',
    'Wind Speed': 'mean',
    'Dewpoint': 'mean',
    'Precipitation': 'sum',
    'Vapor Pressure': 'mean',
    'Relative Humidity': 'mean',
    'Air Temp': 'max',
}
data_daily = data.resample('D').agg(stat_by_variable)</pre>			<p>We aggregate the time series into a daily periodicity using different summary statistics. For example, we want to sum up the solar radiation observed each day. For the air temperature variable (<strong class="source-inline">Air Temp</strong>), we take the maximum value o<a id="_idTextAnchor129"/>bserved <span class="No-Break">each day.</span></p>
			<h2 id="_idParaDest-71"><a id="_idTextAnchor130"/>How it works…</h2>
			<p>By using a dictionary to pass different summary statistics, we can adjust the frequency of the<a id="_idIndexMarker040"/> time series in a more flexible way. Note that if you wanted to apply the mean for all variables, you would not need a dictionary. A simpler way would be to <span class="No-Break">run </span><span class="No-Break"><strong class="source-inline">data.<a id="_idTextAnchor131"/><a id="_idTextAnchor132"/>resample('D').mean()</strong></span><span class="No-Break">.</span></p>
			<h1 id="_idParaDest-72"><a id="_idTextAnchor133"/>Analyzing correlation among pairs of variables</h1>
			<p>This recipe walks you<a id="_idIndexMarker041"/> through the process <a id="_idIndexMarker042"/>of using correlation to analyze a multivariate time series. This task is useful to understand the relationship among the different variables in the series and thereby u<a id="_idTextAnchor134"/>nderstand <span class="No-Break">its dynamics.</span></p>
			<h2 id="_idParaDest-73"><a id="_idTextAnchor135"/>Getting ready</h2>
			<p>A common way to analyze the dynamics of multiple variables is by computing the correlation of each pair. You can use this information to perform feature selection. For example, when pairs of variables are highly correlated, you may want to<a id="_idTextAnchor136"/> keep only one <span class="No-Break">of them.</span></p>
			<h2 id="_idParaDest-74"><a id="_idTextAnchor137"/>How to do it…</h2>
			<p>First, we compute the correlation among each pair <span class="No-Break">of variables:</span></p>
			<pre class="source-code">
corr_matrix = data_daily.corr(method='pearson')</pre>			<p>We can visualize the results using a heatmap from the <span class="No-Break"><strong class="source-inline">seaborn</strong></span><span class="No-Break"> library:</span></p>
			<pre class="source-code">
import seaborn as sns
import matplotlib.pyplot as plt
sns.heatmap(data=corr_matrix,
            cmap=sns.diverging_palette(230, 20, as_cmap=True),
            xticklabels=data_daily.columns,
            yticklabels=data_daily.columns,
            center=0,
            square=True,
            linewidths=.5,
            cbar_kws={"shrink": .5})
plt.xticks(rotation=30)</pre>			<p>Heatmaps are a common way of visualizing matrices. We pick a diverging color set from <strong class="source-inline">sns.diverging_palette</strong> to distinguish between negative correlation (blue) and <a id="_idIndexMarker043"/>pos<a id="_idTextAnchor138"/>itive<a id="_idIndexMarker044"/> <span class="No-Break">correlation (red).</span></p>
			<h2 id="_idParaDest-75"><a id="_idTextAnchor139"/>How it works…</h2>
			<p>The following figure shows the heatmap with the <span class="No-Break">correlation results:</span></p>
			<div>
				<div id="_idContainer011" class="IMG---Figure">
					<img src="image/B21145_01_007.jpg" alt="Figure 1.7: Correlation matrix for a multivariate time series" width="616" height="504"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.7: Correlation matrix for a multivariate time series</p>
			<p>The <strong class="source-inline">corr</strong><strong class="source-inline">()</strong> method computes<a id="_idIndexMarker045"/> the <a id="_idIndexMarker046"/>correlation among each pair of variables in the <strong class="source-inline">data_daily</strong> object. In this case, we use the Pearson correlation with the <strong class="source-inline">method='pearson'</strong> argument. Kendall and Spearman are two common alternatives to the <span class="No-Break">Pearson correlation.</span></p>
		</div>
	</div>
</div>
</body></html>