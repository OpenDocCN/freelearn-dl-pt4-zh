<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Image Classification with TensorFlow on Spark</h1>
                </header>
            
            <article>
                
<p>The following recipes will be covered in this chapter:</p>
<ul>
<li>Downloading 30 images each of Messi and Ronaldo</li>
<li>Configuring PySpark installation with deep learning packages</li>
<li>Loading images onto PySpark dataframes</li>
<li>Understanding transfer learning</li>
<li>Creating a pipeline for image classification training</li>
<li>Evaluating model performance</li>
<li>Fine-tuning model parameters</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introduction</h1>
                </header>
            
            <article>
                
<p class="mce-root">Over the last couple of years,<span> </span>image recognition software has become increasingly in demand. It is not a coincidence that this demand has coincided with the advancements of big data storage. Google Photos, Facebook, and Apple all utilize image classification software to tag photos for their users. Much of the image recognition software used by these companies are powered by deep learning models built on top of popular libraries such as TensorFlow. This chapter extends the technique of deep learning by leveraging the training of one set of images to the learning or recognition of another set of images. This concept is referred to as transfer learning. In this chapter, we will focus on leveraging transfer learning to recognize the top two football players in the world:</p>
<ol>
<li>Lionel Messi</li>
<li>Cristiano Ronaldo</li>
</ol>
<p>Take a look at this photo:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1342 image-border" src="assets/1aa798b3-2945-4cd5-bd03-5d6bc1cc95b3.png" style="width:19.92em;height:20.17em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Downloading 30 images each of Messi and Ronaldo</h1>
                </header>
            
            <article>
                
<p>Before any classification of images can take place, we must first download images of our footballers from the web.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>There are several add-ons to browsers that download images in bulk. Since Ubuntu comes pre-installed with Mozilla Firefox as a browser, we will use it as our browser of choice to install a bulk image downloader extension.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>The following section explains how to download images in bulk. Take a look at these steps:</p>
<ol>
<li><span>Visit the following website for downloading and installing Firefox add-ons:</span></li>
</ol>
<p style="padding-left: 60px"><a href="https://addons.mozilla.org/en-US/firefox/">https://addons.mozilla.org/en-US/firefox/</a></p>
<ol start="2">
<li>Search for and select the <span class="packt_screen">Download all Images</span> add-on, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1515 image-border" src="assets/2e921ad4-e29b-4d4d-bb7e-e71c9b24693d.png" style="width:49.67em;height:16.58em;"/></div>
<ol start="3">
<li>This will take us to the installation page. At which point, select <span class="packt_screen">Add to Firefox</span>, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1517 image-border" src="assets/264ce1b4-6a2c-49fa-a839-525abc4b713a.png" style="width:44.42em;height:21.42em;"/></div>
<ol start="4">
<li>Confirm your installation, as this add-on will require permission to access your browser's download history, access your data for all websites, and send you notifications.</li>
<li>Once that is complete, you should see a small picture icon for <span class="packt_screen">Download all Images</span> on the upper right-hand side of your browser, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1345 image-border" src="assets/bd0c3da6-303f-4194-accb-f2745b35df54.png" style="width:14.92em;height:4.33em;"/></div>
<ol start="6">
<li>We are now ready to begin downloading images of our footballers, using the newly added extension for Firefox. We can visit many different websites to download images from, such as <a href="https://www.google.com">https://www.google.com</a>. For the purposes of this chapter, search for <span>Cristiano Ronaldo</span> and download his images using <a href="https://www.pexels.com">https://www.pexels.com</a>, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1347 image-border" src="assets/b6db583e-4f6b-4502-a0ca-3b3287128844.png" style="width:89.42em;height:45.58em;"/></div>
<ol start="7">
<li>Next, click on the <span class="packt_screen">Download all Images</span> icon and specify the following download settings for the images as shown in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/35952ce0-3f64-4357-af9f-766a2ab4ef2f.png" style="width:43.25em;height:35.92em;"/></div>
<ol start="8">
<li>Click on <span class="packt_screen">Save</span>, as you will then have the option to download all of the pictures as a <kbd>.zip</kbd> file to a local directory. You can then unzip the file into a folder and peruse through all of the images. In our example, the images have all been extracted to <kbd>/Home/sparkNotebooks/Ch13/football/ronaldo/</kbd>, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1348 image-border" src="assets/d05a2be3-3239-45ad-923c-9ecae2733026.png" style="width:162.50em;height:46.67em;"/></div>
<ol start="9">
<li>Of all the images that are available in the folder, choose 30 images of Ronaldo and name them <kbd>ronaldo1.jpg</kbd>, <kbd>ronaldo2.jpg</kbd>....<kbd>ronaldo30.jpg</kbd>, as shown in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1349 image-border" src="assets/a4476a21-9ead-4bb9-98bc-ca9300025f35.png" style="width:162.50em;height:92.67em;"/></div>
<ol start="10">
<li>Repeat the steps again, this time for Messi to obtain 30 images of each. The final folder structure should look like the following:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1350 image-border" src="assets/c981fa82-30e8-4c49-b2af-05e6c8f1205f.png" style="width:42.75em;height:8.83em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>This section explains the process of how the add-on downloads the images in bulk to our desired location:</p>
<ol>
<li>Bulk image downloading software is readily available these days and integrated within browsers. We will use <span class="packt_screen">Download all Images</span> as an add-on with Firefox to quickly download images for Messi and Ronaldo.</li>
<li>We want to specify settings in the app to download lower-quality images, so we set a minimum threshold of 0 bytes, a maximum threshold of 500 bytes, and an image type of <kbd>jpg</kbd> or <kbd>jpeg</kbd>.</li>
<li>Finally, we want to handpick only the 30 images that best represent each player, as 20 of them will serve as our training dataset, and the remaining 10 will serve as our test dataset. All other images can be deleted.</li>
<li>All of the images will be tagged or labeled for training purposes by their last name and a number between 1 and 30. For example, <kbd>Messi1.jpg</kbd>, <kbd>Messi2.jpg</kbd>, <kbd>Ronaldo1.jpg</kbd>, <kbd>Ronaldo2.jpg</kbd>, and so on.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>While you can use your own images that you have downloaded using <span class="packt_screen">Download all Images</span>, you can download the same images for Ronaldo and Messi that will be used for training purposes in this chapter by visiting the following websites:</p>
<p>For Messi:</p>
<p><a href="https://github.com/asherif844/ApacheSparkDeepLearningCookbook/tree/master/CH13/football/messi">https://github.com/asherif844/ApacheSparkDeepLearningCookbook/tree/master/CH13/football/messi</a></p>
<p>For Ronaldo:</p>
<p><a href="https://github.com/asherif844/ApacheSparkDeepLearningCookbook/tree/master/CH13/football/ronaldo">https://github.com/asherif844/ApacheSparkDeepLearningCookbook/tree/master/CH13/football/ronaldo</a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p>There are similar add-ons and extensions for other browsers. If you are working with Google Chrome, there is a similar add-on called <em><span class="packt_screen">D</span></em><span class="packt_screen">ownload'em All</span> that can be downloaded from the following website:</p>
<p><a href="https://chrome.google.com/webstore/detail/downloadem-all/ccdfjnniglfbpaplecpifdiglfmcebce?hl=en-US">https://chrome.google.com/webstore/detail/downloadem-all/ccdfjnniglfbpaplecpifdiglfmcebce?hl=en-US</a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Configuring PySpark installation with deep learning packages</h1>
                </header>
            
            <article>
                
<p>There are some additional configurations that need to be done within PySpark to implement deep learning packages from Databricks called <kbd>spark-deep-learning</kbd>. These are configurations that were made all the way back in <a href="a010c7af-0e48-4bac-9146-47ddecc2cc8e.xhtml">chapter 1</a>, <em>Setting up your Spark Environment for Deep Learning</em>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>This configuration requires making changes in the terminal, using <strong>bash</strong>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>The following section walks through the steps to configure PySpark with deep learning packages:</p>
<ol>
<li>Open the terminal application and type in the following command:</li>
</ol>
<pre style="padding-left: 60px">nano .bashrc.</pre>
<ol start="2">
<li>Scroll all the way to the bottom of the document and look for the <kbd>sparknotebook()</kbd> function we created back in <a href="a010c7af-0e48-4bac-9146-47ddecc2cc8e.xhtml">chapter 1</a>, <em>Setting up your Spark Environment for Deep Learning</em>.</li>
</ol>
<ol start="3">
<li>Update the last row of the function. It should currently look like the following:</li>
</ol>
<pre style="padding-left: 60px">$SPARK_HOME/bin/pyspark.</pre>
<p style="padding-left: 60px">Change it to the following:</p>
<pre style="padding-left: 60px">$SPARK_HOME/bin/pyspark --packages databricks:spark-deep-learning:0.1.0-spark2.1-s_2.11.</pre>
<ol start="4">
<li>Once the configuration change is made, exit the document and execute the following script to confirm that all necessary changes were saved:</li>
</ol>
<pre style="padding-left: 60px">source .bashrc.</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p><span>The following section explains how PySpark is modified to incorporate deep learning packages take a look at these steps:</span></p>
<ol>
<li>Accessing bash allows us to make configurations at the command line, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1351 image-border" src="assets/2180139f-528c-4aac-a32a-f962b417f9c8.png" style="width:41.25em;height:25.75em;"/></div>
<ol start="2">
<li>At the end of our document, we can see our original function, <kbd>sparknotebook()</kbd>, still intact; however, we need to modify it to incorporate the <kbd>spark-deep-learning</kbd> package.</li>
<li>Since this modification is to PySpark directly, and not to a Python library, we cannot incorporate it into our framework using a typical <kbd>pip</kbd> installation. Instead, we will modify our PySpark configuration to appear as shown in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1352 image-border" src="assets/30251b6b-9821-4935-8e95-6622fefeb5ba.png" style="width:53.92em;height:17.83em;"/></div>
<ol start="4">
<li>We have now configured our PySpark installation to incorporate deep learning libraries that incorporate APIs that help build models for all types of solutions, such as image classification.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>This package, <kbd>spark-deep-learning</kbd>, is managed by <kbd>Databricks</kbd>. Databricks was founded by one of the co-creators of Spark, Ali Ghodsi, and is used to deliver managed Spark offerings through a unified platform.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p>To learn more about other third-party packages developed for Spark, visit the following website:</p>
<p><a href="https://spark-packages.org/">https://spark-packages.org/</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Loading images on to PySpark dataframes</h1>
                </header>
            
            <article>
                
<p>We are now ready to begin importing our images into our notebook for classification.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>We will be using several libraries and their dependencies in this section, which will require us to install the following packages through <kbd>pip install</kbd> on the terminal within Ubuntu Desktop:</p>
<pre>pip install tensorflow==1.4.1<br/>pip install keras==2.1.5<br/>pip install sparkdl<br/>pip install tensorframes<br/>pip install kafka<br/>pip install py4j<br/>pip install tensorflowonspark<br/>pip install jieba</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>The following steps will demonstrate how to decode images into a Spark dataframe:</p>
<ol>
<li>Initiate a <kbd>spark</kbd> session, using the following script:</li>
</ol>
<pre style="padding-left: 60px">spark = SparkSession.builder \<br/>      .master("local") \<br/>      .appName("ImageClassification") \<br/>      .config("spark.executor.memory", "6gb") \<br/>      .getOrCreate()</pre>
<ol start="2">
<li>Import the following libraries from PySpark to create dataframes, using the following script:</li>
</ol>
<pre style="padding-left: 60px">import pyspark.sql.functions as f<br/>import sparkdl as dl</pre>
<ol start="3">
<li>Execute the following script to create two dataframes for <span class="packt_screen">Messi </span>and <span class="packt_screen">Ronaldo,</span> using the main folder location for each player:</li>
</ol>
<pre style="padding-left: 60px">dfMessi = dl.readImages('football/messi/').withColumn('label', f.lit(0))<br/>dfRonaldo = dl.readImages('football/ronaldo/').withColumn('label',             f.lit(1))</pre>
<ol start="4">
<li>Split each dataframe into a train-and-test set at a <kbd>66.7/33.3</kbd> ratio, and set a random seed set to <kbd>12</kbd>, using the following script:</li>
</ol>
<pre style="padding-left: 60px">trainDFmessi, testDFmessi = dfMessi.randomSplit([66.7, 33.3], seed = 12)<br/>trainDFronaldo, testDFronaldo = dfRonaldo.randomSplit([66.7, 33.3], seed =     12)</pre>
<ol start="5">
<li>Finally, merge both the training dataframes and the testing dataframes into one new dataframe each, <kbd>trainDF</kbd> and <kbd>testDF</kbd>, using the following script:</li>
</ol>
<pre style="padding-left: 60px">trainDF = trainDFmessi.unionAll(trainDFronaldo)<br/>testDF = testDFmessi.unionAll(testDFronaldo)</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>The following section explains how the images are loaded and read into a Jupyter notebook. Take a look at these steps:</p>
<ol>
<li>We always begin a Spark project by initiating a Spark session to set the application name as well as to set the Spark executor memory.</li>
<li>We import both <kbd>pyspark.sql.functions</kbd> and <kbd>sparkdl</kbd> to help build dataframes based on encoded images. When <kbd>sparkdl</kbd> is imported, we see that it is using <span class="packt_screen">TensorFlow</span> in the backend, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1353 image-border" src="assets/2f0bbcf0-95fb-4966-9bbb-5954cc4b8ff8.png" style="width:27.42em;height:11.00em;"/></div>
<ol start="3">
<li>The dataframes are created using <kbd>sparkdl</kbd> with three columns: <span class="packt_screen">filepath</span>, <span class="packt_screen">image</span>, and <span class="packt_screen">label</span>. Sparkdl is used to import each image and encode it by color and shape. Additionally, a function, <kbd>lit</kbd>, is used to tag a literal value (<span class="packt_screen">0 or 1</span>) to each of the two dataframes under the <span class="packt_screen">label</span> column for training purposes, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/eed74346-0732-4f81-aafc-4d5a7c4859e0.png"/></div>
<ol start="4">
<li>Since there are 30 images for each footballer, a split of 66.7/33.3 is used to create <span class="packt_screen">18</span> training images and <span class="packt_screen">12</span> testing images, as seen in the following screenshot:</li>
</ol>
<div class="packt_tip">Please note that the more images used in the training process the better when using deep learning. However, the point we will try and prove in this chapter is that with transfer learning being implemented as an extension of deep learning, we can classify images using fewer training samples, as is the case in this chapter with only 30 images for Ronaldo and Messi each.</div>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1354 image-border" src="assets/abef3f04-4a7a-4646-a3e4-062e06937597.png" style="width:53.42em;height:12.83em;"/></div>
<ol start="5">
<li>To build out our model, we are only interested in creating a single training dataframe with the <span class="packt_screen">36</span> images, as well as a single testing dataframe with the remaining <span class="packt_screen">24</span> images. Once we merge the dataframes we can confirm that they are the correct size, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1356 image-border" src="assets/7f0beaf7-034e-4afe-9ffb-520857b1b2cb.png" style="width:50.83em;height:8.92em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>It may be lost in the process but it is important to note that loading the images into a dataframe was easy, and only took a few lines of code using <kbd>sparkdl.readImages</kbd>. This showcases the power of the machine learning pipelines that are available with Spark.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p>To learn more about the <kbd>sparkdl</kbd> package, visit the following repository:</p>
<p><a href="https://databricks.github.io/spark-deep-learning/site/api/python/sparkdl.html">https://databricks.github.io/spark-deep-learning/site/api/python/sparkdl.html</a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Understanding transfer learning</h1>
                </header>
            
            <article>
                
<p>The rest of this chapter will involve transfer learning techniques; therefore, we will spend this section explaining how transfer learning works within our architecture.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>There are no dependencies required for this section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>This section walks through the steps for how transfer learning works:</p>
<ol>
<li>Identify a pre-trained model that will be used as the training methodology that will be transferred to our chosen task. In our case, the task will be in identifying images of Messi and Ronaldo.</li>
<li>There are several available pre-trained models that can be used. The most popular ones are the following:
<ol>
<li>Xception</li>
<li>InceptionV3</li>
<li>ResNet50</li>
<li>VGG16</li>
<li>VGG19</li>
</ol>
</li>
<li>The features from the pre-trained convolutional neural network are extracted and saved for a certain set of images over several layers of filtering and pooling.</li>
<li>The final layer for the pre-trained convolutional neural network is substituted with the specific features that we are looking to classify based on our dataset.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>This section explains the methodology of transfer learning:</p>
<ol>
<li>In early chapters, we discuss how machine learning models, and more importantly deep learning models, work best with larger samples for training purposes. In fact, the general motto with deep learning is the more the merrier.</li>
<li>However, there are situations when a high volume of data or images is just not available to train a model. It is in these circumstances where we wish to transfer the learning of one field to predict the outcome of a different field. The heavy lifting of extracting features and filtering through layers and layers within a convolutional neural network have already been performed by institutions that have developed many pre-trained models such as InceptionV3 and ResNet50:
<ol>
<li>InceptionV3 was developed over at Google and has smaller weights than ResNet50 and VGG</li>
<li>ResNet50 uses 50 weight layers</li>
<li>VGG16 and VGG19 have 16 and 19 weight layers respectively</li>
</ol>
</li>
<li>Several higher level deep learning libraries such as Keras now come pre-built with these pre-trained networks for a more simplified application by specifying the model name.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>Determining which pre-trained model works best for the data or image set in question will depend on the image types used. It is always best to try different pre-trained sets and determine which one delivers the best accuracy.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p>To learn more about the Inception V3 pre-trained model, read the following paper:</p>
<p><a href="https://arxiv.org/abs/1409.4842">https://arxiv.org/abs/1409.4842</a></p>
<p>To learn more about the VGG pre-trained models, read the following paper:</p>
<p><a href="https://arxiv.org/abs/1409.1556">https://arxiv.org/abs/1409.1556</a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating a pipeline for image classification training</h1>
                </header>
            
            <article>
                
<p>We are now ready to build the deep learning pipeline for training our dataset.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>The following libraries will be imported to assist with the pipeline development:</p>
<ul>
<li><kbd>LogisticRegression</kbd></li>
<li><kbd>Pipeline</kbd></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>The following section walks through the following steps for creating a pipeline for image classification:</p>
<ol>
<li>Execute the following script to begin the deep learning pipeline as well as to configure the classification parameters:</li>
</ol>
<pre style="padding-left: 60px">from pyspark.ml.classification import LogisticRegression<br/>from pyspark.ml import Pipeline<br/><br/>vectorizer = dl.DeepImageFeaturizer(inputCol="image", <br/>                           outputCol="features", <br/>                           modelName="InceptionV3")<br/>logreg = LogisticRegression(maxIter=30, <br/>         labelCol="label")<br/>pipeline = Pipeline(stages=[vectorizer, logreg])<br/>pipeline_model = pipeline.fit(trainDF)</pre>
<ol start="2">
<li>Create a new dataframe, <kbd>predictDF</kbd>, that houses the original testing labels as well as the new prediction scores, using the following script:</li>
</ol>
<pre style="padding-left: 60px">predictDF = pipeline_model.transform(testDF)<br/>predictDF.select('prediction', 'label').show(n = testDF.toPandas().shape[0], truncate=False)</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p><span>The following section explains how the pipeline for image classification is configured for optimal performance:</span></p>
<ol>
<li><kbd>LogisticRegression</kbd> is imported, as it will be the main classification algorithm used to distinguish between Messi and Ronaldo images. <kbd>DeepImageFeaturizer</kbd> is imported from <kbd>sparkdl</kbd> to create features based off of the images that will be used as the final input to the logistic regression algorithm.</li>
</ol>
<div class="packt_infobox">It is important to note that the features created from <kbd>DeepImageFeaturizer</kbd> will be using a pre-trained model based on <kbd>InceptionV3</kbd>, and assigned a variable of <kbd>vectorizer</kbd>.</div>
<p style="padding-left: 60px">The logistic regression model is tuned to run for a maximum of <span class="packt_screen">30</span> iterations. Finally, the pipeline ingests both <kbd>vectorizer</kbd> and <kbd>LogisticRegression</kbd> variables and fits it into the training dataframe, <kbd>trainDF</kbd>. <kbd>vectorizer</kbd> is used to create numeric values out of the images. The output of the <kbd>DeepImageFeaturizer</kbd> can be seen in the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1357 image-border" src="assets/db806e60-8e9e-4cd1-813d-61c3a991ece1.png" style="width:53.33em;height:14.58em;"/></div>
<ol start="2">
<li>The test dataframe, <kbd>testDF</kbd>, is transformed into a new dataframe, <kbd>predictDF</kbd>, by applying the fitted pipeline model, <kbd>pipeline_model</kbd>, which creates a new column called <span class="packt_screen">prediction</span>. We can then compare our <span class="packt_screen">label</span> column with our <span class="packt_screen">prediction</span> column, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1358 image-border" src="assets/63b637a7-0e98-4870-8c8a-ff58c1b27fee.png" style="width:49.25em;height:32.25em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p><span><kbd>InceptionV3</kbd> is the image classifier model that we used for classifying our images; however, we could have very easily chosen other pre-trained models and compared accuracy within our pipeline.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p>To learn more about transfer learning, read the following article from the University of Wisconsin:</p>
<p><a href="http://ftp.cs.wisc.edu/machine-learning/shavlik-group/torrey.handbook09.pdf">http://ftp.cs.wisc.edu/machine-learning/shavlik-group/torrey.handbook09.pdf</a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Evaluating model performance</h1>
                </header>
            
            <article>
                
<p>We are ready to evaluate our model and see how well we can distinguish between Messi and Ronaldo.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>Since we will be doing some model evaluation, we will need to import the following library:</p>
<ul>
<li><kbd>MulticlassClassificationEvaluator</kbd></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>The following section walks through the following steps to evaluate model performance:</p>
<ol>
<li>Execute the following script to create a confusion matrix from the <kbd>predictDF</kbd> dataframe:</li>
</ol>
<pre style="padding-left: 60px">predictDF.crosstab('prediction', 'label').show().</pre>
<ol start="2">
<li>Calculate an accuracy score based on our 24 test images of Ronaldo and Messi by executing the following script:</li>
</ol>
<pre style="padding-left: 60px">from pyspark.ml.evaluation import MulticlassClassificationEvaluator<br/><br/>scoring = predictDF.select("prediction", "label")<br/>accuracy_score = MulticlassClassificationEvaluator(metricName="accuracy")<br/>rate = accuracy_score.evaluate(scoring)*100<br/>print("accuracy: {}%" .format(round(rate,2))).</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>The following section explains how we evaluate the model performance. Take a look at these images:</p>
<ol>
<li>We can convert our dataframe, <span class="packt_screen">predictDF</span>, into a crosstab to create a confusion matrix. This allows us to understand how many true positives, false positives, true negatives, and false negatives are in our model, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1359 image-border" src="assets/7945778a-5717-4a78-9356-1e26cb9a11ba.png" style="width:31.33em;height:8.58em;"/></div>
<ol start="2">
<li>At this point, we are ready to calculate how well we did with our model in using the 36 training images to accurately classify the 24 remaining test images of Ronaldo and Messi. From the previous screenshot, it shows that we had 21 accurate classifications out of 24. We had 2 images of Messi misclassified as Ronaldo and only one image of Ronaldo misclassified as Messi. This should come out to an accuracy score of 88%. We can see that the accuracy score from the <span class="packt_screen">MulticlassClassificationEvaluator</span> also scores our accuracy at 87.5%, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1360 image-border" src="assets/ea5e38f9-2d4d-4ec5-9170-cde3a73c09cd.png" style="width:43.92em;height:6.50em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>While we did end up using accuracy as our benchmark indicator for how well our model performed, we could have just as easily used precision or recall. Additionally, we used the <kbd>MulticlassClassificationEvaluator</kbd> for evaluating the accuracy of the model. Since we are dealing with a binary outcome in this specific case for only two types of images for Ronaldo or Messi, we could have also just used a <kbd>BinaryClassificationEvaluator</kbd> as seen in the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1637 image-border" src="assets/b99835c6-e22d-41bb-9bb2-53a0081e4b51.png" style="width:122.17em;height:20.33em;"/></div>
<p>We still end up with the same accuracy rate of <span class="packt_screen">87.5%</span>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p>To learn more about <kbd>MulticlassClassificationEvaluator</kbd> from the logistic regression function in PySpark, visit the following website:</p>
<p><a href="https://spark.apache.org/docs/2.2.0/ml-classification-regression.html">https://spark.apache.org/docs/2.2.0/ml-classification-regression.html</a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Fine-tuning model parameters</h1>
                </header>
            
            <article>
                
<p>There is always room for improvement in the accuracy of any model. In this section, we will talk about some of the parameters that can be tweaked to improve our model accuracy score of <span class="packt_screen">87.5%</span> obtained from the previous section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>This section does not require any new prerequisites. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>This section walks through the steps to fine-tune the model.</p>
<ol>
<li>Define a new logistic regression model with additional parameters for <kbd>regParam</kbd> and <kbd>elasticNetParam</kbd> as seen in the following script:</li>
</ol>
<pre style="padding-left: 60px">logregFT = LogisticRegression(<br/> regParam=0.05, <br/> elasticNetParam=0.3,<br/> maxIter=15,labelCol = "label", featuresCol="features")</pre>
<ol start="2">
<li>Create a new pipeline configured for the newly created model using the following script:</li>
</ol>
<pre style="padding-left: 60px">pipelineFT = Pipeline(stages=[vectorizer, logregFT])</pre>
<ol start="3">
<li>Fit the pipeline to the trained dataset, <kbd>trainDF</kbd>, using the following script:</li>
</ol>
<pre style="padding-left: 60px">pipeline_model_FT = pipelineFT.fit(trainDF)</pre>
<ol start="4">
<li>Apply the model transformation to the test dataset, <kbd>testDF</kbd>, to be able to compare actual versus predicted scores using the following script:</li>
</ol>
<pre style="padding-left: 60px">predictDF_FT = pipeline_model_FT.transform(testDF)<br/>predictDF_FT.crosstab('prediction', 'label').show()</pre>
<ol start="5">
<li>Finally, evaluate the new model accuracy rate, <kbd>binary_rate_FT</kbd>, using the following script:</li>
</ol>
<pre style="padding-left: 60px">binary_rate_FT = binaryevaluator.evaluate(predictDF_FT)*100<br/>print("accuracy: {}%" .format(round(binary_rate_FT,2)))</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>This section explains how the model is fine-tuned:</p>
<ol>
<li>The logistic regression model, <kbd>logregFT</kbd>, is fine-tuned using both the <kbd>regParam</kbd> and the <kbd>elasticNetParam</kbd> parameters. Both parameters correspond to the γ and the α parameters of a logistic regression model. The regularization parameter or <kbd>regParam</kbd> is used to find a balance between minimizing the loss function and minimizing overfitting the model. The more complex we make the model, the more likely it will overfit and not be generalized, but we will also likely get a lower training error. Additionally, the less complex we make the model, the less likely it will overfit, but the more likely it will have a higher training error.</li>
<li>The elastic net parameter or <kbd>elasticNetParam</kbd> is another regularization technique that is used to combine multiple regularizers, L1 and L2, to minimize overfitting in a model. Additionally, we have decreased our iteration run from 20 to 15 to see if we can achieve a better accuracy score by including regularization and decreasing runs at the same time.</li>
<li>Once again, as we did previously in this chapter, we create a pipeline that incorporates our numerical features generated from our images, <kbd>vectorizer</kbd>, as well our logistic regression model, <kbd>logregFT</kbd>.</li>
<li>The model is then fit on the training data, <kbd>trainDF</kbd>, and the transformation of the model is applied to the testing data, <kbd>testDF</kbd>.</li>
<li>We can once again compare our actual versus predicted results from the outcome of the model in a crosstab as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/f1062a3c-9ecb-431b-97e0-ff98a224df6d.png" style="width:36.83em;height:25.75em;"/></div>
<ol start="6">
<li>We have now only 1 miss-classified image compared to 3 from the previous section. We accomplished this by lowering our maxIter to <kbd>15</kbd> runs and setting <kbd>regParam</kbd> to <kbd>0.05</kbd> and the <kbd>elasticNetParam</kbd> to <kbd>0.3</kbd>.</li>
<li>Our new accuracy rate is now at <kbd>95.83%</kbd> as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/d34f16a0-ce02-43f6-9881-762972d5cbf3.png" style="width:38.08em;height:4.67em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>Certainly, we have improved our rate from <span class="packt_screen">87.5%</span> from <span class="packt_screen">95.83%</span> simply by incorporating specific parameters into our model. Additional fine-tuning and tweaking of our parameters could take place to determine if an accuracy of 100% could be reached for our image classification model.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p>To learn more about the regularization and elastic net parameters within a logistic regression, visit the following website:</p>
<p><a href="https://spark.apache.org/docs/2.2.0/mllib-linear-methods.html#logistic-regression">https://spark.apache.org/docs/2.2.0/mllib-linear-methods.html#logistic-regression</a></p>


            </article>

            
        </section>
    </body></html>