<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">2D HMM for Image Processing</h1>
                </header>
            
            <article>
                
<p class="mce-root">In this chapter, we will introduce the application of HMM in the case of image segmentation. For image segmentation, we usually split up the given image into multiple blocks of equal size and then perform an estimation for each of these blocks. However, these algorithms usually ignore the contextual information from the neighboring blocks. To deal with that issue, 2D HMMs were introduced, which consider feature vectors to be dependent through an underlying 2D Markovian mesh. In this chapter, we will discuss how these 2D HMMs work and will derive parameter estimation algorithms for them. In this chapter, we will discuss the following topics:</p>
<ul>
<li>Pseudo 2D HMMs</li>
<li>Introduction to 2D HMMs</li>
<li>Parameter learning in 2D HMMs</li>
<li>Applications</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Recap of 1D HMM</h1>
                </header>
            
            <article>
                
<p>Let's recap how 1D HMMs work, which we discussed in the previous chapters of this book. We have seen that HMM is a just a process over Markov chains. At any point in time, an HMM is in one of the possible states, and the next state that the model will transition to depends on the current state and the transition probability of the model. </p>
<p>Suppose that there are <em>M = {1, 2, ..., M}</em> possible states for HMM, and the transition probability of going from some state <em>i</em> to state <em>j</em> is given by <em>a<sub>i,j</sub></em>. For such a model, if at time <em>t-1</em> the model is at state <em>i</em>, then at time <em>t</em> it would be in state <em>j</em> with a probability of <em>a<sub>i,j</sub></em>. This probability is known as the <strong>transition probability</strong>. Also, we have defined the observed variable in the model, which only depends on the current state of our hidden variable. We can define the observed variable at time <em>t</em> as <em>u<sub>t</sub></em>, so let's say the emission distribution for the state <em>i</em> for the variable <em>u<sub>t</sub></em> is given by <em>b<sub>i</sub>(u<sub>t</sub>)</em>. </p>
<p class="mce-root"/>
<p>We also need to define the initial probability, <em>π<sub>i</sub></em>, as the probability of being in state <em>i</em> at time <em>t = 1</em>. With all these given values, we can determine the likelihood of observing any given sequence, <img class="fm-editor-equation" src="assets/3521f387-45e1-4ef5-9b5a-c4278bcc9e0c.png" style="width:4.75em;height:1.25em;"/>, as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/042c0543-12c7-41ed-80d4-b33dffcb2b12.png" style="width:30.33em;height:3.08em;"/></p>
<p>In most situations, we assume the states to be a Gaussian mixture model; in which case, the previous equation can be generalized further, as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/65242904-b50a-4f5f-9b5f-3b7cec0002a2.png" style="width:32.08em;height:4.42em;"/></p>
<p>Here, <em>u<sub>i</sub></em> is the mean, <em>∑<sub>i</sub></em> is the covariance matrix, and <em>k</em> is the dimensionality of the observed variable <em>u<sub>t</sub></em>.</p>
<p>Now we have our model defined, we can move on to the estimation method. Estimation is usually performed using the Baum-Welch algorithm that we saw in <a href="b3f2bff1-0fe7-4d54-8a9e-9911c77e7d62.xhtml" target="_blank"/><a href="b3f2bff1-0fe7-4d54-8a9e-9911c77e7d62.xhtml" target="_blank">Chapter 4</a>, <em>Parameter Inference using Maximum Likelihood</em>, which performs a maximum-likelihood estimation. Let <em>L<sub>i</sub>(t)</em> be the conditional distribution of being in state <em>i</em> at time <em>t,</em> given the observations, and <em>H<sub>i,j</sub>(t)</em> be the conditional probability of transitioning to state <em>j</em> from state <em>i</em> at time <em>t + 1,</em> again, given the observations. Then, we can re-estimate the mean, covariance, and transition probability as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/bb175f4f-5958-4b48-8001-967193bace35.png" style="width:19.92em;height:11.83em;"/></p>
<p>To compute the values of <em>L<sub>i</sub>(t)</em> and <em>H<sub>i,j</sub>(t),</em> we use the forward-backward algorithm. The forward algorithm gives us the probability, <em>α<sub>i</sub>(t),</em> of observing the first <em>t</em> outcomes, <img class="fm-editor-equation" src="assets/c6ef61da-9aa5-474e-9394-ba29bcd71567.png" style="width:8.42em;height:1.92em;"/>, and being in state <em>i</em> at time <em>t</em>. </p>
<p>This probability can be evaluated using the following set of equations:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/ac5f17a1-566c-42f1-bda1-226ceed116ac.png" style="width:26.00em;height:5.00em;"/></p>
<p>We also define the backward probability, <em>β<sub>i</sub>(t),</em> as the conditional probability of having the observations <em>{u<sub>r</sub>}r=t + 1,...,T</em>, given that the model is in state <em>i</em> at time <em>t</em>. The conditional probability <em>β<sub>i</sub>(t)</em><span> </span>can be computed as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/f5182d06-65fc-4a97-835b-a47b2e57898b.png" style="width:26.17em;height:6.08em;"/></p>
<p>With these values to hand, we can compute that <em>L<sub>i</sub>(t)</em> and <em>H<sub>i,j</sub>(t)</em> can be solved as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/0f83be13-899c-4c40-92dc-5896c50fa924.png" style="width:19.42em;height:10.08em;"/></p>
<p>We can approximate this algorithm by assuming each observation to have resulted from the most likely hidden state. This allows us to simplify the Baum-Welch algorithm; this is commonly also known as the <strong>Viterbi training algorithm</strong>. Given the observed states, and assuming the state sequence to be <img class="fm-editor-equation" src="assets/38ab31a3-1fcc-4aa2-8f9b-e47e836b3667.png" style="width:6.08em;height:1.67em;"/> with the maximum conditional probability, this can be given as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/f80bb564-e3ab-40e5-bf45-04e98b052cd3.png" style="width:16.50em;height:1.92em;"/></p>
<p>Here, <img class="fm-editor-equation" src="assets/b7a2aeba-0caf-497b-886c-33f9030cc85c.png" style="width:5.00em;height:1.58em;"/> can be computed as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/351bc225-75ac-4ef2-8e3a-02286779feef.png" style="width:30.75em;height:5.83em;"/></p>
<p>With these values, we can then compute the model parameters as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/6e6edb61-4de7-4ae6-8240-9c2570a72d84.png" style="width:17.42em;height:10.42em;"/></p>
<p>Here, <em>I</em> is the indicator function, which returns 1 if the function's argument is true; otherwise, it returns 0.</p>
<p class="mce-root">In this section, we have quickly reviewed the basic concepts of 1D HMMs when the states are parameterized using Gaussian mixture models, so we can now move on to 2D HMMs.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">2D HMMs</h1>
                </header>
            
            <article>
                
<p>A lot of work has been done regarding 2D HMMs, but the most recent work and well-received work has been done by Jia Li, Amir Najmi, and Robert Gray in their paper, <em>Image Classification by a Two Dimensional Hidden Markov Model.</em><em> </em>This section has been written based on their work. We will start by giving the general algorithm they have introduced, and then, in further subsections, we will see how the algorithm works.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Algorithm</h1>
                </header>
            
            <article>
                
<p>The algorithm for image classification is as follows:</p>
<ul>
<li>Training:
<ul>
<li>Divide the training images into non-overlapping blocks with equal size and extract a feature vector for each block</li>
<li>Select the number of states for the 2D HMM</li>
<li>Estimate the model parameters based on the feature vectors and the training labels</li>
</ul>
</li>
</ul>
<ul>
<li>Testing:
<ul>
<li>Similar to training, generate feature vectors for the testing images</li>
<li>Search for the set of classes with the maximum a posteriori probability, given the feature vectors, according to the training model</li>
</ul>
</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Assumptions for the 2D HMM model</h1>
                </header>
            
            <article>
                
<p>In this section, we will quickly go through the assumptions for the 2D HMM model and the derivation of how these assumptions simplify our equations. For a more detailed derivation, please refer to the original paper.</p>
<p>We start by dividing the image into smaller blocks, from which we evaluate the feature vectors, and, using these feature vectors, we classify the image. In the case of a 2D HMM, we make the assumption that the feature vectors are generated by a Markov model with a state change happening once every block. We also define the relationship between the blocks based on which block comes before or after which block. A block at position <em>(i', j')</em> is said to come before the block at position <em>(i, j)</em> if <em>i'</em> or <em>i' = i</em> and <em>j' &lt; j</em>. Assuming that there are <em>M = {1, 2, ... M}</em> states, the state of any given block at position <em>(i, j)</em> is denoted by <em>S<sub>i,j</sub></em>, the feature vector is denoted by <em>u<sub>i,j</sub></em>, and the class is denoted by <em>c<sub>i,j</sub></em>. Another point to keep in mind is that the order of the blocks has been introduced just to explain the assumptions of the model, and the algorithm doesn't consider any order of blocks while doing the classification.</p>
<p>The first assumption made by the model is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/4c3eb9bf-477f-4321-8d16-2db25feaa3c7.png" style="width:64.58em;height:6.58em;"/></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p>This assumption states that knowing the current state is a sufficient statistic for estimating the transition probabilities, which means that <em>u</em> is conditionally independent. Also, according to the assumption, the state transition is a Markov process in two dimensions, and the probability of the system entering any particular state depends on the state of the model in both the horizontal and vertical directions in the previous time and observation instance. We also assume that there is one-to-one mapping from state to class, so that once we know the state, the class can be directly computed. </p>
<p>The second assumption is that the feature vectors are a Gaussian mixture distribution for each state. We know that any M-component Gaussian mixture can be split into M substates with single Gaussian distributions; therefore, for a block with state <em>s</em> and feature vector <em>u</em>, the probability of the distribution is given by the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/58b278e3-5a42-4ffa-bcf7-4a412c916567.png" style="width:27.42em;height:4.25em;"/></p>
<p>Here, <em>∑<sub>s</sub></em> is the covariance matrix and <em>μ<sub>s</sub></em> is the mean vector of the Gaussian distribution.</p>
<p>We can now use the Markovian assumptions to simplify the evaluation of the probability of the states. The probability of the states for all the blocks in the image is denoted by <em>P{s<sub>i,j</sub> : (i,j) ∈ N}</em>, where <em>N = {(i,j) : 0 ≤ i &lt; w, 0 <span>≤ j &lt; z</span>}</em>. But before we use the Markovian assumptions to efficiently expand the probability, we need to prove that, given the two previous assumptions, a rotated form of two-dimensional Markovian property holds for the image.</p>
<p>We define a rotated relation of <img class="fm-editor-equation" src="assets/3c09049a-47b5-4f1c-879e-b62c5ae7c047.png" style="width:2.42em;height:1.17em;"/>, denoted by <img class="fm-editor-equation" src="assets/bf1768a6-d1d0-4807-8510-e7e986aa189e.png" style="width:3.00em;height:1.25em;"/>, which specifies <img class="fm-editor-equation" src="assets/596b1745-78e3-4d41-be38-213c8116f383.png" style="width:6.42em;height:1.42em;"/>, if <em>j' &lt; j</em>, or <em>j' = j</em> and <em>i' &lt; i</em>. We need to prove the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/79ff27fe-7ec0-4bad-b171-b7e7136b11a2.png" style="width:52.83em;height:5.67em;"/></p>
<p>So, we use the previous definition of <img class="fm-editor-equation" src="assets/8c06ffa1-e05e-495c-b5b2-86669d53cdd2.png" style="width:15.75em;height:1.50em;"/> and introduce the following new notation:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/4d933c53-807c-49d6-977f-bd810ca54879.png" style="width:29.50em;height:5.67em;"/></p>
<p>From the preceding equations, we can also see this:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/eeddc6c8-43d8-4b44-8e17-34f7ac4a7e4d.png" style="width:13.92em;height:1.83em;"/></p>
<p>Now, to simplify notation, let's introduce <img class="fm-editor-equation" src="assets/b68105e2-f519-4505-ba80-a315a1478499.png" style="width:13.67em;height:1.50em;"/> and <img class="fm-editor-equation" src="assets/06f8b9c4-4aed-45be-8a0a-8eeb4f8e6ae9.png" style="width:19.17em;height:1.83em;"/>. From these we can do the following derivation:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/58cb7618-9a25-4eb7-b3d8-d5e79b4f6cb4.png" style="width:40.00em;height:5.42em;"/></p>
<p>Expanding the conditional probability, we get the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/7250fd03-5f94-47b8-95ec-18a1dc043e5b.png" style="width:36.92em;height:4.92em;"/></p>
<p>Using the Markovian assumption, we get the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/6fe48d95-9c3e-450e-8eba-734330c19647.png" style="width:35.67em;height:4.75em;"/></p>
<p>And, finally, using the Markovian assumption and the assumption that the feature vector of a block is conditionally independent of other blocks given its state, we have the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/8b01f2c6-4fda-49dc-ab90-eb64650b4f0e.png" style="width:34.08em;height:7.50em;"/></p>
<p>Where <em>m = s<sub>i-1,j</sub></em>, <em>n = s<sub>i,j-1</sub></em>, and <em>l = s<sub>i,j</sub></em>. </p>
<p>If we replace <img class="fm-editor-equation" src="assets/4c8ad46c-f557-4b7f-a6ea-4f8d6560d501.png" style="width:3.00em;height:1.25em;"/> with <img class="fm-editor-equation" src="assets/19fe49ce-a212-4450-a337-3b8006b7747c.png" style="width:0.92em;height:1.08em;"/>, and replace <img class="fm-editor-equation" src="assets/7eed13f5-8e55-464b-9c0e-1d43f4ca917d.png" style="width:0.92em;height:1.42em;"/> with <img class="fm-editor-equation" src="assets/90b91eb4-b566-4bf1-827e-df853411dbfb.png" style="width:2.75em;height:1.17em;"/> in the derivation, all the <span>equations </span>will still hold. This gives us the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/dea74b78-e673-4d7c-9ce0-ef8dce4f395c.png" style="width:33.17em;height:2.00em;"/></p>
<p>Since the preceding equation implies the original Markovian assumption and its rotated version, we can show the equivalent end of the two assumptions as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/7c7cdb97-5dd2-4d69-be8d-98c616b266cc.png" style="width:31.42em;height:3.50em;"/></p>
<p>Now we can simplify the expansion of <em>P{s<sub>i,j</sub> : (i,j) ∈ N}</em>, as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/a5b60120-a1df-4be4-ab1a-e8b9b72d6821.png" style="width:43.17em;height:1.67em;"/></p>
<p>Here, <em>w</em> and <em>z</em> are the numbers of rows and columns in the image, respectively, and <em>T<sub>i</sub></em> is the sequence of states for blocks on the diagonal <em>i</em>. Next, we need to prove that <em>P(T<sub>i</sub>|T<sub>i-1</sub>,...,T<sub>0</sub>) = P(T<sub>i</sub>|T<sub>i-1</sub>)</em>. Assuming <em>T<sub>i</sub> = {s<sub>i,0</sub>, s<sub>i-1,1</sub>, ..., s<sub>0,i</sub>}</em>, this means <em>T<sub>i-1</sub><span> </span>= {s<sub>i-1,0</sub>, s<sub>i-2,1</sub>, ..., s<sub>0,i-1</sub>}</em> and hence we have the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/c6f12b4f-77fd-4c19-a1d3-a88d2728c541.png" style="width:40.58em;height:6.50em;"/></p>
<p>Therefore, we can conclude:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/df39c7ac-122a-4ffa-9716-2eb4325006d1.png" style="width:19.25em;height:1.58em;"/></p>
<p>Using this, we get the following simplified equation:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/f3f98132-ebce-4291-8343-be8ab1f9a950.png" style="width:35.92em;height:1.75em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Parameter estimation using EM</h1>
                </header>
            
            <article>
                
<p>Since we have the model ready, we now need to estimate the parameters of the model. We need to estimate the mean vectors<em> μ<sub>m</sub></em>; the covariance matrices <em>∑<sub>m</sub></em>; and the transition probabilities <em>a<sub>m,n,l</sub></em>, where <em>m,n,l = 1,..., M</em>, and <em>M</em> is the total number of states. We will use the <strong>expectation maximization</strong> (<strong>EM</strong>) algorithm. </p>
<p>As we have seen in previous chapters, EM is an iterative algorithm that can learn the maximum likelihood estimates in the case of missing data; that is, when we have unobserved variables in our data. Let's say that our unobserved variable <em>x</em> is in the sample space <em>x</em>, and the observed variable <em>y is</em> in the sample space <em>y</em>. If we postulate a family of distribution <em>f(x|Φ)</em>, with parameters <em>Φ ∈ Ω</em>, then the distribution over <em>y</em> is given as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/e0df3b3b-5947-49b7-a79b-54219b731b50.png" style="width:10.25em;height:2.58em;"/></p>
<p>The EM algorithm will then try to find the value of <img class="fm-editor-equation" src="assets/754282b8-979e-4614-b427-d7a6abe56fad.png" style="width:0.92em;height:1.67em;"/> that would maximize the value of <em>g(y|Φ)</em> given the observed <em>y</em>. The EM iteration <em>Φ<sup>(p)</sup> → Φ<sup>(p+1)</sup></em> is defined as follows:</p>
<ul>
<li><strong>E-step</strong>: Compute <em>Q</em>(<em>Φ<span>|</span></em><em>Φ<sup>(p)</sup></em>) where <em>Q(Φ'|Φ)</em> is the expected value of <em>log f(x|Φ')</em></li>
<li><strong>M-step</strong>: Choose <em>Φ<sup>(p+1)</sup></em> to be a value of <em>Φ ∈ Ω</em> that maximizes <em>Q</em><span>(</span><em>Φ<span>|</span></em><em>Φ<sup>(p)</sup></em><span>)</span></li>
</ul>
<p>Let's now define the terms needed for 2D HMMs:</p>
<ul>
<li>The set of observed feature vectors for the entire image is <img class="fm-editor-equation" src="assets/5baf8d28-1c1c-43e3-b639-1916db29e96b.png" style="width:10.75em;height:1.42em;"/></li>
<li>The set of states for the image is <img class="fm-editor-equation" src="assets/36684bb8-35ff-45fc-8c9a-e5befbb557c7.png" style="width:10.42em;height:1.42em;"/></li>
<li>The set of classes for the image is <img class="fm-editor-equation" src="assets/8fb5bae3-a5db-426e-b073-c21269e90748.png" style="width:11.08em;height:1.50em;"/></li>
<li>The mapping from a state <em>s<sub>i,j</sub></em> to its class is C(<em>s<sub>i,j</sub></em>), and the set of classes mapped from states <em>s</em>, is denoted by <em>C(s)</em></li>
</ul>
<p>Now let's define the distribution over <em>x</em> for a 2D HMM, as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/c7bb7c16-b1fc-4f19-a125-347c08dc501e.png" style="width:30.42em;height:6.33em;"/></p>
<p>From this, we can compute the following <em>log f(x|Φ')</em>:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/dfc8e4d5-0475-46bf-ad04-c6ad42bf944b.png" style="width:36.42em;height:3.33em;"/></p>
<p>We now know that, given <em>y</em>, <em>x</em> can only have a finite number of values corresponding to states that are consistent with the value of <em>y</em>. Therefore, the distribution over <em>x</em> is given as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/d343cd48-215c-40bb-bc1b-6b457581740f.png" style="width:40.33em;height:6.92em;"/></p>
<p>Here, <em>α</em> is the normalizing constant and <em>I</em> is the indicator function. Now, for the M-step, we need to set the value of <em>Φ<sup>(p+1)</sup></em> to <em>Φ'</em>, which will maximize the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/9f08f7a9-b0b0-47e3-827d-eedceb60bd93.png" style="width:34.50em;height:7.08em;"/></p>
<p>Since the previous term has two parts with an addition between them, we can deal with each term separately, since we are trying to maximize the total. Consider the first term:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/5e4cdb78-25e4-424a-9d1a-7d3f0dba5af2.png" style="width:39.58em;height:7.83em;"/></p>
<p>By defining <img class="fm-editor-equation" src="assets/3e673b47-f5a0-4471-b1eb-e3e60933e5f0.png" style="width:19.33em;height:1.75em;"/>, the preceding equation can be reduced to this:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/06a06dbc-eea3-4365-8b99-d67e16aca866.png" style="width:14.33em;height:2.67em;"/></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>This term is concave in <img class="fm-editor-equation" src="assets/16ae97f5-a5a0-4366-8677-b50ddae3bb22.png" style="width:2.92em;height:1.75em;"/>; therefore, using the Lagrangian multiplier and taking the derivative we get the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/d976faaa-5f1f-4853-9b72-8ab8a8016870.png" style="width:22.08em;height:5.33em;"/></p>
<p>Coming back to maximizing the second term of <img class="fm-editor-equation" src="assets/51b62008-0348-43ac-ac06-db11ff691a62.png" style="width:9.50em;height:1.42em;"/>:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/d04d67ed-25f4-426c-9100-f30ef17b88f9.png" style="width:46.42em;height:10.92em;"/></p>
<p>Again, to simplify the preceding equation, we define <img class="fm-editor-equation" src="assets/0bdaf41a-7daa-4727-a14e-b46a5593304a.png" style="width:12.75em;height:1.83em;"/>, and the preceding term becomes this:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/264efbef-64f4-4c7c-a4b4-0928a4a1f95e.png" style="width:20.92em;height:4.42em;"/></p>
<p>In this case, our ML estimates for our Gaussian distribution are given by the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/94e685d6-6ba3-4b77-abc9-2fae6b4ef39c.png" style="width:23.75em;height:9.08em;"/></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>To summarize the whole derivation, we can write the EM algorithm in the following two steps:</p>
<ol>
<li><span>Given the model estimation <em>Φ<sup>(p)</sup></em></span><span>, the parameters are updated as follows:</span></li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/31e11a3a-7e50-48eb-a615-c011fe7eadfe.png" style="width:24.83em;height:8.00em;"/></p>
<p style="padding-left: 60px">Here, the term <img class="fm-editor-equation" src="assets/426b5f7c-b95f-43fc-9c79-7e443ca525bf.png" style="width:5.67em;height:2.25em;"/> can be computed as this:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/854f7887-920d-4a60-97d7-49950b0712b7.png" style="width:29.75em;height:6.75em;"/></p>
<ol start="2">
<li>The transition probability is updated as follows:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/e8e8ecf5-7202-414f-ab0d-a21ba88ebe43.png" style="width:18.00em;height:4.83em;"/></p>
<p style="padding-left: 60px">And, here, <img class="fm-editor-equation" src="assets/4e68c128-e7df-4413-abe4-42050f931fdc.png" style="width:7.08em;height:2.58em;"/> is calculated as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/b7250355-067f-4f1c-9d82-d2c4e2e13eff.png" style="width:36.83em;height:7.17em;"/></p>
<p>By applying the preceding two equations iteratively, our algorithm will converge to the maximum likelihood estimation of the parameters of the model.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter <span> we started with a short recap of 1D HMMs which we introduced in the previous chapter. Later we introduced the concepts of 2D HMMs and derived the various assumptions that we make for 2D HMMs to simplify our computations and it can be applied in image processing tasks. We then introduce a generic EM algorithm for learning the parameters in the case of 2D-HMMs.</span></p>
<p>In the next chapter, we will look at another application of HMMs in the field of reinforcement learning and will introduce MDP.</p>


            </article>

            
        </section>
    </body></html>