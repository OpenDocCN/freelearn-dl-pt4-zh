["```py\nimport numpy as np\n\nclass MultinomialHMM:\n def __init__(self, num_states, observation_states, prior_probabilities,\n transition_matrix, emission_probabilities):\n \"\"\"\n Initialize Hidden Markov Model\n\n Parameters\n -----------\n num_states: int\n Number of states of latent variable\n observation_states: 1-D array\n An array representing the set of all observations\n prior_probabilities: 1-D array\n An array representing the prior probabilities of all the states\n of latent variable\n        transition_matrix: 2-D array\n            A matrix representing the transition probabilities of change of\n            state of latent variable\n        emission_probabilities: 2-D array\n            A matrix representing the probability of a given observation\n            given the state of the latent variable\n        \"\"\"\n        # As latent variables form a Markov chain, we can use\n        # use the previous defined MarkovChain class to create it\n        self.latent_variable_markov_chain = MarkovChain(\n            transition_matrix=transition_matrix,\n            states=['z{index}'.format(index=index) for index in range(num_states)],\n        )\n        self.observation_states = observation_states\n        self.prior_probabilities = np.atleast_1d(prior_probabilities)\n        self.transition_matrix = np.atleast_2d(transition_matrix)\n        self.emission_probabilities = np.atleast_2d(emission_probabilities)\n```", "```py\ncoin_hmm = MultinomialHMM(num_states=2,\n                          observation_states=['H', 'T'],\n                          prior_probabilities=[0.5, 0.5],\n                          transition_matrix=[[0.5, 0.5], [0.5, 0.5]],\n                          emission_probabilities=[[0.8, 0.2], [0.3, 0.7]])\n```", "```py\ndef observation_from_state(self, state):\n    \"\"\"\n    Generate observation for a given state in accordance with\n    the emission probabilities\n\n    Parameters\n    ----------\n    state: int\n        Index of the current state\n    \"\"\"\n    state_index = self.latent_variable_markov_chain.index_dict[state]\n    return np.random.choice(self.observation_states,\n                            p=self.emission_probabilities[state_index, :])\n\ndef generate_samples(self, no=10):\n    \"\"\"\n    Generate samples from the hidden Markov model\n\n    Parameters\n    ----------\n    no: int\n        Number of samples to be drawn\n\n    Returns\n    -------\n    observations: 1-D array\n        An array of sequence of observations\n\n    state_sequence: 1-D array\n        An array of sequence of states\n    \"\"\"\n    observations = []\n    state_sequence = []\n\n    initial_state = np.random.choice(self.latent_variable_markov_chain.states,\n                                     p=self.prior_probabilities)\n\n    state_sequence.append(initial_state)\n    observations.append(self.observation_from_state(initial_state))\n\n    current_state = initial_state\n    for i in range(2, no):\n        next_state = self.latent_variable_markov_chain.next_state(current_state)\n        state_sequence.append(next_state)\n        observations.append(self.observation_from_state(next_state))\n        current_state = next_state\n\n    return observations, state_sequence\n```", "```py\n>>> coin_hmm.generate_samples()\n(['T', 'H', 'H', 'T', 'T', 'H', 'H', 'H', 'H'], ['z1', 'z0', 'z0', 'z1', 'z1', 'z0', 'z1', 'z1', 'z1'])\n```", "```py\nsource activate hmm\nconda install scikit-learn\npip install hmmlearn\n```", "```py\nfrom hmmlearn.hmm import GaussianHMM\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nstartprob = np.array([0.6, 0.3, 0.1, 0.0])\n# The transition matrix, note that there are no transitions possible\n# between component 1 and 3\ntransmat = np.array([[0.7, 0.2, 0.0, 0.1],\n                     [0.3, 0.5, 0.2, 0.0],\n                     [0.0, 0.3, 0.5, 0.2],\n                     [0.2, 0.0, 0.2, 0.6]])\n# The means of each component\nmeans = np.array([[0.0,  0.0],\n                  [0.0, 11.0],\n                  [9.0, 10.0],\n                  [11.0, -1.0]])\n# The covariance of each component\ncovars = .5 * np.tile(np.identity(2), (4, 1, 1))\n\n# Build an HMM instance and set parameters\nmodel = hmm.GaussianHMM(n_components=4, covariance_type=\"full\")\n\n# Instead of fitting it from the data, we directly set the estimated\n# parameters, the means and covariance of the components\nmodel.startprob_ = startprob\nmodel.transmat_ = transmat\nmodel.means_ = means\nmodel.covars_ = covars\n\nX, state_sequence = model.sample(n_samples=100)\n\nplt.plot(X[:, 0], X[:, 1], \".-\", label=\"observations\", ms=6,\n         mfc=\"orange\", alpha=0.7)\nfor i, m in enumerate(means):\n    plt.text(m[0], m[1], 'Component %i' % (i + 1),\n             size=12, horizontalalignment='center',\n             bbox=dict(alpha=.7, facecolor='w'))\nplt.legend(loc='best')\nplt.show()\n```"]