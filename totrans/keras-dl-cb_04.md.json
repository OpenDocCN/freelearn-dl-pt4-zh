["```py\nsess = tf.InteractiveSession()\nimage_batch = tf.constant([\n   [ # First Image\n     [[255, 0, 0], [255, 0, 0], [0, 255, 0]],\n     [[255, 0, 0], [255, 0, 0], [0, 255, 0]]\n   ],\n   [ # Second Image\n     [[0, 0, 0], [0, 255, 0], [0, 255, 0]],\n     [[0, 0, 0], [0, 255, 0], [0, 255, 0]]\n   ],\n   [ # Third Image\n     [[0, 0, 255], [0, 0, 255], [0, 0, 255]],\n     [[0, 0, 255], [0, 0, 255], [0, 0, 255]]\n   ]\n ])\n print(image_batch.get_shape())\n print(sess.run(image_batch)[1][0][0])\n```", "```py\n(3, 2, 3, 3)\n[255 0 0]\n```", "```py\ni = tf.constant([\n                 [1.0, 1.0, 1.0, 0.0, 0.0],\n                 [0.0, 0.0, 1.0, 1.0, 1.0],\n                 [0.0, 0.0, 1.0, 1.0, 0.0],\n                 [0.0, 0.0, 1.0, 0.0, 0.0]], dtype=tf.float32)\nk = tf.constant([\n                [1.0, 0.0, 1.0],\n                [0.0, 1.0, 0.0],\n                [1.0, 0.0, 1.0]\n        ], dtype=tf.float32),\nkernel = tf.reshape(k, [3, 3, 1, 1], name='kernel')\nimage = tf.reshape(i, [1, 4, 5, 1], name='image')\nres = tf.squeeze(tf.nn.conv2d(image, kernel, strides=[1, 1, 1, 1], padding=\"VALID\"))\n# VALID means no padding\nwith tf.Session() as sess:\n    print sess.run(res)\n```", "```py\n[[ 3\\. 3\\. 3.]\n [ 2\\. 2\\. 4.]]\n```", "```py\nimport tensorflow as tf\n\ndef main():\n  session = tf.InteractiveSession()\n  input_batch = tf.constant([\n    [ # First Input (6x6x1)\n      [[0.0], [1.0], [2.0], [3.0], [4.0], [5.0]],\n      [[0.1], [1.1], [2.1], [3.1], [4.1], [5.1]],\n      [[0.2], [1.2], [2.2], [3.2], [4.2], [5.2]],\n      [[0.3], [1.3], [2.3], [3.3], [4.3], [5.3]],\n      [[0.4], [1.4], [2.4], [3.4], [4.4], [5.4]],\n      [[0.5], [1.5], [2.5], [3.5], [4.5], [5.5]],\n  ],\n ])\nkernel = tf.constant([ # Kernel (3x3x1)\n  [[[0.0]], [[0.5]], [[0.0]]],\n  [[[0.0]], [[0.5]], [[0.0]]],\n  [[[0.0]], [[0.5]], [[0.0]]]\n])\n\n# NOTE: the change in the size of the strides parameter.\nconv2d = tf.nn.conv2d(input_batch, kernel, strides=[1, 3, 3, 1], padding='SAME')\nconv2d_output = session.run(conv2d)\nprint(conv2d_output)\nif __name__ == '__main__':\nmain()\n```", "```py\n[[[[ 1.64999998][ 6.1500001 ]]\n  [[ 2.0999999 ][ 6.60000038]]]]\n```", "```py\nmax_pool(\n  value, ksize, strides, padding, data_format='NHWC', name=None\n)\n```", "```py\nimport tensorflow as tf\n\nbatch_size=1\ninput_height = 3\ninput_width = 3\ninput_channels = 1\n\ndef main():\n  sess = tf.InteractiveSession()\n  layer_input = tf.constant([\n    [\n     [[1.0], [0.2], [2.0]],\n     [[0.1], [1.2], [1.4]],\n     [[1.1], [0.4], [0.4]]\n    ] \n  ])\n\n# The strides will look at the entire input by using the image_height and image_width\nkernel = [batch_size, input_height, input_width, input_channels]\nmax_pool = tf.nn.max_pool(layer_input, kernel, [1, 1, 1, 1], \"VALID\")\nprint(sess.run(max_pool))\n\nif __name__ == '__main__':\n  main()\n```", "```py\n[[[[ 2.]]]]\n```", "```py\navg_pool( value, ksize, strides, padding, data_format='NHWC', name=None)\n```", "```py\nimport tensorflow as tf\n\nbatch_size=1\ninput_height = 3\ninput_width = 3\ninput_channels = 1\n\ndef main():\n  sess = tf.InteractiveSession()\n  layer_input = tf.constant([\n    [\n      [[1.0], [0.2], [2.0]],\n      [[0.1], [1.2], [1.4]],\n      [[1.1], [0.4], [0.4]]\n    ]\n  ])\n\n  # The strides will look at the entire input by using the image_height and image_width\n  kernel = [batch_size, input_height, input_width, input_channels]\n  avg_pool = tf.nn.avg_pool(layer_input, kernel, [1, 1, 1, 1], \"VALID\")\n  print(sess.run(avg_pool))\n\nif __name__ == '__main__': \n    main()\n```", "```py\n[[[[ 0.86666667]]]]\n```", "```py\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nimport time\nfrom datetime import timedelta\nimport math\nimport dataset\nimport random\n```", "```py\n# Convolutional Layer 1.\nfilter_size1 = 3 \nnum_filters1 = 32\n\n# Convolutional Layer 2.\nfilter_size2 = 3\nnum_filters2 = 32\n\n# Convolutional Layer 3.\nfilter_size3 = 3\nnum_filters3 = 64\n\n# Fully-connected layer.\n# Number of neurons in fully-connected layer.\nfc_size = 128\n\n# Number of color channels for the images: 1 channel for gray-scale.\nnum_channels = 3\n\n# image dimensions (only squares for now)\nimg_size = 128\n\n# Size of image when flattened to a single dimension\nimg_size_flat = img_size * img_size * num_channels\n\n# Tuple with height and width of images used to reshape arrays.\nimg_shape = (img_size, img_size)\n```", "```py\n# class info\nclasses = ['dogs', 'cats']\nnum_classes = len(classes)\n\n# batch size\nbatch_size = 2\n\n# validation split\nvalidation_size = .2\ntotal_iterations = 0\nearly_stopping = None  # use None if you don't want to implement early stoping\nhome = '/home/ubuntu/Downloads/dogs_vs_cats'\ntrain_path = home + '/train-cat-dog-100/'\ntest_path = home + '/test-cat-dog-100/'\ncheckpoint_dir = home + \"/models/\"\n```", "```py\ndata = dataset.read_train_sets(train_path, img_size, classes, validation_size=validation_size)\n```", "```py\ndef read_train_sets(train_path, image_size, classes, validation_size=0):\n  class DataSets(object):\n    pass\n  data_sets = DataSets()\n\n  images, labels, ids, cls = load_train(train_path, image_size, classes)\n  images, labels, ids, cls = shuffle(images, labels, ids, cls)  # shuffle the data\n\n  if isinstance(validation_size, float):\n    validation_size = int(validation_size * images.shape[0])\n\n  validation_images = images[:validation_size]\n  validation_labels = labels[:validation_size]\n  validation_ids = ids[:validation_size]\n  validation_cls = cls[:validation_size]\n\n  train_images = images[validation_size:]\n  train_labels = labels[validation_size:]\n  train_ids = ids[validation_size:]\n  train_cls = cls[validation_size:]\n\n  data_sets.train = DataSet(train_images, train_labels, train_ids, train_cls)\n  data_sets.valid = DataSet(validation_images, validation_labels, validation_ids, \n   validation_cls)\n\n  return data_sets\n```", "```py\ndef load_train(train_path, image_size, classes) :\n images = labels = []\n ids = cls = []\n # load data into arrays\n images = np.array(images) \n labels = np.array(labels) \n ids = np.array(ids) \n cls =  np.array(cls)   \n return images, labels, ids, cls\n```", "```py\nvalidation_size = int(validation_size * images.shape[0])\n```", "```py\ntest_images, test_ids = dataset.read_test_set(test_path, img_size)\n```", "```py\ndef read_test_set(test_path, image_size):\n  images, ids  = load_test(test_path, image_size)\n  return images, ids\n```", "```py\ndef load_test(test_path, image_size):\n  path = os.path.join(test_path, '*g')\n  files = sorted(glob.glob(path))\n\n  X_test = []\n  X_test_id = []\n  print(\"Reading test images\")\n  for fl in files:\n      flbase = os.path.basename(fl)\n      img = cv2.imread(fl)\n      img = cv2.resize(img, (image_size, image_size), fx=0.5, fy=0.5,\n        interpolation=cv2.INTER_LINEAR)\n\n      #img = cv2.resize(img, (image_size, image_size), cv2.INTER_LINEAR)\n      X_test.append(img)\n      X_test_id.append(flbase)\n\n  ### because we're not creating a DataSet object for the test images, \n  ### normalization happens here\n  X_test = np.array(X_test, dtype=np.uint8)\n  X_test = X_test.astype('float32')\n  X_test = X_test / 255\n\n  return X_test, X_test_id\n```", "```py\nprint(\"Size of:\")\nprint(\"- Training-set:\\t\\t{}\".format(len(data.train.labels)))\nprint(\"- Test-set:\\t\\t{}\".format(len(test_images)))\nprint(\"- Validation-set:\\t{}\".format(len(data.valid.labels)))\n```", "```py\nSize of:Size of:\n- Training-set: 233\n- Test-set: 100\n- Validation-set: 58\n```", "```py\n images, cls_true = data.train.images, data.train.cls\n plot_images(images=images, cls_true=cls_true\n```", "```py\ndef plot_images(images, cls_true, cls_pred=None):\n\n    if len(images) == 0:\n        print(\"no images to show\")\n        return \n    else:\n        random_indices = random.sample(range(len(images)), min(len(images), 9))\n\n    images, cls_true  = zip(*[(images[i], cls_true[i]) for i in random_indices])\n\n    # Create figure with 3x3 sub-plots.\n    fig, axes = plt.subplots(3, 3)\n    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n\n    for i, ax in enumerate(axes.flat):\n        # Plot image.\n        print(images[i])\n        ax.imshow(images[i].reshape(img_size, img_size, num_channels))\n        print(images[i].size)\n        print(img_size)\n        print(num_channels)\n        # Show true and predicted classes.\n        if cls_pred is None:\n            xlabel = \"True: {0}\".format(cls_true[i])\n        else:\n            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n\n        # Show the classes as the label on the x-axis.\n        ax.set_xlabel(xlabel)\n\n        # Remove ticks from the plot.\n        ax.set_xticks([])\n        ax.set_yticks([])\n\n    # Ensure the plot is shown correctly with multiple plots\n    # in a single Notebook cell.\n    plt.show()\n```", "```py\nx = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')\nx_image = tf.reshape(x, [-1, img_size, img_size, num_channels])\n```", "```py\n\nlayer_conv1, weights_conv1 = new_conv_layer(input=x_image,\n                                            num_input_channels=num_channels,\n                                            filter_size=filter_size1,\n                                            num_filters=num_filters1,\n                                            use_pooling=True)\nprint(layer_conv1)\n```", "```py\ndef new_conv_layer(input,              # The previous layer.\n                   num_input_channels, # Num. channels in prev. layer.\n                   filter_size,        # Width and height of each filter.\n                   num_filters,        # Number of filters.\n                   use_pooling=True):  # Use 2x2 max-pooling.\n\n    # Shape of the filter-weights for the convolution.\n    # This format is determined by the TensorFlow API.\n    shape = [filter_size, filter_size, num_input_channels, num_filters]\n\n    # Create new weights aka. filters with the given shape.\n    weights = new_weights(shape=shape)\n\n    # Create new biases, one for each filter.\n    biases = new_biases(length=num_filters)\n\n    # Create the TensorFlow operation for convolution.\n    # Note the strides are set to 1 in all dimensions.\n    # The first and last stride must always be 1,\n    # because the first is for the image-number and\n    # the last is for the input-channel.\n    # But e.g. strides=[1, 2, 2, 1] would mean that the filter\n    # is moved 2 pixels across the x- and y-axis of the image.\n    # The padding is set to 'SAME' which means the input image\n    # is padded with zeroes so the size of the output is the same.\n    layer = tf.nn.conv2d(input=input,\n                         filter=weights,\n                         strides=[1, 1, 1, 1],\n                         padding='SAME')\n\n    # Add the biases to the results of the convolution.\n    # A bias-value is added to each filter-channel.\n    layer += biases\n\n    # Use pooling to down-sample the image resolution?\n    if use_pooling:\n        # This is 2x2 max-pooling, which means that we\n        # consider 2x2 windows and select the largest value\n        # in each window. Then we move 2 pixels to the next window.\n        layer = tf.nn.max_pool(value=layer,\n                               ksize=[1, 2, 2, 1],\n                               strides=[1, 2, 2, 1],\n                               padding='SAME')\n\n    # Rectified Linear Unit (ReLU).\n    # It calculates max(x, 0) for each input pixel x.\n    # This adds some non-linearity to the formula and allows us\n    # to learn more complicated functions.\n    layer = tf.nn.relu(layer)\n\n    # Note that ReLU is normally executed before the pooling,\n    # but since relu(max_pool(x)) == max_pool(relu(x)) we can\n    # save 75% of the relu-operations by max-pooling first.\n\n    # We return both the resulting layer and the filter-weights\n    # because we will plot the weights later.\n    return layer, weights\n```", "```py\nTensor(\"Relu:0\", shape=(?, 64, 64, 32), dtype=float32)\n```", "```py\ny_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n\ny_true_cls = tf.argmax(y_true, dimension=1)\n```", "```py\n\nlayer_conv2, weights_conv2 = new_conv_layer(input=layer_conv1,\n                                            num_input_channels=num_filters1,filter_size=filter_size2,num_filters=num_filters2,use_pooling=True)\n```", "```py\nTensor(\"Relu_1:0\", shape=(?, 32, 32, 32), dtype=float32)\n```", "```py\nshape = [filter_size, filter_size, num_input_channels, num_filters] weights = new_weights(shape=shape)\n```", "```py\nlayer_conv3, weights_conv3 = new_conv_layer(input=layer_conv2,\n                                            num_input_channels=num_filters2,filter_size=filter_size3,num_filters=num_filters3,use_pooling=True) \n```", "```py\nprint(layer_conv3)\n```", "```py\nTensor(\"Relu_2:0\", shape=(?, 16, 16, 64), dtype=float32)\n```", "```py\nlayer_flat, num_features = flatten_layer(layer_conv3)\n```", "```py\nTensor(\"Reshape_1:0\", shape=(?, 16384), dtype=float32)\n16384\n```", "```py\nlayer_fc1 = new_fc_layer(input=layer_flat,\n                         num_inputs=num_features,\n                         num_outputs=fc_size,\n                         use_relu=True)\n```", "```py\nprint(layer_fc1)\n```", "```py\nTensor(\"Relu_3:0\", shape=(?, 128), dtype=float32)\n```", "```py\nlayer_fc2 = new_fc_layer(input=layer_fc1,\n                         num_inputs=fc_size,\n                         num_outputs=num_classes,\n                         use_relu=False)\n```", "```py\nprint(layer_fc2)\n```", "```py\nTensor(\"add_4:0\", shape=(?, 2), dtype=float32)\n```", "```py\ny_pred = tf.nn.softmax(layer_fc2)\ny_pred_cls = tf.argmax(y_pred, dimension=1)\n```", "```py\ncross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n  logits=layer_fc2,\n  labels=y_true)\ncost = tf.reduce_mean(cross_entropy)\n```", "```py\noptimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n```", "```py\ncorrect_prediction = tf.equal(y_pred_cls, y_true_cls)\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n```", "```py\nsession = tf.Session()\nsession.run(tf.global_variables_initializer())\nbatch_size = 2\ntrain_batch_size = batch_size\noptimize(num_iterations = 1, data=data, train_batch_size=train_batch_size, x=x, y_true=y_true,\nsession=session, optimizer=optimizer, cost=cost, accuracy=accuracy)\n```", "```py\ndef optimize(num_iterations, data, train_batch_size, x, y_true, session, optimizer, cost, accuracy):\n    # Ensure we update the global variable rather than a local copy.\n    global total_iterations\n\n    # Start-time used for printing time-usage below.\n    start_time = time.time()\n\n    best_val_loss = float(\"inf\")\n    patience = 0\n\n    for i in range(total_iterations,\n                   total_iterations + num_iterations):\n\n        # Get a batch of training examples.\n        # x_batch now holds a batch of images and\n        # y_true_batch are the true labels for those images.\n        x_batch, y_true_batch, _, cls_batch = data.train.next_batch(train_batch_size)\n        x_valid_batch, y_valid_batch, _, valid_cls_batch = data.valid.next_batch(train_batch_size)\n\n        # Convert shape from [num examples, rows, columns, depth]\n        # to [num examples, flattened image shape]\n\n        x_batch = x_batch.reshape(train_batch_size, img_size_flat)\n        x_valid_batch = x_valid_batch.reshape(train_batch_size, img_size_flat)\n\n        # Put the batch into a dict with the proper names\n        # for placeholder variables in the TensorFlow graph.\n        feed_dict_train = {x: x_batch,\n                           y_true: y_true_batch}\n\n        feed_dict_validate = {x: x_valid_batch,\n                              y_true: y_valid_batch}\n\n        # Run the optimizer using this batch of training data.\n        # TensorFlow assigns the variables in feed_dict_train\n        # to the placeholder variables and then runs the optimizer.\n        session.run(optimizer, feed_dict=feed_dict_train)\n\n        # Print status at end of each epoch (defined as full pass through \n        # training dataset).\n        if i % int(data.train.num_examples/batch_size) == 0: \n            val_loss = session.run(cost, feed_dict=feed_dict_validate)\n            epoch = int(i / int(data.train.num_examples/batch_size))\n\n            #print_progress(epoch, feed_dict_train, feed_dict_validate, val_loss)\n            print_progress(session, accuracy, epoch, feed_dict_train, feed_dict_validate,\n              val_loss)\n\n            if early_stopping:    \n                if val_loss < best_val_loss:\n                    best_val_loss = val_loss\n                    patience = 0\n                else:\n                    patience += 1\n\n                if patience == early_stopping:\n                    break\n\n    # Update the total number of iterations performed.\n    total_iterations += num_iterations\n\n    # Ending time.\n    end_time = time.time()\n\n    # Difference between start and end-times.\n    time_dif = end_time - start_time\n\n    # Print the time-usage.\n    print(\"Time elapsed: \" + str(timedelta(seconds=int(round(time_dif)))))\n```", "```py\nEpoch 1 --- Training Accuracy: 100.0%, Validation Accuracy: 50.0%, Validation Loss: 0.705\n```", "```py\nprint_validation_accuracy(x, y_true, y_pred_cls, session, data, show_example_errors=True, show_confusion_matrix=False)\nEpoch 2 --- Training Accuracy: 50.0%, Validation Accuracy: 100.0%, Validation Loss: 0.320\nAccuracy on Test-Set: 43.1% (25 / 58)\n```", "```py\noptimize(num_iterations=100, data=data, train_batch_size=train_batch_size, x=x, y_true=y_true,session=session, optimizer=optimizer, cost=cost, accuracy=accuracy)\n\nprint_validation_accuracy(x, y_true, y_pred_cls, session, data, show_example_errors=True,\n                              show_confusion_matrix=False)\nAccuracy on Test-Set: 62.1% (36 / 58)\n```", "```py\nimage1 = test_images[0] \nplot_image(image1)\n```", "```py\nimage2 = test_images[13]\nplot_image(image2)\n```", "```py\nplot_conv_layer(layer=layer_conv1, image=image1, session=session, x=x)\n```", "```py\nplot_conv_layer(layer=layer_conv1, image=image2, session=session, x=x)\n```", "```py\nplot_conv_weights(weights=weights_conv1, session=session)\n```", "```py\nplot_conv_weights(weights=weights_conv2, session=session, input_channel=1)\n```", "```py\nplot_conv_layer(layer=layer_conv2, image=image1, session=session, x=x)\nplot_conv_layer(layer=layer_conv2, image=image2, session=session, x=x)\n```", "```py\nplot_conv_weights(weights=weights_conv3, session=session, input_channel=0)\n```", "```py\nplot_conv_weights(weights=weights_conv3, session=session, input_channel=1)\n```", "```py\nplot_conv_layer(layer=layer_conv3, image=image1, session=session, x=x)\nplot_conv_layer(layer=layer_conv3, image=image2, session=session, x=x)\n```"]