- en: Creating Custom OpenAI Gym Environments - CARLA Driving Simulator
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the first chapter, we looked at the various categories of learning environments
    available in the OpenAI Gym environment catalog. We then explored the list of
    environments and their nomenclature in [Chapter 5](part0078.html#2ACBS0-22c7fc7f93b64d07be225c00ead6ce12),
    *Implementing your First Learning Agent – Solving the Mountain Car problem*, as
    well as a sneak peek into some of them. We also developed our agents to solve
    the Mountain Car and Cart Pole problems, and a few Atari game environments. By
    now, then, you should have a good understanding of the various environment types
    and flavors that are available with OpenAI Gym. Most often, once we learn how
    to develop our own intelligent agents, we want to use that knowledge and skill
    to develop intelligent agents to solve new problems, problems that we already
    face, or even problems that are of interest to us. For instance, you might be
    a game developer wanting to add intelligent behaviors to your game characters
    or a robotics engineer wanting to instill artificial intelligence to your robot,
    or you could be an autonomous driving engineer wanting to apply reinforcement
    learning to autonomous driving. You might be a tinkerer wanting to turn a gadget
    into an intelligent **Internet of Things** (**IoT**) device, or you might even
    be a healthcare professional wanting to improve your lab's diagnostic capabilities
    using machine learning. The potential for application is almost limitless.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: One of the reasons we have chosen OpenAI Gym as our learning environment is
    because of its simple yet standard interface that decouples the type and nature
    of the environment from the environment-agent interface. In this chapter, we will
    look at how you can create your own environment based on your own personal or
    professional needs. This will enable you to use agent implementations, training
    and testing scripts, the parameter manager, and the logging and visualization
    routines that we developed in earlier chapters with your own design or problem.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the anatomy of Gym environments
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Any Gym-compatible environment should subclass the `gym.Env` class and implement
    the `reset` and `step` methods and the `observation_space` and `action_space`
    properties and attributes. There is also the opportunity to implement other, optional
    methods that can add additional functionality to our custom environments. The
    following table lists and describes the other methods available:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '| **Method** | ** Functionality description** |'
  id: totrans-5
  prefs: []
  type: TYPE_TB
- en: '| `observation_space` | The shape and type of the observations returned by
    the environment. |'
  id: totrans-6
  prefs: []
  type: TYPE_TB
- en: '| `action_space` | The shape and type of the actions accepted by the environment.
    |'
  id: totrans-7
  prefs: []
  type: TYPE_TB
- en: '| `reset()` | Routines to reset the environment at the start or end of an episode.
    |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
- en: '| `step(...)` | Routines that calculate the necessary information to advance
    the environment, simulation, or game to the next step. The routine includes applying
    the chosen action in the environment, calculating the reward, producing the next
    observation, and determining if an episode has ended. |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| `step(...)` | 用于计算推进环境、仿真或游戏至下一步所需的信息的程序。该程序包括在环境中应用所选的动作、计算奖励、生成下一次观察，并判断回合是否结束。
    |'
- en: '| `_render()` | (Optional) This renders the state or observation of the Gym
    environment. |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| `_render()` | （可选）此项渲染 Gym 环境的状态或观察结果。 |'
- en: '| `_close()` | (Optional) This closes the Gym environment. |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| `_close()` | （可选）此项用于关闭 Gym 环境。 |'
- en: '| `_seed` | (Optional) This seeds the random functions in the Gym environment
    with a custom seed that makes the environment behave in a reproducible way for
    a given seed. |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| `_seed` | （可选）此项为 Gym 环境的随机函数提供一个自定义种子，使得环境在给定种子下能以可复现的方式运行。 |'
- en: '| `_configure` | (Optional) This enables additional environment configuration.
    |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| `_configure` | （可选）此项启用额外的环境配置。 |'
- en: Creating a template for custom Gym environment implementations
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建自定义 Gym 环境实现的模板
- en: 'Based on the anatomy of the Gym environment we have already discussed, we will
    now lay out a basic version of a custom environment class implementation named `CustomEnv`,
    which will be a subclass of `gym.Env` and implement the essential methods and
    arguments required to make it a Gym-compatible environment. A template for a minimal
    implementation is as follows:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 基于我们已经讨论的 Gym 环境结构，我们现在将展示一个名为 `CustomEnv` 的自定义环境类实现的基本版本，它将是 `gym.Env` 的子类，并实现所需的必要方法和参数，以使其成为一个与
    Gym 兼容的环境。以下是最小实现的模板：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: After we have finished our environment class implementation, we should register
    it with the OpenAI Gym registry so that we can use `gym.make(ENV_NAME)` to create
    an instance of the environment, as we have previously with Gym environments.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们完成环境类的实现后，我们应当将其注册到 OpenAI Gym 注册表中，以便可以像之前使用 Gym 环境一样通过 `gym.make(ENV_NAME)`
    创建环境实例。
- en: Registering custom environments with OpenAI Gym
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 注册自定义环境到 OpenAI Gym
- en: '[PRE2]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We will make use of this template later on in this chapter to create a custom
    Gym environment that uses a very sophisticated driving simulator.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章后面使用此模板来创建一个使用非常复杂的驾驶模拟器的自定义 Gym 环境。
- en: Creating an OpenAI Gym-compatible CARLA driving simulator environment
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个与 OpenAI Gym 兼容的 CARLA 驾驶模拟环境
- en: CARLA is a driving simulator environment built on top of the UnrealEngine4 game
    engine with more realistic rendering compared to some of its competitors. You
    can read more about the CARLA simulator on their official website at [https://carla.org](https://carla.org).
    In this section, we will look into how we can create a custom OpenAI Gym-compatible
    car driving environment to train our learning agents. This is a fairly complex
    environment and requires a GPU to run—which is unlike other Gym environments we
    have seen so far. Once you understand how to create a custom environment interface
    that is Gym-compatible for CARLA, you may well have enough information to develop
    interfaces for any of your own custom environments, no matter how complex they
    might be.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: CARLA 是一个基于 UnrealEngine4 游戏引擎构建的驾驶模拟环境，相较于一些竞争对手，CARLA 提供了更为真实的渲染效果。你可以在其官方网站
    [https://carla.org](https://carla.org) 阅读更多关于 CARLA 模拟器的信息。在本节中，我们将探讨如何创建一个与 OpenAI
    Gym 兼容的自定义汽车驾驶环境，以训练我们的学习代理。这个环境相当复杂，需要 GPU 支持才能运行——与我们之前见过的其他 Gym 环境不同。一旦你理解了如何为
    CARLA 创建一个兼容 Gym 的自定义环境接口，你就能获得足够的信息，来为任何复杂的自定义环境开发接口。
- en: The latest version of CARLA is CARLA 0.8.2\. While most (if not all) of the
    core environment interfaces, especially the `PythonClient` library, might stay
    the same, there is a chance of future changes that necessitate tweaks in this
    custom environment implementation. If that happens, the code repository of this
    book will be updated accordingly to support newer versions of CARLA. You may want
    to make sure you use the latest version of the code from the book's code repository
    when you work on this chapter (which is yet another reason to subscribe to notifications
    in GitHub). Nevertheless, the custom environment implementation building blocks
    discussed in this chapter will stay generally applicable, and will walk you through
    defining your own custom environments that are compatible with the OpenAI Gym
    interface. The complete code for the custom CARLA environment interface is available
    in the book's code repository under `ch7/carla-gym`.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we start a Gym-compatible CARLA environment, let''s first take a look
    at the CARLA simulator. So, let''s go ahead and download the CARLA release binaries.
    In the following section, we will use `VER_NUM` to denote the version number,
    so be sure to replace the `VER_NUM` text with the version number you are using
    before running the following commands:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: 'First, create a folder named `software` in your home directory using the following
    bash command:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Download the CARLA binary release version for Linux ([CARLA_VER_NUM.tar.gz](https://drive.google.com/open?id=1ZtVt1AqdyGxgyTm69nzuwrOYoPUn_Dsm))
    using the link on the official release page at [https://github.com/carla-simulator/carla/releases/tag/VER_NUM](https://github.com/carla-simulator/carla/releases/tag/0.8.2).
    (The direct link to version 0.8.2 is: [https://drive.google.com/open?id=1ZtVt1AqdyGxgyTm69nzuwrOYoPUn_Dsm](https://drive.google.com/open?id=1ZtVt1AqdyGxgyTm69nzuwrOYoPUn_Dsm).)
    Then, extract it into `~/software`. You should now have a file named `CarlaUE4.sh`
    in the `~/software/CARLA_VER_NUM` folder.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Set the `CARLA_SERVER` environment variable to point to `CarlaUE4.sh` on your
    computer using the following command:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now you are ready to test-run the CARLA driving simulator! Just execute `$CARLA_SERVER`
    or, directly, `~/software/CARLA_VER_NUM/CarlaUE4.sh`. For CARLA version 0.8.2,
    this command will be `~/software/CARLA_0.8.2/CarlaUE4.sh`. You should now see
    a CARLA simulator screen, as shown in the following screenshot:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00149.jpeg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
- en: 'The previous screenshot shows the vehicle (the agent) in one of CARLA''s starting
    positions. The following screenshot shows the vehicle in another starting position
    in the CARLA environment:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00150.jpeg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
- en: Once the vehicle is initialized, you should be able to control the vehicle using
    the *w*, *a*, *s*, *d* keys on your keyboard. The *w* key will move the car forwards,
    the *a* key will turn the car to the left, and... you can probably figure out
    the rest!
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: Let's now move on and start our Gym-compatible CARLA environment implementation
    with configuration and initialization.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: Configuration and initialization
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will first define some environment-specific configuration parameters, as
    well as briefly look at scenario configurations, as well. We will then start the
    initialization process for the `CarlaEnv` class implementation, which will inherit
    from the `Gym.Env` class.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: Configuration
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s first define a list of configuration parameters for the environment
    using a dictionary, shown as follows:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '`scenario_config` defines several parameters that are useful for creating a
    variety of driving scenarios. The scenario configuration is described in the `scenarios.json`
    file, which can be found in the book''s code repository at `ch7/carla-gym/carla_gym
    /envs/scenarios.json`.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: Initialization
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the `__init__` method, we define the initialization parameters along with
    the action and state spaces, which, as we saw in the previous section, are necessary.
    The implementation is straight-forward, as follows:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Implementing the reset method
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you may have noticed, at the beginning of every episode, we call the `reset`
    method of the Gym environment. For the CARLA environment, we want to update the
    CARLA server to restart the level through the CARLA client.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: So, let's get on with starting our implementation of the `reset` method.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: Customizing the CARLA simulation using the CarlaSettings object
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we start a new episode, we want to be able to configure the start state
    (where the agent or vehicle starts), the goal state (the agent or vehicle's intended
    destination), the complexity of the episode (measured by the number of vehicles
    or pedestrians in the episode), the type and sources of observations (the sensors
    configured on the vehicle), and so on.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: The CARLA project manages the interface between the UE4 environment and the
    external configuration and control using a server-client architecture, for which
    there are two servers.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: For the CARLA environment, we can configure the environment's start state, goal
    state, complexity level, and the sensor sources using the `CarlaSettings` object
    or the `CarlaSettings.ini` file.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now create a `CarlaSettings` object and configure some of the settings,
    as follows:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Adding cameras and sensors to a vehicle in CARLA
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To add an RGB color camera in the CARLA environment, use the following code:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'You can also add a depth measuring sensor or camera using the following code
    snippet:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'To add `LIDAR` to the CARLA environment, use the following code:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Once we have created a CARLA settings object based on our desired driving simulation
    configuration, we can send it to the CARLA server to set up the environment and
    start the simulation.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we have sent the CARLA settings object to the CARLA server, it responds
    with a scene description object that contains the available start positions for
    the ego vehicle, as follows:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We can now choose a particular starting position for the host or ego vehicle,
    or even choose a starting spot at random, as shown in the following code snippet:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以为主车或自车选择一个特定的起始位置，或者随机选择一个起始点，如以下代码片段所示：
- en: '[PRE14]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We can also send this start spot preference to the server and request the start
    of a new episode using the following code snippet:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以将这个起始点偏好发送到服务器，并使用以下代码片段请求启动新的一集：
- en: '[PRE15]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Note that the previous line is a blocking function call that will block action
    until the CARLA server actually starts the episode.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，前一行是一个阻塞函数调用，它将在CARLA服务器实际启动本集之前阻塞动作。
- en: 'We can now step through the episode from this starting position until the end.
    In the next section, we will see what we need to implement the CARLA environment''s
    `step()` method, which is used to step through the environment to the end of an
    episode:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以从这个起始位置开始，逐步进行，直到本集的结束。在下一节中，我们将看到我们需要实现CARLA环境的`step()`方法，这个方法用于逐步推进环境，直到本集结束：
- en: '[PRE16]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Implementing the step function for the CARLA environment
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为CARLA环境实现`step()`函数
- en: 'Once we have initialized the CARLA simulator by sending the CARLA settings
    object to the CARLA server and calling `client.start_episode(start_spot)`, the
    driving simulation will begin. We can then use the `client.read_data()` method
    to get the data produced by the simulation at a given step. We can do this using
    the following line of code:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们通过将CARLA设置对象发送到CARLA服务器并调用`client.start_episode(start_spot)`来初始化CARLA模拟器，驾驶模拟就会开始。然后，我们可以使用`client.read_data()`方法获取在给定步骤下模拟产生的数据。我们可以通过以下代码行来实现这一点：
- en: '[PRE17]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Accessing camera or sensor data
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 访问相机或传感器数据
- en: 'We can retrieve the sensor data at any given time step using the returned `sensor_data`
    object''s `data` property. To retrieve the RGB camera frames, input the following
    code:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过返回的`sensor_data`对象的`data`属性，在任何给定的时间步获取传感器数据。要获取RGB摄像头帧，请输入以下代码：
- en: '[PRE18]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '`rgb_image` is a NumPy n-d array, which you can access and manipulate as you
    would usually access and manipulate a NumPy n-d array.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '`rgb_image`是一个NumPy n维数组，您可以像通常访问和操作NumPy n维数组一样访问和操作它。'
- en: 'For example, to access the pixel value of the RGB camera image at the (*x*,
    *y*) image plane coordinates, you can do so using the following line:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，要访问RGB摄像头图像在(*x*, *y*)图像平面坐标处的像素值，可以使用以下代码行：
- en: '[PRE19]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'To retrieve the depth camera frames, input the following code:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取深度摄像头帧，请输入以下代码：
- en: '[PRE20]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Sending actions to control agents in CARLA
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 发送动作以控制CARLA中的代理
- en: 'We can control the car in CARLA by sending the desired steer, throttle, brake,
    hand-brake, and reverse (gear) commands to the CARLA server through a TCP client.
    The following table displays the value, range, and a description of the commands
    that a car in CARLA will obey:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过向CARLA服务器发送所需的转向、油门、刹车、手刹和倒车（档）命令，来控制CARLA中的汽车。下表展示了汽车在CARLA中将遵循的命令的值、范围和描述：
- en: '| **Command/action name** | **Value type, range** | **Description** |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| **命令/动作名称** | **值类型，范围** | **描述** |'
- en: '| Steer | `Float`, [-1.0, +1.0] | Normalized steering angle |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 转向 | `Float`，[-1.0，+1.0] | 标准化转向角度 |'
- en: '| Throttle | `Float`, [0.0, 1.0] | Normalized throttle input |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 油门 | `Float`，[0.0，1.0] | 标准化油门输入 |'
- en: '| Brake | `Float`, [0.0, 1.0] | Normalized brake input |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 刹车 | `Float`，[0.0，1.0] | 标准化刹车输入 |'
- en: '| Hand Brake | `Boolean`, True/False | This tells the car whether to engage
    the hand brake (`True`) or not (`False`) |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 手刹 | `Boolean`，真/假 | 这告诉汽车是否启用手刹（`True`）或不启用（`False`） |'
- en: '| Reverse | `Boolean`, True/False | This tells the car whether to be in reverse
    gear (`True`) or not (`False`) |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 倒车 | `Boolean`，真/假 | 这告诉汽车是否处于倒档（`True`）或不是（`False`） |'
- en: 'As noted in the CARLA documentation, the actual steering angle will depend
    on the vehicle. For example, the default Mustang vehicle has a maximum steering
    angle of 70 degrees, as defined in the vehicle''s front wheel UE4 blueprint file.
    Those are the five different commands that are needed to control a car in CARLA.
    Among the five commands, three of them (steer, throttle, and brake) are real-value
    floating-point numbers. Though their range is limited between -1 and +1 or 0 and
    1, the number of (unique) possible values is enormous. For example, if we use
    single precision floating point representation for throttle values that lie between
    0 and 1, there are ![](img/00151.jpeg), which means there are 1,056,964,608 different
    possible values for that throttle command. The same holds true for the brake command,
    as it also lies between 0 and 1\. There are about twice as many possible float
    values for the steering command, as it lies between -1 and +1\. Since a single
    control message is composed of a set of values for each of the five commands,
    the number of distinct actions (or control messages) is the product of the unique
    values for each of the commands, which are roughly in the order that follows:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00152.jpeg)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
- en: This generates a huge action space as you can see, and it might prove to be
    a very hard problem for a deep learning agent to regress onto such a huge action
    space. So, let's simplify the action space and define the action space in two
    flavors – one for continuous space and the other for discrete space, which is
    useful for applying different reinforcement learning algorithms. For example,
    the deep Q-learning based algorithms (without the naturalized advantage function)
    can only work on discrete action spaces.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: Continuous action space in CARLA
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'While driving, we don''t usually accelerate and brake at the same time; because
    the action space in CARLA is continuous, and the agent will apply an action at
    every step, it may be enough to have one command for accelerating and decelerating. Let''s
    now combine the throttle and brake commands into one with a value range of -1
    to +1, using the value range between -1 and 0 for the brake command and the value
    range between 0 and 1 for the throttle or acceleration command. We can define
    this using the following command:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '`action[0]` signifies the command for steering, while `action[1]` signifies
    the value for our combined throttle and brake commands. For now, we will set both
    `hand_brake` and `reverse` to False. Next, we will look at how we can define a
    discrete action space so we choose what we want for our agent.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: Discrete action space in CARLA
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We've already seen that the full action space is quite large (in the order of ![](img/00153.jpeg)
    ). You may have played video games where you only used a joystick with four arrow
    buttons or the arrow keys on a keyboard to control the speed and heading (the
    direction in which the car is pointed) to drive, so why can't we ask the agent
    to control the car in a similar way here? Well, that is the idea behind discretizing
    the action space. Although we won't be able to have precise control over the car,
    we can make sure that the discretized space gives us good control in a simulation
    environment.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s begin by using the similar convention we used in the continuous action
    space case – where we used one floating point value to represent the throttle
    (acceleration) and brake (deceleration) actions, thereby using a two-dimensional
    bounded space internally. This means the action space, in this case, can be defined
    as follows:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: As you can see here, `NUM_DISCRETE_ACTONS` is equal to the number of different
    actions available, which we will define later on in this section.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: 'We will then discretize the space using two-dimensional bounded space and exposing
    this as the discrete action space to the agent. To keep the number of possible
    actions to a minimum while still allowing control over the car, we use the following
    list of actions:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '| **Action index** | **Action description** | ** Action array value** |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
- en: '| 0 | Coast | [0.0, 0.0] |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
- en: '| 1 | Turn Left | [0.0, -0.5] |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
- en: '| 2 | Turn Right | [0.0, 0.5] |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
- en: '| 3 | Forward | [1.0, 0.0] |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
- en: '| 4 | Brake | [-0.5, 0.0] |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
- en: '| 5 | Bear Left & Accelerate | [1.0, -0.5] |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
- en: '| 6 | Bear Right & Accelerate | [1.0, 0.5] |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
- en: '| 7 | Bear Left & Decelerate | [-0.5, -0.5] |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
- en: '| 8 | Bear Right & Decelerate | [-0.5, 0.5] |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
- en: 'Let''s now define the previous set of discrete actions in a `DISCRETE_ACTIONS`
    dictionary in our `carla_env` implementation script, shown as follows:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Sending actions to the CARLA simulation server
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have the action space of the CARLA Gym environment defined, we can
    look at how to convert the continuous or discrete actions we have defined into
    values the CARLA simulation server will accept.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we have followed the same convention for two-dimensional bounded action
    values in both the continuous and discrete action spaces, we can simply convert
    the actions into steer, throttle, and brake commands using the following code
    snippet:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: As you can see, this is where `action[0]` is for throttle and brake, and `action[1]`
    is for the steering angle.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: We will make use of the `CarlaClient` class implementation in the CARLA `PythonClient`
    library to handle the communication with the CARLA server. You can look at the
    implementation of the `CarlaClient` class in `ch7/carla-gym/carla_gym/envs/carla/client.py`,
    if you want to understand how communication with the server is handled using protocol
    buffers.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: 'To implement a reward function for the CARLA environment, input the following
    code:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Determining the end of episodes in the CARLA environment
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have implemented `meta hod` to calculate the reward and defined the permitted
    actions, observations, and the reset method for the custom CARLA environment.
    According to our custom Gym environment creation template, those are the required
    methods we need to implement for creating a custom environment that is compatible
    with the OpenAI Gym interface.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: While this is true, there is one more thing we need to take care of so that
    the agent can interact with our environment continuously. Remember when we were
    developing our Q-learning agent in [Chapter 5](part0078.html#2ACBS0-22c7fc7f93b64d07be225c00ead6ce12),
    *Implementing your First Learning Agent – Solving the Mountain Car problem*, for
    the mountain car environment, the environment that always resets itself after
    200 steps? Or in the cart pole environment, where the environment resets itself
    if the pole falls below a certain threshold value? Or how about in Atari games,
    where the environment is reset automatically if an agent loses their final life?
    Yes, we need to look at the routine that determines when to reset the environment,
    which is currently missing in our custom CARLA Gym environment implementation.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: 'While we could pick any criteria to reset the CARLA Gym environment, there
    are three things to consider, as follows:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: When the host or ego car the agent is controlling collides with a car, pedestrian,
    building, or other roadside object, that can be fatal (similar to losing a life
    in Atari games)
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When the host or ego car reaches its destination or end goal
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When a time limit has been exceeded (similar to the 200 time step limit we have
    in the mountain car Gym environment)
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can use these conditions to form the criteria that will determine the end
    of an episode. The pseudo-code to determine the value of the `done` variable that
    `.step(...)` will return is as follows (note that the complete code can be found
    in the book''s code repository in `ch7/carla-gym/carla_gym/envs/`):'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: We have now gone through all the required components for creating our own custom
    Gym-compatible environment based on the CARLA driving simulator! In the next section,
    we will test the environment and finally see it in action.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: Testing the CARLA Gym environment
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To make it easy to test the basics of our environment implementation, we will
    implement a simple `main()` routine so we can run the environment as a script.
    This will show us if the basic interfaces have been set up correctly, as well
    as how the environment actually looks!
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Now, go ahead and test the environment we just created! Keep in mind that CARLA
    requires a GPU to run smoothly, and the system environment `CARLA_SERVER` variable
    to be defined and pointing to the `CarlaUE4.sh` file on your system. Once you
    are ready, you can test the environment we created by running the following command
    inside the `rl_gym_book` conda environment:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The previous command should open a small CARLA simulator window and initialize
    the vehicle for the scenario configuration used in the `carla_env.py` script.
    This should look similar to the following screenshots:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00154.jpeg)  ![](img/00155.jpeg)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
- en: As you can see, by default, the vehicle is scripted to drive straight. Note
    that the `carla_env.py` script will also produce a console output to show the
    current time step in the environment, the calculated instantaneous reward, the
    total reward in the episode, and the value of `done` (True or False),  which is
    all useful for testing our environment. As the vehicle starts moving forward,
    you should see the reward value increasing!
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: 'The console output is as follows:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00156.jpeg)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
- en: So, you now have your custom CARLA Gym environment working! You can create several
    different driving scenarios using the definitions in the `ch7/carla-gym/carla_gym/envs/scenarios.json`
    file. You can then create new custom CARLA environments for each of those scenarios,
    which you can use with the usual `gym.make(...)` command after you have registered
    the custom environment, for example, `gym.make("Carla-v0")` .
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: The code in the book's code repository takes care of the environment registration
    with the OpenAI Gym registry using the method we discussed earlier in this chapter.
    You can now use OpenAI Gym to create an instance of the custom environment we
    built.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the Python commands you can use to test the
    custom Gym environment:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00157.jpeg)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
- en: And that's it! The rest is similar to any other Gym environment.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we went through a custom Gym environment implementation step-by-step,
    starting with a template that laid out the bare-bones structure of an OpenAI Gym
    environment that provided all of the necessary interfaces to the agents. We also
    looked at how to register a custom environment implementation in the Gym registry
    so that we can use the familiar `gym.make(ENV_NAME)` command to create an instance
    of an existing environment. We then looked at how to create a Gym-compatible environment
    implementation for the UnrealEngine based on the open-source driving simulator,
    CARLA. We then quickly walked through the steps required to install and run CARLA
    and then started implementing the `CarlaEnv` class piece-by-piece, carefully covering
    all the important details involved in implementing custom environments compatible
    with OpenAI Gym.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will build an advanced agent from the ground up with
    hands-on examples, before eventually using the custom CARLA environment we created
    in this chapter to train an intelligent agent that can learn to drive the car
    around all by itself!
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
