<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer588">
<h1 class="chapter-number" id="_idParaDest-140"><a id="_idTextAnchor144"/>12</h1>
<h1 id="_idParaDest-141"><a id="_idTextAnchor145"/>Learning from Heterogeneous Graphs</h1>
<p>In the previous chapter, we tried to generate realistic molecules that contain different types of nodes (atoms) and edges (bonds). We also observe this kind of behavior in other applications, such as recommender systems (users and items), social networks (followers and followees), or cybersecurity (routers and servers). We call these kinds of graphs <strong class="bold">heterogeneous</strong>, as opposed to homogeneous graphs, which only involve one type of node and one type <span class="No-Break">of edge.</span></p>
<p>In this chapter, we will recap everything we know about homogeneous GNNs. We will introduce the message passing neural network framework to generalize the architectures we have seen so far. This summary will allow us to understand how to expand our framework to heterogeneous networks. We will start by creating our own heterogeneous dataset. Then, we will transform homogeneous architectures into <span class="No-Break">heterogeneous ones.</span></p>
<p>In the last section, we will take a different approach and discuss an architecture specifically designed to process heterogeneous networks. We will describe how it works to understand better the difference between this architecture and a classic GAT. Finally, we will implement it in PyTorch Geometric and compare our results with the <span class="No-Break">previous techniques.</span></p>
<p>By the end of this chapter, you will have a strong understanding of the differences between homogeneous and heterogeneous graphs. You will be able to create your own heterogeneous datasets and convert traditional models to use them in this context. You will also be able to implement architectures specifically designed to make the most of heterogeneous networks. </p>
<p>In this chapter, we will cover the following <span class="No-Break">main topics:</span></p>
<ul>
<li>The message passing neural <span class="No-Break">network framework</span></li>
<li>Introducing <span class="No-Break">heterogeneous graphs</span></li>
<li>Transforming homogeneous GNNs to <span class="No-Break">heterogeneous GNNs</span></li>
<li>Implementing a hierarchical <span class="No-Break">self-attention network</span></li>
</ul>
<h1 id="_idParaDest-142"><a id="_idTextAnchor146"/>Technical requirements</h1>
<p>All the code examples from this chapter can be found on GitHub <span class="No-Break">at </span><a href="https://github.com/PacktPublishing/Hands-On-Graph-Neural-Networks-Using-Python/tree/main/Chapter12"><span class="No-Break">https://github.com/PacktPublishing/Hands-On-Graph-Neural-Networks-Using-Python/tree/main/Chapter12</span></a><span class="No-Break">.</span></p>
<p>The installation steps required to run the code on your local machine can be found in the <em class="italic">Preface</em> of <span class="No-Break">this book.</span></p>
<h1 id="_idParaDest-143"><a id="_idTextAnchor147"/>The message passing neural network framework</h1>
<p>Before exploring <a id="_idIndexMarker711"/>heterogeneous graphs, let’s recap what we have learned about homogeneous GNNs. In the previous chapters, we saw different functions for aggregating and combining features from different nodes. As seen in <a href="B19153_05.xhtml#_idTextAnchor064"><span class="No-Break"><em class="italic">Chapter 5</em></span></a>, the simplest GNN layer consists of summing the linear combination of features from neighboring nodes (including the target node itself) with a weight matrix. The output of the previous sum then replaces the previous target <span class="No-Break">node embedding.</span></p>
<p>The node-level operator can be written <span class="No-Break">as follows:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer535">
<img alt="" height="133" src="image/Formula_B19153_12_001.jpg" width="336"/>
</div>
</div>
<p><img alt="" height="41" src="image/Formula_B19153_12_002.png" width="52"/> is the set of neighboring nodes of the <img alt="" height="34" src="image/Formula_B19153_12_003.png" width="21"/> node (including itself), <img alt="" height="44" src="image/Formula_B19153_12_004.png" width="36"/> is the embedding of the <img alt="" height="33" src="image/Formula_B19153_12_005.png" width="19"/> node, and <img alt="" height="35" src="image/Formula_B19153_12_006.png" width="44"/> is a <span class="No-Break">weight matrix:</span></p>
<p>GCN and GAT layers added fixed and dynamic weights to node features but kept the same idea. Even GraphSAGE’s LSTM operator or GIN’s max aggregator did not change the main concept of a GNN layer. If we look at all these variants, we can generalize GNN layers into a common framework called the <strong class="bold">Message Passing Neural Network</strong> (<strong class="bold">MPNN</strong> or <strong class="bold">MP-GNN</strong>). Introduced in 2017 by Gilmer et al. [1], this framework consists of three <span class="No-Break">main operations:</span></p>
<ul>
<li><strong class="bold">Message</strong>: Every <a id="_idIndexMarker712"/>node uses a function to create a message for each neighbor. It can simply consist of its own features (as in the previous example) or also consider the neighboring node’s features and <span class="No-Break">edge features.</span></li>
<li><strong class="bold">Aggregate</strong>: Every node aggregates messages from its neighbors using a permutation-equivariant function, such as the sum in the <span class="No-Break">previous example.</span></li>
<li><strong class="bold">Update</strong>: Every node updates its features using a function to combine its current features and the aggregated messages. In the previous example, we introduced a self-loop to aggregate the current features of the <img alt="" height="34" src="image/Formula_B19153_12_007.png" width="19"/> node, such as <span class="No-Break">a neighbor.</span></li>
</ul>
<p>These steps<a id="_idIndexMarker713"/> can be summarized in a <span class="No-Break">single equation:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer542">
<img alt="" height="76" src="image/Formula_B19153_12_008.jpg" width="538"/>
</div>
</div>
<p>Here, <img alt="" height="44" src="image/Formula_B19153_12_009.png" width="37"/> is the node embedding of the <img alt="" height="34" src="image/Formula_B19153_12_010.png" width="19"/> node, <img alt="" height="38" src="image/Formula_B19153_12_011.png" width="48"/> is the edge embedding of the <img alt="" height="37" src="image/Formula_B19153_12_012.png" width="104"/> link, <img alt="" height="42" src="image/Formula_B19153_12_013.png" width="31"/> is the message function, <img alt="" height="41" src="image/Formula_B19153_12_014.png" width="41"/> is the aggregation function, and <img alt="" height="33" src="image/Formula_B19153_12_015.png" width="28"/> is the update function. You can find an illustrated version of this framework in the <span class="No-Break">following figure:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer550">
<img alt="Figure 12.1 – The MPNN framework" height="578" src="image/B19153_12_001.jpg" width="574"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.1 – The MPNN framework</p>
<p>PyTorch Geometric<a id="_idIndexMarker714"/> directly implements this framework with the <strong class="source-inline">MessagePassing</strong> class. For instance, here is how to implement the GCN layer using <span class="No-Break">this class:</span></p>
<ol>
<li value="1">First, we import the <span class="No-Break">required libraries:</span><pre class="source-code">
import torch
from torch.nn import Linear
from torch_geometric.nn import MessagePassing
from torch_geometric.utils import add_self_loops, degree</pre></li>
<li>We declare the GCN class that inherits <span class="No-Break">from </span><span class="No-Break"><strong class="source-inline">MessagePassing</strong></span><span class="No-Break">:</span><pre class="source-code">
class GCNConv(MessagePassing):</pre></li>
<li>This takes two parameters – the input dimensionality and the output (hidden) dimensionality. <strong class="source-inline">MessagePassing</strong> is initialized with the “add” aggregation. We define a single PyTorch linear layer <span class="No-Break">without bias:</span><pre class="source-code">
    def __init__(self, dim_in, dim_h):
        super().__init__(aggr='add')
        self.linear = Linear(dim_in, dim_h, bias=False)</pre></li>
<li>The <strong class="source-inline">forward()</strong> function<a id="_idIndexMarker715"/> contains the logic. First, we add self-loops to the adjacency matrix to consider <span class="No-Break">target nodes:</span><pre class="source-code">
    def forward(self, x, edge_index):
        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))</pre></li>
<li>Then, we apply a linear transformation using the linear layer we <span class="No-Break">previously defined:</span><pre class="source-code">
        x = self.linear(x)</pre></li>
<li>We compute the normalization factor – <img alt="" height="112" src="image/Formula_B19153_12_016.png" width="331"/>:<pre class="source-code">
        row, col = edge_index
        deg = degree(col, x.size(0), dtype=x.dtype)
        deg_inv_sqrt = deg.pow(-0.5)
        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0
        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]</pre></li>
<li>We call the <strong class="source-inline">propagate()</strong> method with our updated <strong class="source-inline">edge_index</strong> (including self-loops) and our normalization factors, stored in the <strong class="source-inline">norm</strong> tensor. Internally, this method calls <strong class="source-inline">message()</strong>, <strong class="source-inline">aggregate()</strong>, and <strong class="source-inline">update()</strong>. We do not need to redefine <strong class="source-inline">update()</strong> because we already included the self-loops. The <strong class="source-inline">aggregate()</strong> function is already specified in <em class="italic">step 3</em> <span class="No-Break">with </span><span class="No-Break"><strong class="source-inline">aggr='add'</strong></span><span class="No-Break">:</span><pre class="source-code">
        out = self.propagate(edge_index, x=x, norm=norm)
        return out</pre></li>
<li>We redefine the <strong class="source-inline">message()</strong> function to normalize the neighboring node features <strong class="source-inline">x</strong> <span class="No-Break">with </span><span class="No-Break"><strong class="source-inline">norm</strong></span><span class="No-Break">:</span><pre class="source-code">
    def message(self, x, norm):
        return norm.view(-1, 1) * x</pre></li>
<li>We can now initialize and use this object as a <span class="No-Break">GCN layer:</span><pre class="source-code">
conv = GCNConv(16, 32)</pre></li>
</ol>
<p>This example shows how you can create your own GNN layers in PyTorch Geometric. You can also read how the GCN or GAT layers are implemented in the <span class="No-Break">source code.</span></p>
<p>The MPNN <a id="_idIndexMarker716"/>framework is an important concept that will help us to transform our GNNs into <span class="No-Break">heterogeneous models.</span></p>
<h1 id="_idParaDest-144"><a id="_idTextAnchor148"/>Introducing heterogeneous graphs</h1>
<p>Heterogeneous<a id="_idIndexMarker717"/> graphs are a powerful tool to represent general relationships between different entities. Having different types of nodes and edges creates graph structures that are more complex but also more difficult to learn. In particular, one of the main problems with heterogeneous networks is that features from different types of nodes or edges do not necessarily have the same meaning or dimensionality. Therefore, merging different features would destroy a lot of information. This is not the case with homogeneous graphs, where each dimension has the exact same meaning for every node <span class="No-Break">or edge.</span></p>
<p>Heterogeneous graphs are a more general kind of network that can represent different types of nodes and edges. Formally, it is defined as a graph, <img alt="" height="43" src="image/Formula_B19153_12_017.png" width="186"/>, comprising <img alt="" height="32" src="image/Formula_B19153_12_018.png" width="29"/>, a set of nodes, and <img alt="" height="34" src="image/Formula_B19153_12_019.png" width="32"/>, a set of edges. In the heterogeneous setting, it is associated with a node-type mapping function, <img alt="" height="41" src="image/Formula_B19153_12_020.png" width="172"/> (where <img alt="" height="34" src="image/Formula_B19153_12_021.png" width="29"/> denotes the set of node types), and a link-type mapping<a id="_idIndexMarker718"/> function, <img alt="" height="41" src="image/Formula_B19153_12_022.png" width="168"/> (where <img alt="" height="34" src="image/Formula_B19153_12_023.png" width="30"/> denotes the set of <span class="No-Break">edge types).</span></p>
<p>The following figure is an example of a <span class="No-Break">heterogeneous graph.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer559">
<img alt="Figure 12.2 – An example of a heteregeneous graph with three types of nodes and three types of edges" height="665" src="image/B19153_12_002.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.2 – An example of a heteregeneous graph with three types of nodes and three types of edges</p>
<p>In this graph, we see three types of nodes (users, games, and developers) and three types of edges (<strong class="bold">follows</strong>, <strong class="bold">plays</strong>, and <strong class="bold">develops</strong>). It represents a network involving people (users and developers) and games that could be used for various applications, such as recommending games. If this graph contained millions of elements, it could be used as a graph-structured knowledge database, or a knowledge graph. Knowledge graphs are used by Google <a id="_idIndexMarker719"/>or Bing to answer queries such as, “Who plays games developed by <span class="No-Break"><strong class="bold">Dev 1</strong></span><span class="No-Break">?”</span></p>
<p>Similar queries can extract useful homogeneous graphs. For example, we might want only to consider users who play <strong class="bold">Game 1</strong>. The output would be <strong class="bold">User 1</strong> and <strong class="bold">User 2</strong>. We can create more complex queries, such as, “Who are the users who play games developed by <strong class="bold">Dev 1</strong>?” The result is the same, but we traversed two relations to obtain our users. This kind of query is called <span class="No-Break">a meta-path.</span></p>
<p>In the first example, our meta-path was <em class="italic">User → Game → User</em> (commonly denoted as <strong class="bold">UGU</strong>), and in <a id="_idIndexMarker720"/>the second one, our meta-path was <em class="italic">User → Game → Dev → Game → User</em> (or <strong class="bold">UGDGU</strong>). Note<a id="_idIndexMarker721"/> that the start node type and the end node type are the same. Meta-paths are an essential concept in heterogeneous graphs, often used to measure the similarity of <span class="No-Break">different nodes.</span></p>
<p>Now, let’s see how to implement the previous graph with PyTorch Geometric. We will use a special data object called <strong class="source-inline">HeteroData</strong>. The following steps create a data object to store the graph from <span class="No-Break"><em class="italic">Figure 12</em></span><span class="No-Break"><em class="italic">.2</em></span><span class="No-Break">:</span></p>
<ol>
<li value="1">We import the <strong class="source-inline">HeteroData</strong> class from <strong class="source-inline">torch_geometric.data</strong> and create a <span class="No-Break"><strong class="source-inline">data</strong></span><span class="No-Break"> variable:</span><pre class="source-code">
from torch_geometric.data import HeteroData
data = HeteroData()</pre></li>
<li>First, let’s store node features. We can access user features with <strong class="source-inline">data['user'].x</strong>, for instance. We feed it a tensor with the <strong class="source-inline">[num_users, num_features_users]</strong> dimensions. The content does not matter in this example, so we will create feature vectors filled with ones for <strong class="source-inline">user 1</strong>, twos for <strong class="source-inline">user 2</strong>, and threes for <span class="No-Break"><strong class="source-inline">user 3</strong></span><span class="No-Break">:</span><pre class="source-code">
data['user'].x = torch.Tensor([[1, 1, 1, 1], [2, 2, 2, 2], [3, 3, 3, 3]])</pre></li>
<li>We repeat this process with <strong class="source-inline">games</strong> and <strong class="source-inline">devs</strong>. Note that the dimensionality of feature vectors is not the same; this is an important benefit of heterogeneous graphs when<a id="_idIndexMarker722"/> handling <span class="No-Break">different representations:</span><pre class="source-code">
data['game'].x = torch.Tensor([[1, 1], [2, 2]])
data['dev'].x = torch.Tensor([[1], [2]])</pre></li>
<li>Let’s create connections between our nodes. Links have different meanings, which is why we will create three sets of edge indices. We can declare each set using a triplet <img alt="" height="54" src="image/Formula_B19153_12_024.png" width="926"/>, such as <strong class="source-inline">data['user', 'follows', 'user'].edge_index</strong>. Then, we store the connections in a tensor with the <strong class="source-inline">[2, number of </strong><span class="No-Break"><strong class="source-inline">edges]</strong></span><span class="No-Break"> dimensions:</span><pre class="source-code">
data['user', 'follows', 'user'].edge_index = torch.Tensor([[0, 1], [1, 2]]) # [2, num_edges_follows]
data['user', 'plays', 'game'].edge_index = torch.Tensor([[0, 1, 1, 2], [0, 0, 1, 1]])
data['dev', 'develops', 'game'].edge_index = torch.Tensor([[0, 1], [0, 1]])</pre></li>
<li>Edges can also have features – for example, the <strong class="source-inline">plays</strong> edges could include the number of hours the user played the corresponding game. In the following, we assume that <strong class="source-inline">user 1</strong> played <strong class="source-inline">game 1</strong> for 2 hours, <strong class="source-inline">user 2</strong> played <strong class="source-inline">game 1</strong> for half an hour and <strong class="source-inline">game 2</strong> for 10 hours, and <strong class="source-inline">user 3</strong> played <strong class="source-inline">game 2</strong> for <span class="No-Break">12 hours:</span><pre class="source-code">
data['user', 'plays', 'game'].edge_attr = torch.Tensor([[2], [0.5], [10], [12]])</pre></li>
<li>Finally, we <a id="_idIndexMarker723"/>can print the <strong class="source-inline">data</strong> object to see <span class="No-Break">the result:</span><pre class="source-code">
<strong class="bold">HeteroData(</strong>
<strong class="bold">  user={ x=[3, 4] },</strong>
<strong class="bold">  game={ x=[2, 2] },</strong>
<strong class="bold">  dev={ x=[2, 1] },</strong>
<strong class="bold">  (user, follows, user)={ edge_index=[2, 2] },</strong>
<strong class="bold">  (user, plays, game)={</strong>
<strong class="bold">    edge_index=[2, 4],</strong>
<strong class="bold">    edge_attr=[4, 1]</strong>
<strong class="bold">  },</strong>
<strong class="bold">  (dev, develops, game)={ edge_index=[2, 2] }</strong>
<strong class="bold">)</strong></pre></li>
</ol>
<p>As you can see in this implementation, different types of nodes and edges do not share the same tensors. In fact, it is impossible because they don’t share the same dimensionality either. This raises a new issue – how do we aggregate information from multiple tensors <span class="No-Break">using GNNs?</span></p>
<p>So far, we have only focused our efforts on a single type. In practice, our weight matrices have the<a id="_idIndexMarker724"/> right size to be multiplied with a predefined dimension. However, how do we implement GNNs when we get inputs with <span class="No-Break">different dimensionalities?</span></p>
<h1 id="_idParaDest-145"><a id="_idTextAnchor149"/>Transforming homogeneous GNNs to heterogeneous GNNs</h1>
<p>To better <a id="_idIndexMarker725"/>understand the problem, let’s take a real dataset as an example. The DBLP computer science bibliography offers a dataset, <strong class="source-inline">[2-3]</strong>, that contains four types of nodes – <strong class="source-inline">papers</strong> (14,328), <strong class="source-inline">terms</strong> (7,723), <strong class="source-inline">authors</strong> (4,057), and <strong class="source-inline">conferences</strong> (20). This dataset’s goal is to correctly classify the authors into four categories – database, data mining, artificial intelligence, and information retrieval. The authors’ node features are a bag-of-words (“<strong class="source-inline">0</strong>” or “<strong class="source-inline">1</strong>”) of 334 keywords they might have used in their publications. The following figure summarizes the relations between the different <span class="No-Break">node types.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer561">
<img alt="Figure 12.3 – Relationships between node types in the DBLP dataset" height="752" src="image/B19153_12_003.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.3 – Relationships between node types in the DBLP dataset</p>
<p>These node types do not have the same dimensionalities and semantic relationships. In heterogeneous graphs, relations between nodes are essential, which is why we want to consider node pairs. For example, instead of feeding author nodes to a GNN layer, we would consider a pair such as (<strong class="source-inline">author</strong>, <strong class="source-inline">paper</strong>). It means we now need a GNN layer per relation; in this case, the “to” relations are bidirectional, so we would get <span class="No-Break">six layers.</span></p>
<p>These new layers have independent weight matrices with the right size for each node type. Unfortunately, we have only solved half of the problem. Indeed, we now have six distinct layers <a id="_idIndexMarker726"/>that do <a id="_idIndexMarker727"/>not share any information. We can fix that <a id="_idIndexMarker728"/>by introducing <strong class="bold">skip-connections</strong>, <strong class="bold">shared layers</strong>, <strong class="bold">jumping knowledge</strong>, and so <span class="No-Break">on [4].</span></p>
<p>Before we transform a homogeneous model into a heterogeneous one, let’s implement a classic GAT on the DBLP dataset. The GAT cannot take into account different relations; we have to give it a unique adjacency matrix that connects authors to each other. Fortunately, we now <a id="_idIndexMarker729"/>have a technique to generate this adjacency matrix easily – we can create a meta-path, such as <strong class="source-inline">author-paper-author</strong>, that will connect authors from the <span class="No-Break">same papers.</span></p>
<p class="callout-heading">Note</p>
<p class="callout">We can also build a good adjacency matrix through random walks. Even if the graph is heterogeneous, we can explore it and connect nodes that often appear in the <span class="No-Break">same sequences.</span></p>
<p>The code is a little more verbose, but we can implement a regular GAT <span class="No-Break">as follows:</span></p>
<ol>
<li value="1">We import the <span class="No-Break">required libraries:</span><pre class="source-code">
from torch import nn
import torch.nn.functional as F
import torch_geometric.transforms as T
from torch_geometric.datasets import DBLP
from torch_geometric.nn import GAT</pre></li>
<li>We define the meta-path we will use using this <span class="No-Break">specific syntax:</span><pre class="source-code">
metapaths = [[('author', 'paper'), ('paper', 'author')]]</pre></li>
<li>We use the <strong class="source-inline">AddMetaPaths</strong> transform function to automatically calculate our meta-path. We use <strong class="source-inline">drop_orig_edge_types=True</strong> to remove the other relations from the dataset (the GAT can only <span class="No-Break">consider one):</span><pre class="source-code">
transform = T.AddMetaPaths(metapaths=metapaths, drop_orig_edge_types=True)</pre></li>
<li>We load the <strong class="source-inline">DBLP</strong> dataset and <span class="No-Break">print it:</span><pre class="source-code">
dataset = DBLP('.', transform=transform)
data = dataset[0]
print(data)</pre></li>
<li>We obtain the <a id="_idIndexMarker730"/>following output. Note the <strong class="source-inline">(author, metapath_0, author)</strong> relation that was created with our <span class="No-Break">transform function:</span><pre class="source-code">
<strong class="bold">HeteroData(</strong>
<strong class="bold">  metapath_dict={ (author, metapath_0, author)=[2] },</strong>
<strong class="bold">  author={</strong>
<strong class="bold">    x=[4057, 334],</strong>
<strong class="bold">    y=[4057],</strong>
<strong class="bold">    train_mask=[4057],</strong>
<strong class="bold">    val_mask=[4057],</strong>
<strong class="bold">    test_mask=[4057]</strong>
<strong class="bold">  },</strong>
<strong class="bold">  paper={ x=[14328, 4231] },</strong>
<strong class="bold">  term={ x=[7723, 50] },</strong>
<strong class="bold">  conference={ num_nodes=20 },</strong>
<strong class="bold">  (author, metapath_0, author)={ edge_index=[2, 11113] }</strong>
<strong class="bold">)</strong></pre></li>
<li>We directly create a one-layer GAT model with <strong class="source-inline">in_channels=-1</strong> to perform lazy initialization (the model will automatically calculate the value) and <strong class="source-inline">out_channels=4</strong> because we need to classify the author nodes into <span class="No-Break">four categories:</span><pre class="source-code">
model = GAT(in_channels=-1, hidden_channels=64, out_channels=4, num_layers=1)</pre></li>
<li>We implement the <strong class="source-inline">Adam</strong> optimizer and store the model and the data on a GPU <span class="No-Break">if possible:</span><pre class="source-code">
optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
data, model = data.to(device), model.to(device)</pre></li>
<li>The <strong class="source-inline">test()</strong> function <a id="_idIndexMarker731"/>measures the accuracy of <span class="No-Break">the prediction:</span><pre class="source-code">
@torch.no_grad()
def test(mask):
    model.eval()
    pred = model(data.x_dict['author'], data.edge_index_dict[('author', 'metapath_0', 'author')]).argmax(dim=-1)
    acc = (pred[mask] == data['author'].y[mask]).sum() / mask.sum()
    return float(acc)</pre></li>
<li>We create a classic training loop, where the node features (<strong class="source-inline">author</strong>) and edge indexes (<strong class="source-inline">author</strong>, <strong class="source-inline">metapath_0</strong>, and <strong class="source-inline">author</strong>) are <span class="No-Break">carefully selected:</span><pre class="source-code">
for epoch in range(101):
    model.train()
    optimizer.zero_grad()
    out = model(data.x_dict['author'], data.edge_index_dict[('author', 'metapath_0', 'author')])
    mask = data['author'].train_mask
    loss = F.cross_entropy(out[mask], data['author'].y[mask])
    loss.backward()
    optimizer.step()
    if epoch % 20 == 0:
        train_acc = test(data['author'].train_mask)
        val_acc = test(data['author'].val_mask)
        print(f'Epoch: {epoch:&gt;3} | Train Loss: {loss:.4f} | Train Acc: {train_acc*100:.2f}% | Val Acc: {val_acc*100:.2f}%')</pre></li>
<li>We test it on <a id="_idIndexMarker732"/>the test set with the <span class="No-Break">following output:</span><pre class="source-code">
test_acc = test(data['author'].test_mask)
print(f'Test accuracy: {test_acc*100:.2f}%')
<strong class="bold">Test accuracy: 73.29%</strong></pre></li>
</ol>
<p>We reduced our heterogeneous dataset into a homogeneous one using a meta-path and applied a traditional GAT. We obtained a test accuracy of 73.29%, which provides a good baseline to compare it to <span class="No-Break">other techniques.</span></p>
<p>Now, let’s create a heterogeneous version of this GAT model. Following the method we described previously, we need six GAT layers instead of one. We don’t have to do it manually, since PyTorch Geometric can do it automatically using the <strong class="source-inline">to_hetero()</strong> or <strong class="source-inline">to_hetero_bases()</strong> functions. The <strong class="source-inline">to_hetero()</strong> function takes three <span class="No-Break">important parameters:</span></p>
<ul>
<li><strong class="source-inline">module</strong>: The homogeneous model we want <span class="No-Break">to convert</span></li>
<li><strong class="source-inline">metadata</strong>: Information about the heterogeneous nature of the graph, represented by a tuple, <strong class="source-inline">(</strong><span class="No-Break"><strong class="source-inline">node_types, edge_types)</strong></span></li>
<li><strong class="source-inline">aggr</strong>: The aggregator to combine node embeddings generated by different relations (for instance, <strong class="source-inline">sum</strong>, <strong class="source-inline">max</strong>, <span class="No-Break">or </span><span class="No-Break"><strong class="source-inline">mean</strong></span><span class="No-Break">)</span></li>
</ul>
<p>The following figure shows our homogeneous GAT (left) and its heterogeneous version (right), obtained<a id="_idIndexMarker733"/> <span class="No-Break">with </span><span class="No-Break"><strong class="source-inline">to_hetero()</strong></span><span class="No-Break">.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer562">
<img alt="Figure 12.4 – Architecture of a homogeneous GAT (left) and a heterogeneous GAT (right) on the DBLP dataset" height="868" src="image/B19153_12_004.jpg" width="1637"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.4 – Architecture of a homogeneous GAT (left) and a heterogeneous GAT (right) on the DBLP dataset</p>
<p>As shown in the following steps, the heterogeneous GAT’s implementation <span class="No-Break">is similar:</span></p>
<ol>
<li value="1">First, we import GNN layers from <span class="No-Break">PyTorch Geometric:</span><pre class="source-code">
from torch_geometric.nn import GATConv, Linear, to_hetero</pre></li>
<li>We load the <span class="No-Break"><strong class="source-inline">DBLP</strong></span><span class="No-Break"> dataset:</span><pre class="source-code">
dataset = DBLP(root='.')
data = dataset[0]</pre></li>
<li>When we printed information about this dataset, you might have noticed that conference nodes do not have any features. This is an issue because our architecture assumes that each node type has its own features. We can fix this problem by generating zero values as features, <span class="No-Break">as follows:</span><pre class="source-code">
data['conference'].x = torch.zeros(20, 1)</pre></li>
<li>We create our own GAT class with a GAT and linear layers. Note that we use lazy initialization <a id="_idIndexMarker734"/>again with the <strong class="source-inline">(-1, -</strong><span class="No-Break"><strong class="source-inline">1)</strong></span><span class="No-Break"> tuple:</span><pre class="source-code">
class GAT(torch.nn.Module):
    def __init__(self, dim_h, dim_out):
        super().__init__()
        self.conv = GATConv((-1, -1), dim_h, add_self_loops=False)
        self.linear = nn.Linear(dim_h, dim_out)
    def forward(self, x, edge_index):
        h = self.conv(x, edge_index).relu()
        h = self.linear(h)
        return h</pre></li>
<li>We <strong class="source-inline">instantiate</strong> the model and convert it <span class="No-Break">using </span><span class="No-Break"><strong class="source-inline">to_hetero()</strong></span><span class="No-Break">:</span><pre class="source-code">
model = GAT(dim_h=64, dim_out=4)
model = to_hetero(model, data.metadata(), aggr='sum')</pre></li>
<li>We implement the <strong class="source-inline">Adam</strong> optimizer and store the model and data on a GPU <span class="No-Break">if possible:</span><pre class="source-code">
optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
data, model = data.to(device), model.to(device)</pre></li>
<li>The test process is very similar. This time, we don’t need to specify any relation, since the model considers all <span class="No-Break">of them:</span><pre class="source-code">
@torch.no_grad()
def test(mask):
    model.eval()
    pred = model(data.x_dict, data.edge_index_dict)['author'].argmax(dim=-1)
    acc = (pred[mask] == data['author'].y[mask]).sum() / mask.sum()
    return float(acc)</pre></li>
<li>The same<a id="_idIndexMarker735"/> is true for the <span class="No-Break">training loop:</span><pre class="source-code">
for epoch in range(101):
    model.train()
    optimizer.zero_grad()
    out = model(data.x_dict, data.edge_index_dict)['author']
    mask = data['author'].train_mask
    loss = F.cross_entropy(out[mask], data['author'].y[mask])
    loss.backward()
    optimizer.step()
    if epoch % 20 == 0:
        train_acc = test(data['author'].train_mask)
        val_acc = test(data['author'].val_mask)
        print(f'Epoch: {epoch:&gt;3} | Train Loss: {loss:.4f} | Train Acc: {train_acc*100:.2f}% | Val Acc: {val_acc*100:.2f}%')</pre></li>
<li>We obtain the following <span class="No-Break">test accuracy:</span><pre class="source-code">
<strong class="bold">test_acc = test(data['author'].test_mask)</strong>
<strong class="bold">print(f'Test accuracy: {test_acc*100:.2f}%')</strong>
<strong class="bold">Test accuracy: 78.42%</strong></pre></li>
</ol>
<p>The heterogeneous GAT obtains a test accuracy of 78.42%. This is a good improvement (+5.13%) over the<a id="_idIndexMarker736"/> homogeneous version, but can we do better? In the next section, we will explore an architecture that is specifically designed to process <span class="No-Break">heterogeneous networks.</span></p>
<h1 id="_idParaDest-146"><a id="_idTextAnchor150"/>Implementing a hierarchical self-attention network</h1>
<p>In this section, we <a id="_idIndexMarker737"/>will implement a GNN model designed to handle heterogeneous graphs – the <strong class="bold">hierarchical self-attention network</strong> (<strong class="bold">HAN</strong>). This architecture was introduced by Liu et al. in 2021 [5]. HAN uses self-attention at two <span class="No-Break">different levels:</span></p>
<ul>
<li><strong class="bold">Node-level attention</strong> to<a id="_idIndexMarker738"/> understand<a id="_idIndexMarker739"/> the importance of neighboring nodes in a given meta-path (such as a GAT in a <span class="No-Break">homogeneous setting).</span></li>
<li><strong class="bold">Semantic-level attention</strong> to learn the importance of each meta-path. This is the main feature <a id="_idIndexMarker740"/>of HAN, allowing us to select the best meta-paths for a given task automatically – for example, the meta-path <strong class="source-inline">game-user-game</strong> might be more relevant than <strong class="source-inline">game-dev-game</strong> in some tasks, such as predicting the number <span class="No-Break">of players.</span></li>
</ul>
<p>In the following section, we will detail the three main components – node-level attention, semantic-level attention, and the prediction module. This architecture is illustrated in <span class="No-Break"><em class="italic">Figure 12</em></span><span class="No-Break"><em class="italic">.5</em></span><span class="No-Break">.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer563">
<img alt="Figure 12.5 – HAN’s architecture with its three main modules" height="842" src="image/B19153_12_005.jpg" width="1448"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.5 – HAN’s architecture with its three main modules</p>
<p>Like in a GAT, the first step consists of projecting nodes into a unified feature space for each meta-path. We<a id="_idIndexMarker741"/> then calculate the weight of a node pair (concatenation of two projected nodes) in the same meta-path, with a second weight matrix. A nonlinear function is applied to this result, which is then normalized with the softmax function. The normalized attention score (importance) of the <img alt="" height="43" src="image/Formula_B19153_12_025.png" width="23"/> node to the <img alt="" height="33" src="image/Formula_B19153_12_026.png" width="17"/> node is calculated <span class="No-Break">as follows:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer566">
<img alt="" height="173" src="image/Formula_B19153_12_027.jpg" width="839"/>
</div>
</div>
<p>Here, <img alt="" height="43" src="image/Formula_B19153_12_028.png" width="36"/> denotes the features of the <img alt="" height="34" src="image/Formula_B19153_12_029.png" width="19"/> node, <img alt="" height="43" src="image/Formula_B19153_12_030.png" width="61"/> is a shared weight matrix for the <img alt="" height="33" src="image/Formula_B19153_12_031.png" width="34"/> meta-path, <img alt="" height="33" src="image/Formula_B19153_12_032.png" width="50"/> is the attention weight matrix for the <img alt="" height="33" src="image/Formula_B19153_12_033.png" width="35"/> meta-path, <img alt="" height="25" src="image/Formula_B19153_12_034.png" width="26"/> is a nonlinear activation function (such as LeakyReLU), and <img alt="" height="54" src="image/Formula_B19153_12_035.png" width="74"/> is the set of neighbors of the <img alt="" height="34" src="image/Formula_B19153_12_036.png" width="16"/> node (including itself) in the <img alt="" height="33" src="image/Formula_B19153_12_031.png" width="34"/> <span class="No-Break">meta-path.</span></p>
<p>Multi-head <a id="_idIndexMarker742"/>attention is also performed to obtain the <span class="No-Break">final embedding:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer577">
<img alt="" height="211" src="image/Formula_B19153_12_038.jpg" width="698"/>
</div>
</div>
<p>With semantic-level attention, we repeat a similar process for the attention score of every meta-path (denoted <img alt="" height="55" src="image/Formula_B19153_12_039.png" width="300"/>). Every node embedding in a given meta-path (denoted as <img alt="" height="54" src="image/Formula_B19153_12_040.png" width="70"/>) is fed to an MLP that applies a nonlinear transformation. We compare this result to a new attention vector, <img alt="" height="33" src="image/Formula_B19153_12_041.png" width="23"/>, as a similarity measure. We average this result to calculate the importance of a <span class="No-Break">given meta-path:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer581">
<img alt="" height="166" src="image/Formula_B19153_12_042.jpg" width="926"/>
</div>
</div>
<p>Here, <img alt="" height="32" src="image/Formula_B19153_12_043.png" width="41"/> (the MLP’s weight matrix), <img alt="" height="33" src="image/Formula_B19153_12_044.png" width="22"/> (the MLP’s bias), and <img alt="" height="32" src="image/Formula_B19153_12_045.png" width="24"/> (the semantic-level attention vector) are shared across <span class="No-Break">the meta-paths.</span></p>
<p>We must <a id="_idIndexMarker743"/>normalize this result to compare the different semantic-level attention scores. We use the softmax function to obtain our <span class="No-Break">final weights:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer585">
<img alt="" height="188" src="image/Formula_B19153_12_046.jpg" width="554"/>
</div>
</div>
<p>The final embedding, <img alt="" height="34" src="image/Formula_B19153_12_047.png" width="30"/>, that combines node-level and semantic-level attention is obtained <span class="No-Break">as follows:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer587">
<img alt="" height="202" src="image/Formula_B19153_12_048.jpg" width="471"/>
</div>
</div>
<p>A final layer, like an MLP, is used to fine-tune the model for a particular downstream task, such as node classification or <span class="No-Break">link prediction.</span></p>
<p>Let’s implement this architecture in PyTorch Geometric on the <span class="No-Break"><strong class="source-inline">DBLP</strong></span><span class="No-Break"> dataset:</span></p>
<ol>
<li>First, we import the <span class="No-Break">HAN layer:</span><pre class="source-code">
from torch_geometric.nn import HANConv</pre></li>
<li>We load the <strong class="source-inline">DBLP</strong> dataset and introduce dummy features for <span class="No-Break">conference nodes:</span><pre class="source-code">
dataset = DBLP('.')
data = dataset[0]
data['conference'].x = torch.zeros(20, 1)</pre></li>
<li>We create<a id="_idIndexMarker744"/> the <strong class="source-inline">HAN</strong> class with two layers – a <strong class="source-inline">HAN</strong> convolution using <strong class="source-inline">HANConv</strong> and a <strong class="source-inline">linear</strong> layer for the <span class="No-Break">final classification:</span><pre class="source-code">
class HAN(nn.Module):
    def __init__(self, dim_in, dim_out, dim_h=128, heads=8):
        super().__init__()
        self.han = HANConv(dim_in, dim_h, heads=heads, dropout=0.6, metadata=data.metadata())
        self.linear = nn.Linear(dim_h, dim_out)</pre></li>
<li>In the <strong class="source-inline">forward()</strong> function, we have to specify that we are interested in <span class="No-Break">the authors:</span><pre class="source-code">
    def forward(self, x_dict, edge_index_dict):
        out = self.han(x_dict, edge_index_dict)
        out = self.linear(out['author'])
        return out</pre></li>
<li>We initialize our model with lazy initialization (<strong class="source-inline">dim_in=-1</strong>), so PyTorch Geometric automatically calculates the input size for each <span class="No-Break">node type:</span><pre class="source-code">
model = HAN(dim_in=-1, dim_out=4)</pre></li>
<li>We choose the <strong class="source-inline">Adam</strong> optimizer and transfer our data and model to the GPU <span class="No-Break">if possible:</span><pre class="source-code">
optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
data, model = data.to(device), model.to(device)</pre></li>
<li>The <strong class="source-inline">test()</strong> function <a id="_idIndexMarker745"/>calculates the accuracy of the <span class="No-Break">classification task:</span><pre class="source-code">
@torch.no_grad()
def test(mask):
    model.eval()
    pred = model(data.x_dict, data.edge_index_dict).argmax(dim=-1)
    acc = (pred[mask] == data['author'].y[mask]).sum() / mask.sum()
    return float(acc)</pre></li>
<li>We train the model for 100 epochs. The only difference with a training loop for a homogeneous GNN is that we need to specify we’re interested in the author <span class="No-Break">node type:</span><pre class="source-code">
for epoch in range(101):
    model.train()
    optimizer.zero_grad()
    out = model(data.x_dict, data.edge_index_dict)
    mask = data['author'].train_mask
    loss = F.cross_entropy(out[mask], data['author'].y[mask])
    loss.backward()
    optimizer.step()
    if epoch % 20 == 0:
        train_acc = test(data['author'].train_mask)
        val_acc = test(data['author'].val_mask)
        print(f'Epoch: {epoch:&gt;3} | Train Loss: {loss:.4f} | Train Acc: {train_acc*100:.2f}% | Val Acc: {val_acc*100:.2f}%')</pre></li>
<li>The training <a id="_idIndexMarker746"/>gives us the <span class="No-Break">following output:</span><pre class="source-code">
<strong class="bold">Epoch:   0 | Train Loss: 1.3829 | Train Acc: 49.75% | Val Acc: 37.75%</strong>
<strong class="bold">Epoch:  20 | Train Loss: 1.1551 | Train Acc: 86.50% | Val Acc: 60.75%</strong>
<strong class="bold">Epoch:  40 | Train Loss: 0.7695 | Train Acc: 94.00% | Val Acc: 67.50%</strong>
<strong class="bold">Epoch:  60 | Train Loss: 0.4750 | Train Acc: 97.75% | Val Acc: 73.75%</strong>
<strong class="bold">Epoch:  80 | Train Loss: 0.3008 | Train Acc: 99.25% | Val Acc: 78.25%</strong>
<strong class="bold">Epoch: 100 | Train Loss: 0.2247 | Train Acc: 99.50% | Val Acc: 78.75%</strong></pre></li>
<li>Finally, we test our solution on the <span class="No-Break">test set:</span><pre class="source-code">
test_acc = test(data['author'].test_mask)
print(f'Test accuracy: {test_acc*100:.2f}%')
<strong class="bold">Test accuracy: 81.58%</strong></pre></li>
</ol>
<p>HAN obtains a test accuracy of 81.58%, which is higher than what we got with the heterogeneous GAT (78.42%) and the classic GAT (73.29%). It shows the importance of building good representations that aggregate different types of nodes and relations. Heterogeneous <a id="_idIndexMarker747"/>graphs’ techniques are highly application-dependent, but it is worth trying different options, especially when the relationships described in the network <span class="No-Break">are meaningful.</span></p>
<h1 id="_idParaDest-147"><a id="_idTextAnchor151"/>Summary</h1>
<p>In this chapter, we introduced the MPNN framework to generalize GNN layers using three steps – message, aggregate, and update. In the rest of the chapter, we expanded this framework to consider heterogeneous networks, composed of different types of nodes and edges. This particular kind of graph allows us to represent various relations between entities, which are more insightful than a single type <span class="No-Break">of connection.</span></p>
<p>Moreover, we saw how to transform homogeneous GNNs into heterogeneous ones thanks to PyTorch Geometric. We described the different layers in our heterogeneous GAT, which take node pairs as inputs to model their relations. Finally, we implemented a heterogeneous-specific architecture with <strong class="source-inline">HAN</strong> and compared the results of three techniques on the <strong class="source-inline">DBLP</strong> dataset. It proved the importance of exploiting the heterogeneous information that is represented in this kind <span class="No-Break">of network.</span></p>
<p>In <a href="B19153_13.xhtml#_idTextAnchor153"><span class="No-Break"><em class="italic">Chapter 13</em></span></a>, <em class="italic">Temporal Graph Neural Networks</em>, we will see how to consider time in GNNs. This chapter will unlock a lot of new applications thanks to temporal graphs, such as traffic forecasting. It will also introduce PyG’s extension library called PyTorch Geometric Temporal, which will help us to implement new models specifically designed to <span class="No-Break">handle time.</span></p>
<h1 id="_idParaDest-148"><a id="_idTextAnchor152"/>Further reading</h1>
<ul>
<li>[1] J. Gilmer, S. S. Schoenholz, P. F. Riley, O. Vinyals, and G. E. Dahl. <em class="italic">Neural Message Passing for Quantum Chemistry</em>. arXiv, 2017. DOI: 10.48550/ARXIV.1704.01212. <span class="No-Break">Available: </span><a href="https://arxiv.org/abs/1704.01212"><span class="No-Break">https://arxiv.org/abs/1704.01212</span></a><span class="No-Break">.</span></li>
<li>[2] Jie Tang, Jing Zhang, Limin Yao, Juanzi Li, Li Zhang, and Zhong Su. <em class="italic">ArnetMiner: Extraction and Mining of Academic Social Networks</em>. In Proceedings of the Fourteenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (SIGKDD’2008). pp.990–998. <span class="No-Break">Available: </span><a href="https://dl.acm.org/doi/abs/10.1145/1401890.1402008"><span class="No-Break">https://dl.acm.org/doi/abs/10.1145/1401890.1402008</span></a><span class="No-Break">.</span></li>
<li>[3] X. Fu, J. Zhang, Z. Meng, and I. King. <em class="italic">MAGNN: Metapath Aggregated Graph Neural Network for Heterogeneous Graph Embedding</em>. Apr. 2020. DOI: 10.1145/3366423.3380297. <span class="No-Break">Available: </span><a href="https://arxiv.org/abs/2002.01680"><span class="No-Break">https://arxiv.org/abs/2002.01680</span></a><span class="No-Break">.</span></li>
<li>[4] M. Schlichtkrull, T. N. Kipf, P. Bloem, R. van den Berg, I. Titov, and M. Welling. <em class="italic">Modeling Relational Data with Graph Convolutional Networks</em>. arXiv, 2017. DOI: 10.48550/ARXIV.1703.06103. <span class="No-Break">Available: </span><a href="https://arxiv.org/abs/1703.06103"><span class="No-Break">https://arxiv.org/abs/1703.06103</span></a><span class="No-Break">.</span></li>
<li>[5] J. Liu, Y. Wang, S. Xiang, and C. Pan. <em class="italic">HAN: An Efficient Hierarchical Self-Attention Network for Skeleton-Based Gesture Recognition</em>. arXiv, 2021. DOI: 10.48550/ARXIV.2106.13391. <span class="No-Break">Available: </span><a href="https://arxiv.org/abs/2106.13391"><span class="No-Break">https://arxiv.org/abs/2106.13391</span></a><span class="No-Break">.</span></li>
</ul>
</div>
</div></body></html>