- en: Parameter Inference Using the Bayesian Approach
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用贝叶斯方法进行参数推断
- en: 'In the previous chapter, we discussed inferring the parameters using the maximum-likelihood
    approach. In this chapter, we will explore the same issue through a Bayesian approach.
    The main topics are as follows:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们讨论了使用最大似然法推断参数。在本章中，我们将通过贝叶斯方法探讨相同的问题。主要内容如下：
- en: Introduction to Bayesian learning
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 贝叶斯学习简介
- en: Bayesian learning in HMMs
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 隐马尔可夫模型中的贝叶斯学习
- en: Approximate algorithms for estimating distributions
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于估计分布的近似算法
- en: Bayesian learning
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 贝叶斯学习
- en: 'In the maximum-likelihood approach to learning, we try to find the most optimal
    parameters for our model that maximizes our likelihood function. But data in real
    life is usually really noisy, and in most cases, it doesn''t represent the true
    underlying distribution. In such cases, the maximum-likelihood approach fails.
    For example, consider tossing a fair coin a few times. It is possible that all
    of our tosses result in either heads or tails. If we use a maximum-likelihood
    approach on this data, it will assign a probability of 1 to either heads or tails,
    which would suggest that we would never get the other side of the coin. Or, let''s
    take a less extreme case: let''s say we toss a coin 10 times and get three heads
    and seven tails. In this case, a maximum-likelihood approach will assign a probability
    of 0.3 to heads and 0.7 to tails, which is not the true distribution of a fair
    coin. This problem is also commonly known as **overfitting**.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在最大似然学习方法中，我们试图找到使得似然函数最大化的最优参数。但现实中的数据通常是非常嘈杂的，并且在大多数情况下，它并不能代表真实的底层分布。在这种情况下，最大似然方法会失败。例如，考虑投掷一枚公平的硬币几次。可能我们的所有投掷结果都是正面或反面。如果我们对这些数据使用最大似然方法，它会将正面或反面分别赋予概率1，意味着我们永远不会得到另一面。或者，假设我们投掷硬币10次，得到了三次正面和七次反面。在这种情况下，最大似然方法会将正面的概率定为0.3，反面的概率定为0.7，这并不是公平硬币的真实分布。这个问题也通常被称为**过拟合**。
- en: Bayesian learning takes a slightly different approach to learn these parameters.
    We start by assigning a prior distribution over the parameters of our model. The
    prior makes our assumptions about the model explicit. In the case of tossing the
    coin, we can start by using a prior that assigns equal probabilities to both heads
    and tails. Then we apply the Bayes theorem to compute the posterior distribution
    over our parameters based on the data. This allows us to shift our belief (prior)
    toward where the data points to, and this makes us do a less extreme estimate
    of the parameters. And in this way, Bayesian learning can solve one of the major
    drawbacks of maximum likelihood.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯学习采用略有不同的方法来学习这些参数。我们首先为模型的参数分配一个先验分布。先验使我们对模型的假设变得显式。在投掷硬币的例子中，我们可以从一个将正面和反面赋予相等概率的先验开始。然后，我们应用贝叶斯定理根据数据计算参数的后验分布。这使我们能够根据数据将我们的信念（先验）向数据的指向转移，从而进行更为温和的参数估计。通过这种方式，贝叶斯学习能够解决最大似然方法的一个主要缺点。
- en: 'In more general terms, in the case of Bayesian learning, we try to learn a
    distribution over the parameters of our model instead of learning a single parameter
    that maximizes the likelihood. For learning this distribution over the parameters,
    we use the Bayes theorem, given by the following:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 更一般来说，在贝叶斯学习的情况下，我们尝试学习模型参数的分布，而不是学习一个能够最大化似然的单一参数。为了学习这种参数分布，我们使用贝叶斯定理，公式如下：
- en: '![](img/0f629c8c-5429-46a3-a693-2f2d0b609354.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0f629c8c-5429-46a3-a693-2f2d0b609354.png)'
- en: 'Here, *P(θ)* is our prior over the parameters of the model, *P(D|θ)* is the
    likelihood of the data given the parameters, and *P(D)* is the probability of
    the observed data. *P(D)* can also be written in terms of prior and likelihood
    as follows:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*P(θ)* 是我们对模型参数的先验分布，*P(D|θ)* 是给定参数下数据的似然，*P(D)* 是观察到数据的概率。*P(D)* 也可以通过先验和似然表示如下：
- en: '![](img/dbdfc5df-65e2-41d4-a980-28e5f75354ec.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](img/dbdfc5df-65e2-41d4-a980-28e5f75354ec.png)'
- en: Now let's talk about each of these terms separately and see how can we compute
    them. The prior, *P(θ)*, is a probability distribution over the parameters representing
    our belief about the values of the parameters. For example, in the case of coin
    tossing, we can have our initial belief as *θ* is in between 0 and 1 and is uniformly
    distributed. The likelihood term, *P(D|θ)*, is the same term that we tried to
    maximize in [Chapter 4](8d06a68a-e427-4f7d-9472-9be25b5351c0.xhtml), *Parameter
    Inference using Maximum Likelihood*. It represents how likely our observed data
    is, given the parameters of the model. The next term, *P(D)*, is the probability
    of observing our data and it acts as the normalizing term. It is computationally
    difficult to compute because it requires us to sum over all the possible values
    of *θ* and, for any sufficiently large number of parameters, it quickly becomes
    intractable. In the next sections of this chapter, we will see the different algorithms
    that we can use to approximate these values. The term that we are trying to compute,
    *P(D|θ),* is known as the **posterior**. It represents our final probability distribution
    over the parameters of the model given our observed data. Basically, our prior
    is updated using the likelihood term to give the final distribution.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们分别讨论这些术语，看看我们如何计算它们。先验，*P(θ)*，是一个参数的概率分布，代表我们对参数值的信念。例如，在抛硬币的情况下，我们可以将初始信念设为*θ*在0到1之间，并且是均匀分布的。似然项，*P(D|θ)*，是我们在[第4章](8d06a68a-e427-4f7d-9472-9be25b5351c0.xhtml)中尝试最大化的相同项，*使用最大似然进行参数推断*。它表示给定模型参数的情况下，观测数据的可能性。下一个术语，*P(D)*，是观测到数据的概率，它充当归一化项。由于它要求我们对所有可能的*θ*值求和，因此计算上非常困难，对于任何足够多的参数，计算会迅速变得不可处理。在本章的接下来的部分中，我们将看到可以用来近似这些值的不同算法。我们试图计算的术语，*P(D|θ)*，被称为**后验**。它表示给定我们的观测数据后，模型参数的最终概率分布。基本上，我们的先验通过使用似然项来更新，得到最终的分布。
- en: Another problem that Bayesian learning solves is the model selection. Since
    Bayesian learning gives a distribution over the different possible models rather
    than a single model, we have a couple of options of how we want to do predictions
    from these models. The first method is to just select a specific model that has
    the maximum probability, which is also commonly known as the **Maximum Aposteriori**
    (**MAP**) estimate. The other possible way is to compute the expectation of the
    prediction from all the models based on the posterior distribution. This allows
    us to regularize our predictions since we are computing expectation over all possible
    models.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯学习解决的另一个问题是模型选择。由于贝叶斯学习为不同的可能模型提供了一个分布，而不是单一的模型，我们有几种方式可以从这些模型中进行预测。第一种方法是选择具有最大概率的特定模型，这也通常被称为**最大后验（MAP）**估计。另一种可能的方法是基于后验分布计算所有模型的预测期望。这使我们能够对预测进行正则化，因为我们是在对所有可能的模型进行期望计算。
- en: Selecting the priors
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择先验
- en: A common question when doing Bayesian learning is how to select the appropriate
    prior. As David Mackay has said, *there is no inference without assumptions, we
    need to make a guess for the prior*. Our prior should be representative of what
    we think the most likely parameters are for our model. A huge benefit of using
    our own prior is that we make our assumption about the model explicit. Once we
    start applying Bayes, theorem using our prior and the observed data, our posterior
    would be a shift from our prior toward a distribution that represents our data
    better.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行贝叶斯学习时，一个常见的问题是如何选择合适的先验。正如大卫·麦凯所说，*没有假设就没有推理，我们需要对先验做出一个猜测*。我们的先验应该代表我们认为模型中最可能的参数。使用我们自己的先验的一个巨大好处是，我们使得关于模型的假设变得明确。一旦我们开始应用贝叶斯定理，使用我们的先验和观测数据，后验分布就会从我们的先验向一个更能代表数据的分布偏移。
- en: Theoretically, this sounds good as we can probably select very complex priors
    that capture our idea of the model, but for applying the Bayes theorem, we need
    to multiply our prior with the likelihood, and for complex distributions, it very
    quickly becomes computationally intractable. Therefore, in practice, we usually
    select a prior that is a conjugate distribution to our likelihood. A conjugate
    prior allows us to have a closed-form solution to the Bayes theorem. Because of
    this, Gaussian distributions are used for priors and likelihoods as multiplying
    a Gaussian distribution with another Gaussian distribution results in a Gaussian
    distribution. Also computations it's not expensive to compute the product of two
    Gaussians.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: Intractability
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Apart from selecting difficult priors, another source of intractability in
    Bayesian learning is the denominator term of Bayes'' theorem:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/94eab2cf-86ad-4a4d-8333-2fe419d34fd4.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
- en: As we can see in the preceding equation for computing *P(D)*, we need to compute
    a summation over all the possible values of *θ*, which is the set of all the parameters
    of our model. If we have a lot of parameters in our model, it is computationally
    intractable to compute this term since the size of the term grows exponentially
    with the number of parameters. A lot of work has been done to approximate this
    value, as we will see in the next section of this chapter.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian learning in HMM
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we saw in the previous section, in the case of Bayesian learning we assume
    all the variables as a random variable, assign a prior to it, and then try to
    compute the posterior based on that. Therefore, in the case of HMM, we can assign
    a prior on our transition probabilities, emission probabilities, or the number
    of observation states.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, the first problem that we need to solve is to select the prior. Theoretically,
    a prior can be any distribution over the parameters of the model, but in practice,
    we usually try to use a conjugate prior to the likelihood, so that we have a closed-form
    solution to the equation. For example, in the case when the output of the HMM
    is discrete, a common choice of prior is the Dirichlet distribution. It is mainly
    for two reasons, the first of which is that the Dirichlet distribution is a conjugate
    distribution to multinomial distribution which allows us to multiply them easily.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '**Conjugate distribution**: A family of priors is said to be conjugate to a
    family of likelihoods if the posterior obtained by multiplying the prior by the
    likelihood is in the same family of distribution as the prior distribution.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, since the likelihood of the initial state given the *π* parameter
    vector is multinomial:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d5960650-e1ce-46e9-8598-7c16419a6e9c.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
- en: 'And if the prior probability of *π* is Dirichlet:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1b0a0141-4f7d-4935-a5f1-661689aafd0f.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
- en: 'Where *u = [u[1], u[2], ..., u[K]]* is the hyperparameter vector and *Z* is
    the normalizing constant. We can now compute the posterior from the likelihood
    and the prior, which is given as follows:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/df4cf2c1-e1bf-4876-91f9-e7338aa89ada.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
- en: And we can see that the posterior is also a Dirichlet distribution. Hence we
    can say that the Dirichlet distribution is a conjugate prior to the multinomial
    distribution. And in a similar way, we can set up Dirichlet priors for our transition
    matrix and emission matrix.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: The second reason for choosing a Dirichlet prior is that it has the desirable
    property that its hyperparameters can be interpreted as a hypothetical count of
    observations. In the preceding example, if *u[i] = 2* and *u[j] = 1* for *j ≠
    i*, the MAP estimate of *π* would be the same as a maximum-likelihood estimation
    with the assumption that the training data had an extra data point with the initial
    state being in state *i*. This conjugate property allows us to do MAP estimation
    in the case of Dirichlet priors by doing a minor variation in the Baum-Welch algorithm.
    It also gives theoretical justification for the seemingly ad hoc but very common
    regularization method for HMMs, which just adds a small positive number to all
    elements of the parameter vector.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: In the last couple of paragraphs, we talked specifically about the case when
    the output is discrete. But the same concepts can be extended to the case of continuous
    output as well. Conjugate distributions exist in the case of continuous distributions
    as well. One of the most commonly used distributions is the Gaussian distribution
    as it stays in the same family after different operations.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: Approximating required integrals
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we discussed before, the Bayesian approach treats all unknown quantities
    as random variables. We assign prior distributions to these variables and then
    estimate the posterior distribution over these after the data is observed. In
    the case of HMMs, the unknown quantities comprise the structure of the HMM, that
    is, the number of states, the parameters of the network, and the hidden states.
    Unlike maximum-likelihood or MAP estimations, in which we find point estimates
    for these parameters, we now have distributions over these parameters. This allows
    us to compare between model structures, but for doing that we need to integrate
    over both the parameters and the hidden states of the model. This is commonly
    known as Bayesian integration.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: Since these integrations are computationally intractable, we resort to approximate
    methods to compute these values. In the next few subsections, we will give an
    overview of some of these methods. A detailed analysis of these methods is outside
    the scope of this book.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: Sampling methods
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sampling methods are one of the most common ways to estimate intractable distributions.
    The general idea is to sample points from the distribution space in a way such
    that we get more samples from high-probability areas. And then based on these
    samples we estimate the distributions.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: Laplace approximations
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Laplace approximations use the central limit theorem, which from well-behaved
    priors and data asserts that the posterior parameter will converge in the limit
    of a large number of training samples to a Gaussian around the MAP estimate of
    the parameters. To estimate the evidence using the Laplace approximation, MAP
    parameters are found in the usual optimization routines and then the Hessian of
    the log-likelihood is computed at the MAP estimate. The evidence is approximated
    by evaluating the *P(θ,D)/P(θ|D)* ratio at the MAP estimate of *θ*, using the
    Gaussian approximation in the denominator. The Laplace approximation suffers from
    several disadvantages:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: Computing the Hessian matrix from the parameters is usually very costly
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Gaussian approximation is not very good for models with parameters that
    are positive and sum to 1, especially when there are many parameters relative
    to the size of the dataset
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For these reasons, the Laplace approximation is usually not used for HMMs.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: Stolke and Omohundro's method
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the famous paper *HMM induction by Bayesian model merging* Stolke and Omohundro
    present a new technique for approximating the Bayesian integrals of HMMs. Consider the
    case of having all the states of the HMM to be observed and the priors to be Dirichlet
    distributions. In this case, when learning the parameters using Bayesian learning,
    the posteriors are also going to be Dirichlet distributions, and then the evidence
    integral can be represented as a product of Dirichlet integrals, which can be
    easily computed. Therefore, in a sense, we can say that the reason for the intractability
    of evidence integrals is the fact that the states and parameters are hidden.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: Stolke and Omohundro's method proposed to find the single most likely sequence
    of hidden states using a Viterbi-like algorithm and using this sequence as observed
    states. Using these observed values, we can easily do evidence integrals. The
    method proposes to iterate between these two steps, incrementally searching over
    model structures, merging or splitting states based on comparisons of this approximate
    evidence. In their paper, Stolke and Omohundro show that this method of trading
    off integration over hidden variables by integrating over parameters is able to
    get good results.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: Variational methods
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Variational methods are another very common method used for approximating distributions.
    The general idea is to start by choosing a simpler family of distributions and
    then try to find the hyperparameters of this distribution such that the distribution
    is as close as possible to our original distribution. There are different metrics
    that are used to determine the closeness of two distributions; the most commonly
    used metric is Kullback-Leiber divergence. This method basically converts an inference
    problem into an optimization problem where we try to minimize our divergence metric.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: 'In the case of HMMs, we usually make an assumption that the hidden states are
    independent of the parameters of the model. This allows us to approximate distributions
    over both the hidden states and parameters simultaneously. More specifically,
    the evidence can be lower bounded by applying Jenson''s inequality twice:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f6441a3c-4b9b-4f5f-b46e-47a3ede9e751.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
- en: The variational Bayesian approach iteratively maximizes ![](img/a53434d0-4c21-4db9-9f3f-611212895d68.png) as
    a functional of the two free distributions, *Q(S) *and *Q(θ)*. In the preceding
    equations, we can see that this maximization is equivalent to minimizing the KL
    divergence between *Q(S)Q(θ)* and the joint posterior over hidden states and the *P(S,θ|D,M)* parameters.
    David MacKay first presented a variational Bayesian approach to learning in HMMs.
    He assumed the prior to be a Dirichlet distribution, making the assumption that
    the parameters are independent of the hidden states, he showed that the optimal
    *Q(θ)* is a Dirichlet distribution. Furthermore, he showed that the optimal *Q(S)* could
    be obtained by applying the forward-backward algorithm to an HMM with pseudo-parameters
    given by ![](img/881223eb-6a9e-4209-a083-d9fa362eac42.png), which can be evaluated
    for Dirichlet distributions. Thus the whole variational Bayesian method can be
    implemented as a simple modification of the Baum-Welch algorithm. Essentially
    we can state that the variational Bayesian method is a combination of special
    cases of both the MAP approach and Stolke and Omohundro's approach. This is very
    promising, especially given that it has been used successfully for non-trivial
    model-structure learning in other models; its potential has not been fully explored
    for HMMs and their extensions.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: Code
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Currently, there are no packages in Python that support learning using Bayesian
    learning and it would be really difficult to write the complete code to fit in
    this book. And even though there are a lot of advantages to using Bayesian learning,
    it is usually computationally infeasible in a lot of cases. For these reasons,
    we are skipping the code for Bayesian learning in HMMs.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we talked about applying Bayesian learning in the case of learning
    parameters in HMMs. Bayesian learning has a few benefits over the maximum-likelihood
    estimator, but it turns out to be computationally quite expensive except when
    we have closed-form solutions. Closed-form solutions are only possible when we
    use conjugate priors. In the following chapters, we will discuss detailed applications
    of HMMs for a wide variety of problems.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了在隐马尔可夫模型（HMMs）中应用贝叶斯学习来学习参数。贝叶斯学习相比最大似然估计器有一些优势，但除非我们有闭式解，否则它在计算上是相当昂贵的。闭式解只有在使用共轭先验时才有可能。接下来的章节中，我们将讨论隐马尔可夫模型在各种问题中的详细应用。
