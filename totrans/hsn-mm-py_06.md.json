["```py\n\"\"\"\nUsage: get_data.py --year=<year>\n\"\"\"\nimport requests\nimport os\nfrom docopt import docopt\n\n# docopt helps parsing the command line argument in\n# a simple manner (http://docopt.org/)\nargs = docopt(doc=__doc__, argv=None,\n              help=True, version=None,\n              options_first=False)\n\nyear = args['--year']\n\n# Create directory if not present\nyear_directory_name = 'data/{year}'.format(year=year)\nif not os.path.exists(year_directory_name):\n    os.makedirs(year_directory_name)\n\n# Fetching file list for the corresponding year\nyear_data_files = requests.get(\n    'http://data.pystock.com/{year}/index.txt'.format(year=year)\n).text.strip().split('\\n')\n\nfor data_file_name in year_data_files:\n    file_location = '{year_directory_name}/{data_file_name}'.format(\n        year_directory_name=year_directory_name,\n        data_file_name=data_file_name)\n\n    with open(file_location, 'wb+') as data_file:\n        print('>>> Downloading \\t {file_location}'.format(file_location=file_location))\n        data_file_content = requests.get(\n            'http://data.pystock.com/{year}/{data_file_name}'.format(year=year, data_file_name=data_file_name)\n        ).content\n        print('<<< Download Completed \\t {file_location}'.format(file_location=file_location))\n        data_file.write(data_file_content)\n```", "```py\npython get_data.py --year 2015\npython get_data.py --year 2016\npython get_data.py --year 2017\n```", "```py\n\"\"\"\nUsage: parse_data.py --company=<company>\n\"\"\"\nimport os\nimport tarfile\nimport pandas as pd\nfrom pandas import errors as pd_errors\nfrom functools import reduce\nfrom docopt import docopt\n\nargs = docopt(doc=__doc__, argv=None,\n              help=True, version=None,\n              options_first=False)\n\nyears = [2015, 2016, 2017]\ncompany = args['--company']\n\n# Getting the data files list\ndata_files_list = []\nfor year in years:\n    year_directory = 'data/{year}'.format(year=year)\n    for file in os.listdir(year_directory):\n        data_files_list.append('{year_directory}/{file}'.format(year_directory=year_directory, file=file))\n\ndef parse_data(file_name, company_symbol):\n    \"\"\"\n    Returns data for the corresponding company\n\n    :param file_name: name of the tar file\n    :param company_symbol: company symbol\n    :type file_name: str\n    :type company_symbol: str\n    :return: dataframe for the corresponding company data\n    :rtype: pd.DataFrame\n    \"\"\"\n    tar = tarfile.open(file_name)\n    try:\n        price_report = pd.read_csv(tar.extractfile('prices.csv'))\n        company_price_data = price_report[price_report['symbol'] == company_symbol]\n        return company_price_data\n    except (KeyError, pd_errors.EmptyDataError):\n        return pd.DataFrame()\n\n# Getting the complete data for a given company\ncompany_data = reduce(lambda df, file_name: df.append(parse_data(file_name, company)),\n                      data_files_list,\n                      pd.DataFrame())\ncompany_data = company_data.sort_values(by=['date'])\n\n# Create folder for company data if does not exists\nif not os.path.exists('data/company_data'):\n    os.makedirs('data/company_data')\n\n# Write data to a CSV file\ncompany_data.to_csv('data/company_data/{company}.csv'.format(company=company),\n                    columns=['date', 'open', 'high', 'low', 'close', 'volume', 'adj_close'],\n                    index=False)\n```", "```py\npython parse_data.py --company GOOGL\npython parse_data.py --company FB\npython parse_data.py --company AAPL\n```", "```py\nimport pandas as pd\n\nclass StockPredictor(object):\n    def __init__(self, company, n_latency_days=10):\n        self._init_logger()\n\n        self.company = company\n        self.n_latency_days = n_latency_days\n        self.data = pd.read_csv(\n            'data/company_data/{company}.csv'.format(company=self.company))\n\n    def _init_logger(self):\n        self._logger = logging.getLogger(__name__)\n        handler = logging.StreamHandler()\n        formatter = logging.Formatter(\n            '%(asctime)s %(name)-12s %(levelname)-8s %(message)s')\n        handler.setFormatter(formatter)\n        self._logger.addHandler(handler)\n        self._logger.setLevel(logging.DEBUG)\n\n    @staticmethod\n    def _extract_features(data):\n        open_price = np.array(data['open'])\n        close_price = np.array(data['close'])\n        high_price = np.array(data['high'])\n        low_price = np.array(data['low'])\n\n        # Compute the fraction change in close, high and low prices\n        # which would be used a feature\n        frac_change = (close_price - open_price) / open_price\n        frac_high = (high_price - open_price) / open_price\n        frac_low = (open_price - low_price) / open_price\n\n        return np.column_stack((frac_change, frac_high, frac_low))\n\n# Predictor for GOOGL stocks\nstock_predictor = StockPredictor(company='GOOGL')\n```", "```py\nfrom hmmlearn.hmm import GaussianHMM\n\nclass StockPredictor(object):\n    def __init__(self, company, n_latency_days=10, n_hidden_states=4):\n        self._init_logger()\n\n        self.company = company\n        self.n_latency_days = n_latency_days\n\n        self.hmm = GaussianHMM(n_components=n_hidden_states)\n\n        self.data = pd.read_csv(\n            'data/company_data/{company}.csv'.format(company=self.company))\n\n    def fit(self):\n        self._logger.info('>>> Extracting Features')\n        feature_vector = StockPredictor._extract_features(self.data)\n        self._logger.info('Features extraction Completed <<<')\n\n        self.hmm.fit(feature_vector)\n```", "```py\nfrom sklearn.model_selection import train_test_split\n\nclass StockPredictor(object):\n    def __init__(self, company, test_size=0.33,\n                 n_latency_days=10, n_hidden_states=4):\n        self._init_logger()\n\n        self.company = company\n        self.n_latency_days = n_latency_days\n\n        self.hmm = GaussianHMM(n_components=n_hidden_states)\n\n        self._split_train_test_data(test_size)\n\n    def _split_train_test_data(self, test_size):\n        data = pd.read_csv(\n            'data/company_data/{company}.csv'.format(company=self.company))\n        _train_data, test_data = train_test_split(\n            data, test_size=test_size, shuffle=False)\n\n        self._train_data = _train_data\n        self._test_data = test_data\n\n    def fit(self):\n        self._logger.info('>>> Extracting Features')\n        feature_vector = StockPredictor._extract_features(self._train_data)\n        self._logger.info('Features extraction Completed <<<')\n\n        self.hmm.fit(feature_vector)\n```", "```py\ndef _compute_all_possible_outcomes(self, n_steps_frac_change,\n                                       n_steps_frac_high, n_steps_frac_low):\n        frac_change_range = np.linspace(-0.1, 0.1, n_steps_frac_change)\n        frac_high_range = np.linspace(0, 0.1, n_steps_frac_high)\n        frac_low_range = np.linspace(0, 0.1, n_steps_frac_low)\n\n        self._possible_outcomes = np.array(list(itertools.product(\n            frac_change_range, frac_high_range, frac_low_range)))\n```", "```py\ndef _get_most_probable_outcome(self, day_index):\n        previous_data_start_index = max(0, day_index - self.n_latency_days)\n        previous_data_end_index = max(0, day_index - 1)\n        previous_data = self._test_data.iloc[previous_data_end_index: previous_data_start_index]\n        previous_data_features = StockPredictor._extract_features(\n            previous_data)\n\n        outcome_score = []\n        for possible_outcome in self._possible_outcomes:\n            total_data = np.row_stack(\n                (previous_data_features, possible_outcome))\n            outcome_score.append(self.hmm.score(total_data))\n        most_probable_outcome = self._possible_outcomes[np.argmax(\n            outcome_score)]\n\n        return most_probable_outcome\n\n    def predict_close_price(self, day_index):\n        open_price = self._test_data.iloc[day_index]['open']\n        predicted_frac_change, _, _ = self._get_most_probable_outcome(\n            day_index)\n        return open_price * (1 + predicted_frac_change)\n```", "```py\n\"\"\"\nUsage: analyse_data.py --company=<company>\n\"\"\"\nimport warnings\nimport logging\nimport itertools\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom hmmlearn.hmm import GaussianHMM\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nfrom docopt import docopt\n\nargs = docopt(doc=__doc__, argv=None, help=True,\n              version=None, options_first=False)\n\n# Supress warning in hmmlearn\nwarnings.filterwarnings(\"ignore\")\n# Change plot style to ggplot (for better and more aesthetic visualisation)\nplt.style.use('ggplot')\n\nclass StockPredictor(object):\n    def __init__(self, company, test_size=0.33,\n                 n_hidden_states=4, n_latency_days=10,\n                 n_steps_frac_change=50, n_steps_frac_high=10,\n                 n_steps_frac_low=10):\n        self._init_logger()\n\n        self.company = company\n        self.n_latency_days = n_latency_days\n\n        self.hmm = GaussianHMM(n_components=n_hidden_states)\n\n        self._split_train_test_data(test_size)\n\n        self._compute_all_possible_outcomes(\n            n_steps_frac_change, n_steps_frac_high, n_steps_frac_low)\n\n    def _init_logger(self):\n        self._logger = logging.getLogger(__name__)\n        handler = logging.StreamHandler()\n        formatter = logging.Formatter(\n            '%(asctime)s %(name)-12s %(levelname)-8s %(message)s')\n        handler.setFormatter(formatter)\n        self._logger.addHandler(handler)\n        self._logger.setLevel(logging.DEBUG)\n\n    def _split_train_test_data(self, test_size):\n        data = pd.read_csv(\n            'data/company_data/{company}.csv'.format(company=self.company))\n        _train_data, test_data = train_test_split(\n            data, test_size=test_size, shuffle=False)\n\n        self._train_data = _train_data\n        self._test_data = test_data\n\n    @staticmethod\n    def _extract_features(data):\n        open_price = np.array(data['open'])\n        close_price = np.array(data['close'])\n        high_price = np.array(data['high'])\n        low_price = np.array(data['low'])\n\n        # Compute the fraction change in close, high and low prices\n        # which would be used a feature\n        frac_change = (close_price - open_price) / open_price\n        frac_high = (high_price - open_price) / open_price\n        frac_low = (open_price - low_price) / open_price\n\n        return np.column_stack((frac_change, frac_high, frac_low))\n\n    def fit(self):\n        self._logger.info('>>> Extracting Features')\n        feature_vector = StockPredictor._extract_features(self._train_data)\n        self._logger.info('Features extraction Completed <<<')\n\n        self.hmm.fit(feature_vector)\n\n    def _compute_all_possible_outcomes(self, n_steps_frac_change,\n                                       n_steps_frac_high, n_steps_frac_low):\n        frac_change_range = np.linspace(-0.1, 0.1, n_steps_frac_change)\n        frac_high_range = np.linspace(0, 0.1, n_steps_frac_high)\n        frac_low_range = np.linspace(0, 0.1, n_steps_frac_low)\n\n        self._possible_outcomes = np.array(list(itertools.product(\n            frac_change_range, frac_high_range, frac_low_range)))\n\n    def _get_most_probable_outcome(self, day_index):\n        previous_data_start_index = max(0, day_index - self.n_latency_days)\n        previous_data_end_index = max(0, day_index - 1)\n        previous_data = self._test_data.iloc[previous_data_end_index: previous_data_start_index]\n        previous_data_features = StockPredictor._extract_features(\n            previous_data)\n\n        outcome_score = []\n        for possible_outcome in self._possible_outcomes:\n            total_data = np.row_stack(\n                (previous_data_features, possible_outcome))\n            outcome_score.append(self.hmm.score(total_data))\n        most_probable_outcome = self._possible_outcomes[np.argmax(\n            outcome_score)]\n\n        return most_probable_outcome\n\n    def predict_close_price(self, day_index):\n        open_price = self._test_data.iloc[day_index]['open']\n        predicted_frac_change, _, _ = self._get_most_probable_outcome(\n            day_index)\n        return open_price * (1 + predicted_frac_change)\n\n    def predict_close_prices_for_days(self, days, with_plot=False):\n        predicted_close_prices = []\n        for day_index in tqdm(range(days)):\n            predicted_close_prices.append(self.predict_close_price(day_index))\n\n        if with_plot:\n            test_data = self._test_data[0: days]\n            days = np.array(test_data['date'], dtype=\"datetime64[ms]\")\n            actual_close_prices = test_data['close']\n\n            fig = plt.figure()\n\n            axes = fig.add_subplot(111)\n            axes.plot(days, actual_close_prices, 'bo-', label=\"actual\")\n            axes.plot(days, predicted_close_prices, 'r+-', label=\"predicted\")\n            axes.set_title('{company}'.format(company=self.company))\n\n            fig.autofmt_xdate()\n\n            plt.legend()\n            plt.show()\n\n        return predicted_close_prices\n\nstock_predictor = StockPredictor(company=args['--company'])\nstock_predictor.fit()\nstock_predictor.predict_close_prices_for_days(500, with_plot=True)\n```"]