<html><head></head><body>
        <section>

            <header>
                <h1 class="header-title">Preface</h1>
            </header>

            <article>
                
<p><em>Hands-on deep learning with Keras</em> is a concise yet thorough introduction to modern neural networks, artificial intelligence, and deep learning technologies designed especially for software engineers and data scientists.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Mission</h1>
            </header>

            <article>
                
<p>The book presents more than 20 working deep neural networks coded in Python using Keras, a modular neural network library that runs on top of either Google's TensorFlow or Lisa Lab's Theano backends.</p>
<p>The reader is introduced step by step to supervised learning algorithms such as simple linear regression, classical multilayer perceptron, and more sophisticated deep convolutional networks and generative adversarial networks. In addition, the book covers unsupervised learning algorithms such as autoencoders and generative networks. Recurrent networks and <strong>long short-term memory</strong> (<strong>LSTM</strong>) networks are also explained in detail. The book goes on to cover the Keras functional API and how to customize Keras in case the reader's use case is not covered by Keras's extensive functionality. It also looks at larger, more complex systems composed of the building blocks covered previously. The book concludes with an introduction to deep reinforcement learning and how it can be used to build game playing AIs.</p>
<p>Practical applications include code for the classification of news articles into predefined categories, syntactic analysis of texts, sentiment analysis, synthetic generation of texts, and parts of speech annotation. Image processing is also explored, with recognition of handwritten digit images, classification of images into different categories, and advanced object recognition with related image annotations. An example of identification of salient points for face detection will be also provided. Sound analysis comprises recognition of discrete speeches from multiple speakers. Reinforcement learning is used to build a deep Q-learning network capable of playing games autonomously.</p>
<p>Experiments are the essence of the book. Each net is augmented by multiple variants that progressively improve the learning performance by changing the input parameters, the shape of the network, loss functions, and algorithms used for optimizations. Several comparisons between training on CPUs and GPUs are also provided.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How deep learning is different from machine learning and artificial intelligence</h1>
            </header>

            <article>
                
<p><strong>Artificial intelligence</strong> (<strong>AI</strong>) is a very large research field, where machines show <em>cognitive</em> capabilities such as learning behaviours, proactive interaction with the environment, inference and deduction, computer vision, speech recognition, problem solving, knowledge representation, perception, and many others (for more information, refer to this article: <em>Artificial Intelligence: A Modern Approach</em>, by <span>S. Russell and P. Norvig, Prentice Hall, 2003</span>). More colloquially, AI denotes any activity where machines mimic <em>intelligent</em> behaviors typically shown by humans. Artificial intelligence takes inspiration from elements of computer science, mathematics, and statistics.</p>
<p><strong>Machine learning</strong> (<strong>ML</strong>) is a subbranch of AI that focuses on teaching computers how to learn without the need to be programmed for specific tasks (<span>for more information refer to <em>Pattern Recognition and Machine Learning</em></span>, by <span>C. M. Bishop, Springer, 2006</span>). In fact, the key idea behind ML is that it is possible to create algorithms that learn from and make predictions on data. There are three different broad categories of ML. In supervised learning, the machine is presented with input data and desired output, and the goal is to learn from those training examples in such a way that meaningful predictions can be made for fresh unseen data. In unsupervised learning, the machine is presented with input data only and the machine has to find some meaningful structure by itself with no external supervision. In reinforcement learning, the machine acts as an agent interacting with the environment and learning what are the behaviours that generate rewards.</p>
<p><strong>Deep learning</strong> (<strong>DL</strong>) is a particular subset of ML methodologies using <strong>artificial neural networks</strong> (<strong>ANN</strong>) slightly inspired by the structure of neurons located in the human brain (<span>for more information, refer to the article <em>Learning Deep Architectures for AI</em>, by Y. Bengio, </span>Found. Trends, <span>vol. 2, 2009</span>). Informally, the word <em>deep</em> refers to the presence of many layers in the artificial neural network, but this meaning has changed over time. While 4 years ago, 10 layers were already sufficient to consider a network as <em>deep</em>, today it is more common to consider a network as <em>deep</em> when it has hundreds of layers.</p>
<div class="CDPAlignCenter CDPAlign"><img class="image-border" height="189" src="assets/B06258_Intro_001.png" width="187"/></div>
<p>DL is a real tsunami (for more information, refer to <span><em>Computational Linguistics and Deep Learning</em> by C. D. Manning, "Computational Linguistics", vol. 41, 2015</span>) for machine learning in that a relatively small number of clever methodologies have been very successfully applied to so many different domains (image, text, video, speech, and vision), significantly improving previous state-of-the-art results achieved over dozens of years. The success of DL is also due to the availability of more training data (such as ImageNet for images) and the relatively low-cost availability of GPUs for very efficient numerical computation. Google, Microsoft, Amazon, Apple, Facebook, and many others use those deep learning techniques every day for analyzing massive amounts of data. However, this kind of expertise is not limited any more to the domain of pure academic research and to large industrial companies. It has become an integral part of modern software production and therefore something that the reader should definitively master. The book does not require any particular mathematical background. However, it assumes that the reader is already a Python programmer.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">What this book covers</h1>
            </header>

            <article>
                
<p><a href="c2484fb4-248d-49ed-8166-06aff812e5e9.xhtml" target="_blank">Chapter 1</a>, <em>Neural Networks Foundations</em>, teaches the basics of neural networks.</p>
<p><a href="c2acf180-41e0-4f09-94c8-187edc23931c.xhtml" target="_blank">Chapter 2</a>, <em>Keras Installation and API</em>, shows how to install Keras on AWS, Microsoft Azure, Google Cloud, and your own machine. In addition to that, we provide an overview of the Keras APIs.</p>
<p><a href="4be2a04a-4545-4051-bcd9-32764d21f0f2.xhtml" target="_blank">Chapter 3</a>, <em>Deep Learning with ConvNets</em>, introduces the concept of convolutional networks. It is a fundamental innovation in deep learning that has been used with success in multiple domains, from text to video to speech, going well beyond the initial image processing domain where it was originally conceived.</p>
<p><a href="a67ea944-b1a6-48a3-b8aa-4e698166c0eb.xhtml" target="_blank">Chapter 4</a>, <em>Generative Adversarial Networks and WaveNet</em>, introduces generative adversarial networks used to reproduce synthetic data that looks like data generated by humans. And we will present WaveNet, a deep neural network used for reproducing human voice and musical instruments with high quality.</p>
<p><a href="700e9954-f126-49b5-b4e4-fa7321296e85.xhtml" target="_blank">Chapter 5</a>, <em>Word Embeddings</em>, <span>discusses word embeddings, a set of deep learning methodologies for detecting relationships between words and grouping together similar words.</span></p>
<p><a href="57a694a6-93f4-4eec-9fbf-e4eafd2d6824.xhtml" target="_blank">Chapter 6</a>, <em>Recurrent Neural Networks – RNN</em>, covers recurrent neural networks, a class of network optimized for handling sequence data such as text.</p>
<p><a href="9384823c-eb58-4a0f-91e7-1a5508eeb520.xhtml" target="_blank">Chapter 7</a>, <em>Additional Deep Learning Models</em>, gives a brief look into the Keras functional API, regression networks, autoencoders, and so on.</p>
<p><a href="5e7efad7-29cf-4d55-a923-d81988e44c21.xhtml" target="_blank">Chapter 8</a>, <em>AI Game Playing</em>, teaches you deep reinforcement learning and how it can be used to build deep learning networks with Keras that learn how to play arcade games based on reward feedback.</p>
<p><a href="c0a1905f-57cc-401c-b485-6bf0854e43e9.xhtml" target="_blank">Appendix</a>, <em>Conclusion,</em> is a crisp refresher of the topics covered in this book and walks the users through what is new in Keras 2.0.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">What you need for this book</h1>
            </header>

            <article>
                
<p>To be able to smoothly follow through the chapters, you will need the following pieces of software:</p>
<ul>
<li>TensorFlow 1.0.0 or higher</li>
<li>Keras 2.0.2 or higher</li>
<li>Matplotlib 1.5.3 or higher</li>
<li>Scikit-learn 0.18.1 or higher</li>
<li>NumPy 1.12.1 or higher</li>
</ul>
<p>The hardware specifications are as follows:</p>
<ul>
<li>Either 32-bit or 64-bit architecture</li>
<li>2+ GHz CPU</li>
<li>4 GB RAM</li>
<li>At least 10 GB of hard disk space available</li>
</ul>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Who this book is for</h1>
            </header>

            <article>
                
<p><span class="sugar_field">If you are a data scientist with experience in machine learning or an AI programmer with some exposure to neural networks, you will find this book a useful entry point to deep learning with Keras. Knowledge of Python is required for this book.</span></p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Conventions</h1>
            </header>

            <article>
                
<p>In this book, you will find a number of text styles that distinguish between different kinds of information. Here are some examples of these styles and an explanation of their meaning.</p>
<p>Code words in text, database table names, folder names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles are shown as follows: "<span>In addition, we load the true labels into</span> <kbd>Y_train</kbd> <span>and</span> <kbd>Y_test</kbd> <span>respectively and perform a one-hot encoding on them.</span>"</p>
<p>A block of code is set as follows:</p>
<pre>
from keras.models import Sequential<br/>model = Sequential()<br/>model.add(Dense(12, input_dim=8, kernel_initializer='random_uniform'))
</pre>
<p>When we wish to draw your attention to a particular part of a code block, the relevant lines or items are set in bold:</p>
<pre>
# 10 outputs<br/># final stage is softmax<br/>model = Sequential()<br/>model.add(<strong>Dense</strong>(NB_CLASSES, input_shape=(RESHAPED,)))<br/>model.add(<strong>Activation</strong>('softmax'))<br/>model.summary()
</pre>
<p>Any command-line input or output is written as follows:</p>
<pre>
<strong>pip install quiver_engine</strong>
</pre>
<p><strong>New terms</strong> and <strong>important words</strong> are shown in bold. Words that you see on the screen, for example, in menus or dialog boxes, appear in the text like this: "<span>Our simple net started with an accuracy of</span> <span class="packt_screen">92.22%</span><span>, which means that about eight handwritten characters out of 100 are not correctly recognized.</span>"</p>
<div class="packt_infobox">Warnings or important notes appear in a box like this.</div>
<div class="packt_tip">Tips and tricks appear like this.</div>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Reader feedback</h1>
            </header>

            <article>
                
<p>Feedback from our readers is always welcome. Let us know what you think about this book-what you liked or disliked. Reader feedback is important for us as it helps us develop titles that you will really get the most out of.<br/>
To send us general feedback, simply e-mail <kbd><span>feedback@packtpub.com</span></kbd>, and mention the book's title in the subject of your message.<br/>
If there is a topic that you have expertise in and you are interested in either writing or contributing to a book, see our author guide at <span><a href="http://www.packtpub.com/authors" target="_blank">www.packtpub.com/authors</a></span>.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Customer support</h1>
            </header>

            <article>
                
<p>Now that you are the proud owner of a Packt book, we have a number of things to help you to get the most from your purchase.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Downloading the example code</h1>
            </header>

            <article>
                
<p>You can download the example code files for this book from your account at <a href="http://www.packtpub.com" target="_blank">http://www.packtpub.com</a>. If you purchased this book elsewhere, you can visit <a href="http://www.packtpub.com/support" target="_blank">http://www.packtpub.com/support</a> and register to have the files e-mailed directly to you.</p>
<p>You can download the code files by following these steps:</p>
<ol>
<li>Log in or register to our website using your e-mail address and password.</li>
<li>Hover the mouse pointer on the <span class="packt_screen">SUPPORT</span> tab at the top.</li>
<li>Click on <span class="packt_screen">Code Downloads &amp; Errata</span>.</li>
<li>Enter the name of the book in the <span class="packt_screen">Search</span> box.</li>
<li>Select the book for which you're looking to download the code files.</li>
<li>Choose from the drop-down menu where you purchased this book from.</li>
<li>Click on <span class="packt_screen">Code Download</span>.</li>
</ol>
<p>Once the file is downloaded, please make sure that you unzip or extract the folder using the latest version of:</p>
<ul>
<li>WinRAR / 7-Zip for Windows</li>
<li>Zipeg / iZip / UnRarX for Mac</li>
<li>7-Zip / PeaZip for Linux</li>
</ul>
<p><span>The code bundle for the book is also hosted on GitHub at <a href="https://github.com/PacktPublishing/Deep-Learning-with-Keras">https://github.com/PacktPublishing/Deep-Learning-with-Keras</a>. We also have other code bundles from our rich catalog of books and videos available at <a href="https://github.com/PacktPublishing/">https://github.com/PacktPublishing/</a>. Check them out!</span></p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Downloading the color images of this book</h1>
            </header>

            <article>
                
<p>We also provide you with a PDF file that has color images of the screenshots/diagrams used in this book. The color images will help you better understand the changes in the output. You can download this file from <a href="https://www.packtpub.com/sites/default/files/downloads/DeepLearningwithKeras_ColorImages.pdf" target="_blank">https://www.packtpub.com/sites/default/files/downloads/DeepLearningwithKeras_ColorImages.pdf</a>.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Errata</h1>
            </header>

            <article>
                
<p>Although we have taken every care to ensure the accuracy of our content, mistakes do happen. If you find a mistake in one of our books-maybe a mistake in the text or the code-we would be grateful if you could report this to us. By doing so, you can save other readers from frustration and help us improve subsequent versions of this book. If you find any errata, please report them by visiting <span><a href="http://www.packtpub.com/submit-errata" target="_blank">http://www.packtpub.com/submit-errata</a></span>, selecting your book, clicking on the <span class="packt_screen">Errata Submission Form</span> link, and entering the details of your errata. Once your errata are verified, your submission will be accepted and the errata will be uploaded to our website or added to any list of existing errata under the Errata section of that title.</p>
<p>To view the previously submitted errata, go to <span><a href="https://www.packtpub.com/books/content/support" target="_blank">https://www.packtpub.com/books/content/support</a></span> and enter the name of the book in the search field. The required information will appear under the <span class="packt_screen">Errata</span> section.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Piracy</h1>
            </header>

            <article>
                
<p>Piracy of copyrighted material on the Internet is an ongoing problem across all media. At Packt, we take the protection of our copyright and licenses very seriously. If you come across any illegal copies of our works in any form on the Internet, please provide us with the location address or website name immediately so that we can pursue a remedy.</p>
<p>Please contact us at <kbd><span>copyright@packtpub.com</span></kbd> with a link to the suspected pirated material.</p>
<p>We appreciate your help in protecting our authors and our ability to bring you valuable content.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Questions</h1>
            </header>

            <article>
                
<p>If you have a problem with any aspect of this book, you can contact us at <kbd><span>questions@packtpub.com</span></kbd>, and we will do our best to address the problem.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    </body></html>