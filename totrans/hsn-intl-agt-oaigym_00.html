<html><head></head><body>
        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Preface</h1>
                
            
            <article>
                
<p class="calibre2"><span class="calibre5">This book will guide you through the process of implementing your own intelligent agents to solve both discrete- and continuous-valued sequential decision-making problems with all the essential building blocks to develop, debug, train, visualize, customize, and test your intelligent agent implementations in a variety of learning environments, ranging from the Mountain Car and Cart Pole problems to Atari games and CARLA – an advanced simulator for autonomous driving.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Who this book is for</h1>
                
            
            <article>
                
<p class="calibre2">If you're a student, a game/machine learning developer, or an AI enthusiast looking to get started building intelligent agents and algorithms to solve a variety of problems using learning environments with the OpenAI Gym interface, this book is for you. You will also find this book useful if you want to learn how to build deep reinforcement learning-based, artificially intelligent agents to solve problems in your domain of interest. Though the book covers all the basic concepts that you need to know, some working knowledge of Python will help you get the most out of it.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">What this book covers</h1>
                
            
            <article>
                
<p class="calibre2">Chapter 1, <em class="calibre13">Introduction to Intelligent Agents and Learning Environments</em><span class="calibre5">, which enables the development of several AI systems. It sheds light on the important features of the toolkit, which provides you with endless opportunities to create autonomous intelligent agents to solve several algorithmic tasks, games, and control tasks. By the end of this chapter, you will know enough to create an instance of a Gym environment using Python yourself.</span></p>
<p class="calibre2">Chapter 2, <em class="calibre13">Reinforcement Learning and Deep Reinforcement Learning</em><span class="calibre5">, provides a concise<br class="calibre6"/>
explanation of the basic terminologies and concepts in reinforcement learning. The chapter<br class="calibre6"/>
will give you a good understanding of the basic reinforcement learning framework for<br class="calibre6"/>
developing AI agents. The chapter will also introduce deep reinforcement learning and<br class="calibre6"/>
provide you with a flavor of the types of advanced problem the algorithms enable you to<br class="calibre6"/>
solve.</span></p>
<p class="calibre2">Chapter 3, <em class="calibre13">Getting Started with OpenAI Gym and Deep Reinforcement Learning</em><span class="calibre5">, jumps right in and gets your development machine/computer ready with all the required installations and configurations needed for using the learning environments as well as PyTorch for developing deep learning algorithms.</span></p>
<p class="calibre2"/>
<p class="calibre2">Chapter 4, <em class="calibre13">Exploring the Gym and its Features</em>, <span class="calibre5">walks you through the inventory of learning environments available with the Gym library starting with the overview of how the environments are classified and named which will help you choose the correct version and type of environments from the 700+ learning environments available. You will then learn to explore the Gym, test out any of the environment you would like to, understand the interface and description of various environments.</span></p>
<p class="calibre2">Chapter 5, <em class="calibre13">Implementing your First Learning Agent – Solving the Mountain Car problem</em><span class="calibre5">, explains how to implement an AI agent using reinforcement learning to solve the mountain<br class="calibre6"/>
car problem. You will implement the agent, train it, and see it improve on its own. The<br class="calibre6"/>
implementation details will enable you to apply the concepts to develop and train an agent<br class="calibre6"/>
to solve various other tasks and/or games.</span></p>
<p class="calibre2">Chapter 6, <em class="calibre13">Implementing an Intelligent Agent for Optimal Control using Deep Q-Learning</em><span class="calibre5">, covers various methods to improve Q-learning including action-value function approximation using deep neural network, experience replay, target networks and also the necessary utilities and building-blocks that are useful for training and testing deep reinforcement learning agents in general. You will implement a DQN based intelligent agent for taking optimal discrete control actions and train it to play several Atari games and watch the agent's performance.</span></p>
<p class="calibre2">Chapter 7, <em class="calibre13">Creating Custom OpenAI Gym Environments – Carla Driving Simulator</em><span class="calibre5">, will teach you how to convert a real-world problem into a learning environment with interfaces compatible with the OpenAI Gym. You will learn the anatomy of Gym environments and create your custom learning environment based on the Carla simulator that can be registered with the Gym and used for training agents that we develop.</span></p>
<p class="calibre2">Chapter 8, <em class="calibre13">Implementing an Intelligent &amp; Autonomous Car Driving Agent using Deep Actor-Critic Algorithm</em><span class="calibre5">, teaches you the fundamentals of the Policy Gradient based reinforcement learning algorithms and helps you intuitively understand the deep n-step advantage actor-critic algorithm. You will then learn to implement a super-intelligent agent that can drive a car autonomously in the Carla simulator using both the synchronous as well as asynchronous implementation of the deep n-step advantage actor-critic algorithm.</span></p>
<p class="calibre2">Chapter 9, <em class="calibre13">Exploring the Learning Environment Landscape – Roboschool, Gym-Retro, StarCraft-II, DeepMindLab</em><span class="calibre5">, takes you beyond the Gym and shows you around other well developed suite of learning environments that you can use to train your intelligent agents. You will understand and learn to use the various Roboschool environments, the Gym Retro environments, the very popular Star Craft II environment and the DeepMind Lab environments.</span></p>
<p class="calibre2"/>
<p class="calibre2"><span class="calibre5">Chapter 10, <em class="calibre13">Exploring the Learning Algorithm Landscape – DDPG (Actor-Critic), PPO (Policy-Gradient), Rainbow (Value-Based)</em></span><em class="calibre13">,</em> Provides insights into latest deep reinforcement learning algorithms with their fundamentals demystified based on what you learned in the previous chapters of this book. You will get a quick understanding of the core concepts behind the best algorithms in the three different classes of deep reinforcement learning algorithms namely: The actor-critic based Deep Deterministic Policy Gradient (DDPG) algorithm, the Policy Gradient based Proximal Policy Optimization (PPO) and the value based Rainbow algorithm.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">To get the most out of this book</h1>
                
            
            <article>
                
<p class="calibre2">The following will be required:</p>
<ul class="calibre10">
<li class="calibre11">Some working knowledge of Python programming in order to understand the syntax, module imports, and library installations</li>
<li class="calibre11"><span>Some experience with Linux or macOS X command line for basic tasks, such as navigating the filesystem and running Python scripts</span></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Download the example code files</h1>
                
            
            <article>
                
<p class="calibre2">You can download the example code files for this book from your account at <a href="http://www.packtpub.com" target="_blank" class="calibre9">www.packtpub.com</a>. If you purchased this book elsewhere, you can visit <a href="http://www.packtpub.com/support" target="_blank" class="calibre9">www.packtpub.com/support</a> and register to have the files emailed directly to you.</p>
<p class="calibre2">You can download the code files by following these steps:</p>
<ol class="calibre14">
<li value="1" class="calibre11">Log in or register at <a href="http://www.packtpub.com/support" target="_blank" class="calibre9">www.packtpub.com</a>.</li>
<li value="2" class="calibre11">Select the <span>SUPPORT</span> tab.</li>
<li value="3" class="calibre11">Click on <span>Code Downloads &amp; Errata</span>.</li>
<li value="4" class="calibre11">Enter the name of the book in the <span>Search</span> box and follow the onscreen instructions.</li>
</ol>
<p class="calibre2">Once the file is downloaded, please make sure that you unzip or extract the folder using the latest version of:</p>
<ul class="calibre10">
<li class="calibre11">WinRAR/7-Zip for Windows</li>
<li class="calibre11">Zipeg/iZip/UnRarX for Mac</li>
<li class="calibre11">7-Zip/PeaZip for Linux</li>
</ul>
<p class="calibre2"/>
<p class="calibre2"><span class="calibre5">The code bundle for the book is also hosted on GitHub at</span><span class="calibre5"> <a href="https://github.com/PacktPublishing/Hands-On-Intelligent-Agents-with-OpenAI-Gym" class="calibre9">https://github.com/PacktPublishing/Hands-On-Intelligent-Agents-with-OpenAI-Gym</a></span><span class="calibre5">. </span><span class="calibre5">In case there's an update to the code, it will be updated on the existing GitHub repository.</span></p>
<p class="calibre2"><span class="calibre5">We also have other code bundles from our rich catalog of books and videos available at</span><span class="calibre5"> </span><strong class="calibre4"><span class="calibre5"><a href="https://github.com/PacktPublishing/" target="_blank" class="calibre9">https://github.com/PacktPublishing/</a></span></strong><span class="calibre5">. Check them out!</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Download the color images</h1>
                
            
            <article>
                
<p class="calibre2">We also provide a PDF file that has color images of the screenshots/diagrams used in this book. You can download it here: <a href="http://www.packtpub.com/sites/default/files/downloads/HandsOnIntelligentAgentswithOpenAIGym_ColorImages.pdf" class="calibre9">http://www.packtpub.com/sites/default/files/downloads/HandsOnIntelligentAgentswithOpenAIGym_ColorImages.pdf</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Conventions used</h1>
                
            
            <article>
                
<p class="calibre2">There are a number of text conventions used throughout this book.</p>
<p class="calibre2"><kbd class="calibre12">CodeInText</kbd>: <span class="calibre5">Indicates c</span>ode words in text, database table names, folder names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles. <span class="calibre5">Here is an example:</span> "Mount the downloaded <kbd class="calibre12">WebStorm-10*.dmg</kbd> disk image file as another disk in your system."</p>
<p class="calibre2">A block of code is set as follows:</p>
<pre class="calibre17">#!/usr/bin/env python<br class="title-page-name"/>import gym<br class="title-page-name"/>env = gym.make("Qbert-v0")<br class="title-page-name"/>MAX_NUM_EPISODES = 10<br class="title-page-name"/>MAX_STEPS_PER_EPISODE = 500</pre>
<p class="calibre2">When we wish to draw your attention to a particular part of a code block, the relevant lines or items are set in bold:</p>
<pre class="calibre17">for episode in range(MAX_NUM_EPISODES):<br class="title-page-name"/>    <strong class="calibre1">obs = env.reset()</strong><br class="title-page-name"/>    for step in range(MAX_STEPS_PER_EPISODE):<br class="title-page-name"/>        env.render()</pre>
<p class="calibre2">Any command-line input or output is written as follows:</p>
<pre class="calibre17"><strong class="calibre1">$ python get_observation_action_space.py 'MountainCar-v0'</strong></pre>
<p class="calibre2"/>
<p class="calibre2"><strong class="calibre4">Bold</strong>: Indicates a new term, an important word, or w<span class="calibre5">ords that you see onscreen. For example, words in menus or dialog boxes appear in the text like this. Here is an example: "Select <span class="calibre5">System info</span> from the <span class="calibre5">Administration</span> panel.</span><span class="calibre5">"</span></p>
<div class="packt_infobox">Warnings or important notes appear like this.</div>
<div class="packt_tip">Tips and tricks appear like this.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Get in touch</h1>
                
            
            <article>
                
<p class="calibre2">Feedback from our readers is always welcome.</p>
<p class="calibre2"><strong class="calibre4">General feedback</strong>: Email <kbd class="calibre12">feedback@packtpub.com</kbd> and mention the book title in the subject of your message. If you have questions about any aspect of this book, please email us at <kbd class="calibre12">questions@packtpub.com</kbd>.</p>
<p class="calibre2"><strong class="calibre4">Errata</strong>: Although we have taken every care to ensure the accuracy of our content, mistakes do happen. If you have found a mistake in this book, we would be grateful if you would report this to us. Please visit <a href="http://www.packtpub.com/submit-errata" target="_blank" class="calibre9">www.packtpub.com/submit-errata</a>, selecting your book, clicking on the Errata Submission Form link, and entering the details.</p>
<p class="calibre2"><strong class="calibre4">Piracy</strong>: If you come across any illegal copies of our works in any form on the Internet, we would be grateful if you would provide us with the location address or website name. Please contact us at <kbd class="calibre12">copyright@packtpub.com</kbd> with a link to the material.</p>
<p class="calibre2"><strong class="calibre4">If you are interested in becoming an author</strong>: If there is a topic that you have expertise in and you are interested in either writing or contributing to a book, please visit <a href="http://authors.packtpub.com/" target="_blank" class="calibre9">authors.packtpub.com</a>.</p>
<p class="calibre2"/>
<p class="calibre2"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Reviews</h1>
                
            
            <article>
                
<p class="calibre2">Please leave a review. Once you have read and used this book, why not leave a review on the site that you purchased it from? Potential readers can then see and use your unbiased opinion to make purchase decisions, we at Packt can understand what you think about our products, and our authors can see your feedback on their book. Thank you!</p>
<p class="calibre2">For more information about Packt, please visit <a href="https://www.packtpub.com/" target="_blank" class="calibre9">packtpub.com</a>.</p>


            </article>

            
        </section>
    </body></html>