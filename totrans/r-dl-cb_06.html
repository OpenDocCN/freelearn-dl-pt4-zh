<html><head></head><body>
        <section id="7CGBG1-a0a93989f17f4d6cb68b8cfd331bc5ab">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Recurrent Neural Networks</h1>
                
            
            <article>
                
<p class="calibre2">The current chapter will introduce Recurrent Neural Networks used for the modeling of sequential datasets. In this chapter, we will cover:</p>
<ul class="calibre12">
<li class="calibre13">Setting up a basic Recurrent Neural Network</li>
<li class="calibre13">Setting up a bidirectional RNN model</li>
<li class="calibre13">Setting up a deep RNN model</li>
<li class="calibre13">Setting up a Long short-term memory based sequence model</li>
</ul>


            </article>

            
        </section>
    

        <section id="7DES21-a0a93989f17f4d6cb68b8cfd331bc5ab">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Setting up a basic Recurrent Neural Network</h1>
                
            
            <article>
                
<p class="calibre2"><strong class="calibre1">Recurrent Neural Networks</strong> (<strong class="calibre1">RNN</strong>) are used for sequential modeling on datasets where high autocorrelation exists among observations. For example, predicting patient journeys using their historical dataset or predicting the next words in given sentences. The main commonality among these problem statements is that input length is not constant and there is a sequential dependence. Standard neural network and deep learning models are constrained by fixed size input and produce a fixed length output. For example, deep learning neural networks built on occupancy datasets have six input features and a binomial outcome.</p>


            </article>

            
        </section>
    

        <section id="7EDCK1-a0a93989f17f4d6cb68b8cfd331bc5ab">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Getting ready</h1>
                
            
            <article>
                
<p class="calibre2">Generative models in machine learning domains are referred to as models that have an ability to generate observable data values. For example, training a generative model on an images repository to generate new images like it. All generative models aim to compute the joint distribution over given datasets, either implicitly or explicitly:</p>
<ol class="calibre15">
<li value="1" class="calibre13">Install and set up TensorFlow.</li>
<li value="2" class="calibre13">Load required packages:</li>
</ol>
<pre class="calibre23">
library(tensorflow) 
</pre>


            </article>

            
        </section>
    

        <section id="7FBT61-a0a93989f17f4d6cb68b8cfd331bc5ab">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">How to do it...</h1>
                
            
            <article>
                
<p class="calibre2">The section will provide steps to set-up an RNN model.</p>
<ol class="calibre15">
<li value="1" class="calibre13">Load the <kbd class="calibre10">MNIST</kbd> dataset:</li>
</ol>
<pre class="calibre23">
# Load mnist dataset from tensorflow library 
datasets &lt;- tf$contrib$learn$datasets 
mnist &lt;- datasets$mnist$read_data_sets("MNIST-data", one_hot = TRUE) 
</pre>
<ol start="2" class="calibre15">
<li value="2" class="calibre13">Reset the graph and start an interactive session:</li>
</ol>
<pre class="calibre23">
# Reset the graph and set-up a interactive session 
tf$reset_default_graph() 
sess&lt;-tf$InteractiveSession() 
</pre>
<ol start="3" class="calibre15">
<li value="3" class="calibre13">Reduce image size to 16 x 16 pixels using the <kbd class="calibre10">reduceImage</kbd> function from <a href="part0166.html#4U9TC1-a0a93989f17f4d6cb68b8cfd331bc5ab" target="_blank" class="calibre4">Chapter 4</a>, <em class="calibre9">Data Representation using Autoencoders</em>:</li>
</ol>
<pre class="calibre23">
# Covert train data to 16 x 16  pixel image 
trainData&lt;-t(apply(mnist$train$images, 1, FUN=reduceImage)) 
validData&lt;-t(apply(mnist$test$images, 1, FUN=reduceImage)) 
 
</pre>
<ol start="4" class="calibre15">
<li value="4" class="calibre13">Extract labels for the defined <kbd class="calibre10">train</kbd> and <kbd class="calibre10">valid</kbd> datasets:</li>
</ol>
<pre class="calibre23">
labels &lt;- mnist$train$labels 
labels_valid &lt;- mnist$test$labels
</pre>
<ol start="5" class="calibre15">
<li value="5" class="calibre13">Define model parameters such as size of input pixels (<kbd class="calibre10">n_input</kbd>), step size (<kbd class="calibre10">step_size</kbd>), number of hidden layers (<kbd class="calibre10">n.hidden</kbd>), and number of outcome classes (<kbd class="calibre10">n.classes</kbd>):</li>
</ol>
<pre class="calibre23">
# Define Model parameter 
n_input&lt;-16 
step_size&lt;-16 
n.hidden&lt;-64 
n.class&lt;-10 
</pre>
<ol start="6" class="calibre15">
<li value="6" class="calibre13">Define training parameters such as learning rate (<kbd class="calibre10">lr</kbd>), number of inputs per batch run (<kbd class="calibre10">batch</kbd>), and number of iterations (<kbd class="calibre10">iteration</kbd>):</li>
</ol>
<pre class="calibre23">
lr&lt;-0.01 
batch&lt;-500 
iteration = 100 
</pre>
<ol start="7" class="calibre15">
<li value="7" class="calibre13">Define a function <kbd class="calibre10">rnn</kbd> that takes in batch input dataset (<kbd class="calibre10">x</kbd>), weight matrix (<kbd class="calibre10">weight</kbd>), and bias vector (<kbd class="calibre10">bias</kbd>); and returns a final outcome predicted vector of a most basic RNN:</li>
</ol>
<pre class="calibre23">
# Set up a most basic RNN 
rnn&lt;-function(x, weight, bias){ 
  # Unstack input into step_size 
  x = tf$unstack(x, step_size, 1) 
   
  # Define a most basic RNN  
  rnn_cell = tf$contrib$rnn$BasicRNNCell(n.hidden) 
   
  # create a Recurrent Neural Network 
  cell_output = tf$contrib$rnn$static_rnn(rnn_cell, x, dtype=tf$float32) 
   
  # Linear activation, using rnn inner loop  
  last_vec=tail(cell_output[[1]], n=1)[[1]] 
  return(tf$matmul(last_vec, weights) + bias) 
} 
Define a function eval_func to evaluate mean accuracy using actual (y) and predicted labels (yhat): 
# Function to evaluate mean accuracy 
eval_acc&lt;-function(yhat, y){ 
  # Count correct solution 
  correct_Count = tf$equal(tf$argmax(yhat,1L), tf$argmax(y,1L)) 
   
  # Mean accuracy 
  mean_accuracy = tf$reduce_mean(tf$cast(correct_Count, tf$float32)) 
   
  return(mean_accuracy) 
}
</pre>
<ol start="8" class="calibre15">
<li value="8" class="calibre13">Define <kbd class="calibre10">placeholder</kbd> variables (<kbd class="calibre10">x</kbd> and <kbd class="calibre10">y</kbd>) and initialize weight matrix and bias vector:</li>
</ol>
<pre class="calibre23">
with(tf$name_scope('input'), { 
# Define placeholder for input data 
x = tf$placeholder(tf$float32, shape=shape(NULL, step_size, n_input), name='x') 
y &lt;- tf$placeholder(tf$float32, shape(NULL, n.class), name='y') 
 
# Define Weights and bias 
weights &lt;- tf$Variable(tf$random_normal(shape(n.hidden, n.class))) 
bias &lt;- tf$Variable(tf$random_normal(shape(n.class))) 
}) 
</pre>
<ol start="9" class="calibre15">
<li value="9" class="calibre13">Generate the predicted labels:</li>
</ol>
<pre class="calibre23">
# Evaluate rnn cell output 
yhat = rnn(x, weights, bias) 
Define the loss function and optimizer 
cost = tf$reduce_mean(tf$nn$softmax_cross_entropy_with_logits(logits=yhat, labels=y)) 
optimizer = tf$train$AdamOptimizer(learning_rate=lr)$minimize(cost) 
</pre>
<ol start="10" class="calibre15">
<li value="10" class="calibre13">Run the optimization post initializing a session using the global variables initializer:</li>
</ol>
<pre class="calibre23">
sess$run(tf$global_variables_initializer()) 
for(i in 1:iteration){ 
  spls &lt;- sample(1:dim(trainData)[1],batch) 
  sample_data&lt;-trainData[spls,] 
  sample_y&lt;-labels[spls,] 
   
  # Reshape sample into 16 sequence with each of 16 element 
  sample_data=tf$reshape(sample_data, shape(batch, step_size, n_input)) 
  out&lt;-optimizer$run(feed_dict = dict(x=sample_data$eval(), y=sample_y)) 
   
  if (i %% 1 == 0){ 
    cat("iteration - ", i, "Training Loss - ",  cost$eval(feed_dict = dict(x=sample_data$eval(), y=sample_y)), "\n") 
  } 
} 
</pre>
<ol start="11" class="calibre15">
<li value="11" class="calibre13">Get the mean accuracy on <kbd class="calibre10">valid_data</kbd>:</li>
</ol>
<pre class="calibre23">
valid_data=tf$reshape(validData, shape(-1, step_size, n_input)) 
cost$eval(feed_dict=dict(x=valid_data$eval(), y=labels_valid)) 
</pre>


            </article>

            
        </section>
    

        <section id="7GADO1-a0a93989f17f4d6cb68b8cfd331bc5ab">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">How it works...</h1>
                
            
            <article>
                
<p class="calibre2">Any changes to the structure require model retraining. However, these assumptions may not be valid for a lot of sequential datasets, such as text-based classifications that may have varying input and output. RNN architecture helps to address the issue of variable input length.</p>
<p class="calibre2">The standard architecture for RNN with input and output is shown in the following figure:</p>
<div class="cdpaligncenter"><img class="image-border56" src="../images/00135.jpeg"/></div>
<div class="packt_figref">Recurrent Neural Network architecture</div>
<p class="calibre2">The RNN architecture can be formulated as follows:</p>
<div class="cdpaligncenter"><img src="../images/00129.jpeg" class="calibre39"/></div>
<p class="calibre2">Where <img src="../images/00070.jpeg" class="calibre47"/> is state at time/index <em class="calibre9">t</em> and <img src="../images/00096.jpeg" class="calibre48"/> is input at time/index <em class="calibre9">t</em>. The matrix <em class="calibre9">W</em> represents weights to connect hidden nodes and <em class="calibre9">S</em> connects input with the hidden layer. The output node at time/index <em class="calibre9">t</em> is related to state <em class="calibre9">h<sub class="calibre30">t</sub></em> as shown as follows:</p>
<div class="cdpaligncenter"><img src="../images/00019.jpeg" class="calibre39"/></div>
<p class="calibre2">In the previous Equations layer, weights remain constant across state and time.</p>


            </article>

            
        </section>
    

        <section id="7H8UA1-a0a93989f17f4d6cb68b8cfd331bc5ab">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Setting up a bidirectional RNN model</h1>
                
            
            <article>
                
<p class="calibre2">Recurrent Neural Networks focus on capturing the sequential information at time <em class="calibre9">t</em> by using historical states only. However, bidirectional RNN train the model from both directions using two RNN layers with one moving forwards from start to end and another RNN layer moving backwards from end to start of sequence.</p>
<p class="calibre2">Thus, the model is dependent on historical and future data. The bidirectional RNN models are useful where causal structure exists such as in text and speech. The unfolded structure of bidirectional RNN is shown in the following figure:</p>
<div class="cdpaligncenter"><img class="image-border86" src="../images/00033.jpeg"/></div>
<div class="packt_figref">Unfolded bidirectional RNN architecture</div>


            </article>

            
        </section>
    

        <section id="7I7ES1-a0a93989f17f4d6cb68b8cfd331bc5ab">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Getting ready</h1>
                
            
            <article>
                
<p class="calibre2">Install and set up TensorFlow:</p>
<ol class="calibre15">
<li value="1" class="calibre13">Load required packages:</li>
</ol>
<pre class="calibre23">
library(tensorflow) 
</pre>
<ol start="2" class="calibre15">
<li value="2" class="calibre13">Load <kbd class="calibre10">MNIST</kbd> dataset.</li>
<li value="3" class="calibre13">The image from <kbd class="calibre10">MNIST</kbd> dataset is reduced to 16 x 16 pixels and normalized (Details are discussed in the <em class="calibre9">Setting-up RNN model</em> section)<kbd class="calibre10">.</kbd></li>
</ol>


            </article>

            
        </section>
    

        <section id="7J5VE1-a0a93989f17f4d6cb68b8cfd331bc5ab">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">How to do it...</h1>
                
            
            <article>
                
<p class="calibre2">This section covers the steps to set-up a bidirectional RNN model.</p>
<ol class="calibre15">
<li value="1" class="calibre13">Reset the graph and start an interactive session:</li>
</ol>
<pre class="calibre23">
# Reset the graph and set-up a interactive session 
tf$reset_default_graph() 
sess&lt;-tf$InteractiveSession() 
 
</pre>
<ol start="2" class="calibre15">
<li value="2" class="calibre13">Reduce image size to 16 x 16 pixels using the <kbd class="calibre10">reduceImage</kbd> function from <a href="part0166.html#4U9TC1-a0a93989f17f4d6cb68b8cfd331bc5ab" target="_blank" class="calibre4">Chapter 4</a>, <em class="calibre9">Data Representation using Autoencoders</em>:</li>
</ol>
<pre class="calibre23">
# Covert train data to 16 x 16  pixel image 
trainData&lt;-t(apply(mnist$train$images, 1, FUN=reduceImage)) 
validData&lt;-t(apply(mnist$test$images, 1, FUN=reduceImage)) 
</pre>
<ol start="3" class="calibre15">
<li value="3" class="calibre13">Extract labels for the defined <kbd class="calibre10">train</kbd> and <kbd class="calibre10">valid</kbd> datasets:</li>
</ol>
<pre class="calibre23">
labels &lt;- mnist$train$labels 
labels_valid &lt;- mnist$test$labels 
</pre>
<ol start="4" class="calibre15">
<li value="4" class="calibre13">Define model parameters such as the size of input pixels (<kbd class="calibre10">n_input</kbd>), step size (<kbd class="calibre10">step_size</kbd>), number of hidden layers (<kbd class="calibre10">n.hidden</kbd>), and number of outcome classes (<kbd class="calibre10">n.classes</kbd>):</li>
</ol>
<pre class="calibre23">
# Define Model parameter 
n_input&lt;-16 
step_size&lt;-16 
n.hidden&lt;-64 
n.class&lt;-10 
</pre>
<ol start="5" class="calibre15">
<li value="5" class="calibre13">Define training parameters such as learning rate (<kbd class="calibre10">lr</kbd>), number of inputs per batch run (<kbd class="calibre10">batch</kbd>), and number of iterations (<kbd class="calibre10">iteration</kbd>):</li>
</ol>
<pre class="calibre23">
lr&lt;-0.01 
batch&lt;-500 
iteration = 100 
</pre>
<ol start="6" class="calibre15">
<li value="6" class="calibre13">Define a function to perform <kbd class="calibre10">bidirectional</kbd> Recurrent Neural Network:</li>
</ol>
<pre class="calibre23">
bidirectionRNN&lt;-function(x, weights, bias){ 
  # Unstack input into step_size 
  x = tf$unstack(x, step_size, 1) 
   
  # Forward lstm cell 
  rnn_cell_forward = tf$contrib$rnn$BasicRNNCell(n.hidden) 
   
  # Backward lstm cell 
  rnn_cell_backward = tf$contrib$rnn$BasicRNNCell(n.hidden) 
   
  # Get lstm cell output 
  cell_output = tf$contrib$rnn$static_bidirectional_rnn(rnn_cell_forward, rnn_cell_backward, x, dtype=tf$float32) 
   
  # Linear activation, using rnn inner loop last output 
  last_vec=tail(cell_output[[1]], n=1)[[1]] 
  return(tf$matmul(last_vec, weights) + bias) 
} 
</pre>
<ol start="7" class="calibre15">
<li value="7" class="calibre13">Define an <kbd class="calibre10">eval_func</kbd> function to evaluate mean accuracy using actual (<kbd class="calibre10">y</kbd>) and predicted labels (<kbd class="calibre10">yhat</kbd>):</li>
</ol>
<pre class="calibre23">
# Function to evaluate mean accuracy 
eval_acc&lt;-function(yhat, y){ 
  # Count correct solution 
  correct_Count = tf$equal(tf$argmax(yhat,1L), tf$argmax(y,1L)) 
   
  # Mean accuracy 
  mean_accuracy = tf$reduce_mean(tf$cast(correct_Count, tf$float32)) 
   
  return(mean_accuracy) 
} 
</pre>
<ol start="8" class="calibre15">
<li value="8" class="calibre13">Define <kbd class="calibre10">placeholder</kbd> variables (<kbd class="calibre10">x</kbd> and <kbd class="calibre10">y</kbd>) and initialize weight matrix and bias vector:</li>
</ol>
<pre class="calibre23">
with(tf$name_scope('input'), { 
# Define placeholder for input data 
x = tf$placeholder(tf$float32, shape=shape(NULL, step_size, n_input), name='x') 
y &lt;- tf$placeholder(tf$float32, shape(NULL, n.class), name='y') 
 
# Define Weights and bias 
weights &lt;- tf$Variable(tf$random_normal(shape(n.hidden, n.class))) 
bias &lt;- tf$Variable(tf$random_normal(shape(n.class))) 
}) 
</pre>
<ol start="9" class="calibre15">
<li value="9" class="calibre13">Generate the predicted labels:</li>
</ol>
<pre class="calibre23">
# Evaluate rnn cell output 
yhat = bidirectionRNN(x, weights, bias) 
</pre>
<ol start="10" class="calibre15">
<li value="10" class="calibre13">Define the loss function and optimizer:</li>
</ol>
<pre class="calibre23">
cost = tf$reduce_mean(tf$nn$softmax_cross_entropy_with_logits(logits=yhat, labels=y)) 
optimizer = tf$train$AdamOptimizer(learning_rate=lr)$minimize(cost) 
 
</pre>
<ol start="11" class="calibre15">
<li value="11" class="calibre13">Run the optimization post initializing a session using global variables initializer:</li>
</ol>
<pre class="calibre23">
sess$run(tf$global_variables_initializer()) 
# Running optimization 
for(i in 1:iteration){ 
  spls &lt;- sample(1:dim(trainData)[1],batch) 
  sample_data&lt;-trainData[spls,] 
  sample_y&lt;-labels[spls,] 
   
  # Reshape sample into 16 sequence with each of 16 element 
  sample_data=tf$reshape(sample_data, shape(batch, step_size, n_input)) 
  out&lt;-optimizer$run(feed_dict = dict(x=sample_data$eval(), y=sample_y)) 
   
  if (i %% 1 == 0){ 
    cat("iteration - ", i, "Training Loss - ",  cost$eval(feed_dict = dict(x=sample_data$eval(), y=sample_y)), "\n") 
  } 
} 
</pre>
<ol start="12" class="calibre15">
<li value="12" class="calibre13">Get the mean accuracy on valid data:</li>
</ol>
<pre class="calibre23">
valid_data=tf$reshape(validData, shape(-1, step_size, n_input)) 
cost$eval(feed_dict=dict(x=valid_data$eval(), y=labels_valid))
</pre>
<ol start="13" class="calibre15">
<li value="13" class="calibre13">The convergence of cost function for RNN is shown in the following figure:</li>
</ol>
<div class="cdpaligncenter"><img class="image-border87" src="../images/00154.gif"/></div>
<div class="packt_figref">Bidirectional Recurrent Neural Network convergence plot on MNIST dataset</div>


            </article>

            
        </section>
    

        <section id="7K4G01-a0a93989f17f4d6cb68b8cfd331bc5ab">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Setting up a deep RNN model</h1>
                
            
            <article>
                
<p class="calibre2">The RNN architecture is composed of input, hidden, and output layers. A RNN network can be made deep by decomposing the hidden layer into multiple groups or by adding computational nodes within RNN architecture such as including model computation such as multilayer perceptron for micro learning. The computational nodes can be added between input-hidden, hidden-hidden, and hidden-output connection. An example of a multilayer deep RNN model is shown in the following figure:</p>
<div class="cdpaligncenter"><img class="image-border88" src="../images/00093.jpeg"/></div>
<div class="packt_figref">An example of two-layer Deep Recurrent Neural Network architecture</div>


            </article>

            
        </section>
    

        <section id="7L30I1-a0a93989f17f4d6cb68b8cfd331bc5ab">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">How to do it...</h1>
                
            
            <article>
                
<p class="calibre2">The RNN models in TensorFlow can easily be extended to Deep RNN models by using <kbd class="calibre10">MultiRNNCell</kbd>. The previous <kbd class="calibre10">rnn</kbd> function can be replaced with the <kbd class="calibre10">stacked_rnn</kbd>function to achieve a deep RNN architecture:</p>
<ol class="calibre15">
<li value="1" class="calibre13">Define the number of layers in the deep RNN architecture:</li>
</ol>
<pre class="calibre23">
num_layers &lt;- 3 
</pre>
<ol start="2" class="calibre15">
<li value="2" class="calibre13">Define a <kbd class="calibre10">stacked_rnn</kbd> function to perform multi-hidden layers deep RNN:</li>
</ol>
<pre class="calibre23">
stacked_rnn&lt;-function(x, weight, bias){ 
  # Unstack input into step_size 
  x = tf$unstack(x, step_size, 1) 
   
  # Define a most basic RNN  
  network = tf$contrib$rnn$GRUCell(n.hidden) 
  
  # Then, assign stacked RNN cells 
  network = tf$contrib$rnn$MultiRNNCell(lapply(1:num_layers,function(k,network){network},network)) 
   
  # create a Recurrent Neural Network 
  cell_output = tf$contrib$rnn$static_rnn(network, x, dtype=tf$float32) 
   
  # Linear activation, using rnn inner loop  
  last_vec=tail(cell_output[[1]], n=1)[[1]] 
  return(tf$matmul(last_vec, weights) + bias) 
} 
</pre>


            </article>

            
        </section>
    

        <section id="7M1H41-a0a93989f17f4d6cb68b8cfd331bc5ab">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Setting up a Long short-term memory based sequence model</h1>
                
            
            <article>
                
<p class="calibre2">In sequence learning the objective is to capture short-term and long-term memory. The short-term memory is captured very well by standard RNN, however, they are not very effective in capturing long-term dependencies as the gradient vanishes (or explodes rarely) within an RNN chain over time.</p>
<div class="packt_infobox">The gradient vanishes when the weights have small values that on multiplication vanish over time, whereas in contrast, scenarios where weights have large values keep increasing over time and lead to divergence in the learning process. To deal with the issue <strong class="calibre36">Long Short Term Memory</strong> (<strong class="calibre36">LSTM</strong>) is proposed.</div>


            </article>

            
        </section>
    

        <section id="7N01M1-a0a93989f17f4d6cb68b8cfd331bc5ab">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">How to do it...</h1>
                
            
            <article>
                
<p class="calibre2">The RNN models in TensorFlow can easily be extended to LSTM models by using <kbd class="calibre10">BasicLSTMCell</kbd>. The previous <kbd class="calibre10">rnn</kbd> function can be replaced with the <kbd class="calibre10">lstm</kbd> function to achieve an LSTM architecture:</p>
<pre class="calibre20">
# LSTM implementation 
lstm&lt;-function(x, weight, bias){ 
  # Unstack input into step_size 
  x = tf$unstack(x, step_size, 1) 
   
  # Define a lstm cell 
  lstm_cell = tf$contrib$rnn$BasicLSTMCell(n.hidden, forget_bias=1.0, state_is_tuple=TRUE) 
   
  # Get lstm cell output 
  cell_output = tf$contrib$rnn$static_rnn(lstm_cell, x, dtype=tf$float32) 
   
  # Linear activation, using rnn inner loop last output 
  last_vec=tail(cell_output[[1]], n=1)[[1]] 
  return(tf$matmul(last_vec, weights) + bias) 
} 
</pre>
<p class="calibre2">For brevity the other parts of the code are not replicated.</p>


            </article>

            
        </section>
    

        <section id="7NUI81-a0a93989f17f4d6cb68b8cfd331bc5ab">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">How it works...</h1>
                
            
            <article>
                
<p class="calibre2">The LSTM has a similar structure to RNN, however, the basic cell is very different as traditional RNN uses single <strong class="calibre1">multi-layer perceptron</strong> (<strong class="calibre1">MLP</strong>), whereas a single cell of LSTM includes four input layers interacting with each other. These three layers are:</p>
<ul class="calibre12">
<li class="calibre13">forget gate</li>
<li class="calibre13">input gate</li>
<li class="calibre13">output gate</li>
</ul>
<p class="calibre2">The <em class="calibre9">forget gate</em> in LSTM decides which information to throw away and it depends on the last hidden state output <em class="calibre9">h<sub class="calibre30">t-1</sub></em>, <em class="calibre9">X<sub class="calibre30">t</sub></em>, which represents input at time <em class="calibre9">t.</em></p>
<div class="cdpaligncenter"><img class="image-border89" src="../images/00131.jpeg"/></div>
<div class="packt_figref">Illustration of forget gate</div>
<p class="calibre2">In the earlier figure, <em class="calibre9">C<sub class="calibre30">t</sub></em> represents cell state at time <em class="calibre9">t</em>. The input data is represented by <em class="calibre9">X<sub class="calibre30">t</sub></em> and the hidden state is represented as <em class="calibre9">h<sub class="calibre30">t-1</sub></em>. The earlier layer can be formulated as:</p>
<div class="cdpaligncenter"><img src="../images/00141.jpeg" class="calibre39"/></div>
<p class="calibre2">The <em class="calibre9">input gate</em> decides update values and decides the candidate values of the memory cell and updates the cell state, as shown in the following figure:</p>
<div class="cdpaligncenter"><img class="image-border90" src="../images/00098.jpeg"/></div>
<div class="packt_figref">Illustration of input gate</div>
<ul class="calibre12">
<li class="calibre13">The input <em class="calibre9">i<sub class="calibre30">t</sub></em> at time <em class="calibre9">t</em> is updated as:</li>
</ul>
<div class="cdpaligncenter"><img src="../images/00049.jpeg" class="calibre49"/></div>
<div class="cdpaligncenter"><img src="../images/00100.jpeg" class="calibre50"/></div>
<ul class="calibre12">
<li class="calibre13">
<p class="calibre37">The expected value of current state <img src="../images/00136.jpeg" class="calibre48"/> and the output from input gate <img src="../images/00017.jpeg" class="calibre48"/> is used to update the current state <img src="../images/00024.jpeg" class="calibre48"/> at time <em class="calibre9">t</em> as:</p>
</li>
</ul>
<div class="cdpaligncenter"><img src="../images/00036.jpeg" class="calibre51"/></div>
<p class="calibre2">The output gates, as shown in the following figure, compute the output from the LSTM cell based on input <em class="calibre9">X<sub class="calibre30">t</sub></em> , previous layer output <em class="calibre9">h<sub class="calibre30">t-1</sub>,</em> and current state <em class="calibre9">C<sub class="calibre30">t</sub></em>:</p>
<div class="cdpaligncenter"><img class="image-border91" src="../images/00109.jpeg"/></div>
<div class="packt_figref">Illustration of output gate</div>
<p class="calibre2">The output based on <em class="calibre9">output gate</em> can be computed as follows:</p>
<div class="cdpaligncenter"><img src="../images/00094.jpeg" class="calibre52"/></div>
<div class="cdpaligncenter"><img src="../images/00143.jpeg" class="calibre53"/></div>


            </article>

            
        </section>
    </body></html>