["```py\nimport torch\nimport torch_geometric\nfrom torch_geometric.data import Data\nfrom torch_geometric.nn import GCNConv, GAE\nfrom torch_geometric.utils import train_test_split_edges\nfrom torch_geometric.transforms import RandomLinkSplit\nfrom sklearn.manifold import TSNE\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nimport networkx as nx\nfrom sklearn.metrics import roc_auc_score\n```", "```py\npip install torch torch_geometric scikit-learn matplotlib networkx\n```", "```py\n    torch.manual_seed(42)\n    ```", "```py\n    num_nodes = 1000\n    num_features = 10\n    num_classes = 5\n    ```", "```py\n    x = torch.randn((num_nodes, num_features))\n    ```", "```py\n    edge_index = torch.randint(0, num_nodes, (2, 5000))\n    ```", "```py\n    y = torch.randint(0, num_classes, (num_nodes,))\n    ```", "```py\n    data = Data(x=x, edge_index=edge_index, y=y)\n    data.num_classes = num_classes\n    ```", "```py\n    print(f\"Number of nodes: {data.num_nodes}\")\n    print(f\"Number of edges: {data.num_edges}\")\n    print(f\"Number of node features: {data.num_node_features}\")\n    print(f\"Number of classes: {data.num_classes}\")\n    ```", "```py\nNumber of nodes: 1000\nNumber of edges: 5000\nNumber of node features: 10\nNumber of classes: 5\n```", "```py\nclass GCN(torch.nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels):\n        super().__init__()\n        self.conv1 = GCNConv(in_channels, hidden_channels)\n        self.conv2 = GCNConv(hidden_channels, out_channels)\n    def forward(self, x, edge_index):\n        x = self.conv1(x, edge_index).relu()\n        x = self.conv2(x, edge_index)\n        return x\n# Initialize the model\nmodel = GCN(in_channels=num_features,\n            hidden_channels=16,\n            out_channels=num_classes)\n```", "```py\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n    criterion = torch.nn.CrossEntropyLoss()\n    ```", "```py\n    def train():\n        model.train()\n        optimizer.zero_grad()\n        out = model(data.x, data.edge_index)\n        loss = criterion(out, data.y)\n        loss.backward()\n        optimizer.step()\n        return loss\n    ```", "```py\n    def test():\n        model.eval()\n        out = model(data.x, data.edge_index)\n        pred = out.argmax(dim=1)\n        correct = (pred == data.y).sum()\n        acc = int(correct) / int(data.num_nodes)\n        return acc\n    ```", "```py\n    for epoch in range(200):\n        loss = train()\n        if epoch % 10 == 0:\n            acc = test()\n            print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, \\\n                  Accuracy: {acc:.4f}')\n    ```", "```py\n    final_acc = test()\n    print(f\"Final Accuracy: {final_acc:.4f}\")\n    ```", "```py\ndef visualize_predictions(model, data):\n    model.eval()\n    out = model(data.x, data.edge_index)\n    pred = out.argmax(dim=1)\n    plt.figure(figsize=(10, 5))\n    plt.subplot(121)\n    plt.title(\"True Interests\")\n    plt.scatter(\n        data.x[:, 0], data.x[:, 1], c=data.y, cmap='viridis')\n    plt.colorbar()\n    plt.subplot(122)\n    plt.title(\"Predicted Interests\")\n    plt.scatter(\n        data.x[:, 0], data.x[:, 1], c=pred, cmap='viridis')\n    plt.colorbar()\n    plt.tight_layout()\n    plt.show()\nvisualize_predictions(model, data)\n```", "```py\nclass LinkPredictor(torch.nn.Module):\n    def __init__(self, in_channels, hidden_channels):\n        super().__init__()\n        self.encoder = GCNConv(in_channels, hidden_channels)\n    def encode(self, x, edge_index):\n        return self.encoder(x, edge_index).relu()\n    def decode(self, z, edge_label_index):\n        return (\n            z[edge_label_index[0]] * z[edge_label_index[1]]\n        ).sum(dim=-1)\n    def forward(self, x, edge_index, edge_label_index):\n        z = self.encode(x, edge_index)\n        return self.decode(z, edge_label_index)\n# Initialize the model\nmodel = LinkPredictor(in_channels=num_features, hidden_channels=64)\n```", "```py\nfrom torch_geometric.transforms import RandomLinkSplit\n# Prepare data for link prediction\ntransform = RandomLinkSplit(\n    num_val=0.1, num_test=0.1, is_undirected=True,\n    add_negative_train_samples=False\n)\ntrain_data, val_data, test_data = transform(data)\n# Define optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n```", "```py\n    def train_link_predictor():\n        model.train()\n        optimizer.zero_grad()\n        z = model.encode(train_data.x, train_data.edge_index)\n    ```", "```py\n        pos_edge_index = train_data.edge_index\n        neg_edge_index = torch_geometric.utils.negative_sampling(\n            edge_index=pos_edge_index,\n            num_nodes=train_data.num_nodes,\n            num_neg_samples=pos_edge_index.size(1),\n        )\n    ```", "```py\n        edge_label_index = torch.cat([\n            pos_edge_index, neg_edge_index], dim=-1)\n        edge_label = torch.cat([\n            torch.ones(pos_edge_index.size(1)),\n            torch.zeros(neg_edge_index.size(1))\n        ], dim=0)\n    ```", "```py\n        out = model.decode(z, edge_label_index)\n        loss = torch.nn.BCEWithLogitsLoss()(out, edge_label)\n        loss.backward()\n        optimizer.step()\n        return loss\n    ```", "```py\n    def test_link_predictor(data):\n        model.eval()\n        with torch.no_grad():\n            z = model.encode(data.x, data.edge_index)\n            out = model.decode(z, data.edge_label_index)\n    ```", "```py\n        y_true = data.edge_label.cpu().numpy()\n        y_pred = out.cpu().numpy()\n        return roc_auc_score(y_true, y_pred)\n    ```", "```py\n    for epoch in range(100):\n        loss = train_link_predictor()\n        if epoch % 10 == 0:\n    ```", "```py\n            val_auc = test_link_predictor(val_data)\n            print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, \\\n                  Val AUC: {val_auc:.4f}')\n    ```", "```py\n    test_auc = test_link_predictor(test_data)\n    print(f\"Test AUC: {test_auc:.4f}\")\n    ```", "```py\n    Epoch: 000, Loss: 0.6911, Val AUC: 0.5528\n    Epoch: 010, Loss: 0.6779, Val AUC: 0.5297\n    Epoch: 020, Loss: 0.6732, Val AUC: 0.5068\n    Epoch: 030, Loss: 0.6696, Val AUC: 0.5156\n    Epoch: 040, Loss: 0.6666, Val AUC: 0.5172\n    Epoch: 050, Loss: 0.6668, Val AUC: 0.5139\n    Epoch: 060, Loss: 0.6642, Val AUC: 0.5142\n    Epoch: 070, Loss: 0.6631, Val AUC: 0.5132\n    Epoch: 080, Loss: 0.6611, Val AUC: 0.5130\n    Epoch: 090, Loss: 0.6600, Val AUC: 0.5135\n    Test AUC: 0.4843\n    ```", "```py\n    def recommend_friends(student_id, top_k=5):\n        model.eval()\n        with torch.no_grad():\n            z = model.encode(data.x, data.edge_index)\n    ```", "```py\n            other_students = torch.arange(data.num_nodes)\n            other_students = other_students[\n                other_students != student_id]\n            edge_index = torch.stack([\n                torch.full_like(other_students, student_id),\n                other_students\n            ])\n    ```", "```py\n            scores = model.decode(z, edge_index)\n            top_scores, top_indices = scores.topk(top_k)\n            recommended_friends = other_students[top_indices]\n    ```", "```py\n        return recommended_friends, top_scores\n    # Example usage\n    student_id = 42  # Example student ID\n    recommended_friends, scores = recommend_friends(student_id)\n    print(f\"Top 5 friend recommendations for student {student_id}:\")\n    for friend, score in zip(recommended_friends, scores):\n        print(f\"Student {friend.item()}: Score {score:.4f}\")\n    ```", "```py\n    Top 5 friend recommendations for student 42:\n    Student 381: Score 1.8088\n    Student 91: Score 1.6567\n    Student 662: Score 1.5878\n    Student 467: Score 1.5143\n    Student 870: Score 1.4449\n    ```"]