["```py\nmodel = Net().to(device)\n```", "```py\ntrace_input = torch.rand(BATCH_SIZE, IMG_CHANNEL, IMG_HEIGHT, IMG_WIDTH).to(device)\ntraced_model = torch.jit.trace(model, trace_input)\n```", "```py\ntraced_model.save(\"model_jit.pth\")\n```", "```py\ntorch::Device device = torch::kCUDA;\nstd::shared_ptr<torch::jit::script::Module> module = torch::jit::load(\"model_jit.pth\");\nmodule->to(device);\n```", "```py\nstd::vector<torch::jit::IValue> inputs;\ninputs.push_back(torch::ones({BATCH_SIZE, IMG_CHANNEL, IMG_HEIGHT, IMG_WIDTH}).to(device));\nat::Tensor output = module->forward(inputs).toTensor();\n```", "```py\n$ python -m torch.distributed.launch --nproc_per_node=NUM_GPUS YOUR_SCRIPT.py --YOUR_ARGUMENTS\n```", "```py\n# Node 1\n$ python -m torch.distributed.launch --nproc_per_node=NUM_GPUS --nnodes=2 --node_rank=0 --master_addr=MASTER_IP --master_port=MASTER_PORT YOUR_SCRIPT.py --YOUR_ARGUMENTS\n# Node 2\n$ python -m torch.distributed.launch --nproc_per_node=NUM_GPUS --nnodes=2 --node_rank=1 --master_addr=MASTER_IP --master_port=MASTER_PORT YOUR_SCRIPT.py --YOUR_ARGUMENTS\n```", "```py\ndependencies = ['torch']\n\ndef cnn(pretrained=True, *args, **kwargs):\n    model = Net()\n    checkpoint = 'models/cnn.pth'\n    if pretrained:\n        model.load_state_dict(torch.load(checkpoint))\n    return model\n```", "```py\n    if pretrained:\n        import torch.utils.model_zoo as model_zoo\n        model.load_state_dict(model_zoo.load_url(checkpoint))\n```", "```py\nimport torch.hub as hub\nmodel = hub.load(\"johnhany/torchhub:master\", \"cnn\", force_reload=True, pretrained=True).to(device)\n```", "```py\n$ sudo add-apt-repository ppa:graphics-drivers/ppa\n$ sudo apt-get update\n```", "```py\n$ ubuntu-drivers devices\n```", "```py\n== /sys/devices/pci0000:00/0000:00:01.0/0000:01:00.0 ==\nmodalias : pci:v000010DEd00001B06sv00001458sd00003752bc03sc00i00\nvendor : NVIDIA Corporation\nmodel : GP102 [GeForce GTX 1080 Ti]\ndriver : nvidia-driver-390 - third-party free\ndriver : nvidia-driver-396 - third-party free\ndriver : nvidia-driver-415 - third-party free recommended\ndriver : nvidia-driver-410 - third-party free\ndriver : xserver-xorg-video-nouveau - distro free builtin\n```", "```py\n$ sudo ubuntu-drivers autoinstall\n```", "```py\n$ cd ~/Downloads\n$ sudo chmod +x cuda_10.1.243_418.86.00_linux.run\n$ sudo sh cuda_10.1.243_418.86.00_linux.run\n```", "```py\n$ export PATH=$PATH:/usr/local/cuda/bin\n$ export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64\n```", "```py\nPATH=$PATH:/usr/local/cuda/bin\nLD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64\n```", "```py\n$ cd ~/Downloads\n$ tar -xzvf cudnn-10.0-linux-x64-v7.5.0.56.tgz\n```", "```py\n$ sudo cp cuda/include/cudnn.h /usr/local/cuda/include\n$ sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64\n$ sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*\n```", "```py\n> .\\deviceQuery.exe\n```", "```py\nCUDA Device Query (Runtime API) version (CUDART static linking)\n\nDetected 1 CUDA Capable device(s)\n\nDevice 0: \"GeForce GTX 1080 Ti\"\n CUDA Driver Version / Runtime Version 10.0 / 10.0\n CUDA Capability Major/Minor version number: 6.1\n Total amount of global memory: 11175 MBytes (11718230016 bytes)\n...\nResult = PASS\n```", "```py\n$ cd 1_Utilities/deviceQuery\n$ make\n```", "```py\n$ cd ../../bin/x86_64/linux/release\n$ ./deviceQuery\n```", "```py\n$ cd ~/Downloads\n$ chmod +x Anaconda3-2018.12-Linux-x86_64.sh\n$./Anaconda3-2018.12-Linux-x86_64.sh\n```", "```py\n#For Python 2\n$ pip install numpy scipy opencv-python matplotlib\n#For Python 3\n$ pip3 install numpy scipy opencv-python matplotlib\n```", "```py\n(torch-nt)$ conda install numpy pyyaml mkl mkl-include setuptools cmake cffi typing\n(torch-nt)$ conda install magma-cuda100 -c pytorch\n```", "```py\n(torch-nt)$ git clone --recursive https://github.com/pytorch/pytorch\n(torch-nt)$ cd pytorch\n(torch-nt)$ export CMAKE_PREFIX_PATH=\"/home/john/anaconda3/envs/torch-nt\"\n(torch-nt)$ python setup.py install\n```", "```py\nimport torch\n\nprint(\"PyTorch version: {}\".format(torch.__version__))\nprint(\"CUDA version: {}\".format(torch.version.cuda))\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\na = torch.randn(1, 10).to(device)\nb = torch.randn(10, 1).to(device)\nc = a @ b\nprint(c.item())\n```", "```py\n$ conda activate torch\n$ python pytorch_test.py\n```", "```py\nPyTorch version: 1.3.1\nCUDA version: 10.1.243\ncuda\n-2.18083119392395\n```", "```py\n    \"python.pythonPath\": \"C:\\\\Users\\\\John\\\\Anaconda3\\\\envs\\\\torch\"\n```", "```py\n    \"python.pythonPath\": \"~/anaconda3/envs/torch/bin/python3\"\n```"]