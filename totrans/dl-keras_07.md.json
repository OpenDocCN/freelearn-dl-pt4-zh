["```py\nfrom keras.models import Sequential\nfrom keras.layers.core import dense, Activation\n\nmodel = Sequential([\n   dense(32, input_dim=784),\n   Activation(\"sigmoid\"),\n   dense(10),\n   Activation(\"softmax\"),\n])\n\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n\n```", "```py\nfrom keras.layers import Input\nfrom keras.layers.core import dense\nfrom keras.models import Model\nfrom keras.layers.core import Activation\n\ninputs = Input(shape=(784,))\n\nx = dense(32)(inputs)\nx = Activation(\"sigmoid\")(x)\nx = dense(10)(x)\npredictions = Activation(\"softmax\")(x)\n\nmodel = Model(inputs=inputs, outputs=predictions)\n\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n\n```", "```py\nsequence_predictions = TimeDistributed(model)(input_sequences)\n\n```", "```py\nmodel = Model(inputs=[input1, input2], outputs=[output1, output2])\n\n```", "```py\nfrom keras.layers import Input\nfrom keras.layers.core import dense\nfrom keras.models import Model\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport pandas as pd\n\n```", "```py\nDATA_DIR = \"../data\"\nAIRQUALITY_FILE = os.path.join(DATA_DIR, \"AirQualityUCI.csv\")\n\naqdf = pd.read_csv(AIRQUALITY_FILE, sep=\";\", decimal=\",\", header=0)\n\n# remove first and last 2 cols \ndel aqdf[\"Date\"]\ndel aqdf[\"Time\"]\ndel aqdf[\"Unnamed: 15\"]\ndel aqdf[\"Unnamed: 16\"]\n\n# fill NaNs in each column with the mean value\naqdf = aqdf.fillna(aqdf.mean())\n\nXorig = aqdf.as_matrix()\n\n```", "```py\nscaler = StandardScaler()\nXscaled = scaler.fit_transform(Xorig)\n# store these off for predictions with unseen data\nXmeans = scaler.mean_\nXstds = scaler.scale_\n\ny = Xscaled[:, 3]\nX = np.delete(Xscaled, 3, axis=1)\n\n```", "```py\ntrain_size = int(0.7 * X.shape[0])\nXtrain, Xtest, ytrain, ytest = X[0:train_size], X[train_size:], \n    y[0:train_size], y[train_size:]\n\n```", "```py\nreadings = Input(shape=(12,))\nx = dense(8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")(readings)\nbenzene = dense(1, kernel_initializer=\"glorot_uniform\")(x)\n\nmodel = Model(inputs=[readings], outputs=[benzene])\nmodel.compile(loss=\"mse\", optimizer=\"adam\")\n\n```", "```py\nNUM_EPOCHS = 20\nBATCH_SIZE = 10\n\nhistory = model.fit(Xtrain, ytrain, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS,\n    validation_split=0.2)\n\n```", "```py\nytest_ = model.predict(Xtest).flatten()\nfor i in range(10):\n    label = (ytest[i] * Xstds[3]) + Xmeans[3]\n    prediction = (ytest_[i] * Xstds[3]) + Xmeans[3]\n    print(\"Benzene Conc. expected: {:.3f}, predicted: {:.3f}\".format(label, prediction))\n\n```", "```py\nBenzene Conc. expected: 4.600, predicted: 5.254\nBenzene Conc. expected: 5.500, predicted: 4.932\nBenzene Conc. expected: 6.500, predicted: 5.664\nBenzene Conc. expected: 10.300, predicted: 8.482\nBenzene Conc. expected: 8.900, predicted: 6.705\nBenzene Conc. expected: 14.000, predicted: 12.928\nBenzene Conc. expected: 9.200, predicted: 7.128\nBenzene Conc. expected: 8.200, predicted: 5.983\nBenzene Conc. expected: 7.200, predicted: 6.256\nBenzene Conc. expected: 5.500, predicted: 5.184\n\n```", "```py\nplt.plot(np.arange(ytest.shape[0]), (ytest * Xstds[3]) / Xmeans[3], \n    color=\"b\", label=\"actual\")\nplt.plot(np.arange(ytest_.shape[0]), (ytest_ * Xstds[3]) / Xmeans[3], \n    color=\"r\", alpha=0.5, label=\"predicted\")\nplt.xlabel(\"time\")\nplt.ylabel(\"C6H6 concentrations\")\nplt.legend(loc=\"best\")\nplt.show()\n\n```", "```py\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.layers import Input\nfrom keras.layers.core import RepeatVector\nfrom keras.layers.recurrent import LSTM\nfrom keras.layers.wrappers import Bidirectional\nfrom keras.models import Model\nfrom keras.preprocessing import sequence\nfrom scipy.stats import describe\nimport collections\nimport matplotlib.pyplot as plt\nimport nltk\nimport numpy as np\nimport os\n\n```", "```py\nsents = []\nfsent = open(sent_filename, \"rb\")\nfor line in fsent:\n    docid, sent_id, sent = line.strip().split(\"t\")\n    sents.append(sent)\nfsent.close()\n\n```", "```py\ndef is_number(n):\n    temp = re.sub(\"[.,-/]\", \"\", n)\n    return temp.isdigit()\n\nword_freqs = collections.Counter()\nsent_lens = []\nparsed_sentences = []\nfor sent in sentences:\n    words = nltk.word_tokenize(sent)\n    parsed_words = []\n    for word in words:\n        if is_number(word):\n            word = \"9\"\n        word_freqs[word.lower()] += 1\n        parsed_words.append(word)\n    sent_lens.append(len(words))\n    parsed_sentences.append(\" \".join(parsed_words))\n\n```", "```py\nsent_lens = np.array(sent_lens)\nprint(\"number of sentences: {:d}\".format(len(sent_lens)))\nprint(\"distribution of sentence lengths (number of words)\")\nprint(\"min:{:d}, max:{:d}, mean:{:.3f}, med:{:.3f}\".format(\nnp.min(sent_lens), np.max(sent_lens), np.mean(sent_lens),\nnp.median(sent_lens)))\nprint(\"vocab size (full): {:d}\".format(len(word_freqs)))\n\n```", "```py\nnumber of sentences: 131545\n distribution of sentence lengths (number of words)\n min: 1, max: 429, mean: 22.315, median: 21.000\n vocab size (full): 50751\n\n```", "```py\nVOCAB_SIZE = 5000\nSEQUENCE_LEN = 50\n\n```", "```py\nword2id = {}\nword2id[\"PAD\"] = 0\nword2id[\"UNK\"] = 1\nfor v, (k, _) in enumerate(word_freqs.most_common(VOCAB_SIZE - 2)):\n    word2id[k] = v + 2\nid2word = {v:k for k, v in word2id.items()}\n\n```", "```py\nEMBED_SIZE = 50\n\ndef lookup_word2id(word):\n    try:\n        return word2id[word]\n    except KeyError:\n        return word2id[\"UNK\"]\n\ndef load_glove_vectors(glove_file, word2id, embed_size):\n    embedding = np.zeros((len(word2id), embed_size))\n    fglove = open(glove_file, \"rb\")\n    for line in fglove:\n        cols = line.strip().split()\n        word = cols[0]\n        if embed_size == 0:\n            embed_size = len(cols) - 1\n        if word2id.has_key(word):\n            vec = np.array([float(v) for v in cols[1:]])\n        embedding[lookup_word2id(word)] = vec\n    embedding[word2id[\"PAD\"]] = np.zeros((embed_size))\n    embedding[word2id[\"UNK\"]] = np.random.uniform(-1, 1, embed_size)\n    return embedding\n\nembeddings = load_glove_vectors(os.path.join(\n    DATA_DIR, \"glove.6B.{:d}d.txt\".format(EMBED_SIZE)), word2id, EMBED_SIZE)\n\n```", "```py\nBATCH_SIZE = 64\n\ndef sentence_generator(X, embeddings, batch_size):\n    while True:\n        # loop once per epoch\n        num_recs = X.shape[0]\n        indices = np.random.permutation(np.arange(num_recs))\n        num_batches = num_recs // batch_size\n        for bid in range(num_batches):\n            sids = indices[bid * batch_size : (bid + 1) * batch_size]\n            Xbatch = embeddings[X[sids, :]]\n            yield Xbatch, Xbatch\n\ntrain_size = 0.7\nXtrain, Xtest = train_test_split(sent_wids, train_size=train_size)\ntrain_gen = sentence_generator(Xtrain, embeddings, BATCH_SIZE)\ntest_gen = sentence_generator(Xtest, embeddings, BATCH_SIZE)\n\n```", "```py\ninputs = Input(shape=(SEQUENCE_LEN, EMBED_SIZE), name=\"input\")\nencoded = Bidirectional(LSTM(LATENT_SIZE), merge_mode=\"sum\",\n    name=\"encoder_lstm\")(inputs)\ndecoded = RepeatVector(SEQUENCE_LEN, name=\"repeater\")(encoded)\ndecoded = Bidirectional(LSTM(EMBED_SIZE, return_sequences=True),\n    merge_mode=\"sum\",\n    name=\"decoder_lstm\")(decoded)\n\nautoencoder = Model(inputs, decoded)\n\nautoencoder.compile(optimizer=\"sgd\", loss=\"mse\")\n\n```", "```py\nnum_train_steps = len(Xtrain) // BATCH_SIZE\nnum_test_steps = len(Xtest) // BATCH_SIZE\ncheckpoint = ModelCheckpoint(filepath=os.path.join(DATA_DIR,\n    \"sent-thoughts-autoencoder.h5\"), save_best_only=True)\nhistory = autoencoder.fit_generator(train_gen,\n    steps_per_epoch=num_train_steps,\n    epochs=NUM_EPOCHS,\n    validation_data=test_gen,\n    validation_steps=num_test_steps,\n    callbacks=[checkpoint])\n\n```", "```py\nencoder = Model(autoencoder.input, autoencoder.get_layer(\"encoder_lstm\").output)\n\n```", "```py\ndef compute_cosine_similarity(x, y):\n    return np.dot(x, y) / (np.linalg.norm(x, 2) * np.linalg.norm(y, 2))\n\nk = 500\ncosims = np.zeros((k))\ni = 0\nfor bid in range(num_test_steps):\n    xtest, ytest = test_gen.next()\n    ytest_ = autoencoder.predict(xtest)\n    Xvec = encoder.predict(xtest)\n    Yvec = encoder.predict(ytest_)\n    for rid in range(Xvec.shape[0]):\n        if i >= k:\n            break\n        cosims[i] = compute_cosine_similarity(Xvec[rid], Yvec[rid])\n        if i <= 10:\n            print(cosims[i])\n            i += 1\nif i >= k:\n    break\n\n```", "```py\n0.982818722725\n0.970908224583\n0.98131018877\n0.974798440933\n0.968060493469\n0.976065933704\n0.96712064743\n0.949920475483\n0.973583400249\n0.980291545391\n0.817819952965\n\n```", "```py\nfrom keras.layers import Input\nfrom keras.layers.core import Activation, dense, Dropout, Permute\nfrom keras.layers.embeddings import Embedding\nfrom keras.layers.merge import add, concatenate, dot\nfrom keras.layers.recurrent import LSTM\nfrom keras.models import Model\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.utils import np_utils\nimport collections\nimport itertools\nimport nltk\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\n\n```", "```py\nDATA_DIR = \"../data\"\nTRAIN_FILE = os.path.join(DATA_DIR, \"qa1_single-supporting-fact_train.txt\")\nTEST_FILE = os.path.join(DATA_DIR, \"qa1_single-supporting-fact_test.txt\")\n\ndef get_data(infile):\n    stories, questions, answers = [], [], []\n    story_text = []\n    fin = open(TRAIN_FILE, \"rb\")\n    for line in fin:\n        line = line.decode(\"utf-8\").strip()\n        lno, text = line.split(\" \", 1)\n        if \"t\" in text:\n            question, answer, _ = text.split(\"t\")\n            stories.append(story_text)\n            questions.append(question)\n            answers.append(answer)\n            story_text = []\n        else:\n            story_text.append(text)\n    fin.close()\n    return stories, questions, answers\n\ndata_train = get_data(TRAIN_FILE)\ndata_test = get_data(TEST_FILE)\n\n```", "```py\ndef build_vocab(train_data, test_data):\n    counter = collections.Counter()\n    for stories, questions, answers in [train_data, test_data]:\n        for story in stories:\n            for sent in story:\n                for word in nltk.word_tokenize(sent):\n                    counter[word.lower()] += 1\n                for question in questions:\n                    for word in nltk.word_tokenize(question):\n                         counter[word.lower()] += 1\n                for answer in answers:\n                    for word in nltk.word_tokenize(answer):\n                         counter[word.lower()] += 1\n    word2idx = {w:(i+1) for i, (w, _) in enumerate(counter.most_common())}\n    word2idx[\"PAD\"] = 0\nidx2word = {v:k for k, v in word2idx.items()}\n    return word2idx, idx2word\n\nword2idx, idx2word = build_vocab(data_train, data_test)\n\nvocab_size = len(word2idx)\n\n```", "```py\ndef get_maxlens(train_data, test_data):\n    story_maxlen, question_maxlen = 0, 0\n    for stories, questions, _ in [train_data, test_data]:\n        for story in stories:\n            story_len = 0\n            for sent in story:\n                swords = nltk.word_tokenize(sent)\n                story_len += len(swords)\n            if story_len > story_maxlen:\n                story_maxlen = story_len\n        for question in questions:\n            question_len = len(nltk.word_tokenize(question))\n            if question_len > question_maxlen:\n                question_maxlen = question_len\n    return story_maxlen, question_maxlen\n\nstory_maxlen, question_maxlen = get_maxlens(data_train, data_test)\n\n```", "```py\ndef vectorize(data, word2idx, story_maxlen, question_maxlen):\n    Xs, Xq, Y = [], [], []\n    stories, questions, answers = data\n    for story, question, answer in zip(stories, questions, answers):\n        xs = [[word2idx[w.lower()] for w in nltk.word_tokenize(s)] \n                   for s in story]\n        xs = list(itertools.chain.from_iterable(xs))\n        xq = [word2idx[w.lower()] for w in nltk.word_tokenize(question)]\n        Xs.append(xs)\n        Xq.append(xq)\n        Y.append(word2idx[answer.lower()])\n    return pad_sequences(Xs, maxlen=story_maxlen),\n        pad_sequences(Xq, maxlen=question_maxlen),\n        np_utils.to_categorical(Y, num_classes=len(word2idx))\n\nXstrain, Xqtrain, Ytrain = vectorize(data_train, word2idx, story_maxlen, question_maxlen)\nXstest, Xqtest, Ytest = vectorize(data_test, word2idx, story_maxlen, question_maxlen)\n\n```", "```py\nEMBEDDING_SIZE = 64\nLATENT_SIZE = 32\n\n# inputs\nstory_input = Input(shape=(story_maxlen,))\nquestion_input = Input(shape=(question_maxlen,))\n\n# story encoder memory\nstory_encoder = Embedding(input_dim=vocab_size,\noutput_dim=EMBEDDING_SIZE,\n    input_length=story_maxlen)(story_input)\nstory_encoder = Dropout(0.3)(story_encoder)\n\n# question encoder\nquestion_encoder = Embedding(input_dim=vocab_size,\noutput_dim=EMBEDDING_SIZE,\n    input_length=question_maxlen)(question_input)\nquestion_encoder = Dropout(0.3)(question_encoder)\n\n# match between story and question\nmatch = dot([story_encoder, question_encoder], axes=[2, 2])\n\n# encode story into vector space of question\nstory_encoder_c = Embedding(input_dim=vocab_size,\noutput_dim=question_maxlen,\n    input_length=story_maxlen)(story_input)\nstory_encoder_c = Dropout(0.3)(story_encoder_c)\n\n# combine match and story vectors\nresponse = add([match, story_encoder_c])\nresponse = Permute((2, 1))(response)\n\n# combine response and question vectors\nanswer = concatenate([response, question_encoder], axis=-1)\nanswer = LSTM(LATENT_SIZE)(answer)\nanswer = Dropout(0.3)(answer)\nanswer = dense(vocab_size)(answer)\noutput = Activation(\"softmax\")(answer)\n\nmodel = Model(inputs=[story_input, question_input], outputs=output)\nmodel.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"])\n\n```", "```py\nBATCH_SIZE = 32\nNUM_EPOCHS = 50\nhistory = model.fit([Xstrain, Xqtrain], [Ytrain], batch_size=BATCH_SIZE, \n    epochs=NUM_EPOCHS,\n    validation_data=([Xstest, Xqtest], [Ytest]))\n\n```", "```py\nytest = np.argmax(Ytest, axis=1)\nYtest_ = model.predict([Xstest, Xqtest])\nytest_ = np.argmax(Ytest_, axis=1)\n\nfor i in range(NUM_DISPLAY):\n    story = \" \".join([idx2word[x] for x in Xstest[i].tolist() if x != 0])\n    question = \" \".join([idx2word[x] for x in Xqtest[i].tolist()])\n    label = idx2word[ytest[i]]\n    prediction = idx2word[ytest_[i]]\n    print(story, question, label, prediction)\n\n```", "```py\nmodel.add(lambda(lambda x: x ** 2))\n\n```", "```py\ndef euclidean_distance(vecs):\n    x, y = vecs\n    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n\ndef euclidean_distance_output_shape(shapes):\n    shape1, shape2 = shapes\n    return (shape1[0], 1)\n\n```", "```py\nlhs_input = Input(shape=(VECTOR_SIZE,))\nlhs = dense(1024, kernel_initializer=\"glorot_uniform\", activation=\"relu\")(lhs_input)\n\nrhs_input = Input(shape=(VECTOR_SIZE,))\nrhs = dense(1024, kernel_initializer=\"glorot_uniform\", activation=\"relu\")(rhs_input)\n\nsim = lambda(euclidean_distance, output_shape=euclidean_distance_output_shape)([lhs, rhs])\n\n```", "```py\nfrom keras.models import Sequential\nfrom keras.layers.core import Dropout, Reshape\n\ndef test_layer(layer, x):\n    layer_config = layer.get_config()\n    layer_config[\"input_shape\"] = x.shape\n    layer = layer.__class__.from_config(layer_config)\n    model = Sequential()\n    model.add(layer)\n    model.compile(\"rmsprop\", \"mse\")\n    x_ = np.expand_dims(x, axis=0)\n    return model.predict(x_)[0]\n\n```", "```py\nfrom keras.layers.core import Dropout, Reshape\nfrom keras.layers.convolutional import ZeroPadding2D\nimport numpy as np\n\nx = np.random.randn(10, 10)\nlayer = Dropout(0.5)\ny = test_layer(layer, x)\nassert(x.shape == y.shape)\n\nx = np.random.randn(10, 10, 3)\nlayer = ZeroPadding2D(padding=(1,1))\ny = test_layer(layer, x)\nassert(x.shape[0] + 2 == y.shape[0])\nassert(x.shape[1] + 2 == y.shape[1])\n\nx = np.random.randn(10, 10)\nlayer = Reshape((5, 20))\ny = test_layer(layer, x)\nassert(y.shape == (5, 20))\n\n```", "```py\nfrom keras import backend as K\nfrom keras.engine.topology import Layer, InputSpec\n\nclass LocalResponseNormalization(Layer):\n\n    def __init__(self, n=5, alpha=0.0005, beta=0.75, k=2, **kwargs):\n        self.n = n\n        self.alpha = alpha\n        self.beta = beta\n        self.k = k\n        super(LocalResponseNormalization, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        self.shape = input_shape\n        super(LocalResponseNormalization, self).build(input_shape)\n\n    def call(self, x, mask=None):\n        if K.image_dim_ordering == \"th\":\n            _, f, r, c = self.shape\n        else:\n            _, r, c, f = self.shape\n        squared = K.square(x)\n        pooled = K.pool2d(squared, (n, n), strides=(1, 1),\n            padding=\"same\", pool_mode=\"avg\")\n        if K.image_dim_ordering == \"th\":\n            summed = K.sum(pooled, axis=1, keepdims=True)\n            averaged = self.alpha * K.repeat_elements(summed, f, axis=1)\n        else:\n            summed = K.sum(pooled, axis=3, keepdims=True)\n            averaged = self.alpha * K.repeat_elements(summed, f, axis=3)\n        denom = K.pow(self.k + averaged, self.beta)\n        return x / denom\n\n    def get_output_shape_for(self, input_shape):\n        return input_shape\n\n```", "```py\nx = np.random.randn(225, 225, 3)\nlayer = LocalResponseNormalization()\ny = test_layer(layer, x)\nassert(x.shape == y.shape)\n\n```", "```py\nfrom keras import backend as K\nfrom keras.applications import vgg16\nfrom keras.layers import Input\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n```", "```py\nDATA_DIR = \"../data\"\nIMAGE_FILE = os.path.join(DATA_DIR, \"cat.jpg\")\nimg = plt.imread(IMAGE_FILE)\nplt.imshow(img)\n\n```", "```py\ndef preprocess(img):\n    img4d = img.copy()\n    img4d = img4d.astype(\"float64\")\n    if K.image_dim_ordering() == \"th\":\n        # (H, W, C) -> (C, H, W)\n        img4d = img4d.transpose((2, 0, 1))\n        img4d = np.expand_dims(img4d, axis=0)\n        img4d = vgg16.preprocess_input(img4d)\n    return img4d\n\ndef deprocess(img4d):\n    img = img4d.copy()\n    if K.image_dim_ordering() == \"th\":\n        # (B, C, H, W)\n        img = img.reshape((img4d.shape[1], img4d.shape[2],         img4d.shape[3]))\n        # (C, H, W) -> (H, W, C)\n        img = img.transpose((1, 2, 0))\n    else:\n        # (B, H, W, C)\n        img = img.reshape((img4d.shape[1], img4d.shape[2], img4d.shape[3]))\n    img[:, :, 0] += 103.939\n    img[:, :, 1] += 116.779\n    img[:, :, 2] += 123.68\n    # BGR -> RGB\n    img = img[:, :, ::-1]\n    img = np.clip(img, 0, 255).astype(\"uint8\")\nreturn img\n\n```", "```py\nimg_copy = img.copy()\nprint(\"Original image shape:\", img.shape)\np_img = preprocess(img_copy)\nbatch_shape = p_img.shape\ndream = Input(batch_shape=batch_shape)\nmodel = vgg16.VGG16(input_tensor=dream, weights=\"imagenet\", include_top=False)\n\n```", "```py\nlayer_dict = {layer.name : layer for layer in model.layers}\nprint(layer_dict)\n\n```", "```py\n{'block1_conv1': <keras.layers.convolutional.Convolution2D at 0x11b847690>,\n 'block1_conv2': <keras.layers.convolutional.Convolution2D at 0x11b847f90>,\n 'block1_pool': <keras.layers.pooling.MaxPooling2D at 0x11c45db90>,\n 'block2_conv1': <keras.layers.convolutional.Convolution2D at 0x11c45ddd0>,\n 'block2_conv2': <keras.layers.convolutional.Convolution2D at 0x11b88f810>,\n 'block2_pool': <keras.layers.pooling.MaxPooling2D at 0x11c2d2690>,\n 'block3_conv1': <keras.layers.convolutional.Convolution2D at 0x11c47b890>,\n 'block3_conv2': <keras.layers.convolutional.Convolution2D at 0x11c510290>,\n 'block3_conv3': <keras.layers.convolutional.Convolution2D at 0x11c4afa10>,\n 'block3_pool': <keras.layers.pooling.MaxPooling2D at 0x11c334a10>,\n 'block4_conv1': <keras.layers.convolutional.Convolution2D at 0x11c345b10>,\n 'block4_conv2': <keras.layers.convolutional.Convolution2D at 0x11c345950>,\n 'block4_conv3': <keras.layers.convolutional.Convolution2D at 0x11d52c910>,\n 'block4_pool': <keras.layers.pooling.MaxPooling2D at 0x11d550c90>,\n 'block5_conv1': <keras.layers.convolutional.Convolution2D at 0x11d566c50>,\n 'block5_conv2': <keras.layers.convolutional.Convolution2D at 0x11d5b1910>,\n 'block5_conv3': <keras.layers.convolutional.Convolution2D at 0x11d5b1710>,\n 'block5_pool': <keras.layers.pooling.MaxPooling2D at 0x11fd68e10>,\n 'input_1': <keras.engine.topology.InputLayer at 0x11b847410>}\n\n```", "```py\nnum_pool_layers = 5\nnum_iters_per_layer = 3\nstep = 100\n\nfor i in range(num_pool_layers):\n    # identify each pooling layer\n    layer_name = \"block{:d}_pool\".format(i+1)\n    # build loss function that maximizes the mean activation in layer\n    layer_output = layer_dict[layer_name].output\n    loss = K.mean(layer_output)\n    # compute gradient of image wrt loss and normalize\n    grads = K.gradients(loss, dream)[0]\n    grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n    # define function to return loss and grad given input image\n    f = K.function([dream], [loss, grads])\n    img_value = p_img.copy()\n    fig, axes = plt.subplots(1, num_iters_per_layer, figsize=(20, 10))\n    for it in range(num_iters_per_layer):\n        loss_value, grads_value = f([img_value])\n        img_value += grads_value * step \n        axes[it].imshow(deprocess(img_value))\n    plt.show()\n\n```", "```py\nimg_noise = np.random.randint(100, 150, size=(227, 227, 3), dtype=np.uint8)\nplt.imshow(img_noise)\n\n```", "```py\nloss = layer_output[:, :, :, 24]\n\n```", "```py\nfrom keras.applications import vgg16\nfrom keras import backend as K\nfrom scipy.misc import imresize\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n```", "```py\nDATA_DIR = \"../data\"\nCONTENT_IMAGE_FILE = os.path.join(DATA_DIR, \"cat.jpg\")\nSTYLE_IMAGE_FILE = os.path.join(DATA_DIR, \"JapaneseBridgeMonetCopy.jpg\")\nRESIZED_WH = 400\n\ncontent_img_value = imresize(plt.imread(CONTENT_IMAGE_FILE), (RESIZED_WH, RESIZED_WH))\nstyle_img_value = imresize(plt.imread(STYLE_IMAGE_FILE), (RESIZED_WH, RESIZED_WH))\n\nplt.subplot(121)\nplt.title(\"content\")\nplt.imshow(content_img_value)\n\nplt.subplot(122)\nplt.title(\"style\")\nplt.imshow(style_img_value)\n\nplt.show()\n\n```", "```py\ndef preprocess(img):\n    img4d = img.copy()\n    img4d = img4d.astype(\"float64\")\n    if K.image_dim_ordering() == \"th\":\n        # (H, W, C) -> (C, H, W)\n        img4d = img4d.transpose((2, 0, 1))\n    img4d = np.expand_dims(img4d, axis=0)\n    img4d = vgg16.preprocess_input(img4d)\n    return img4d\n\ndef deprocess(img4d):\n    img = img4d.copy()\n    if K.image_dim_ordering() == \"th\":\n        # (B, C, H, W)\n        img = img.reshape((img4d.shape[1], img4d.shape[2], img4d.shape[3]))\n        # (C, H, W) -> (H, W, C)\n        img = img.transpose((1, 2, 0))\n    else:\n        # (B, H, W, C)\n        img = img.reshape((img4d.shape[1], img4d.shape[2], img4d.shape[3]))\n    img[:, :, 0] += 103.939\n    img[:, :, 1] += 116.779\n    img[:, :, 2] += 123.68\n    # BGR -> RGB\n    img = img[:, :, ::-1]\n    img = np.clip(img, 0, 255).astype(\"uint8\")\n    return img\n\n```", "```py\ncontent_img = K.variable(preprocess(content_img_value))\nstyle_img = K.variable(preprocess(style_img_value))\nif K.image_dim_ordering() == \"th\":\n    comb_img = K.placeholder((1, 3, RESIZED_WH, RESIZED_WH))\nelse:\n    comb_img = K.placeholder((1, RESIZED_WH, RESIZED_WH, 3))\n\n# concatenate images into single input\ninput_tensor = K.concatenate([content_img, style_img, comb_img], axis=0)\n\n```", "```py\nmodel = vgg16.VGG16(input_tensor=input_tensor, weights=\"imagenet\", include_top=False)\n\n```", "```py\nlayer_dict = {layer.name : layer.output for layer in model.layers}\n\n```", "```py\ndef content_loss(content, comb):\n    return K.sum(K.square(comb - content))\n\ndef gram_matrix(x):\n    if K.image_dim_ordering() == \"th\":\n        features = K.batch_flatten(x)\n    else:\n        features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n    gram = K.dot(features, K.transpose(features))\n    return gram\n\ndef style_loss_per_layer(style, comb):\n    S = gram_matrix(style)\n    C = gram_matrix(comb)\n    channels = 3\n    size = RESIZED_WH * RESIZED_WH\n    return K.sum(K.square(S - C)) / (4 * (channels ** 2) * (size ** 2))\n\ndef style_loss():\n    stl_loss = 0.0\n    for i in range(NUM_LAYERS):\n        layer_name = \"block{:d}_conv1\".format(i+1)\n        layer_features = layer_dict[layer_name]\n        style_features = layer_features[1, :, :, :]\n        comb_features = layer_features[2, :, :, :]\n        stl_loss += style_loss_per_layer(style_features, comb_features)\n    return stl_loss / NUM_LAYERS\n\ndef variation_loss(comb):\n    if K.image_dim_ordering() == \"th\":\n        dx = K.square(comb[:, :, :RESIZED_WH-1, :RESIZED_WH-1] - \n                      comb[:, :, 1:, :RESIZED_WH-1])\n        dy = K.square(comb[:, :, :RESIZED_WH-1, :RESIZED_WH-1] - \n                      comb[:, :, :RESIZED_WH-1, 1:])\n    else:\n        dx = K.square(comb[:, :RESIZED_WH-1, :RESIZED_WH-1, :] - \n                      comb[:, 1:, :RESIZED_WH-1, :])\n        dy = K.square(comb[:, :RESIZED_WH-1, :RESIZED_WH-1, :] - \n                      comb[:, :RESIZED_WH-1, 1:, :])\n     return K.sum(K.pow(dx + dy, 1.25))\n\nCONTENT_WEIGHT = 0.1\nSTYLE_WEIGHT = 5.0\nVAR_WEIGHT = 0.01\nNUM_LAYERS = 5\n\nc_loss = content_loss(content_img, comb_img)\ns_loss = style_loss()\nv_loss = variation_loss(comb_img)\nloss = (CONTENT_WEIGHT * c_loss) + (STYLE_WEIGHT * s_loss) + (VAR_WEIGHT * v_loss)\n\n```", "```py\ngrads = K.gradients(loss, comb_img)[0]\nf = K.function([comb_img], [loss, grads])\n\nNUM_ITERATIONS = 5\nLEARNING_RATE = 0.001\n\ncontent_img4d = preprocess(content_img_value)\nfor i in range(NUM_ITERATIONS):\n    print(\"Epoch {:d}/{:d}\".format(i+1, NUM_ITERATIONS))\n    loss_value, grads_value = f([content_img4d])\n    content_img4d += grads_value * LEARNING_RATE \n    plt.imshow(deprocess(content_img4d))\n    plt.show()\n\n```"]