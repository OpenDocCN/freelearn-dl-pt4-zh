<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Preface</h1>
                </header>
            
            <article>
                
<p>With continuously evolving research and development, <strong>Generative Adversarial Networks</strong> (<strong>GANs</strong>) are the next big thing in the field of deep learning. This book highlights the key improvements in GANs over traditional generative models and shows you how to make the best out of GANs with the help of hands-on examples.</p>
<p class="mce-root">This book will help you understand how GAN architecture works using PyTorch. You will get familiar with the most flexible deep learning toolkit and use it to transform ideas into actual working code. You will apply GAN models to areas such as computer vision, multimedia, and natural language processing using a sample-generation methodology.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Who this book is for</h1>
                </header>
            
            <article>
                
<p>This book is for machine learning practitioners and deep learning researchers looking to get hands-on guidance on implementing GAN models using PyTorch 1.0. You'll become familiar with state-of-the-art GAN architectures with the help of real-world examples. Working knowledge of the Python programming language is necessary to grasp the concepts covered in this book.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">What this book covers</h1>
                </header>
            
            <article>
                
<p><a href="66a945c3-9fd3-4d27-a6ec-b47d2e299e84.xhtml">Chapter 1</a>, <em>Generative Adversarial Networks Fundamentals</em><span>, exploits the new features of PyTorch. You will also learn how to build a simple GAN with NumPy to generate sine signals.</span></p>
<p><a href="4459c703-9610-43e7-9eda-496d63a45924.xhtml">Chapter 2</a>, <em>Getting Started with PyTorch 1.3</em><span>, introduces how to install CUDA in order to take advantage of the GPU for faster training and evaluation. We will also look into the step-by-step installation process of PyTorch on Windows and Ubuntu and build PyTorch from source.</span></p>
<p><a href="8aa2141f-1f14-405f-a5e6-31daf5f4163a.xhtml">Chapter 3</a>, <em>Best Practices in Model Design and Training</em><span>, looks at the overall design of the model architecture and the steps that need to be followed to choose the required convolutional operation.</span></p>
<p class="mce-root"/>
<p><a href="3894df8d-1a40-418e-ac36-d9357abdfd6a.xhtml">Chapter 4</a>, <em>Building Your First GAN with PyTorch</em><span>, introduces you to a classic and well-performing GAN model, called DCGAN, for generating 2D images. You will also be introduced to the architecture of DCGANs and learn how to train and evaluate them. Following this, you will learn how to use a DCGAN to generate hand-written digits and human faces, and take a look at adversarial learning with autoencoders. You will also be shown how to efficiently organize your source code for easy adjustments and extensions.</span></p>
<p><a href="685b2621-6dbb-4157-a258-f3cf2825728c.xhtml">Chapter 5</a>, <em>Generating Images Based on Label Information</em><span>, shows how to use a CGAN to generate images based on a given label and how to implement adversarial learning with autoencoders.</span></p>
<p><a href="209b2357-05d7-48d4-9c91-e061eccf8344.xhtml">Chapter 6</a>, <em>Image-to-Image Translation and Its Applications</em><span>, shows how to use pixel-wise label information to perform image-to-image translation with pix2pix and how to translate high-resolution images with pix2pixHD. You will also learn how to flexibly design model architectures to accomplish your goals, including generating larger images and transferring textures between different types of images.</span></p>
<p><a href="c9fec01a-2b58-4de3-a62d-da11928e5afe.xhtml">Chapter 7</a>, <em>Image Restoration with GANs</em><span>, shows you to how to perform image super-resolution with SRGAN to generate high-resolution images from low-resolution ones and how to use a data prefetcher to speed up data loading and increase your GPU's efficiency during training. You will also learn how to train a GAN model to perform image inpainting and fill in the missing parts of an image.</span></p>
<p><a href="f05fbf9f-30b6-41d4-b706-5f3ef0d6fff7.xhtml">Chapter 8</a>, <em>Training Your GANs to Break Different Models</em><span>, looks into the fundamentals of adversarial examples and how to attack and confuse a CNN model with <strong>FGSM</strong> (<strong>Fast Gradient Sign Method</strong>). After this, we will look at how to use an accimage library to speed up your image loading even more and train a GAN model to generate adversarial examples and fool the image classifier.</span></p>
<p><a href="464e6361-6a52-4de2-960a-4fa0576f42c7.xhtml">Chapter 9</a>, <em>Image Generation from <span>Description</span> Text</em><span>, provides basic knowledge on word embeddings and how are they used in the NLP field. You will also learn how to design a text-to-image GAN model to generate images based on one sentence of description text.</span></p>
<p><span><a href="e05f7dcc-b1fe-4b9b-a893-124e67718cac.xhtml">Chapter 10</a>, <em>Sequence Synthesis with GANs</em></span><span>, covers commonly used techniques in the NLP field, such as RNN and LSTM. You will also learn some of the basic concepts of reinforcement learning and see how it differ from supervised learning (such as SGD-based CNNs). You will also learn how to use SEGAN to remove background noise and enhance the quality of speech audio.</span></p>
<p class="mce-root"/>
<p><span><a href="09d087ce-5d7e-4bd4-af48-693ac63d891c.xhtml">Chapter 11</a>, <em>Reconstructing 3D Models with GANs</em></span><span>, shows how 3D objects are represented in <strong>computer graphics</strong> (<strong>CG</strong>). We will also look at the fundamental concepts of CG, including camera and projection matrices. You will then learn how to construct a 3D-GAN model with 3D convolutions and train it to generate 3D objects.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">To get the most out of this book</h1>
                </header>
            
            <article>
                
<p>You should have basic knowledge of Python and PyTorch.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Download the example code files</h1>
                </header>
            
            <article>
                
<p>You can download the example code files for this book from your account at <a href="http://www.packt.com" target="_blank">www.packt.com</a>. If you purchased this book elsewhere, you can visit <a href="https://www.packtpub.com/support">www.packtpub.com/support</a> and register to have the files emailed directly to you.</p>
<p>You can download the code files by following these steps:</p>
<ol>
<li>Log in or register at <a href="http://www.packt.com" target="_blank">www.packt.com</a>.</li>
<li>Select the <span class="packt_screen">Support</span> tab.</li>
<li>Click on <span class="packt_screen">Code Downloads</span>.</li>
<li>Enter the name of the book in the <span class="packt_screen">Search</span> box and follow the onscreen instructions.</li>
</ol>
<p>Once the file is downloaded, please make sure that you unzip or extract the folder using the latest version of:</p>
<ul>
<li>WinRAR/7-Zip for Windows</li>
<li>Zipeg/iZip/UnRarX for Mac</li>
<li>7-Zip/PeaZip for Linux</li>
</ul>
<p><span>The code bundle for the book is also hosted on GitHub at</span><span> </span><a href="https://github.com/PacktPublishing/Hands-On-Generative-Adversarial-Networks-with-PyTorch-1.x"><span class="Object">https://github.com/PacktPublishing/Hands-On-Generative-Adversarial-Networks-with-PyTorch-1.x</span></a><span>. </span><span>In case there's an update to the code, it will be updated on the existing GitHub repository.</span></p>
<p><span>We also have other code bundles from our rich catalog of books and videos available at</span><span> </span><strong><span class="Object"><a href="https://github.com/PacktPublishing/" target="_blank">https://github.com/PacktPublishing/</a></span></strong><span>. Check them out!</span></p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Download the color images</h1>
                </header>
            
            <article>
                
<p>We also provide a PDF file that has color images of the screenshots/diagrams used in this book. You can download it here: <a href="http://www.packtpub.com/sites/default/files/downloads/9781789530513_ColorImages.pdf">http://www.packtpub.com/sites/default/files/downloads/<span>9781789530513</span>_ColorImages.pdf</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Conventions used</h1>
                </header>
            
            <article>
                
<p>There are a number of text conventions used throughout this book.</p>
<p><kbd>CodeInText</kbd>: <span>Indicates c</span>ode words in text, database table names, folder names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles. <span>Here is an example:</span> "Mount the downloaded <kbd>WebStorm-10*.dmg</kbd> disk image file as another disk in your system."</p>
<p>A block of code is set as follows:</p>
<pre>    # Derivative with respect to w3<br/>    d_w3 = np.matmul(np.transpose(self.x2), delta)<br/>    # Derivative with respect to b3<br/>    d_b3 = delta.copy()</pre>
<p>Any command-line input or output is written as follows:</p>
<pre style="padding-left: 60px"><strong>$ python -m torch.distributed.launch --nproc_per_node=NUM_GPUS YOUR_SCRIPT.py --YOUR_ARGUMENTS</strong></pre>
<p><strong>Bold</strong>: Indicates a new term, an important word, or w<span>ords that you see onscreen. For example, words in menus or dialog boxes appear in the text like this. Here is an example: "Select <span class="packt_screen">System info</span> from the <span class="packt_screen">Administration</span> panel.</span><span>"</span></p>
<div class="packt_infobox">Warnings or important notes appear like this.</div>
<div class="packt_tip">Tips and tricks appear like this.</div>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Get in touch</h1>
                </header>
            
            <article>
                
<p>Feedback from our readers is always welcome.</p>
<p class="mce-root"><strong>General feedback</strong>: If you have questions about any aspect of this book, <span>mention the book title in the subject of your message and</span> email us at <kbd><span>customercare@packtpub.com</span></kbd>.</p>
<p><strong>Errata</strong>: Although we have taken every care to ensure the accuracy of our content, mistakes do happen. If you have found a mistake in this book, we would be grateful if you would report this to us. Please visit <a href="https://www.packtpub.com/support/errata" target="_blank">www.packtpub.com/support/errata</a>, selecting your book, clicking on the Errata Submission Form link, and entering the details.</p>
<p><strong>Piracy</strong>: If you come across any illegal copies of our works in any form on the Internet, we would be grateful if you would provide us with the location address or website name. Please contact us at <kbd>copyright@packt.com</kbd> with a link to the material.</p>
<p class="mce-root"><strong>If you are interested in becoming an author</strong>: If there is a topic that you have expertise in and you are interested in either writing or contributing to a book, please visit <a href="http://authors.packtpub.com/" target="_blank">authors.packtpub.com</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Reviews</h1>
                </header>
            
            <article>
                
<p>Please leave a review. Once you have read and used this book, why not leave a review on the site that you purchased it from? Potential readers can then see and use your unbiased opinion to make purchase decisions, we at Packt can understand what you think about our products, and our authors can see your feedback on their book. Thank you!</p>
<p>For more information about Packt, please visit <a href="http://www.packt.com/" target="_blank">packt.com</a>.</p>


            </article>

            
        </section>
    </body></html>