["```py\n$ git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix.git\n```", "```py\n$ pip install dominate visdom\n```", "```py\n\nimport torch.nn as nn\nclass UnetGenerator(nn.Module):\n    def __init__(self):\n        super(UnetGenerator, self).__init__()\n        unet_block = UnetSkipConnectionBlock(64 * 8, 64 * 8, submodule=None, innermost=True)\n        for i in range(8 - 5):\n            unet_block = UnetSkipConnectionBlock(64 * 8, 64 * 8, submodule=unet_block, use_dropout=True)\n        unet_block = UnetSkipConnectionBlock(64 * 4, 64 * 8, submodule=unet_block)\n        unet_block = UnetSkipConnectionBlock(64 * 2, 64 * 4, submodule=unet_block)\n        unet_block = UnetSkipConnectionBlock(64, 64 * 2, submodule=unet_block)\n        self.model = UnetSkipConnectionBlock(3, 64, input_nc=3, submodule=unet_block, outermost=True)\n\n    def forward(self, input):\n        return self.model(input)\n```", "```py\nclass UnetSkipConnectionBlock(nn.Module):\n    # Innermost block */\n    def __init__(self):\n        down = [nn.LeakyReLU(0.2, inplace=True),\n                nn.Conv2d(64 * 8, 64 * 8, kernel_size=4,\n                          stride=2, padding=1, bias=False)]\n        up = [nn.ReLU(inplace=True),\n              nn.ConvTranspose2d(64 * 8, 64 * 8,\n                                 kernel_size=4, stride=2,\n                                 padding=1, bias=False),\n              nn.BatchNorm2d(64 * 8)]\n        model = down + up\n        self.model = nn.Sequential(*model)\n\n    def forward(self, x):\n        return torch.cat([x, self.model(x)], 1)\n```", "```py\nclass UnetSkipConnectionBlock(nn.Module):\n    # Other blocks */\n    def __init__(self, out_channels, in_channels, submodule, use_dropout):\n        down = [nn.LeakyReLU(0.2, inplace=True),\n                nn.Conv2d(out_channels, in_channels, kernel_size=4,\n                          stride=2, padding=1, bias=False),\n                nn.BatchNorm2d(in_channels)]\n        up = [nn.ReLU(inplace=True),\n              nn.ConvTranspose2d(in_channels * 2, out_channels,\n                                 kernel_size=4, stride=2,\n                                 padding=1, bias=False),\n              nn.BatchNorm2d(out_channels)]\n        if use_dropout:\n            model = down + [submodule] + up + [nn.Dropout(0.5)]\n        else:\n            model = down + [submodule] + up\n        self.model = nn.Sequential(*model)\n\n    def forward(self, x):\n        return torch.cat([x, self.model(x)], 1)\n```", "```py\nclass UnetSkipConnectionBlock(nn.Module):\n    # Outermost block */\n    def __init__(self):\n        down = [nn.Conv2d(3, 64, kernel_size=4,\n                          stride=2, padding=1, bias=False)]\n        up = [nn.ReLU(inplace=True),\n              nn.ConvTranspose2d(64 * 2, 3,\n                                 kernel_size=4, stride=2,\n                                 padding=1),\n              nn.Tanh()]\n        model = down + [submodule] + up\n        self.model = nn.Sequential(*model)\n\n    def forward(self, x):\n        return self.model(x)\n```", "```py\nclass NLayerDiscriminator(nn.Module):\n    def __init__(self, n_layers=3):\n        super(NLayerDiscriminator, self).__init__()\n        sequence = [nn.Conv2d(3 + 3, 64, kernel_size=4, stride=2, padding=1),\n                    nn.LeakyReLU(0.2, True)]\n        channel_scale = 1\n        channel_scale_prev = 1\n        for n in range(1, n_layers):\n            channel_scale_prev = channel_scale\n            channel_scale = 2**n\n            sequence += [\n                nn.Conv2d(64 * channel_scale_prev, 64 * channel_scale, kernel_size=4, stride=2, padding=1, bias=False),\n                nn.BatchNorm2d(64 * channel_scale),\n                nn.LeakyReLU(0.2, True)\n            ]\n        channel_scale_prev = channel_scale\n        sequence += [\n            nn.Conv2d(64 * channel_scale_prev, 64 * 8, kernel_size=4, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(64 * 8),\n            nn.LeakyReLU(0.2, True)\n        ]\n        sequence += [nn.Conv2d(64 * 8, 1, kernel_size=4, stride=1, padding=1)]\n        self.model = nn.Sequential(*sequence)\n\n    def forward(self, input):\n        return self.model(input)\n```", "```py\nclass SomeModel(nn.Module):\n    def __init__(self):\n        super(SomeModel, self).__init__()\n        sequence = [layer1, layer2, ...]\n        self.model = nn.Sequential(*sequence)\n\n    def forward(self, input):\n        return self.model(input)\n```", "```py\n def forward(self, input):\n x = input\n for i in range(len(self.model)):\n print(x.shape)\n x = self.model[i](x)\n print(x.shape)\n return x\n```", "```py\nclass Pix2PixModel(BaseModel):\n    def __init__(self):\n        BaseModel.__init__(self)\n        self.netG = networks.define_G()\n        self.netD = networks.define_D()\n\n        self.criterionGAN = torch.nn.BCEWithLogitsLoss()\n        self.criterionL1 = torch.nn.L1Loss()\n        self.optimizer_G = torch.optim.Adam(self.netG.parameters(), lr=0.0002, betas=(0.5, 0.999))\n        self.optimizer_D = torch.optim.Adam(self.netD.parameters(), lr=0.0002, betas=(0.5, 0.999))\n        self.optimizers.append(self.optimizer_G)\n        self.optimizers.append(self.optimizer_D)\n\n    def forward(self):\n        self.fake_B = self.netG(self.real_A)\n\n    def backward_D(self):\n        fake_AB = torch.cat((self.real_A, self.fake_B), 1)\n        pred_fake = self.netD(fake_AB.detach())\n        self.loss_D_fake = self.criterionGAN(pred_fake, False)\n\n        real_AB = torch.cat((self.real_A, self.real_B), 1)\n        pred_real = self.netD(real_AB)\n        self.loss_D_real = self.criterionGAN(pred_real, True)\n\n        self.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\n        self.loss_D.backward()\n\n    def backward_G(self):\n        fake_AB = torch.cat((self.real_A, self.fake_B), 1)\n        pred_fake = self.netD(fake_AB)\n        self.loss_G_GAN = self.criterionGAN(pred_fake, True)\n\n        self.loss_G_L1 = self.criterionL1(self.fake_B, self.real_B)\n\n        self.loss_G = self.loss_G_GAN + self.loss_G_L1 * 100.0\n        self.loss_G.backward()\n\n    def optimize_parameters(self):\n        self.forward()\n        # update D\n        self.set_requires_grad(self.netD, True)\n        self.optimizer_D.zero_grad()\n        self.backward_D()\n        self.optimizer_D.step()\n        # update G\n        self.set_requires_grad(self.netD, False)\n        self.optimizer_G.zero_grad()\n        self.backward_G()\n        self.optimizer_G.step()\n```", "```py\n$ ./datasets/download_pix2pix_dataset.sh maps\n```", "```py\n$ python train.py --dataroot /media/john/HouseOfData/image_transfer/maps --name maps_pix2pix --model pix2pix --direction BtoA\n```", "```py\n$ git clone https://github.com/NVIDIA/apex\n$ cd apex\n$ pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" .\n```", "```py\n$ git clone https://github.com/NVIDIA/pix2pixHD\n```", "```py\n$ python train.py --name label2city_512p\n```", "```py\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\n```", "```py\nclass ResidualBlock(nn.Module):\n    def __init__(self, channels):\n        super(ResidualBlock, self).__init__()\n\n        block = [nn.ReflectionPad2d(1),\n                 nn.Conv2d(channels, channels, 3),\n                 nn.InstanceNorm2d(channels),\n                 nn.ReLU(inplace=True),\n                 nn.ReflectionPad2d(1),\n                 nn.Conv2d(channels, channels, 3),\n                 nn.InstanceNorm2d(channels)]\n         self.block = nn.Sequential(*block)\n\n     def forward(self, x):\n         return x + self.block(x)\n```", "```py\nclass Generator(nn.Module):\n    def __init__(self, channels, num_blocks=9):\n        super(Generator, self).__init__()\n        self.channels = channels\n\n        model = [nn.ReflectionPad2d(3)]\n        model += self._create_layer(self.channels, 64, 7, stride=1, padding=0, transposed=False)\n        # downsampling\n        model += self._create_layer(64, 128, 3, stride=2, padding=1, transposed=False)\n        model += self._create_layer(128, 256, 3, stride=2, padding=1, transposed=False)\n        # residual blocks\n        model += [ResidualBlock(256) for _ in range(num_blocks)]\n        # upsampling\n        model += self._create_layer(256, 128, 3, stride=2, padding=1, transposed=True)\n        model += self._create_layer(128, 64, 3, stride=2, padding=1, transposed=True)\n        # output\n        model += [nn.ReflectionPad2d(3),\n                  nn.Conv2d(64, self.channels, 7),\n                  nn.Tanh()]\n\n        self.model = nn.Sequential(*model)\n\n    def _create_layer(self, size_in, size_out, kernel_size, stride=2, padding=1, transposed=False):\n        layers = []\n        if transposed:\n            layers.append(nn.ConvTranspose2d(size_in, size_out, kernel_size, stride=stride, padding=padding, output_padding=1))\n        else:\n            layers.append(nn.Conv2d(size_in, size_out, kernel_size, stride=stride, padding=padding))\n        layers.append(nn.InstanceNorm2d(size_out))\n        layers.append(nn.ReLU(inplace=True))\n        return layers\n\n    def forward(self, x):\n        return self.model(x)\n```", "```py\nclass Discriminator(nn.Module):\n    def __init__(self, channels):\n        super(Discriminator, self).__init__()\n        self.channels = channels\n\n        self.model = nn.Sequential(\n            *self._create_layer(self.channels, 64, 2, normalize=False),\n            *self._create_layer(64, 128, 2),\n            *self._create_layer(128, 256, 2),\n            *self._create_layer(256, 512, 1),\n            nn.Conv2d(512, 1, 4, stride=1, padding=1)\n        )\n\n    def _create_layer(self, size_in, size_out, stride, normalize=True):\n        layers = [nn.Conv2d(size_in, size_out, 4, stride=stride, padding=1)]\n        if normalize:\n            layers.append(nn.InstanceNorm2d(size_out))\n        layers.append(nn.LeakyReLU(0.2, inplace=True))\n        return layers\n\n    def forward(self, x):\n        return self.model(x)\n```", "```py\nimport itertools\nimport os\nimport time\n\nfrom datetime import datetime\n\nimport numpy as np\nimport torch\nimport torchvision.utils as vutils\nimport utils\n\nfrom cyclegan import Generator as cycG\nfrom cyclegan import Discriminator as cycD\n```", "```py\ndef _weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n        torch.nn.init.constant_(m.bias.data, 0.0)\n```", "```py\nclass Model(object):\n    def __init__(self,\n                 name,\n                 device,\n                 data_loader,\n                 test_data_loader,\n                 channels,\n                 img_size,\n                 num_blocks):\n        self.name = name\n        self.device = device\n        self.data_loader = data_loader\n        self.test_data_loader = test_data_loader\n        self.channels = channels\n        self.img_size = img_size\n        self.num_blocks = num_blocks\n        assert self.name == 'cyclegan'\n        self.netG_AB = cycG(self.channels, self.num_blocks)\n        self.netG_AB.apply(_weights_init)\n        self.netG_AB.to(self.device)\n        self.netG_BA = cycG(self.channels, self.num_blocks)\n        self.netG_BA.apply(_weights_init)\n        self.netG_BA.to(self.device)\n        self.netD_A = cycD(self.channels)\n        self.netD_A.apply(_weights_init)\n        self.netD_A.to(self.device)\n        self.netD_B = cycD(self.channels)\n        self.netD_B.apply(_weights_init)\n        self.netD_B.to(self.device)\n        self.optim_G = None\n        self.optim_D_A = None\n        self.optim_D_B = None\n        self.loss_adv = torch.nn.MSELoss()\n        self.loss_cyc = torch.nn.L1Loss()\n        self.loss_iden = torch.nn.L1Loss()\n\n    @property\n    def generator_AB(self):\n        return self.netG_AB\n\n    @property\n    def generator_BA(self):\n        return self.netG_BA\n\n    @property\n    def discriminator_A(self):\n        return self.netD_A\n\n    @property\n    def discriminator_B(self):\n        return self.netD_B\n\n    def create_optim(self, lr, alpha=0.5, beta=0.999):\n        self.optim_G = torch.optim.Adam(itertools.chain(self.netG_AB.parameters(), self.netG_BA.parameters()),\n                                        lr=lr,\n                                        betas=(alpha, beta))\n        self.optim_D_A = torch.optim.Adam(self.netD_A.parameters(),\n                                          lr=lr,\n                                          betas=(alpha, beta))\n        self.optim_D_B = torch.optim.Adam(self.netD_B.parameters(),\n                                          lr=lr,\n                                          betas=(alpha, beta))\n```", "```py\ndef train(self,\n          epochs,\n          log_interval=100,\n          out_dir='',\n          verbose=True):\n        self.netG_AB.train()\n        self.netG_BA.train()\n        self.netD_A.train()\n        self.netD_B.train()\n        lambda_cyc = 10\n        lambda_iden = 5\n        real_label = torch.ones((self.data_loader.batch_size, 1, self.img_size//2**4, self.img_size//2**4), device=self.device)\n        fake_label = torch.zeros((self.data_loader.batch_size, 1, self.img_size//2**4, self.img_size//2**4), device=self.device)\n        image_buffer_A = utils.ImageBuffer()\n        image_buffer_B = utils.ImageBuffer()\n        total_time = time.time()\n        for epoch in range(epochs):\n            batch_time = time.time()\n            for batch_idx, data in enumerate(self.data_loader):\n                real_A = data['trainA'].to(self.device)\n                real_B = data['trainB'].to(self.device)\n\n                # Train G\n                self.optim_G.zero_grad()\n\n                # adversarial loss\n                fake_B = self.netG_AB(real_A)\n                _loss_adv_AB = self.loss_adv(self.netD_B(fake_B),  \n                  real_label)\n                fake_A = self.netG_BA(real_B)\n                _loss_adv_BA = self.loss_adv(self.netD_A(fake_A), \n                  real_label)\n                adv_loss = (_loss_adv_AB + _loss_adv_BA) / 2\n\n                # cycle loss\n                recov_A = self.netG_BA(fake_B)\n                _loss_cyc_A = self.loss_cyc(recov_A, real_A)\n                recov_B = self.netG_AB(fake_A)\n                _loss_cyc_B = self.loss_cyc(recov_B, real_B)\n                cycle_loss = (_loss_cyc_A + _loss_cyc_B) / 2\n\n                # identity loss\n                _loss_iden_A = self.loss_iden(self.netG_BA(real_A), real_A)\n                _loss_iden_B = self.loss_iden(self.netG_AB(real_B), real_B)\n                iden_loss = (_loss_iden_A + _loss_iden_B) / 2\n\n                g_loss = adv_loss + lambda_cyc * cycle_loss + \n                  lambda_iden * iden_loss\n                g_loss.backward()\n                self.optim_G.step()\n```", "```py\n                # Train D_A\n                self.optim_D_A.zero_grad()\n\n                _loss_real = self.loss_adv(self.netD_A(real_A), real_label)\n                fake_A = image_buffer_A.update(fake_A)\n                _loss_fake = self.loss_adv(self.netD_A(fake_A.detach()), \n                 fake_label)\n                d_loss_A = (_loss_real + _loss_fake) / 2\n\n                d_loss_A.backward()\n                self.optim_D_A.step()\n\n                # Train D_B\n                self.optim_D_B.zero_grad()\n\n                _loss_real = self.loss_adv(self.netD_B(real_B), real_label)\n                fake_B = image_buffer_B.update(fake_B)\n                _loss_fake = self.loss_adv(self.netD_B(fake_B.detach()), \n                  fake_label)\n                d_loss_B = (_loss_real + _loss_fake) / 2\n\n                d_loss_B.backward()\n                self.optim_D_B.step()\n\n                d_loss = (d_loss_A + d_loss_B) / 2\n```", "```py\n                if verbose and batch_idx % log_interval == 0 and batch_idx > 0:\n                    print('Epoch {} [{}/{}] loss_D: {:.4f} loss_G: {:.4f} time: {:.2f}'.format(\n                          epoch, batch_idx, len(self.data_loader),\n                          d_loss.mean().item(),\n                          g_loss.mean().item(),\n                          time.time() - batch_time))\n                    with torch.no_grad():\n                        imgs = next(iter(self.test_data_loader))\n                        _real_A = imgs['testA'].to(self.device)\n                        _fake_B = self.netG_AB(_real_A)\n                        _real_B = imgs['testB'].to(self.device)\n                        _fake_A = self.netG_BA(_real_B)\n                        viz_sample = torch.cat(\n                            (_real_A, _fake_B, _real_B, _fake_A), 0)\n                        vutils.save_image(viz_sample,\n                                          os.path.join(\n                                              out_dir, 'samples_{}_{}.png'.format(epoch, batch_idx)),\n                                          nrow=self.test_data_loader.batch_size,\n                                          normalize=True)\n                    batch_time = time.time()\n\n            self.save_to(path=out_dir, name=self.name, verbose=False)\n        if verbose:\n            print('Total train time: {:.2f}'.format(time.time() - total_time))\n   def eval(self,\n             batch_size=None):\n        self.netG_AB.eval()\n        self.netG_BA.eval()\n        self.netD_A.eval()\n        self.netD_B.eval()\n        if batch_size is None:\n            batch_size = self.test_data_loader.batch_size\n\n        with torch.no_grad():\n            for batch_idx, data in enumerate(self.test_data_loader):\n                _real_A = data['testA'].to(self.device)\n                _fake_B = self.netG_AB(_real_A)\n                _real_B = data['testB'].to(self.device)\n                _fake_A = self.netG_BA(_real_B)\n                viz_sample = torch.cat((_real_A, _fake_B, _real_B, _fake_A), 0)\n                vutils.save_image(viz_sample,\n                                  'img_{}.png'.format(batch_idx),\n                                  nrow=batch_size,\n                                  normalize=True)\n\n    def save_to(self,\n                path='',\n                name=None,\n                verbose=True):\n        if name is None:\n            name = self.name\n        if verbose:\n            print('\\nSaving models to {}_G_AB.pt and such ...'.format(name))\n        torch.save(self.netG_AB.state_dict(), os.path.join(\n            path, '{}_G_AB.pt'.format(name)))\n        torch.save(self.netG_BA.state_dict(), os.path.join(\n            path, '{}_G_BA.pt'.format(name)))\n        torch.save(self.netD_A.state_dict(), os.path.join(\n            path, '{}_D_A.pt'.format(name)))\n        torch.save(self.netD_B.state_dict(), os.path.join(\n            path, '{}_D_B.pt'.format(name)))\n\n    def load_from(self,\n                  path='',\n                  name=None,\n                  verbose=True):\n        if name is None:\n            name = self.name\n        if verbose:\n            print('\\nLoading models from {}_G_AB.pt and such ...'.format(name))\n        ckpt_G_AB = torch.load(os.path.join(path, '{}_G_AB.pt'.format(name)))\n        if isinstance(ckpt_G_AB, dict) and 'state_dict' in ckpt_G_AB:\n            self.netG_AB.load_state_dict(ckpt_G_AB['state_dict'], strict=True)\n        else:\n            self.netG_AB.load_state_dict(ckpt_G_AB, strict=True)\n        ckpt_G_BA = torch.load(os.path.join(path, '{}_G_BA.pt'.format(name)))\n        if isinstance(ckpt_G_BA, dict) and 'state_dict' in ckpt_G_BA:\n            self.netG_BA.load_state_dict(ckpt_G_BA['state_dict'], strict=True)\n        else:\n            self.netG_BA.load_state_dict(ckpt_G_BA, strict=True)\n        ckpt_D_A = torch.load(os.path.join(path, '{}_D_A.pt'.format(name)))\n        if isinstance(ckpt_D_A, dict) and 'state_dict' in ckpt_D_A:\n            self.netD_A.load_state_dict(ckpt_D_A['state_dict'], strict=True)\n        else:\n            self.netD_A.load_state_dict(ckpt_D_A, strict=True)\n        ckpt_D_B = torch.load(os.path.join(path, '{}_D_B.pt'.format(name)))\n        if isinstance(ckpt_D_B, dict) and 'state_dict' in ckpt_D_B:\n            self.netD_B.load_state_dict(ckpt_D_B['state_dict'], strict=True)\n        else:            self.netD_B.load_state_dict(ckpt_D_B, strict=True)\n```", "```py\nclass ImageBuffer(object):\n    def __init__(self, depth=50):\n        self.depth = depth\n        self.buffer = []\n\n    def update(self, image):\n        if len(self.buffer) == self.depth:\n            i = random.randint(0, self.depth-1)\n            self.buffer[i] = image\n        else:\n            self.buffer.append(image)\n        if random.uniform(0,1) > 0.5:\n            i = random.randint(0, len(self.buffer)-1)\n            return self.buffer[i]\n        else:\n            return image\n```", "```py\nimport glob\nimport random\nimport os\n\nimport torchvision\n\nfrom torch.utils.data import Dataset\nfrom PIL import Image\n\nclass ImageDataset(Dataset):\n    def __init__(self, root_dir, transform=None, unaligned=False, mode='train'):\n        self.transform = torchvision.transforms.Compose(transform)\n        self.unaligned = unaligned\n        self.train = (mode == 'train')\n\n        self.files_A = sorted(glob.glob(os.path.join(root_dir, '%sA' % mode) + '/*.*'))\n        self.files_B = sorted(glob.glob(os.path.join(root_dir, '%sB' % mode) + '/*.*'))\n\n    def __getitem__(self, index):\n        item_A = self.transform(Image.open(self.files_A[index % len(self.files_A)]))\n\n        if self.unaligned:\n            item_B = self.transform(Image.open(self.files_B[random.randint(0, len(self.files_B) - 1)]))\n        else:\n            item_B = self.transform(Image.open(self.files_B[index % len(self.files_B)]))\n\n        if self.train:\n            return {'trainA': item_A, 'trainB': item_B}\n        else:\n            return {'testA': item_A, 'testB': item_B}\n\n    def __len__(self):\n        return max(len(self.files_A), len(self.files_B))\n```", "```py\ndef main():\n    device = torch.device(\"cuda:0\" if FLAGS.cuda else \"cpu\")\n\n    if FLAGS.train:\n        print('Loading data...\\n')\n        transform = [transforms.Resize(int(FLAGS.img_size*1.12), Image.BICUBIC),\n                     transforms.RandomCrop((FLAGS.img_size, FLAGS.img_size)),\n                     transforms.RandomHorizontalFlip(),\n                     transforms.ToTensor(),\n                     transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))]\n        dataloader = DataLoader(ImageDataset(os.path.join(FLAGS.data_dir, FLAGS.dataset),\n                                             transform=transform, unaligned=True, mode='train'),\n                                batch_size=FLAGS.batch_size, shuffle=True, num_workers=2)\n        test_dataloader = DataLoader(ImageDataset(os.path.join(FLAGS.data_dir, FLAGS.dataset),\n                                                  transform=transform, unaligned=True, mode='test'),\n                                     batch_size=FLAGS.test_batch_size, shuffle=True, num_workers=2)\n\n        print('Creating model...\\n')\n        model = Model(FLAGS.model, device, dataloader, test_dataloader, FLAGS.channels, FLAGS.img_size, FLAGS.num_blocks)\n        model.create_optim(FLAGS.lr)\n\n        # Train\n        model.train(FLAGS.epochs, FLAGS.log_interval, FLAGS.out_dir, True)\n```", "```py\n    parser.add_argument('--data_dir', type=str, default='/media/john/HouseOfData/image_transfer', help='Directory for dataset.')\n    parser.add_argument('--dataset', type=str, default='vangogh2photo', help='Dataset name.')\n    ...\n    parser.add_argument('--num_blocks', type=int, default=9, help='number of residual blocks')\n```", "```py\n$ python main.py --dataset vangogh2photo\n```"]