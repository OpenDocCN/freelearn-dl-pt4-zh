<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">State Inference - Predicting the States</h1>
                </header>
            
            <article>
                
<p>In the previous chapters, we introduced Markov chains and the <strong>Hidden Markov Model</strong> (<strong><span>HMM</span></strong>), and saw examples of modeling problems using them. In this chapter, we will see how we can make predictions using these models or ask the models questions (known as <strong>inference</strong>). The algorithms used for computing these values are known as <strong>inference algorithms</strong>. In this chapter, we will specifically look into computing probability distribution over the state variables.</p>
<p>This chapter will cover the following topics:</p>
<ul>
<li>State inference in HMM</li>
<li>Dynamic programming</li>
<li>Forward-backward algorithm</li>
<li>Viterbi algorithm</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">State inference in HMM</h1>
                </header>
            
            <article>
                
<p>Let's start with a simple example to show what kind of interesting questions we <span>can </span>ask our HMM models. We are taking an example of <em>robot localization.</em> There are a lot of variations of this example, but we are assuming that a robot is moving in a 2D grid, as shown in <em>Figure 3.1</em>. The robot also has four sensors on it. Each of these sensors detects whether there's a wall right next to the robot in the sensor's direction.</p>
<p>We would like to model the movement of the robot in the following grid along with the observations from our sensors:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/a54806be-d44a-44da-b9b7-3bdcd05907c7.png" style="width:13.83em;height:47.92em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Figure 3.1: The probability distribution of the position of the robot over time</div>
<p>In <em>Fig<span>ure</span> 3.1</em>, we see how the observations at different time instances change the probability of the location of the robot in the grid. Initially, we start with a uniform probability over all the positions in the grid. Now, at time <em>t=1</em>, let's say the sensors of our robot show that there are walls on the top and bottom sides. Having this observation will change our perception of the location of the robot. Now we will have a higher probability of the robot being in either blocks 2, 4, 10, or 12, as shown in the second block in <em>Fig<span>ure</span> 3.1</em>. If we are at time instance <em>t=2</em>, our robot's sensors say that there is a wall only at the top, we will have the highest probability of it being in block 3, as shown in the third block in <em>Fig<span>ure</span> 3.1</em>. This is because we knew its last most probable position and, when combining that information with the current sensor readings, block 3 is the robot's likely location. Now, if we are at time <em>t=3</em>, the robot's sensors indicate there are walls on the left and right, then it would mean that the robot is most likely in in block 7. This process enables us able to locate the position of our robot in the grid based on just the sensor readings over time.</p>
<p>Since we are modelling the transition of state (position in the grid) of the robot over some duration of time along with an outcome at each instance (sensor output), HMM seems to be the perfect model in the situation. In this example, we are assuming that we know the transition probability of the robot's position. We are also assuming that we know the structure of the grid and therefore we will know the emission probabilities. We can use the emission probability to also model the uncertainty in the output of the sensors since they might give noise results at some instance:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-493 image-border" src="assets/0b2385a5-9df2-418b-8e35-ba8f977e0712.png" style="width:41.17em;height:16.50em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Fig<span>ure</span> 3.2: An example HMM for the robot localization</div>
<p>Now let's think about the kind of questions we might want to ask our model. We might be interested in knowing the position of our robot at any time instance given all the observations till that time instance. Another question that we might want to ask is the probability of our sensor output at some time instance given all the positions of the robot until that time instance. We might also be interested in computing the joint distribution over our observed variables and the position of the robot. All these values can be easily computed using the <em>forward algorithm, backward algorithm, or forward-backward algorithm</em>.</p>
<p>Now, instead of asking for distributions, we might be interested in the most probable path the robot took. To compute the most probable path, we would need to do a MAP inference over the state at each time instance of the robot. This can be done efficiently using the Viterbi algorithm.</p>
<p>In the following sections, we will introduce these algorithms formally and see how we can implement them. All of these algorithms rely on a very important programming paradigm known as <strong>dynamic programming</strong><em>.</em> Dynamic programming allows us to run these inference algorithms in HMMs in tractable time. We will discuss dynamic programming in detail in the next section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Dynamic programming</h1>
                </header>
            
            <article>
                
<p>Dynamic programming is a programming paradigm in which we divide a complex problem into smaller sub-problems. We solve these sub-problems and store the results. Whenever we need to recompute the same sub-problem again, we just used our stored results, thus saving us computation time at the expense of using storage space. This technique of caching the results of sub-problems is known as <strong>memoization</strong><em>. </em>Therefore, using dynamic programming allows us to speed up our computations by using memoization, and in some cases, it can bring the computational complexity from exponential to linear, as we will see in the following example.</p>
<p>One of the simplest examples of optimization using dynamic programming is computing the <em>n<span><sup>th</sup></span></em> member of the Fibonacci sequence. Any term in a Fibonacci sequence is the sum of the last two terms, which can be formally defined as follows:</p>
<p class="CDPAlignCenter CDPAlign"><em>fib(0)=0</em></p>
<p class="CDPAlignCenter CDPAlign"><em>fib(1)=1</em></p>
<p class="CDPAlignCenter CDPAlign"><em>fib(n)=fib(n-1)+fib(n-2)</em></p>
<p>Here, <em>fib(n)</em> represents the <em>n</em><sup><em>th</em> </sup>number in the Fibonacci sequence. From the definition, we can easily compute the Fibonacci sequence as: <em>0, 1, 1, 2, 3, 5, 8, 13</em>.</p>
<p>Now let's say we want to write a function which would return the <em>n</em><sup><em>th</em> </sup>number in the Fibonacci sequence. A simple way to write this function could be to use recursion, as shown in the following code:</p>
<pre>def fibonacci(n):<br/>    """<br/>    Returns the n-th number in the Fibonacci sequence.<br/><br/>    Parameters<br/>    ----------<br/>    n: int<br/>       The n-th number in the Fibonacci sequence.<br/>    """<br/>    if n &lt;= 1:<br/>        return n<br/>    else:<br/>        return fibonacci(n-1) + fibonacci(n-2)</pre>
<p>In the preceding code, we have a simple <kbd>if ... else</kbd> condition, where if <kbd>n</kbd> is less than or equal to 1, we return the value of <kbd>n</kbd>; otherwise, we use recursion to compute the sum of the previous two numbers in the sequence. Now let's try to determine the number of calls to the <kbd>fibonacci</kbd> function for a small <kbd>n</kbd>, let's say 5. Our function calls would look something like the following:</p>
<pre>fibonacci(5) = fibonacci(4) + fibonacci(3)<br/>fibonacci(5) = (fibonacci(3) + fibonacci(2)) + (fibonacci(2) + fibonacci(1))<br/>fibonacci(5) = ((fibonacci(2) + fibonacci(1)) + (fibonacci(1) + fibonacci(0))) + ((fibonacci(1) + fibonacci(0)) + fibonacci(1))<br/>fibonacci(5) = (((fibonacci(1) + fibonacci(0)) + fibonacci(1)) + (fibonacci(1) + fibonacci(0))) + ((fibonacci(1) + fibonacci(0)) + fibonacci(1))</pre>
<p>For such a small value of <kbd>n</kbd>, we can still see the repetition in the number of calls to the function with the same argument. We can see that <kbd>fibonacci(1)</kbd> is being called five times and <kbd>fibonacci(0)</kbd> is getting called three times. If we move a level up, we can see that <kbd>fibonacci(2)</kbd> is also getting called multiple times. In this case, the computation is still tractable, but for large values of <kbd>n</kbd> the run time of this function would grow exponentially; the runtime complexity is given by <em>O(2<sup>n</sup>)</em>. To give an idea of how fast the runtime grows, to compute the 1,000<sup>th </sup>term in the Fibonacci sequence using this algorithm, we would need more time than the age of our universe on a computer built with all the electrons in our observable universe.</p>
<p class="mce-root"/>
<p>Since we have proved that it is impossible to compute the <em>n<sup>th</sup></em> term of the Fibonacci sequence for any moderately large <kbd>n</kbd>, we will look at another algorithm that is based on dynamic programming and looks as follows:</p>
<pre>cache = {0: 0, 1: 1} # Initialize the first two values.<br/>def fibonacci(n):<br/>    """<br/>    Returns the n-th number in the Fibonacci sequence.<br/><br/>    Parameters<br/>    ----------<br/>    n: int<br/>       The n-th number in the Fibonacci sequence.<br/>    """<br/>     try:<br/>         return cache[n]<br/>     except KeyError:<br/>         fib = fibonacci(n-1) + fibonacci(n-2)<br/>         cache[n] = fib <br/>         return fib</pre>
<p>In this case, we are storing the result of each of our calls to the function in a dictionary, which allows us to access it in <em>O(1)</em>. Because of this cache, we only need to compute each term of the Fibonacci sequence exactly once. For each call, we first check whether we have already computed the value. If we have already computed it, we directly access it from the dictionary, otherwise we compute the value. The runtime complexity of this algorithm is <em>O(n)</em> since we are computing each term in the sequence exactly once. We can see, therefore, that using dynamic programming facilitates a trade-off between the runtime complexity and memory complexity, and this allows us to bring down the runtime complexity from being exponential to linear.</p>
<p class="mce-root">If we think about the way we have programmed the Fibonacci series, we start with trying to compute the <em>n<span><sup>th</sup></span></em> number and then compute the values we are missing. This can be thought of as a top-down approach. Another approach could be a bottom-up approach, in which we start by computing the 0th term and then move to the first, second, and so on. The concept of dynamic programming is the same in both cases, but with just a minor difference in how we write the code, shown as follows:</p>
<pre>cache = [0, 1]   # Initialize with the first two terms of Fibonacci series.<br/>def fibonacci(n):<br/>    """<br/>    Returns the n-th number in the Fibonacci sequence.<br/><br/>    Parameters<br/>    ----------<br/>    n: int<br/>       The n-th number in the Fibonacci sequence.<br/>    """<br/>    for i in range(2, n):<br/>        cache.append(cache[i-1] + cache[i-2])<br/>    return cache[-1]</pre>
<p class="mce-root">As you can see, the code in the preceding example is much simpler, and we don't need to check whether we have already computed the values. This works well in problems where we need all the previous values to compute the next value. However, if we don't need all the previous values, we will end up computing unnecessary values with the bottom-up approach. <sup><br/></sup></p>
<p>We will see in the next sections that the inference algorithms in HMMs allow us to use dynamic programming to break the problem into sub-problems, which makes computations tractable.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Forward algorithm</h1>
                </header>
            
            <article>
                
<p>Let's now formally define our problem for the forward algorithm. In the case of the forward algorithm, we are trying to compute the joint distribution of the position of the robot at any time instance using the output of the sensors till that time instance, as shown in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><em>Forward algorithm: P(Z<sub>k</sub>, X<sub>1:k</sub>)</em></p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/d6e7d007-0276-4568-b8ed-40a03bd69f3c.png" style="width:35.75em;height:17.17em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Fig<span>ure</span> 3.3: HMM showing two time slices, <em>k-1</em> and <em><em>k</em></em></div>
<p>To compute this probability distribution, we will try to split the joint distribution term into smaller known terms. As we will see, we can write a recursion formula over time for the distribution. We start by introducing a new variable, <em>Z<sub>k-1</sub></em>, in the distribution, <em>P(Z<sub>k</sub>, X<sub>1:k</sub>)</em>, as follows:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/977c0d76-4972-4f48-a30e-222d265ded21.png" style="width:20.42em;height:3.83em;"/></div>
<div class="packt_infobox">The marginalization rule of probability is: <br/>
<img class="fm-editor-equation" src="assets/131323d8-8601-4e5f-ae64-4c1516addb41.png" style="width:9.17em;height:2.75em;"/><br/>
The product rule of probability is:<br/>
<img class="fm-editor-equation" src="assets/30fffc1c-1dc9-4264-ac07-c6ed7aca8d43.png" style="width:12.42em;height:1.58em;"/></div>
<p>Here, we are basically using the <em>marginalization</em> rule of probability to introduce <em>Z<sub>k-1</sub></em> and then summing its states. In this case, we have assumed that <em>Z<sub>k-1</sub></em> has <em>m</em> states, so now we can use the <em>product</em> rule of probability to split this term as follows:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/3ab6d5f2-d643-4210-a8e7-53a250ee6837.png" style="width:39.75em;height:3.00em;"/></div>
<p>In the last chapter, we saw how the d-separation property of HMM can make variables independent from each other. Here, we will apply some of those conditions to simplify our terms in the preceding equation. As we know that, given the hidden state, the observation is independent of all the terms in previous time instances, we also know: <img class="fm-editor-equation" src="assets/f44ce271-c1e0-44c8-9470-a60440d4adab.png" style="width:12.67em;height:1.42em;"/>. Applying this to the first term of our preceding equation, we can write it as the following:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/db86faa7-0606-446f-ba4d-48c84d6dfa3c.png" style="width:21.75em;height:1.58em;"/></div>
<p>Similarly, we know that the current hidden state is dependent on the last hidden state and is independent of hidden states before that. Hence, in this case, the formula is <img class="fm-editor-equation" src="assets/2b04e26f-a094-4bec-8aa0-00e2354cb748.png" style="width:10.08em;height:1.50em;"/>. Using this property, we can write our second term in the equation as follows:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/71356e3f-001a-4d41-9e86-f5e1d2e9d021.png" style="width:19.33em;height:1.50em;"/></div>
<p>Now, if we compare our last term with the term we were trying to compute, we should see there is a similarity between them. Let's define a new function, <em>α</em>, as follows:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/416b9ab8-b5e5-47ff-9062-70ce86c78097.png" style="width:9.08em;height:1.25em;"/></div>
<p>Now we can rewrite our original equation as the following:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/67167be6-e5a5-4b3e-8b52-1e37241c9da0.png" style="width:19.75em;height:2.75em;"/></div>
<p>So, we now have a nice recursive equation and we are familiar with all the terms in the equation. The first term, <em>P(X<sub>k</sub>|Z<sub>k</sub>)</em>, is the emission probability of the HMM. The second term of the equation, <em>P(Z<sub>k</sub>|Z<sub>k-1</sub>)</em>, is the transition probability and is also known. Now we can focus on solving this recursive equation. When solving any recursive equation, we need to know at least one of the values, so we can start computing consecutive terms. In this case, we know the value of <em>α(1)</em>, which is given as follows:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/09011cb7-a601-4e74-ac6b-9345eea4806f.png" style="width:11.67em;height:2.83em;"/></div>
<p>Here,<span> </span><em><span>P(Z</span><sub>1</sub><span>)</span></em><span> is the initial probability of the position of the robot, which we know, and </span><em>P(X<sub>1</sub>|Z<sub>1</sub>)</em> <span>is the emission probability of HMM, which is also known. Using these two values, we can compute the value of <em>α(1)</em></span><span>. Once we have the value of <em>α(1)</em></span><span>, we can use our recursive equation to compute all the <em>α</em> values</span><span>. </span></p>
<p>Now let's talk about the computational complexity of this algorithm to see whether the inference is tractable. As we can see in the equation for computing each <em>α</em>, we are doing a sum over all the states of <em>Z<sub>k-1</sub></em>, and we have assumed that it has <em>m</em> states; for each one of these steps, we do <em>m</em> multiplications for computing <em>P(X<sub>k</sub>|Z<sub>k</sub>)P(Z<sub>k</sub>|Z<sub>k-1</sub>)α(k-1)</em>. Therefore, to compute the next <em>α</em>, we do <em>m<sup>2</sup></em> computations. If we want to compute <em>α(n)</em>, we will need <em>nm<sup>2</sup></em> computations, which gives us the computational complexity of the algorithm as <em>O(nm<sup>2</sup>)</em>.</p>
<p>Let's now try to write the code for our robot localization problem to compute the joint distribution using the forward algorithm. For simplicity, let's assume that we have only one sensor on the robot that checks whether there is a wall on the left-hand side of the robot. To define the model, we mainly need two quantities: the transition matrix and the emission matrix. In our example, we assume that the robot can either stay at its original position or move a block in any possible direction in any given time instance. Therefore, if the robot is at position 1 at any given time, it can be in positions 1, 2, or 6 at the next time instance with equal probabilities of <em>0.33</em>.</p>
<p>In this way, we can write the transition probability from state 1 as:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/541137a6-293c-47fd-ac6c-ca4c82b141c8.png" style="width:21.83em;height:1.33em;"/></div>
<p>In a similar way, we can write the transition probabilities, <em>P(Z<sub>t+1</sub>|Z<sub>t</sub>)</em>, from each of the position, and we will get the following transition matrix:</p>
<pre>import numpy as np<br/><br/>transition_matrix = np.array([[0.33, 0.33,    0,    0,    0, 0.33,    0,    0,    0,    0,    0,    0,    0],<br/>              [0.33, 0.33, 0.33,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],<br/>              [   0, 0.25, 0.25, 0.25,    0,    0, 0.25,    0,    0,    0,    0,    0,    0],<br/>              [   0,    0, 0.33, 0.33, 0.33,    0,    0,    0,    0,    0,    0,    0,    0],<br/>              [   0,    0,    0, 0.33, 0.33,    0,    0, 0.33,    0,    0,    0,    0,    0],<br/>              [0.33,    0,    0,    0,    0, 0.33,    0,    0, 0.33,    0,    0,    0,    0],<br/>              [   0,    0, 0.33,    0,    0,    0, 0.33,    0,    0,    0, 0.33,    0,    0],<br/>              [   0,    0,    0,    0, 0.33,    0,    0, 0.33,    0,    0,    0,    0, 0.33],<br/>              [   0,    0,    0,    0,    0, 0.33,    0,    0, 0.33, 0.33,    0,    0,    0],<br/>              [   0,    0,    0,    0,    0,    0,    0,    0, 0.33, 0.33, 0.33,    0,    0],<br/>              [   0,    0,    0,    0,    0,    0,    0,    0,    0, 0.33, 0.33, 0.33,    0],<br/>              [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 0.33, 0.33, 0.33],<br/>              [   0,    0,    0,    0,    0,    0,    0, 0.33,    0,    0,    0, 0.33, 0.33]])</pre>
<p>Coming to the emission probability in this problem, <em>P(X<sub>t</sub>|Z<sub>t</sub>)</em>, we should have the emission probability of 1 for the states that have a wall on their left. Hence, the emission probability would be as follows:</p>
<pre>emission = np.array([1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0])</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>However, as we don't know the position of our robot at <em>t=0</em>, we will assume that it has a uniform distribution over all the possible states. Therefore, the initial probability, <em>P(Z<sub>0</sub>)</em>, can be written as follows:</p>
<pre>init_prob = np.array([0.077, 0.077, 0.077, 0.077, 0.077, 0.077, 0.077,<br/>                      0.077, 0.077, 0.077, 0.077, 0.077, 0.077])</pre>
<p>With these values in hand, we should be able to run the forward algorithm, but before that, we need to code up the algorithm, as follows:</p>
<pre>def forward(obs, transition, emission, init):<br/>    """<br/>    Runs forward algorithm on the HMM.<br/><br/>    Parameters<br/>    ----------<br/>    obs:        1D list, array-like<br/>                The list of observed states.<br/><br/>    transition: 2D array-like<br/>                The transition probability of the HMM.<br/>                size = {n_states x n_states}<br/><br/>    emission:   1D array-like<br/>                The emission probability of the HMM.<br/>                size = {n_states}<br/><br/>    init:       1D array-like<br/>                The initial probability of HMM.<br/>                size = {n_states}<br/><br/>    Returns<br/>    -------<br/>    float: Probability value for the obs to occur.<br/>    """<br/>    n_states = transition.shape[0]<br/>    fwd = [{}]<br/><br/>    for i in range(n_states):<br/>        fwd[0][y] = init[i] * emission[obs[0]]<br/>    for t in range(1, len(obs)):<br/>        fwd.append({})<br/>        for i in range(n_states):<br/>            fwd[t][i] = sum((fwd[t-1][y0] * transition[y0][i] * emission[obs[t]]) for y0 in <br/>                                    range(n_states))<br/>    prob = sum((fwd[len(obs) - 1][s]) for s in range(n_states))<br/>    return prob</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>We can try to compute the probability by running it over some observations, as follows:</p>
<pre>&gt;&gt;&gt; obs = [0, 0, 0, 0] # Staying in the same location<br/>&gt;&gt;&gt; forward(obs, transition_matrix, emission, init_prob)<br/>0.97381776799999997<br/><br/>&gt;&gt;&gt; obs = [0, 10, 8, 6] # Should be 0 because can't jump from state 0 to 10.<br/>&gt;&gt;&gt; forward(obs, transition_matrix, emission, init_prob)<br/>0.0</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Computing the conditional distribution of the hidden state given the observations</h1>
                </header>
            
            <article>
                
<p>Using the forward algorithm, we have been able to compute the value of <em>P(Z<sub>x</sub>, X)</em>, so we might be tempted to think that we will easily be able to compute the conditional distribution <em>P(Z<span><sub>k</sub></span>, X)</em> using the following product rule:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/f073c302-f6fb-418e-a47e-fc2251c1bbf8.png" style="width:11.33em;height:3.08em;"/></div>
<p>Computing the distribution, <em>P(X) </em>however, is computationally intractable, as we will see. We can express <em>P(Z<sub>k</sub>, X)</em> as follows:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/e096c04f-37ba-49dc-b4c8-71ee2075d680.png" style="width:15.92em;height:3.25em;"/></div>
<p>And hence we can compute <em><span>P(X)</span></em> as the following:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/a2dce95f-8bbd-4860-8b21-7bb07cbe76d6.png" style="width:15.50em;height:5.67em;"/></div>
<p>If we look at the computational complexity of computing <em><span>P(X)</span></em> using the preceding equation, it is <em>O(m<sup>n</sup>)</em>, which is intractable for any sufficiently large value of <em>m</em> and <em>n</em>. And hence it is impossible to compute the conditional distribution of our hidden state using just the forward algorithm. In the next sections, we will introduce the backward algorithm and then we will show you how can we compute these conditional distributions.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Backward algorithm</h1>
                </header>
            
            <article>
                
<p>Let's formally define the problem statement for the backward algorithm. In this case, we are trying to compute the probability of observation variables given the current state:</p>
<p class="CDPAlignCenter CDPAlign"><em>Backward algorithm: P(X<sub>k+1:n</sub>|Z<sub>k</sub>)</em></p>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/248cab76-6c07-4fd9-b983-0c2260796b9f.png" style="width:37.42em;height:17.00em;"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Fig<span>ure</span> 3.4: <span>HMM showing two time slices, <em>k</em></span><span> and <em>k+1</em></span></div>
<p>Similar to what we did in the case of the forward algorithm, we will again try to convert this probability term into a recursive equation in terms of known distributions, so that we can recursively compute the probabilities at different time instances. First, we introduce a new term, <em>Z<sub>k+1</sub></em> in <em>P(X<sub>k+1:n</sub>|Z<sub>k</sub>)</em>, using the marginalization rule:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/f45ee6a4-7335-44a5-b5ed-e6053c05dd50.png" style="width:20.58em;height:3.00em;"/></div>
<p>Here, we are marginalizing over the <em><span>Z</span><sub>k+1</sub></em> variable by summing over all of its possible states, which we have assumed to be <em>m</em>. Now, we can use the product rule of probability to split the preceding equation as: </p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/41cf8de5-41f6-470f-88d7-0491774cd25c.png" style="width:41.33em;height:3.17em;"/></div>
<p>Now, from the d-separation property of our model, we know that <img class="fm-editor-equation" src="assets/19fa7ae2-606d-455a-a00b-877849f4f47f.png" style="width:14.42em;height:1.58em;"/>. Also, we know from the definition of HMMs that <img class="fm-editor-equation" src="assets/29e48e7c-7ec1-4193-b98d-fd5c4aadffbb.png" style="width:9.25em;height:1.50em;"/>. Using these independent conditions, we can write our equation as:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/50c41c81-088c-456b-ae74-bdcc33dc0353.png" style="width:34.92em;height:3.25em;"/></div>
<p>Now, the terms in our equation look familiar. The second term is the emission probability and the last term is the transition probability of our HMM. Now, to express it as a recursion, let's define a new function, <em>β</em>, given as:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/ba205953-f863-4c95-8556-9a3edb5c2b36.png" style="width:12.58em;height:1.58em;"/></div>
<p>We can use <span>β</span> in the previous equation to represent it as a recursion:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/593de81a-b69a-4a7b-9c4d-e90a34ff2e47.png" style="width:24.25em;height:3.08em;"/></div>
<p>Now, since we have the recursive equation, we can start computing the different values of <em><span>β<sub>k</sub></span></em>. But for computing the values, we will need to know at least one term of the recursion, so let's compute the value of <em><span>β(1)</span></em>:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/f054c7f4-dca8-4097-b091-39108f9712ca.png" style="width:4.75em;height:1.42em;"/></div>
<pre>def backward(obs, transition, emission, init):<br/>    """<br/>    Runs backward algorithm on the HMM.<br/><br/>    Parameters<br/>    ----------<br/>    obs:        1D list, array-like<br/>                The list of observed states.<br/><br/>    transition: 2D array-like<br/>                The transition probability of the HMM.<br/>                size = {n_states x n_states}<br/><br/>    emission:   1D array-like<br/>                The emission probabilitiy of the HMM.<br/>                size = {n_states}<br/><br/>    init:       1D array-like<br/>                The initial probability of HMM.<br/>                size = {n_states}<br/><br/>    Returns<br/>    -------<br/>    float: Probability value for the obs to occur.<br/>    """<br/>    n_states = transition.shape[0]<br/>    bkw = [{} for t in range(len(obs))]<br/>    T = len(obs)<br/>    <br/>    for y in range(n_states):<br/>        bkw[T-1][y] = 1<br/>    for t in reversed(range(T-1)):<br/>        for y in range(n_states):<br/>            bkw[t][y] = sum((bkw[t+1][y1] * transition[y][y1] * emission[obs[t+1]]) for y1 in <br/>                                    range(n_states))<br/>    prob = sum((init[y] * emission[obs[0]] * bkw[0][y]) for y in range(n_states))<br/>    return prob</pre>
<p>We can run this algorithm also on the same observations to see whether the results were correct:</p>
<pre>&gt;&gt;&gt; obs = [0, 0, 0, 0] # Staying in the same location<br/>&gt;&gt;&gt; backward(obs, transition_matrix, emission, init_prob)<br/>0.97381776799999997<br/><br/>&gt;&gt;&gt; obs = [0, 10, 8, 6] # Should be 0 because can't jump from state 0 to 10.<br/>&gt;&gt;&gt; backward(obs, transition_matrix, emission, init_prob)<br/>0.0</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Forward-backward algorithm (smoothing)</h1>
                </header>
            
            <article>
                
<p>Coming to the forward-backward algorithm, we are now trying to compute the conditional distribution of the hidden state given the observations.</p>
<p>Taking the example of our robot localization, we are trying to now find the probability distribution of the robot's position at some time instance given the sensor readings:</p>
<div class="CDPAlignCenter CDPAlign"><em><span>Forward-backward algorithm: P(Z<sub>k</sub>|X)</span></em></div>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/2dabbe7b-8dd2-483d-95ee-02dec8abe31a.png" style="width:28.67em;height:10.00em;"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref"><span>Figure 3.5: HMM showing three time slices, <em>k-1</em>, <em>k</em>, and <em>k+1</em></span></div>
<p>Now, since we have been given all the observed variables in the model, we can say that the value of <em>P(Z<sub>k</sub>|X)</em> is going to be proportional to the joint distribution over <em><span>Z</span><sub>k</sub> </em>and <em>X:</em></p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/75a59eb6-4820-417e-bc30-83812de77d87.png" style="width:10.83em;height:1.33em;"/></div>
<p>Now, we know that we can write <em>X={X<sub>1:k</sub>, X<sub>k+1:n</sub>}</em>. Replacing this in the preceding equation, we get:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/23870c17-ec20-471e-bb16-c765f703fe13.png" style="width:17.83em;height:1.50em;"/></div>
<p>We can apply the chain rule in the preceding equation to write it as:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/144e7b06-2f9f-441a-93ee-df59e8c423ca.png" style="width:22.83em;height:1.42em;"/></div>
<p>From our model structure, we know that <img class="fm-editor-equation" src="assets/190acd23-d62f-45e4-b819-e738501e7fd1.png" style="width:10.33em;height:1.58em;"/>, and using this independence property we can write the preceding equation as:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/c7b78595-168f-423a-8967-d78ebe606723.png" style="width:21.17em;height:1.50em;"/>
<p class="mceNonEditable"><span>Now if we look at the preceding terms, the first term is</span> <em>P(X<sub>k+1:n</sub>|Z<sub>k</sub>)</em><span>, which is what we computed in our backward algorithm. The second term is</span> <em>P(Z<sub>k</sub>, X<sub>1:k</sub>)</em><span>, which we computed in the case of the forward algorithm. So for computing</span> <em>P(Z<sub>k|</sub>X)</em><span>, we can compute both the terms using the forward and the backward algorithm. But since </span><em>P(Z<sub>k|</sub>X)</em><span> is proportional to the product of these two terms, we will need to normalize the distribution. </span></p>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Viterbi algorithm</h1>
                </header>
            
            <article>
                
<p>So far, we have been trying to compute the different conditional and joint probabilities in our model. But one thing that we can't do with the forward-backward algorithm is find the most probable state of the hidden variables in the model given the observations. Formally, we can write this problem as, we know the observed variable, the transition probabilities and the emission probability of the network and we would like to compute <em>Z<sup>*</sup></em>, which is defined as:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/7d6cea05-5fb3-4358-8e3a-28ecf75e8f75.png" style="width:10.58em;height:2.08em;"/></div>
<p class="CDPAlignLeft CDPAlign">Where,</p>
<p class="CDPAlignCenter CDPAlign"><em>Z={Z<sub>1</sub>, Z<sub>2</sub>, …, Z<sub>n</sub>} </em></p>
<p class="CDPAlignLeft CDPAlign">And,</p>
<p class="CDPAlignCenter CDPAlign"><em>X={X<sub>1</sub>, X<sub>2</sub>, …, X<sub>n</sub>}</em></p>
<div class="packt_figref packt_infobox"><strong>Properties of operations on probability distributions</strong>:<br/>
When we do operations on the probability distributions (marginalization, maximization, and so on), we can push in the operation through the independent terms of the distribution. We can see these examples in the case of marginalization and <em>argmax</em>:<br/>
<br/>
<img class="fm-editor-equation" src="assets/d204b37c-5438-4ec5-a374-f41c3001efbd.png" style="width:16.58em;height:2.33em;"/><br/>
<img class="fm-editor-equation" src="assets/c0471f50-a6ac-4a65-9332-aa98eb651a98.png" style="width:19.17em;height:1.75em;"/></div>
<div class="CDPAlignCenter CDPAlign"><img src="assets/9ae3544c-a122-499b-8149-bdaf63d3f6bb.png" style="width:31.33em;height:10.92em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign"><span><span>Figure 3.6: HMM showing three time slices <em>k-2</em>, <em>k-1</em>, and <em>k</em></span></span></div>
<p>Since we saw that <em>P(Z|X)∝ <span>P(Z, X),</span></em> and since we are trying to compute the <em><span>argmax</span></em>, it wouldn't matter if we compute on either of these two terms. And hence we can say that:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/882e1637-33ba-4ede-8df9-a406e31676d6.png" style="width:20.42em;height:2.42em;"/></div>
<p>Now, we will again try to formulate our equation as a recursion so that it is easier for us to compute. So, let's introduce a new term, <em>µ(k)</em>, defined as:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/bb9faaee-1dc9-4f2c-9841-95bdb643c854.png" style="width:16.58em;height:2.67em;"/></div>
<p>And again, we will try to break this term into known terms. Using the chain rule, we can write it as:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/dfa9fde2-0cba-4d20-ac7d-65e036d531b9.png" style="width:33.42em;height:2.83em;"/></div>
<p>Now, we start pushing in the <em>argmax</em> argument using the property (see information box for details). And this gives us:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/fe6663ef-9bc3-4841-abf1-e236f46646cd.png" style="width:37.00em;height:4.17em;"/></div>
<p>These terms look familiar, <em>P(X<sub>k</sub>|Z<sub>k</sub>)</em> is the emission probability, <em>P(Z<sub>k</sub>|Z<sub>k-1</sub>)</em> is the transition probability, and <img class="fm-editor-equation" src="assets/330530a0-916e-4819-8419-92860b1171ae.png" style="width:19.67em;height:1.83em;"/> is <em>µ(k-1)</em>. So now we have a recursive equation to work with:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/a88a719c-ae24-4c87-8cc6-01f0c1b4ee7f.png" style="width:27.25em;height:2.75em;"/></div>
<p>Since we have the recursive formula, we can compute the values for any <em>k</em> if we have the first term. So, let's look at the first term of the recursion, which is <em>µ(1):</em></p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/690c4938-4439-4cc2-8350-248e46e1f012.png" style="width:19.92em;height:1.50em;"/></div>
<p>Here, the first term is <em>P(Z<sub>1</sub>)</em>, which is our initial probability, which is known. The second term is <em><span>P(X<sub>1</sub>|Z</span><sub>1</sub><span>)</span></em>, which is the emission probability of our model:</p>
<pre>import numpy as np<br/><br/>def viterbi(obs, transition, emission, init=None):<br/>    """<br/>    Return the MAP estimate of state trajectory of Hidden Markov Model.<br/><br/>    Parameters<br/>    ----------<br/>    y : array (T,)<br/>        Observation state sequence. int dtype.<br/><br/>    transition : array (K, K)<br/>        State transition matrix. See HiddenMarkovModel.state_transition for<br/>        details.<br/><br/>    emission : array (K,)<br/>        Emission matrix. See HiddenMarkovModel.emission for details.<br/><br/>    init: optional, (K,)<br/>        Initial state probabilities: Pi[i] is the probability x[0] == i. If<br/>        None, uniform initial distribution is assumed (Pi[:] == 1/K).<br/><br/>    Returns<br/>    -------<br/>    x : array (T,)<br/>        Maximum a posteriori probability estimate of hidden state trajectory,<br/>        conditioned on observation sequence y under the model parameters.<br/><br/>    T1: array (K, T)<br/>        the probability of the most likely path so far<br/><br/>    T2: array (K, T)<br/>        the x_j-1 of the most likely path so far<br/>    """<br/>    # Cardinality of the state space<br/>    K = transition.shape[0]<br/><br/>    emission = np.repeat(emission[np.newaxis, :], K, axis=0)<br/><br/>    # Initialize the priors with default (uniform dist) if not given by caller<br/>    init = init if init is not None else np.full(K, 1 / K)<br/>    T = len(obs)<br/>    T1 = np.empty((K, T), 'd')<br/>    T2 = np.empty((K, T), 'B')<br/><br/>    # Initilaize the tracking tables from first observation<br/>    T1[:, 0] = init * emission[:, obs[0]]<br/>    T2[:, 0] = 0<br/><br/>    # Iterate throught the observations updating the tracking tables<br/>    for i in range(1, T):<br/>        T1[:, i] = np.max(T1[:, i - 1] * transition.T * emission[np.newaxis, :, obs[i]].T, 1)<br/>        T2[:, i] = np.argmax(T1[:, i - 1] * transition.T, 1)<br/><br/>    # Build the output, optimal model trajectory<br/>    x = np.empty(T, 'B')<br/>    x[-1] = np.argmax(T1[:, T - 1])<br/>    for i in reversed(range(1, T)):<br/>        x[i - 1] = T2[x[i], i]<br/><br/>    return x, T1, T2</pre>
<p>We can try it out with the same observations:</p>
<pre>&gt;&gt;&gt; x, T1, T2 = viterbi([0, 0, 0, 0], transition_matrix, emission, init_prob)<br/>&gt;&gt;&gt; print(x)<br/>array([0, 0, 0, 0], dtype=uint8)<br/>&gt;&gt;&gt; print(T1)<br/>array([[ 0.077, 0.02541, 0.0083853, 0.00276715],<br/>       [ 0.077, 0.02541, 0.0083853, 0.00276715],<br/>       [ 0.077, 0.02541, 0.0083853, 0.00276715],<br/>       [ 0.077, 0.02541, 0.0083853, 0.00276715],<br/>       [ 0.077, 0.02541, 0.0083853, 0.00276715],<br/>       [ 0.077, 0.02541, 0.0083853, 0.00276715],<br/>       [ 0.077, 0.02541, 0.0083853, 0.00276715],<br/>       [ 0.077, 0.02541, 0.0083853, 0.00276715],<br/>       [ 0.077, 0.02541, 0.0083853, 0.00276715],<br/>       [ 0.077, 0.02541, 0.0083853, 0.00276715],<br/>       [ 0.077, 0.02541, 0.0083853, 0.00276715],<br/>       [ 0.077, 0.02541, 0.0083853, 0.00276715],<br/>       [ 0.077, 0.02541, 0.0083853, 0.00276715]])<br/>&gt;&gt;&gt; print(T2)<br/>array([[ 0, 0, 0, 0],<br/>       [ 0, 0, 0, 0],<br/>       [ 0, 1, 1, 1],<br/>       [ 0, 3, 3, 3],<br/>       [ 0, 3, 3, 3],<br/>       [ 0, 0, 0, 0],<br/>       [ 0, 6, 6, 6],<br/>       [ 0, 4, 4, 4],<br/>       [ 0, 5, 5, 5],<br/>       [ 0, 8, 8, 8],<br/>       [ 0, 6, 6, 6],<br/>       [ 0, 10, 10, 10],<br/>       [ 0, 7, 7, 7]], dtype=uint8)<br/><br/>&gt;&gt;&gt; x, T1, T2 = viterbi([0, 10, 8, 6], transition_matrix, emission, init_prob)<br/>&gt;&gt;&gt; print(x)<br/>array([0, 0, 0, 0], dtype=uint8)<br/>&gt;&gt;&gt; print(T1)<br/>array([[ 0.077, 0., 0., 0. ],<br/>       [ 0.077, 0., 0., 0. ],<br/>       [ 0.077, 0., 0., 0. ],<br/>       [ 0.077, 0., 0., 0. ],<br/>       [ 0.077, 0., 0., 0. ],<br/>       [ 0.077, 0., 0., 0. ],<br/>       [ 0.077, 0., 0., 0. ],<br/>       [ 0.077, 0., 0., 0. ],<br/>       [ 0.077, 0., 0., 0. ],<br/>       [ 0.077, 0., 0., 0. ],<br/>       [ 0.077, 0., 0., 0. ],<br/>       [ 0.077, 0., 0., 0. ],<br/>       [ 0.077, 0., 0., 0. ]])<br/><br/>&gt;&gt;&gt; print(T2)<br/>array([[ 0, 0, 0, 0],<br/>       [ 0, 0, 0, 0],<br/>       [ 0, 1, 0, 0],<br/>       [ 0, 3, 0, 0],<br/>       [ 0, 3, 0, 0],<br/>       [ 0, 0, 0, 0],<br/>       [ 0, 6, 0, 0],<br/>       [ 0, 4, 0, 0],<br/>       [ 0, 5, 0, 0],<br/>       [ 0, 8, 0, 0],<br/>       [ 0, 6, 0, 0],<br/>       [ 0, 10, 0, 0],<br/>       [ 0, 7, 0, 0]], dtype=uint8)</pre>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we introduced algorithms for doing inference over our HMM models. We looked at the forward-backward algorithm to do predictions for our hidden states given the observations. We also discussed the Viterbi algorithm, which is used to compute the most probable states in our model. </p>
<p>In all these algorithms, we assumed that we knew the transition and the emission probabilities of the model. But in real-world problems, we need to compute these values from the data. In the next chapter, we will introduce algorithms for computing transition and emission probabilities using the maximum-likelihood approach. </p>


            </article>

            
        </section>
    </body></html>