- en: Training Your GANs to Break Different Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There has been a clear trend that people enjoy using deep learning methods to
    solve problems in the computer vision field. Has one of your classmates or colleagues
    ever shown off their latest image classifier to you? Now, with GANs, you may actually
    get the chance to show them what you can do by generating adversarial examples
    to break their previous models.
  prefs: []
  type: TYPE_NORMAL
- en: We will be looking into the fundamentals of adversarial examples and how to
    attack and confuse a CNN model with **FGSM** (**Fast Gradient Sign Method**).
    We will also learn how to train an ensemble classifier with several pre-trained
    CNN models via transfer learning on Kaggle's Cats vs. Dogs dataset, following
    which, we will learn how to use an accimage library to speed up your image loading
    even more and train a GAN model to generate adversarial examples and fool the
    image classifier.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Adversarial examples – attacking deep learning models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generative adversarial examples
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adversarial examples – attacking deep learning models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is known that with deep learning methods that have huge numbers of parameters,
    sometimes more than tens of millions, it becomes more difficult for humans to comprehend
    what exactly they have learned, except the fact that they perform unexpectedly
    well in CV and NLP fields. If someone around you feels exceptionally comfortable
    using deep learning to solve each and every practical problem without a second
    thought, what we are about to learn in this chapter will help them to realize
    the potential risks their models are exposed to.
  prefs: []
  type: TYPE_NORMAL
- en: What are adversarial examples and how are they created?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Adversarial examples are a kind of sample (often modified based on real data)
    that are easily mistakenly classified by a machine learning system (and sometimes
    look normal to the human eye). Modifications to image data could be a small amount
    of added noise ([https://openai.com/blog/adversarial-example-research](https://openai.com/blog/adversarial-example-research))
    or a small image patch (Tom B. Brown, et al, 2017). Sometimes, printing them on
    paper and taking pictures of adversarial examples also fools neural networks.
    It is even possible to 3D-print an object that fools neural networks from almost
    all perspectives (Anish Athalye, et al, 2018). Although you can create some random
    samples that look like nothing natural and still cause neural networks to make
    mistakes, it is far more interesting to study the adversarial examples that look
    normal to humans but are misclassified by neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: Be assured that we are not going off-topic discussing adversarial examples here.
    For starters, Ian Goodfellow, known as the father of GANs, has spent a decent
    amount of time studying adversarial examples. Adversarial examples and GANs might
    be siblings! Joking aside, GANs are good for generating convincing and realistic
    samples, as well as generating samples that fool other classifier models. In this
    chapter, we will first walk through how to construct adversarial examples and
    attack a small model in PyTorch. Then, we will show you how to use GANs to generate
    adversarial examples to attack a large model.
  prefs: []
  type: TYPE_NORMAL
- en: Adversarial attacking with PyTorch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There is an excellent toolbox for adversarial attacks, defense, and benchmarks
    for TensorFlow called CleverHans ([https://github.com/tensorflow/cleverhans](https://github.com/tensorflow/cleverhans)).
    Currently, the developers are making plans to support PyTorch ([https://github.com/tensorflow/cleverhans/blob/master/tutorials/future/torch/cifar10_tutorial.py](https://github.com/tensorflow/cleverhans/blob/master/tutorials/future/torch/cifar10_tutorial.py)).
    In this section, we will need to implement an adversarial example in PyTorch.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code snippet is based on the official tutorial by PyTorch: [https://pytorch.org/tutorials/beginner/fgsm_tutorial.html](https://pytorch.org/tutorials/beginner/fgsm_tutorial.html).
    We will slightly modify the model and the creation of adversarial examples will
    be performed in batchs. Start with a blank file named `advAttackGAN.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the modules:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Define the device and the perturbation factors:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Define the CNN model, which is known as the LeNet-5 model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Define the data loader for both training and testing. Here, we''ll use the
    MNIST dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Note that, to make the defined perturbation factors work for our model, we are
    not normalizing (whitening) the data by subtracting the mean value and dividing
    by the standard deviation value.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create the `model`, `optimizer`, and `loss` functions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Define the `train` and `test` functions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s train the model and see what this small model is capable of:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The output messages may look like these:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: We can see that our small CNN model achieves 99.31% test accuracy after only
    5 epochs of training.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, implement FGSM to create an adversarial example from the read sample and
    its derivatives:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Use `fgsm_attack` to perturbate test images and see what happens:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we save the first five test images to `adv_examples` to show the predicted
    labels before and after perturbation. You can always replace the `indices = torch.arange(5)` line with
    the following line to only show adversarial examples that cause the model to fail:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The output messages in the Terminal may look like these:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: We can see that, as `epsilon` increases, more samples are mistakenly classified
    by the model. The test accuracy of the model drops to 16.7% at worst.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, illustrate the perturbed images with `matplotlib`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Here are the first five test images and their predicted labels before and after
    perturbation with different factor values:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c40dba63-d0ee-4476-9f3b-b8d4a4f906f7.png)'
  prefs: []
  type: TYPE_IMG
- en: Adversarial examples created from MNIST
  prefs: []
  type: TYPE_NORMAL
- en: Generative adversarial examples
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have been using GANs to generate various types of images in the previous
    chapters. Now, it's time to try generating adversarial examples with GANs and
    break some models!
  prefs: []
  type: TYPE_NORMAL
- en: Preparing an ensemble classifier for Kaggle's Cats vs. Dogs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To make our demonstration more similar to practical scenarios, we will train
    a decent model on Kaggle's Cats vs. Dogs dataset ([https://www.kaggle.com/c/dogs-vs-cats](https://www.kaggle.com/c/dogs-vs-cats)),
    then break the model with adversarial examples generated by GAN. This dataset
    contains 25,000 training images and 12,500 testing images of either dogs or cats.
    Here, we will only use the 25,000 training images in our experiment.
  prefs: []
  type: TYPE_NORMAL
- en: 'For convenience, after downloading the dataset, put images of cats and dogs
    in separate folders, so that the file structure looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The model we are training on this dataset is formed of several pre-trained
    models provided by PyTorch Hub ([https://github.com/pytorch/hub](https://github.com/pytorch/hub)).
    We will also need to perform transfer training on the pre-trained models to fit
    our dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/76921976-ed7d-47c0-8a37-cbf386539d27.png)'
  prefs: []
  type: TYPE_IMG
- en: Ensemble model for Kaggle's Cats vs. Dogs
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we need to load and preprocess the data, create an ensemble classifier,
    and train this model. Here are the detailed steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a Python file named `cats_dogs.py` and import the Python modules:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Here, the custom module files, `advGAN`, `data_utils`,and `model_ensemble`,
    will be created later.
  prefs: []
  type: TYPE_NORMAL
- en: 'Define the main entry point in `cats_dogs.py`, in which argument values are
    parsed and the image decoding backend is defined. Here, only some of the lines
    are shown due to the length. The full source code is available in the `cats_dogs`
    folder, under the code repository for this chapter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Here, we use `accimage` as an image decoding backend for `torchvision`. **Accimage**
    ([https://github.com/pytorch/accimage](https://github.com/pytorch/accimage)) is
    an image decoding and preprocessing library designed for `torchvision`, which
    uses Intel IPP ([https://software.intel.com/en-us/intel-ipp](https://software.intel.com/en-us/intel-ipp))
    to improve processing speed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Above the main entry point, define the `main` function, in which we first load
    and split the training images into a training set and a validation set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We split the 25,000 training images into 2 collections, in which 80% of the
    images are randomly selected to form the training set and the remaining 20% form
    the validation set. Here, `_transforms_catsdogs` is defined in `data_utils.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Again, we are not whitening the images. However, if you are interested in how
    to efficiently calculate the mean and standard deviation values of a dataset,
    the code snippet is provided in the `mean_std.py` file.
  prefs: []
  type: TYPE_NORMAL
- en: Be comfortable with using `multiprocessing.Pool` to process your data, which
    is demonstrated in `mean_std.py`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Get the pre-trained model files from PyTorch Hub and start transfer learning:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The code for evaluation is omitted due to the length. Here, `transfer_init`
    is defined in `model_ensemble.py` and is responsible for replacing the second
    to the last layer in each model so that we can train it for any number of classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Here's why we can transfer the knowledge learned from one domain (trained on
    ImageNet) to another domain (Cats vs. Dogs) by simply replacing the last layer
    (usually a fully connected layer). All of the convolution layers in a CNN are
    responsible for extracting features from the image and intermediate feature maps.
    The fully connected layer can be seen as recombining the highest-level features
    to form the final abstraction of the raw data. It is obvious that good models
    trained on ImageNet are good at extracting features. Therefore, recombining those
    features differently is highly likely to be capable for an easier dataset such
    as Cats vs. Dogs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, `data_prefetcher` is used to speed up the training process. It''s defined
    in `data_utils.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The training of these individual models can be really fast. Here is the GPU
    memory consumption and validation accuracy after 25 epochs of transfer learning:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Model** | **Memory** | **Accuracy** |'
  prefs: []
  type: TYPE_TB
- en: '| MobileNet V2 | 1665MB | 98.14% |'
  prefs: []
  type: TYPE_TB
- en: '| ResNet-18 | 1185MB | 98.24% |'
  prefs: []
  type: TYPE_TB
- en: '| DenseNet | 1943MB | 98.76% |'
  prefs: []
  type: TYPE_TB
- en: '| GoogleNet | 1447MB | 98.06% |'
  prefs: []
  type: TYPE_TB
- en: '| ResNeXt-50 | 1621MB | 98.98% |'
  prefs: []
  type: TYPE_TB
- en: ResNet-34, ShuffleNet V2, SqueezeNet, and VGG-11 are not selected due to either
    low performance or high memory consumption (over 2 GB).
  prefs: []
  type: TYPE_NORMAL
- en: Saving your model to the hard drive with `torch.save(model.state_dict(), PATH)`
    will only export the parameter values and you need to explicitly define `model`
    before loading it in another script. However, `torch.save(model, PATH)` will save
    everything, including the model definition, to the file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Put together the ensemble classifier in `model_ensemble.py`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Here, the prediction results from all models are combined together to give the
    final prediction in `vote_layer`.
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, you can always directly put together the feature maps from the
    last convolution layers in the pretrained models and train one single fully connected
    layer to predict the image label.
  prefs: []
  type: TYPE_NORMAL
- en: 'Get back to the `cats_dogs.py` file and start training the ensemble classifier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Again, the code for evaluation is omitted due to the length. Validation accuracy
    of the ensemble classifier reaches 99.32% after only 2 epochs of training. The
    training of the ensemble classifier only takes 2775 MB of the GPU memory and the
    exported model file size is no more than 200 MB.
  prefs: []
  type: TYPE_NORMAL
- en: Breaking the classifier with advGAN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The GAN model we''ll use for generating adversarial examples is largely borrowed
    from [https://github.com/mathcbc/advGAN_pytorch](https://github.com/mathcbc/advGAN_pytorch).
    Let''s create two files named `advGAN.py` and `models.py` and put the following
    code in these files:'
  prefs: []
  type: TYPE_NORMAL
- en: '`advGAN.py`: Within this file, you will see the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Part of the code is omitted due to the length. We can see that this GAN model
    is only responsible for generating the noise part in the adversarial example,
    which is clamped to [-0.3, 0.3] before being added to the original image. During
    training, MSE loss is used to measure the discriminator loss. L1-loss is used
    to calculate the adversarial loss for the generator. The L2-norm of the generated
    perturbation noise is also included in the generator loss. However, the performance
    of the GAN is highly related to the classifier (`self.model`) we are aiming to
    break, which means that the GAN model needs to be retrained each time a new classifier
    is introduced.
  prefs: []
  type: TYPE_NORMAL
- en: The code in `models.py` is omitted here but is available in the code repository
    for this chapter, since you can basically design the discriminator and generator
    any way you like. Here, we use a 4-layer CNN as the discriminator network and
    a 14-layer ResNet-like CNN as the generator network.
  prefs: []
  type: TYPE_NORMAL
- en: Back to `cats_dogs.py`, we need to train the GAN model to learn how to break
    the ensemble classifier.
  prefs: []
  type: TYPE_NORMAL
- en: 'Redefine the data loader because we need a smaller batch size to fit in the
    11 GB GPU memory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Start training the GAN model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Attack the ensemble classifier with the GAN:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'It takes about 6 hours to finish 60 epochs of training on the GAN model. The
    attack result may look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: We can see that the validation accuracy drops from 99.32% to 10.3% as a result
    of the adversarial attack by the GAN.
  prefs: []
  type: TYPE_NORMAL
- en: 'Display some of the misclassified images with `matplotlib`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Now that everything in the code is finished, it's time to finally actually run
    our program.  We need to do this multiple times, once for each model. Create an
    empty folder named models in your code folder to hold the saved models.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll start the program from the command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Once all the models have run, we can finally test our ensemble code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Here are some of the pertubated images generated by the GAN that fooled our
    ensemble classifier:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0156142b-1ebb-4e7d-b7b9-67837d9e8eab.png)'
  prefs: []
  type: TYPE_IMG
- en: Adversarial examples generated by the GAN
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A lot that has gone on in this chapter. You've learned the basics of Fast Gradient
    Sign Methods, how to train a  classifier with pre-trained models, how to deal
    with transfer learning, and much more.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will show how to combine **NLP** (**Natural Language
    Processing**) with GANs and generate images from the description text.
  prefs: []
  type: TYPE_NORMAL
- en: References and further reading list
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Goodfellow I, Papernot N, Huang S, et. al. (Feb 24, 2017). *Attacking machine
    learning with adversarial examples*. Retrieved from [https://openai.com/blog/adversarial-example-research](https://openai.com/blog/adversarial-example-research).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Brown T, Mané D, Roy A, et al (2017). *Adversarial Patch*. NIPS.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Athalye A, Engstrom L, Ilyas A. (2018). *Synthesizing Robust Adversarial Examples*.
    ICML.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
