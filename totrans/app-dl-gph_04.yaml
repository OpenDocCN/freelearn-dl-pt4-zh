- en: '4'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deep Learning Models for Graphs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In recent years, the field of machine learning has witnessed a paradigm shift
    with the emergence of **graph neural networks** ( **GNNs** ) as powerful tools
    for addressing prediction tasks on graph-structured data. Here, we'll delve into
    the transformative potential of GNNs, highlighting their role as optimizable transformations
    capable of handling diverse graph attributes, such as nodes, edges, and global
    context while preserving crucial graph symmetries, particularly permutation invariances.
  prefs: []
  type: TYPE_NORMAL
- en: The foundation of GNNs lies in the **message-passing neural network** ( **MPNN**
    ) framework. Through this framework, GNNs leverage a sophisticated mechanism for
    information exchange and aggregation across graph structures, enabling the model
    to capture intricate relationships and dependencies within the data.
  prefs: []
  type: TYPE_NORMAL
- en: One distinctive feature of GNNs is their adherence to a *graph-in, graph-out*
    architecture. This means that the model accepts a graph as input, equipped with
    information embedded in its nodes, edges, and global context. This inherent structure
    aligns with many real-world problems where data exhibits complex relationships
    and dependencies best represented as graphs.
  prefs: []
  type: TYPE_NORMAL
- en: GNNs excel in their ability to perform a progressive embedding transformation
    on the input graph without altering its connectivity. This progressive transformation
    ensures that the model refines its understanding of the underlying patterns and
    structures within the data, contributing to enhanced predictive capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll cover the following topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Message passing in graphs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decoding GNNs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Graph convolutional** **networks** ( **GCNs** )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Graph Sample and** **Aggregation** ( **GraphSAGE** )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Graph attention** **networks** ( **GATs** )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter requires a basic understanding of graphs and representation learning
    as covered in previous chapters. The code present in the chapter and on GitHub
    can be used directly on Google Colab with an additional installation of the **PyTorch
    Geometric** ( **PyG** ) package. The code examples for the book are available
    in its GitHub repository: [https://github.com/PacktPublishing/Applied-Deep-Learning-on-Graphs](https://github.com/PacktPublishing/Applied-Deep-Learning-on-Graphs)
    .'
  prefs: []
  type: TYPE_NORMAL
- en: Message passing in graphs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unlike traditional neural networks, GNNs need to account for the inherent structure
    of the graph, allowing nodes to exchange information and update their representations
    based on their local neighborhoods. This core mechanism is achieved through **message
    passing** , a process of iteratively passing messages between nodes and aggregating
    information from their neighbors.
  prefs: []
  type: TYPE_NORMAL
- en: GNNs operate on graph-structured data and use a message-passing mechanism to
    update node representations based on information from neighboring nodes. Let’s
    delve into the mathematical explanation of message passing in GNNs.
  prefs: []
  type: TYPE_NORMAL
- en: Consider an undirected graph ![<mml:math  ><mml:mi>G</mml:mi><mml:mi mathvariant="normal"> </mml:mi><mml:mo>=</mml:mo><mml:mi
    mathvariant="normal"> </mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi
    mathvariant="normal"> </mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/116.png)
    , where ![<mml:math  ><mml:mi>V</mml:mi></mml:math>](img/1.png) is the set of
    nodes and ![<mml:math  ><mml:mi mathvariant="normal"> </mml:mi><mml:mi>E</mml:mi></mml:math>](img/118.png)
    is the set of edges. Each node ![<mml:math  ><mml:mi>v</mml:mi></mml:math>](img/89.png)
    in ![<math ><mrow><mi>V</mi></mrow></math>](img/120.png) has an associated feature
    vector ![<mml:math  ><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub></mml:math>](img/121.png)
    . The goal of a GNN is to learn a representation ![<mml:math  ><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub></mml:math>](img/122.png)
    for each node ![<mml:math  ><mml:mi>v</mml:mi></mml:math>](img/89.png) that captures
    information from its neighborhood.
  prefs: []
  type: TYPE_NORMAL
- en: 'The basic message-passing operation in a GNN can be broken down into a series
    of steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Aggregation** **of messages** :'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each node ![<mml:math  ><mml:mi>v</mml:mi></mml:math>](img/89.png) , gather
    information   from its neighbors.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Let ![<mml:math  ><mml:mi>N</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/125.png)
    represent the set of neighbors of node ![<mml:math  ><mml:mi>v</mml:mi></mml:math>](img/89.png)
    .
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The aggregated message ![<mml:math  ><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub></mml:math>](img/127.png)
    for node ![<mml:math  ><mml:mi>v</mml:mi></mml:math>](img/128.png) is computed
    by aggregating information from its neighbors:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![<mml:math   display="block"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mi> </mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi> </mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mi> </mml:mi></mml:mrow></mml:msub><mml:mo>:</mml:mo><mml:mi> </mml:mi><mml:mi>u</mml:mi><mml:mi> </mml:mi><mml:mi>ϵ</mml:mi><mml:mi> </mml:mi><mml:mi>N</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math>](img/129.png)'
  prefs: []
  type: TYPE_IMG
- en: The aggregation function can vary (e.g., sum, mean, or attention-weighted sum).
  prefs: []
  type: TYPE_NORMAL
- en: '**UPDATE function** :'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Update the node representation ![<mml:math  ><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub></mml:math>](img/122.png)
    based on the aggregated message ![<mml:math  ><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub></mml:math>](img/131.png)
    and the current node   representation ![<mml:math  ><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub></mml:math>](img/122.png)
    .
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The **UPDATE** function ![<math ><mrow><mrow><mi>u</mi><mi>p</mi><mi>d</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow></mrow></math>](img/133.png)
    ( ![<mml:math  ><mml:mo>∙</mml:mo></mml:math>](img/134.png) ) is a neural network
    layer that takes the aggregated message and the current node representation as
    input and produces the updated representation:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>''</mml:mi></mml:mrow></mml:msubsup></mml:math>](img/135.png)
    = ![<math ><mrow><mrow><mi>u</mi><mi>p</mi><mi>d</mi><mi>a</mi><mi>t</mi><mi>e</mi><mfenced
    open="(" close=")"><mrow><msub><mi>h</mi><mi>v</mi></msub><mo>,</mo><msub><mi>m</mi><mi>v</mi></msub></mrow></mfenced></mrow></mrow></math>](img/136.png)'
  prefs: []
  type: TYPE_IMG
- en: The **UPDATE** function typically involves a neural network layer with learnable
    parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'These steps are iteratively applied for a fixed number of times or until convergence
    to refine the node representations. The overall process can be expressed in a
    few equations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math   display="block"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mi> </mml:mi></mml:mrow></mml:msub><mml:mo>:</mml:mo><mml:mi> </mml:mi><mml:mi>u</mml:mi><mml:mi> </mml:mi><mml:mo>∈</mml:mo><mml:mi> </mml:mi><mml:mi>N</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math>](img/137.png)'
  prefs: []
  type: TYPE_IMG
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>''</mml:mi></mml:mrow></mml:msubsup><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mi>u</mml:mi><mml:mi>p</mml:mi><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mi> </mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math>](img/138.png)'
  prefs: []
  type: TYPE_IMG
- en: These equations capture the essence of the message-passing mechanism in a GNN.
    The specific choices for the aggregation function, **UPDATE** function, and the
    number of iterations depend on the architecture of the GNN (e.g., GraphSAGE, GCN,
    **gated graph neural networks** ( **GGNNs** ), etc.).
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, in a simple **GraphSAGE** formulation, the aggregation function
    might be a mean operation, and the **UPDATE** function might be a simple neural
    network layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math   display="block"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mi> </mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mfenced
    open="|" close="|" separators="|"><mml:mrow><mml:mi>N</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac><mml:mrow><mml:munder><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi> </mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mi> </mml:mi><mml:mi>ϵ</mml:mi><mml:mi> </mml:mi><mml:mi>N</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi> </mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math>](img/139.png)'
  prefs: []
  type: TYPE_IMG
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>''</mml:mi></mml:mrow></mml:msubsup><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mi>σ</mml:mi><mml:mi> </mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mi>W</mml:mi><mml:mi> </mml:mi><mml:mo>⋅</mml:mo><mml:mi> </mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi> </mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:mo>,</mml:mo><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math>](img/140.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![<mml:math  ><mml:mi>σ</mml:mi></mml:math>](img/141.png) is an activation   function,
    ![<mml:math  ><mml:mi>W</mml:mi></mml:math>](img/142.png) is a learnable weight
    matrix, and ![<mml:math  ><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mo>⋅</mml:mo></mml:mrow></mml:mfenced></mml:math>](img/143.png)
    is the concatenation operation.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.1 – Message passing in graphs](img/B22118_04_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.1 – Message passing in graphs
  prefs: []
  type: TYPE_NORMAL
- en: Through these iterative steps, message passing enables nodes to learn representations
    that capture not only their own intrinsic features but also the information from
    their connected neighbors and the overall structure of the graph. This allows
    GNNs to effectively model complex relationships and dependencies within graph-structured
    data.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s try to understand how to formally define a GNN.
  prefs: []
  type: TYPE_NORMAL
- en: Decoding GNNs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A **GNN** is a neural network architecture designed to operate on graph-structured
    data. It learns a function that maps a graph and its associated features to a
    set of node-level, edge-level, or graph-level outputs. The following is a formal
    mathematical definition of a GNN.
  prefs: []
  type: TYPE_NORMAL
- en: Given a graph ![<mml:math  ><mml:mi>G</mml:mi><mml:mi mathvariant="normal"> </mml:mi><mml:mo>=</mml:mo><mml:mi
    mathvariant="normal"> </mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi
    mathvariant="normal"> </mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/144.png)
    , where ![<mml:math  ><mml:mi>V</mml:mi></mml:math>](img/1.png) is the set of
    nodes and ![<mml:math  ><mml:mi>E</mml:mi></mml:math>](img/146.png) is the set
    of edges, let ![<mml:math  ><mml:mi>X</mml:mi><mml:mi mathvariant="normal"> </mml:mi><mml:mo>∈</mml:mo><mml:mi
    mathvariant="normal"> </mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mfenced
    open="|" close="|" separators="|"><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mfenced><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:math>](img/147.png)
    be the node feature matrix, where each row ![<mml:math  ><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mi
    mathvariant="normal"> </mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:math>](img/148.png)
    represents the features of node ![<math ><mrow><mrow><mi>v</mi><mspace width="0.25em"
    /><mo>∈</mo><mspace width="0.25em" /><mi>V</mi></mrow></mrow></math>](img/149.png)
    .
  prefs: []
  type: TYPE_NORMAL
- en: A GNN is a function ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mi
    mathvariant="normal"> </mml:mi><mml:mo>:</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:mi>G</mml:mi><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mi
    mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="|"
    close="|" separators="|"><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mfenced><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup><mml:mo>→</mml:mo><mml:msup><mml:mrow><mml:mi
    mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="|"
    close="|" separators="|"><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mfenced><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi
    mathvariant="normal">'</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:msup></mml:math>](img/150.png)
    parameterized by learnable weights ![<mml:math  ><mml:mi>θ</mml:mi></mml:math>](img/151.png)
    , which maps the graph ![<mml:math  ><mml:mi>G</mml:mi></mml:math>](img/152.png)
    and its node features ![<mml:math  ><mml:mi>X</mml:mi></mml:math>](img/153.png)
    to a new set of node representations ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>H</mml:mi><mml:mi
    mathvariant="normal"> </mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:msup><mml:mrow><mml:mi
    mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="|"
    close="|" separators="|"><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mfenced><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi
    mathvariant="normal">'</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:msup></mml:math>](img/154.png)
    , where ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi
    mathvariant="normal">'</mml:mi></mml:mrow></mml:msup></mml:math>](img/155.png)
    is the dimensionality of the output node representations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The function ![<mml:math  ><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub></mml:math>](img/156.png)
    is computed through a series of message passing and aggregation steps, typically
    organized into ![<mml:math  ><mml:mi>L</mml:mi></mml:math>](img/115.png) layers.
    At each layer ![<mml:math  ><mml:mi>l</mml:mi><mml:mi> </mml:mi><mml:mo>∈</mml:mo><mml:mi> </mml:mi><mml:mfenced
    open="{" close="}" separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi> </mml:mi><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi> </mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/158.png)
    , the node representations are updated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math   display="block"><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi
    mathvariant="normal"> </mml:mi><mml:mi>U</mml:mi><mml:mi>P</mml:mi><mml:mi>D</mml:mi><mml:mi>A</mml:mi><mml:mi>T</mml:mi><mml:msup><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup><mml:mfenced
    separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mi
    mathvariant="normal"> </mml:mi><mml:mi>A</mml:mi><mml:mi>G</mml:mi><mml:msup><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup><mml:mfenced
    separators="|"><mml:mrow><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>:</mml:mo><mml:mi
    mathvariant="normal"> </mml:mi><mml:mi>u</mml:mi><mml:mi mathvariant="normal"> </mml:mi><mml:mo>∈</mml:mo><mml:mi
    mathvariant="normal"> </mml:mi><mml:mi>N</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math>](img/159.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let’s break this down:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math  ><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mi>ϵ</mml:mi><mml:mi> </mml:mi><mml:msup><mml:mrow><mml:mi
    mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math>](img/160.png)
    is the representation of node ![<mml:math  ><mml:mi>v</mml:mi></mml:math>](img/95.png)
    at layer ![<mml:math  ><mml:mi> </mml:mi><mml:mi>l</mml:mi><mml:mo>,</mml:mo></mml:math>](img/162.png)
    with ![<mml:math  ><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub></mml:math>](img/163.png)
    . Here, ![<mml:math  ><mml:mi> </mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:msup></mml:math>](img/164.png)
    represents a real-valued vector space of dimension ![<mml:math  ><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math>](img/165.png)
    .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **UPDATE function** ![<math ><mrow><mrow><mi>U</mi><mi>P</mi><mi>D</mi><mi>A</mi><mi>T</mi><msup><mi>E</mi><mi>l</mi></msup><mo>:</mo><mspace
    width="0.25em" /><msup><mi mathvariant="double-struck">R</mi><mfenced open="("
    close=")"><msub><mi>d</mi><mrow><mi>l</mi><mo>−</mo><mn>1</mn></mrow></msub></mfenced></msup><mspace
    width="0.25em" /><mi mathvariant="normal">Χ</mi><mspace width="0.25em" /><msup><mi
    mathvariant="double-struck">R</mi><mrow><mfenced open="(" close=")"><msub><mi>d</mi><mi>l</mi></msub></mfenced><mspace
    width="0.25em" /></mrow></msup><mo>→</mo><mspace width="0.25em" /><mspace width="0.25em"
    /><msup><mi mathvariant="double-struck">R</mi><mrow><mfenced open="(" close=")"><msub><mi>d</mi><mi>l</mi></msub></mfenced><mspace
    width="0.25em" /></mrow></msup></mrow></mrow></math>](img/166.png) is a learnable
    function that updates the node   representation based on its previous representation
    and the aggregated messages from its neighbors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **aggregation (AGG) function** ![<mml:math  ><mml:mi>A</mml:mi><mml:mi>G</mml:mi><mml:msup><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup><mml:mo>:</mml:mo><mml:msup><mml:mrow><mml:mi
    mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>*</mml:mi></mml:mrow></mml:msup><mml:mo>→</mml:mo><mml:mi> </mml:mi><mml:msup><mml:mrow><mml:mi
    mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math>](img/167.png)
    is a permutation-invariant aggregation function that   combines the representations
    of the neighboring nodes. Common choices include sum, mean, and max.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![<mml:math  ><mml:mi>N</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/125.png)
    denotes the set of neighbors of node ![<mml:math  ><mml:mi>v</mml:mi></mml:math>](img/89.png)
    in the graph ![<math ><mrow><mi>G</mi></mrow></math>](img/170.png) .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After ![<mml:math  ><mml:mi> </mml:mi><mml:mi>L</mml:mi></mml:math>](img/171.png)
    layers of message passing   and aggregation, the final node representations are
    given by ![<mml:math  ><mml:mi>H</mml:mi><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msubsup></mml:math>](img/172.png)
    for all ![<mml:math  ><mml:mi>v</mml:mi><mml:mi> </mml:mi><mml:mo>∈</mml:mo><mml:mi> </mml:mi><mml:mi>V</mml:mi></mml:math>](img/173.png)
    .
  prefs: []
  type: TYPE_NORMAL
- en: The **UPDATE** function is typically implemented as neural networks, such as
    **multi-layer perceptrons** ( **MLPs** ) or attention mechanisms, with learnable
    parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'For graph-level tasks, a **READOUT function** is applied to the final node
    representations to obtain a graph-level representation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math   display="block"><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi
    mathvariant="normal"> </mml:mi><mml:mi>R</mml:mi><mml:mi>E</mml:mi><mml:mi>A</mml:mi><mml:mi>D</mml:mi><mml:mi>O</mml:mi><mml:mi>U</mml:mi><mml:mi>T</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msubsup><mml:mo>:</mml:mo><mml:mi
    mathvariant="normal"> </mml:mi><mml:mi>v</mml:mi><mml:mi mathvariant="normal"> </mml:mi><mml:mo>∈</mml:mo><mml:mi
    mathvariant="normal"> </mml:mi><mml:mi>V</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math>](img/174.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, **READOUT** is a permutation-invariant function that aggregates the node
    representations into a single vector, such as sum, mean, or a more complex pooling
    operation.
  prefs: []
  type: TYPE_NORMAL
- en: The graph-level representation ![<mml:math  ><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub></mml:math>](img/175.png)
    can then be used for downstream tasks, such as graph classification or regression.
  prefs: []
  type: TYPE_NORMAL
- en: This is a general formulation of GNNs, and there are many specific architectures
    that fall under this framework, such as GCNs, GraphSAGE, GATs, and MPNNs, each
    with their own variations of the **UPDATE** , **AGG** , and **READOUT** functions.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s understand how graph learning borrows the concept of convolution networks
    and leverages it to extract learnings from a graph.
  prefs: []
  type: TYPE_NORMAL
- en: GCNs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**GCNs** are a specific type of GNN that extend the concept of convolution
    to graph-structured data. GCNs learn node representations by aggregating information
    from neighboring nodes, allowing for the capture of both node features and graph
    structure.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In a GCN, the graph convolution operation at layer ![<mml:math  ><mml:mi>l</mml:mi></mml:math>](img/176.png)
    is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math   display="block"><mml:msup><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mi>A</mml:mi><mml:mi
    mathvariant="normal"> </mml:mi><mml:msup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mi
    mathvariant="normal"> </mml:mi><mml:msup><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup><mml:mi
    mathvariant="normal"> </mml:mi><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:math>](img/177.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let’s break this down:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math  ><mml:msup><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mfenced
    open="|" close="|" separators="|"><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mfenced><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math>](img/178.png)
    is the matrix of node representations at layer ![<math ><mrow><mi>l</mi></mrow></math>](img/179.png)
    , with ![<mml:math  ><mml:mi>H</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:mfenced><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mi>X</mml:mi></mml:math>](img/180.png)
    (input node features).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![<mml:math  ><mml:mover accent="true"><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mo>+</mml:mo><mml:mi>I</mml:mi></mml:math>](img/181.png)
    is the adjacency matrix ![<mml:math  ><mml:mi>A</mml:mi></mml:math>](img/43.png)
    with added self-loops, where ![<mml:math  ><mml:mi>I</mml:mi></mml:math>](img/183.png)
    is the identity matrix.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![<mml:math  ><mml:mover accent="true"><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/184.png)
    is the diagonal degree matrix of ![<mml:math  ><mml:mover accent="true"><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/185.png)
    , with ![<mml:math  ><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>̂</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math>](img/186.png)
    .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![<mml:math  ><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup><mml:mi> </mml:mi><mml:mo>∈</mml:mo><mml:mi> </mml:mi><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:mi>x</mml:mi><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mi>​</mml:mi><mml:mi>​</mml:mi></mml:math>](img/187.png)
    is a learnable weight matrix for layer ![<mml:math  ><mml:mi>l</mml:mi></mml:math>](img/176.png)
    .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![<mml:math  ><mml:mi>σ</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mo>⋅</mml:mo></mml:mrow></mml:mfenced></mml:math>](img/189.png)
    is a non-linear activation   function, such as the ** rectified linear unit **
    ( ** ReLU ** ) function or sigmoid function.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The term ![<mml:math  ><mml:msup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mi>A</mml:mi><mml:mi> </mml:mi><mml:msup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:math>](img/190.png)
    is the   symmetrically normalized adjacency matrix, which ensures that the scale
    of the node representations remains consistent across layers.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine a citation network, where each node stands for a scientific paper and
    each edge represents a citation connecting two papers. Each paper has a feature
    vector representing its content (e.g., bag-of-words). A GCN can be used to classify
    the papers into different categories (e.g., computer science, physics, biology)
    by learning node representations that capture both the content and the citation
    structure of the network.
  prefs: []
  type: TYPE_NORMAL
- en: 'Building on our mathematical understanding of the GCN, let’s look at a piece
    of sample code leveraging PyG:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'For this example, we import the necessary libraries and load the **Cora dataset**
    using the **Planetoid** class from PyG. The Cora dataset is a citation network
    dataset, where *nodes* represent scientific papers and *edges* represent citations
    between papers. The dataset contains 2,708 nodes, 10,556 edges, and 7 classes
    representing different research areas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we access the graph data using **dataset[0]** . We then print some statistics
    about the graph, including the number of nodes, edges, features, and classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we understand what the data looks like, let’s put down the building
    blocks of the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we define the GCN model. The model consists of two GCN layers ( **GCNConv**
    ) with a hidden layer in between. The **__init__** method initializes the layers
    with the specified input, hidden, and output dimensions. The **forward** method
    defines the forward pass of the model, where **x** and **edge_index** are passed
    through the GCN layers. ReLU activation and dropout are applied after the first
    layer, and **log-softmax** is applied to the output of the second layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we set the model parameters based on the dataset. The input dimension
    ( **in_channels** ) is set to the number of node features in the dataset, the
    hidden dimension ( **hidden_channels** ) is set to **16** , and the output dimension
    ( **out_channels** ) is set to the number of classes in the dataset. We then create
    an instance of the GCN model with these parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: In this part, we define the optimizer ( **Adam** ) and the loss function ( **negative
    log-likelihood loss (NLLLoss)** ) for training the model. We set the learning
    rate to **0.01** and the weight decay to **5e-4** .
  prefs: []
  type: TYPE_NORMAL
- en: 'We then train the model for 200 epochs. In each epoch, we do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Zero the gradients of the optimizer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Perform a forward pass of the model on the node features and edge index.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute the loss using the model’s output and the ground truth labels for the
    training nodes (specified by **data.train_mask** ).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Perform a backward pass to compute the gradients.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Update the model parameters using the optimizer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Finally, we evaluate the trained model on the test set. We set the model to
    evaluation mode using **model.eval()** . We perform a forward pass on the entire
    graph and obtain the predicted class labels using **max(dim=1)** . We then compute
    the accuracy by comparing the predicted labels with the ground truth labels for
    the test nodes (specified by **data.test_mask** ).
  prefs: []
  type: TYPE_NORMAL
- en: This code provides a basic implementation of GCN using PyG on the Cora dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Make sure you have PyG installed before running this code. You can install it
    using **pip** **install torch-geometric** .
  prefs: []
  type: TYPE_NORMAL
- en: Overall, this code creates an instance of the GCN model, trains it on the Cora
    dataset using the specified hyperparameters (hidden units, learning rate, epochs),
    and evaluates the trained model on the test set to measure its performance in
    terms of accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Using GCNs for different graph tasks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'GCNs can be utilized to learn and perform tasks at different levels in a graph.
    The following can be performed with GCNs:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Node-level tasks** : GCNs can be used for **node classification** , where
    the goal is to predict the label of each node in the graph. This is demonstrated
    in the previous example, where the GCN is used to classify nodes in the Cora citation
    network.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Edge-level tasks** : GCNs can be adapted for **edge prediction** or **link**
    **prediction** tasks, where the goal is to predict the existence or attributes
    of edges in the graph. To do this, the node representations learned by the GCN
    can be used to compute edge scores or probabilities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Graph-level tasks** : GCNs can be used for **graph classification** or **regression**
    tasks, where the goal is to predict a label or a continuous value for an entire
    graph. To achieve this, a pooling operation (e.g., global mean pooling or global
    max pooling) is applied to the node representations learned by the GCN to obtain
    a graph-level representation, which is then fed into a classifier or regressor.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GCNs are a powerful and widely used type of GNN that can effectively learn node
    representations by incorporating both node features and graph structure. They
    have shown strong performance on various graph-based tasks and can be adapted
    for node-level, edge-level, and graph-level problems.
  prefs: []
  type: TYPE_NORMAL
- en: Over time, many optimizations over vanilla GCNs have been proposed and utilized
    in the industry. One such optimization, especially for scaling the graph learning
    process, is GraphSAGE.
  prefs: []
  type: TYPE_NORMAL
- en: GraphSAGE
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**GraphSAGE** introduces a scalable and adaptive approach to graph representation
    learning, addressing some limitations of GCN and enhancing scalability. At its
    core, GraphSAGE employs a neighborhood sampling and aggregation strategy, diverging
    from the fixed-weight aggregation mechanism of GCN.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In GraphSAGE, the process of learning node representations involves iteratively
    sampling and aggregating information from local neighborhoods. Let ![<mml:math  ><mml:mi>G</mml:mi><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/191.png)
    be a graph with nodes ![<mml:math  ><mml:mi>V</mml:mi></mml:math>](img/1.png)
    and edges ![<mml:math  ><mml:mi>E</mml:mi></mml:math>](img/2.png) , and ![<mml:math  ><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msubsup></mml:math>](img/194.png)
    denote the embedding of node ![<mml:math  ><mml:mi>i</mml:mi></mml:math>](img/195.png)
    at layer ![<mml:math  ><mml:mi>l</mml:mi></mml:math>](img/176.png) . The update
    rule for GraphSAGE can be expressed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math   display="block"><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mi
    mathvariant="normal">​</mml:mi><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mi>g</mml:mi><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msubsup><mml:mi
    mathvariant="normal">​</mml:mi><mml:mo>,</mml:mo><mml:mo>∀</mml:mo><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mi>S</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi><mml:mi>p</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>N</mml:mi><mml:mi>e</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>b</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>s</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math>](img/197.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![<mml:math  ><mml:mi>S</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi><mml:mi>p</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>N</mml:mi><mml:mi>e</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>b</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>s</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/198.png)
    represents a dynamically sampled subset of neighbors for node ![<mml:math  ><mml:mi>i</mml:mi></mml:math>](img/199.png)
    at each iteration. This adaptability allows GraphSAGE to scale more efficiently
    compared to GCN, especially in scenarios where the graph is large or when computational
    resources are limited, maintaining scalability.
  prefs: []
  type: TYPE_NORMAL
- en: The structure for PyG code remains the same as for the GCN; we will just be
    using the **GraphSAGE** module from **torch_geometric.nn** .
  prefs: []
  type: TYPE_NORMAL
- en: 'To modify the previous code to use GraphSAGE instead of GCN, you need to make
    a few changes. Here are the lines you need to update:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Replace the **import** statement for **GCNConv** with **SAGEConv** :'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Update the **GCN** model class to use **SAGEConv** layers instead of **GCNConv**
    :'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Update the **model** creation line to use the **GraphSAGE** model instead of
    **GCN** :'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: With these changes, the code will now use the GraphSAGE model instead of GCN.
    The rest of the code, including loading the dataset, training, and evaluation,
    remains the same.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.2 – GraphSAGE network leveraging neighborhood sampling](img/B22118_04_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.2 – GraphSAGE network leveraging neighborhood sampling
  prefs: []
  type: TYPE_NORMAL
- en: At times, it is a good idea to assign different weights to neighbors based on
    their relevance to a particular node. We will now look at GATs, which borrow the
    concept of attention from language models.
  prefs: []
  type: TYPE_NORMAL
- en: GATs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**GATs** are an extension of GCNs that incorporate an attention mechanism to
    assign different weights to neighboring nodes based on their relevance. While
    GCNs apply a fixed aggregation function to combine the features of neighboring
    nodes, GATs allow for a more flexible and adaptive approach by learning the importance
    of each neighbor during the aggregation process. The core of GATs is the attention
    network.'
  prefs: []
  type: TYPE_NORMAL
- en: Attention networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An **attention network** , often referred to as an **attention mechanism** or
    **attention model** , is a powerful concept in machine learning and artificial
    intelligence, particularly in the field of neural networks. It’s inspired by how
    human attention works – focusing on specific parts of input data while processing
    information.
  prefs: []
  type: TYPE_NORMAL
- en: An attention mechanism allows the model to dynamically focus on different parts
    of the input data, assigning varying degrees of importance or attention to each
    part. This enables the model to weigh the relevance of different inputs when making
    predictions or decisions.
  prefs: []
  type: TYPE_NORMAL
- en: Attention networks are commonly used in tasks involving sequential data, such
    as **natural language processing** ( **NLP** ) tasks such as machine translation,
    text summarization, and sentiment analysis. In these tasks, the model needs to
    process sequences of words or tokens and understand the contextual relationships
    between them. By using attention mechanisms, the model can effectively capture
    long-range dependencies and attend to relevant parts of the input sequence.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s how an attention mechanism is leveraged in graph learning:'
  prefs: []
  type: TYPE_NORMAL
- en: In GATs, the attention mechanism is used to compute attention coefficients between
    a node and its neighbors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attention coefficients represent the importance of each neighbor’s features
    to the target node.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The attention mechanism is typically implemented using an MLP or a single-layer
    neural network.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attention coefficients are computed based on the learned weights of the attention
    mechanism and the features of the target node and its neighbors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s look at how we can compute the attention coefficient in a graph setting.
  prefs: []
  type: TYPE_NORMAL
- en: Attention coefficients computation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For each node, the attention coefficients are computed for all its neighbors.
    The attention coefficient between node ![<mml:math  ><mml:mi>i</mml:mi></mml:math>](img/195.png)
    and its neighbor ![<math ><mrow><mi>j</mi></mrow></math>](img/201.png) is calculated
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math  display="block"><mrow><mrow><msub><mi>α</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mfrac><mrow><mi>exp</mi><mfenced
    open="(" close=")"><mrow><mi>L</mi><mi>e</mi><mi>a</mi><mi>k</mi><mi>y</mi><mi>R</mi><mi>e</mi><mi>L</mi><mi>U</mi><mfenced
    open="(" close=")"><mrow><msup><mi>W</mi><mi>T</mi></msup><mo>⋅</mo><mfenced open="["
    close="]"><mrow><msub><mi>h</mi><mi>i</mi></msub><mo>∥</mo><msub><mi>h</mi><mi>j</mi></msub></mrow></mfenced></mrow></mfenced></mrow></mfenced></mrow><mfenced
    open="(" close=")"><mrow><msubsup><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mrow><mi>exp</mi><mfenced
    open="(" close=")"><mrow><mi>L</mi><mi>e</mi><mi>a</mi><mi>k</mi><mi>y</mi><mi>R</mi><mi>e</mi><mi>L</mi><mi>U</mi><mfenced
    open="(" close=")"><mrow><msup><mi>W</mi><mi>T</mi></msup><mo>⋅</mo><mfenced open="["
    close="]"><mrow><msub><mi>h</mi><mi>i</mi></msub><mo>|</mo><msub><mi>h</mi><mi>k</mi></msub></mrow></mfenced></mrow></mfenced></mrow></mfenced></mrow></mrow></mfenced></mfrac></mrow></mrow></math>](img/202.png)'
  prefs: []
  type: TYPE_IMG
- en: '![<mml:math  ><mml:mo>∥</mml:mo></mml:math>](img/203.png) is the concatenation
    operation, and ![<mml:math  ><mml:mi>L</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>k</mml:mi><mml:mi>y</mml:mi><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>L</mml:mi><mml:mi>U</mml:mi></mml:math>](img/204.png)
    is the leaky ReLU activation function.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![<mml:math  ><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/205.png)
    and ![<mml:math  ><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math>](img/206.png)
    are the learned node embeddings for nodes ![<mml:math  ><mml:mi>i</mml:mi></mml:math>](img/195.png)
    and ![<mml:math  ><mml:mi>j</mml:mi></mml:math>](img/208.png) , respectively.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![<mml:math  ><mml:mi>W</mml:mi></mml:math>](img/142.png) is a learnable attention
    weight vector that is shared across all nodes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The attention coefficients are normalized using the **softmax** function to
    ensure they sum up to 1 for each node.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we understand how to compute attention coefficients, let’s see how
    these are utilized in the aggregation step of a GNN.
  prefs: []
  type: TYPE_NORMAL
- en: Aggregation of neighbor features
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once the attention coefficients are computed, the features of the neighboring
    nodes are aggregated using a weighted sum.
  prefs: []
  type: TYPE_NORMAL
- en: 'The aggregated features for node ![<mml:math  ><mml:mi>i</mml:mi></mml:math>](img/195.png)
    are calculated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi
    mathvariant="normal">''</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mi>ϵ</mml:mi><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi
    mathvariant="normal"> </mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mi
    mathvariant="normal">*</mml:mi><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math>](img/211.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![<mml:math  ><mml:mi mathvariant="normal"> </mml:mi><mml:mi>σ</mml:mi></mml:math>](img/212.png)
    is a non-linear activation function, such as ReLU. The aggregated features ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi
    mathvariant="normal">'</mml:mi></mml:mrow></mml:msubsup></mml:math>](img/213.png)
    represent the updated representation of node ![<mml:math  ><mml:mi mathvariant="normal"> </mml:mi><mml:mi>i</mml:mi></mml:math>](img/214.png)
    after considering the importance of its neighbors.
  prefs: []
  type: TYPE_NORMAL
- en: '![  Figure 4.3 – Multi-head attention (with K = 3 heads) by node 1 on its neighborhood](img/B22118_04_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.3 – Multi-head attention (with K = 3 heads) by node 1 on its neighborhood
  prefs: []
  type: TYPE_NORMAL
- en: To capture multiple aspects of the relationships between two nodes, we can leverage
    the concept of multi-head attention.
  prefs: []
  type: TYPE_NORMAL
- en: Multi-head attention
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In GNNs, **multi-head attention** can be applied to learn representations of
    nodes as an extension of vanilla attention. Each “head” can be seen as a different
    perspective or attention mechanism applied to a node’s neighborhood. By running
    multiple heads in parallel, the GNN can capture diverse aspects of the node’s
    local graph structure and feature space. This allows the model to aggregate information
    from neighboring nodes in multiple ways, enhancing its ability to learn informative
    node representations that incorporate various patterns and relationships within
    the graph.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several notable aspects to keep in mind for multi-head attention:'
  prefs: []
  type: TYPE_NORMAL
- en: GATs can employ multi-head attention to capture different aspects of the node
    relationships.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In multi-head attention, multiple attention mechanisms are used in parallel,
    each with its own set of learnable parameters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The output features from each attention head are concatenated or averaged to
    obtain the final node representations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multi-head attention allows the model to learn diverse patterns and capture
    different types of dependencies between nodes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At times, a single attention layer might be unable to capture complex relationships
    in a graph. Stacking multiple layers can help improve the learning space.
  prefs: []
  type: TYPE_NORMAL
- en: Stacking GAT layers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can also use multiple GAT layers, similar to GCNs:'
  prefs: []
  type: TYPE_NORMAL
- en: Like GCNs, GAT layers can be stacked to capture higher-order dependencies and
    learn more abstract representations of the graph.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In each layer, the updated node representations from the previous layer serve
    as input to the next layer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The final node representations obtained after multiple GAT layers can be used
    for downstream tasks such as node classification or graph classification.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GATs seamlessly combine the advantages of an **adaptive receptive field** and
    an **interpretable attention mechanism** , making them powerful tools for processing
    graph-structured data. The adaptive receptive field of GATs allows nodes to dynamically
    adjust their focus on relevant neighbors during information aggregation. Importantly,
    GATs provide interpretable attention coefficients, enabling a clear understanding
    of the model’s decision-making process. The transparency in attention weights
    allows for intuitive insights into which neighbors contribute significantly to
    a node’s representation, fostering interpretability and facilitating model debugging.
  prefs: []
  type: TYPE_NORMAL
- en: This combination of adaptability and interpretability makes GATs effective in
    capturing fine-grained local information while maintaining a global perspective,
    contributing to their success in various graph-based tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at the model code for GAT:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: In this code, the GAT model class is defined using two **GATConv** layers. The
    first layer has multiple attention heads specified by the **heads** parameter,
    while the second layer has a single attention head. The activation function used
    is the **exponential linear unit** ( **ELU** ) function.
  prefs: []
  type: TYPE_NORMAL
- en: Note that in the **__init__** method of the GAT class, we multiply **hidden_channels**
    by **heads** when specifying the input channels for the second **GATConv** layer.
    This is because the output of the first layer has **hidden_channels * heads dimensions**
    due to the multiple attention heads.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we provided a comprehensive overview of graph-based deep learning
    models, starting with the fundamental concept of message passing and then delving
    into specific GNN architectures such as GCNs, GraphSAGE, and GATs.
  prefs: []
  type: TYPE_NORMAL
- en: Graph-based models rely on message passing, a key operation where nodes exchange
    information with neighbors to update their representations. GCNs perform convolutions
    on graphs, aggregating neighboring node information to learn node representations.
    GraphSAGE efficiently generates embeddings for large-scale graphs through neighborhood
    sampling. GATs integrate attention mechanisms, enabling nodes to assign varying
    importance weights to neighbors during message passing. These techniques enhance
    the capacity of graph-based models to capture complex relationships and patterns
    within data structures.
  prefs: []
  type: TYPE_NORMAL
- en: Building upon the foundational understanding of prevalent graph learning algorithms,
    we’ll explore the contemporary challenges confronting GNNs in the upcoming chapter.
  prefs: []
  type: TYPE_NORMAL
