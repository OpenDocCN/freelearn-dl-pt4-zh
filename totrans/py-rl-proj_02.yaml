- en: Balancing CartPole
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you will learn about the CartPole balancing problem. The CartPole
    is an inverted pendulum, where the pole is balanced against gravity. Traditionally,
    this problem is solved by control theory, using analytical equations. However,
    in this chapter, we will solve the problem with machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Installing OpenAI Gym
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The different environments of Gym
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenAI Gym
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: OpenAI is a non-profit organization dedicated to researching artificial intelligence.
    Visit [https://openai.com](https://openai.com) for more information about the
    mission of OpenAI. The technologies developed by OpenAI are free for anyone to
    use.
  prefs: []
  type: TYPE_NORMAL
- en: Gym
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Gym provides a toolkit to benchmark AI-based tasks. The interface is easy to
    use. The goal is to enable reproducible research. Visit [https://gym.openai.com](https://gym.openai.com) for more
    information about Gym. An agent can be taught inside of the `gym`, and learn activities such
    as playing games or walking. An environment is a library of problems.
  prefs: []
  type: TYPE_NORMAL
- en: 'The standard set of problems presented in the gym are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: CartPole
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pendulum
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Space Invaders
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lunar Lander
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ant
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mountain Car
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Acrobot
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Car Racing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bipedal Walker
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Any algorithm can work out in the gym by training for these activities. All
    of the problems have the same interface. Therefore, any general reinforcement
    learning algorithm can be used through the interface.
  prefs: []
  type: TYPE_NORMAL
- en: Installation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The primary interface of the gym is used through Python. Once you have Python3
    in an environment with the `pip` installer, the gym can be installed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Advanced users that want to modify the source can compile from the source by
    using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'A new environment can be added to the `gym` with the source code. There are
    several environments that need more dependencies. For macOS, install the dependencies
    by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'For Ubuntu, use the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the dependencies are there, install the complete `gym` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This will install most of the environments that are required.
  prefs: []
  type: TYPE_NORMAL
- en: Running an environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Any gym environment can be initialized and run by using a simple interface.
    Let''s start by importing the `gym` library, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First we import the `gym` library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, create an environment by passing an argument to `gym.make`. In the following
    code, CartPole is used as an example:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, reset the environment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, start an iteration and render the environment, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Also, change the action space at every step, to see CartPole moving. Running
    the preceding program should produce a visualization. The scene should start with
    a visualization, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6348db98-2f96-49a2-8b80-e54de2553228.png)'
  prefs: []
  type: TYPE_IMG
- en: The preceding image is called a **CartPole**. The CartPole is made up of a cart
    that can move horizontally and a pole that can move rotationally, with respect
    to the center of the cart.
  prefs: []
  type: TYPE_NORMAL
- en: 'The pole is pivoted to the cart. After some time, you will notice that the
    pole is falling to one side, as shown in the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a9316fb1-dc22-4c01-9f74-98455f95c0e8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'After a few more iterations, the pole will swing back, as shown in the following image.
    All of the movements are constrained by the laws of physics. The steps are taken
    randomly:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b65a135f-4938-4510-9724-8fa192ed97e6.png)'
  prefs: []
  type: TYPE_IMG
- en: Other environments can be seen in a similar way, by replacing the argument of
    the gym environment, such as `MsPacman-v0` or `MountrainCar-v0`. For other environments,
    other licenses may be required. Next, we will go through the rest of the environments.
  prefs: []
  type: TYPE_NORMAL
- en: Atari
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To play Atari games, any environment can be invoked. The following code refers
    to the game Space Invaders:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the preceding command has executed, you will see the following screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bbaefd4e-bd15-4985-828f-cac8de6259f6.png)'
  prefs: []
  type: TYPE_IMG
- en: An Atari game can be played in this environment.
  prefs: []
  type: TYPE_NORMAL
- en: Algorithmic tasks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are algorithmic tasks that can be learned through reinforcement learning.
    A copy environment can be invoked, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The process of copying a string is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/53e1c62d-adea-4977-a658-cb82c75f4986.png)'
  prefs: []
  type: TYPE_IMG
- en: MuJoCo
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**MuJoCo** stands for **multi-joint dynamics with contact**. It''s a simulation
    environment for robots and multi-body dynamics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is a visualization for the simulation of a humanoid:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ac513818-fed0-4683-bb2d-902ebd991ccd.png)'
  prefs: []
  type: TYPE_IMG
- en: Simulation of a humanoid
  prefs: []
  type: TYPE_NORMAL
- en: There are robots and other objects that can be simulated in this environment.
  prefs: []
  type: TYPE_NORMAL
- en: Robotics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A robotics environment can also be created, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is a visualization of a robot hand:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6285ba5e-91b1-484f-b034-83195a7bc30b.png)'
  prefs: []
  type: TYPE_IMG
- en: There are several environments in which OpenAI Gym can be used.
  prefs: []
  type: TYPE_NORMAL
- en: Markov models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The problem is set up as a reinforcement learning problem, with a trial and
    error method. The environment is described using `state_values` `state_values
    (?)`, and the `state_values` are changed by actions. The actions are determined
    by an algorithm, based on the current `state_value`, in order to achieve a particular
    `state_value` that is termed a **Markov model**. In an ideal case, the past `state_values`
    does have an influence on future `state_values`, but here, we assume that the
    current `state_value` has all of the previous `state_values` encoded. There are
    two types of `state_values`; one is observable, and the other is non-observable.
    The model has to take non-observable `state_values` into account, as well. That
    is called a **Hidden Markov model**.
  prefs: []
  type: TYPE_NORMAL
- en: CartPole
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'At each step of the cart and pole, several variables can be observed, such
    as the position, velocity, angle, and angular velocity. The possible `state_values`
    of the cart are moved right and left:'
  prefs: []
  type: TYPE_NORMAL
- en: '`state_values`: Four dimensions of continuous values.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Actions`: Two discrete values.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The dimensions, or space, can be referred to as the `state_value` space and
    the action space. Let''s start by importing the required libraries, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, make the environment for playing CartPole, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, define the number of buckets and the number of actions, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, define the `state_value_bounds`, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, define the `action_index`, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Next define the `q_value_table`, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, define the minimum exploration rate and the minimum learning rate:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, define the maximum episodes, the maximum time steps, the streak to the
    end, the solving time, the discount, and the number of streaks, as constants:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, define the `select` action that can decide the action, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, select the explore state, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, select the learning rate, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, `bucketize` the `state_value`, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, train the episodes, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, print all of the relevant metrics for the training process, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'After training for a period of time, the CartPole will be able to balance itself,
    as shown in the following image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/eaf363d5-6e10-4327-885b-b5c3211dfbcd.png)'
  prefs: []
  type: TYPE_IMG
- en: You have learned a program that will stabilize the CartPole.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned about the OpenAI Gym, used in reinforcement learning
    projects. You saw several examples of the training platform provided out of the
    box. Then, we formulated the problem of the CartPole, and made the CartPole balance
    by using a trial and error approach.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will learn how to play Atari games by using the Gym
    and a reinforcement learning approach.
  prefs: []
  type: TYPE_NORMAL
