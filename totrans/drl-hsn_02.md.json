["```py\nclass Environment: \n    def __init__(self): \n        self.steps_left = 10\n```", "```py\n def get_observation(self) -> List[float]: \n        return [0.0, 0.0, 0.0]\n```", "```py\n def get_actions(self) -> List[int]: \n        return [0, 1]\n```", "```py\n def is_done(self) -> bool: \n        return self.steps_left == 0\n```", "```py\n def action(self, action: int) -> float: \n        if self.is_done(): \n            raise Exception(\"Game is over\") \n        self.steps_left -= 1 \n        return random.random()\n```", "```py\nclass Agent: \n    def __init__(self): \n        self.total_reward = 0.0\n```", "```py\n def step(self, env: Environment): \n        current_obs = env.get_observation() \n        actions = env.get_actions() \n        reward = env.action(random.choice(actions)) \n        self.total_reward += reward\n```", "```py\nif __name__ == \"__main__\": \n    env = Environment() \n    agent = Agent() \n    while not env.is_done(): \n        agent.step(env) \n    print(\"Total reward got: %.4f\" % agent.total_reward)\n```", "```py\nChapter02$ python 01_agent_anatomy.py \nTotal reward got: 5.8832\n```", "```py\ngymnasium[atari]==0.29.1 \ngymnasium[classic-control]==0.29.1 \ngymnasium[accept-rom-license]==0.29.1 \nmoviepy==1.0.3 \nnumpy<2 \nopencv-python==4.10.0.84 \ntorch==2.5.0 \ntorchvision==0.20.0 \npytorch-ignite==0.5.1 \ntensorboard==2.18.0 \nmypy==1.8.0 \nptan==0.8.1 \nstable-baselines3==2.3.2 \ntorchrl==0.6.0 \nray[tune]==2.37.0 \npytest\n```", "```py\n     Tuple(spaces=( \n        Box(low=-1.0, high=1.0, shape=(3,), dtype=np.float32), \n        Discrete(n=3), \n        Discrete(n=2) \n      ))\n    ```", "```py\n$ python \n>>> import gymnasium as gym \n>>> e = gym.make(\"CartPole-v1\")\n```", "```py\n>>> obs, info = e.reset() \n>>> obs \narray([ 0.02100407,  0.02762252, -0.01519943, -0.0103739 ], dtype=float32) \n>>> info \n{}\n```", "```py\n>>> e.action_space \nDiscrete(2) \n>>> e.observation_space \nBox([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n```", "```py\n>>> e.step(0) \n(array([-0.01254663, -0.22985364, -0.01435183,  0.24902613], dtype=float32), 1.0, False, False, {})\n```", "```py\n>>> e.action_space.sample() \n0 \n>>> e.action_space.sample() \n1 \n>>> e.observation_space.sample() \narray([-4.05354548e+00, -1.13992760e+38, -1.21235274e-01,  2.89040989e+38], \n     dtype=float32) \n>>> e.observation_space.sample() \narray([-3.6149189e-01, -1.0301251e+38, -2.6193827e-01, -2.6395525e+36], \n     dtype=float32)\n```", "```py\nimport gymnasium as gym \n\nif __name__ == \"__main__\": \n    env = gym.make(\"CartPole-v1\") \n    total_reward = 0.0 \n    total_steps = 0 \n    obs, _ = env.reset()\n```", "```py\n while True: \n        action = env.action_space.sample() \n        obs, reward, is_done, is_trunc, _ = env.step(action) \n        total_reward += reward \n        total_steps += 1 \n        if is_done: \n            break \n\n    print(\"Episode done in %d steps, total reward %.2f\" % (total_steps, total_reward))\n```", "```py\nChapter02$ python 02_cartpole_random.py \nEpisode done in 12 steps, total reward 12.00\n```", "```py\nimport gymnasium as gym \nimport random \n\nclass RandomActionWrapper(gym.ActionWrapper): \n    def __init__(self, env: gym.Env, epsilon: float = 0.1): \n        super(RandomActionWrapper, self).__init__(env) \n        self.epsilon = epsilon\n```", "```py\n def action(self, action: gym.core.WrapperActType) -> gym.core.WrapperActType: \n        if random.random() < self.epsilon: \n            action = self.env.action_space.sample() \n            print(f\"Random action {action}\") \n            return action \n        return action\n```", "```py\nif __name__ == \"__main__\": \n    env = RandomActionWrapper(gym.make(\"CartPole-v1\"))\n```", "```py\n obs = env.reset() \n    total_reward = 0.0 \n\n    while True: \n        obs, reward, done, _, _ = env.step(0) \n        total_reward += reward \n        if done: \n            break \n\n    print(f\"Reward got: {total_reward:.2f}\")\n```", "```py\nChapter02$ python 03_random_action_wrapper.py \nRandom action 0 \nRandom action 0 \nReward got: 9.00\n```", "```py\nif __name__ == \"__main__\": \n    env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\") \n    env = gym.wrappers.HumanRendering(env)\n```", "```py\nif __name__ == \"__main__\": \n    env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\") \n    env = gym.wrappers.RecordVideo(env, video_folder=\"video\")\n```", "```py\nChapter02$ python 04_cartpole_random_monitor.py \nMoviepy - Building video Chapter02/video/rl-video-episode-0.mp4\\. \nMoviepy - Writing video Chapter02/video/rl-video-episode-0.mp4 \n\nMoviepy - Done ! \nMoviepy - video ready Chapter02/video/rl-video-episode-0.mp4 \nEpisode done in 30 steps, total reward 30.00\n```"]