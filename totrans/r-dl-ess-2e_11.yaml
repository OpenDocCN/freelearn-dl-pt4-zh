- en: The Next Level in Deep Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习的下一层级
- en: 'We have almost come to the end of our journey in deep learning with R. This
    chapter is a bit of a mixed bag of topics. We will begin this chapter by revisiting
    an image classification task and building a complete image classification solution
    image files rather than tabular data. We will then move on to explaining transfer
    learning, where you can use an existing model on a new dataset. Next we discuss
    an important consideration in any machine learning project - how will your model
    be used in deployment, that is, production? We will show how to create a REST
    API that allows any programming language to call a deep learning model in R to
    predict on new data. We will then move on to briefly discussing two other deep
    learning topics: Generative Adversarial Networks and reinforcement learning. Finally,
    we will close this chapter and the book by providing a few other resources that
    you may be interested in.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的深度学习之旅即将结束。本章内容涉及多个主题。我们将从重新回顾一个图像分类任务开始，构建一个完整的图像分类解决方案，使用图像文件而不是表格数据。然后，我们将解释迁移学习，您可以将现有模型应用于新的数据集。接下来，我们讨论在任何机器学习项目中的一个重要考虑因素——您的模型将在部署中如何使用，也就是在生产环境中如何使用？我们将展示如何创建一个
    REST API，允许任何编程语言调用 R 中的深度学习模型对新数据进行预测。然后，我们将简要讨论另外两个深度学习主题：生成对抗网络和强化学习。最后，我们将通过提供一些您可能感兴趣的其他资源，结束本章和本书的内容。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将涵盖以下主题：
- en: Building a complete image classification solution
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建完整的图像分类解决方案
- en: The ImageNet dataset
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ImageNet 数据集
- en: Transfer learning
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 迁移学习
- en: Deploying TensorFlow models
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署 TensorFlow 模型
- en: Generative adversarial networks
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成对抗网络
- en: Reinforcement learning
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强化学习
- en: Additional deep learning resources
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他深度学习资源
- en: Image classification models
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像分类模型
- en: We covered image classification in Chapter 5,* Image Classification Using Convolutional
    Neural Networks*. In that chapter, we described convolutional and pooling layers
    that are essential for deep learning tasks involving images. We also built a number
    of models on a simple dataset, the MNIST dataset. Here, we are going to look at
    some advanced topics in image classification. First, we will build a complete
    image classification model using image files as input. We will look at callbacks,
    which are a great aid in building complex deep learning models. A call-back function will
    be used to persist (save) a model to file, which will be loaded back later. We
    then use this model in our next example, which is transfer learning. This is where
    you use some of the layers in a pre-trained model on new data.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在第 5 章中介绍了图像分类，*使用卷积神经网络进行图像分类*。在那一章中，我们描述了对于涉及图像的深度学习任务至关重要的卷积层和池化层。我们还在一个简单的数据集——MNIST
    数据集上构建了多个模型。在这里，我们将探讨一些高级的图像分类主题。首先，我们将构建一个完整的图像分类模型，使用图像文件作为输入。我们将了解回调函数，这是构建复杂深度学习模型时的得力助手。一个回调函数将被用来将模型持久化（保存）到文件中，并在之后加载。接下来，我们将使用这个模型进行迁移学习。在迁移学习中，您会使用预训练模型中的一些层来处理新的数据。
- en: Building a complete image classification solution
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建完整的图像分类解决方案
- en: We have built a few image classification models, but they used the MNIST dataset
    that was loaded from Keras or from CSV files. The data was always in tabular format.
    Obviously that is not how images are stored in most situations. This section looks
    at how to build an image classification model using a collection of image files. The
    first task is to acquire a set of image files. We are going to load the `CIFAR10`
    data that is included in Keras and save the data as image files. We will then
    use those files to build a deep learning model. After this exercise, you will
    know how to create a deep learning image classification task with your own image
    files.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经构建了一些图像分类模型，但它们使用的是从 Keras 或 CSV 文件加载的 MNIST 数据集。数据始终是表格格式的。显然，这不是大多数情况下图像存储的方式。本节内容将讨论如何使用一组图像文件构建图像分类模型。第一个任务是获取一组图像文件。我们将加载包含在
    Keras 中的 `CIFAR10` 数据，并将其保存为图像文件。然后，我们将使用这些文件构建深度学习模型。完成这项练习后，您将学会如何使用自己的图像文件创建深度学习图像分类任务。
- en: The deep learning model in this chapter is not a complex model. The focus is
    to show how the data pipeline for an image classification task is structured.
    We look at how to arrange the image files, how to use data augmentation and how
    callbacks can be used during training.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的深度学习模型并不是一个复杂的模型。重点是展示图像分类任务的数据管道结构。我们会看看如何安排图像文件，如何使用数据增强，以及如何在训练过程中使用回调。
- en: Creating the image data
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建图像数据
- en: 'The first step is to create the image files. The code for this section is in
    the `Chapter11/gen_cifar10_data.R` folder. We will load the `CIFAR10` data and
    save the image files in the data directory. The first step is to create the directory
    structure. There are 10 classes in the `CIFAR10` dataset: we will save 8 classes
    for building a model and we will use 2 classes in a later section (*Transfer learning*).
    The following code creates the following directories under `data`:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是创建图像文件。此部分的代码位于 `Chapter11/gen_cifar10_data.R` 文件夹中。我们将加载 `CIFAR10` 数据并将图像文件保存在数据目录中。第一步是创建目录结构。`CIFAR10`
    数据集包含 10 个类别：我们将为构建模型保存 8 个类别，并将在后面的部分中使用 2 个类别（*迁移学习*）。以下代码将在 `data` 下创建以下目录：
- en: '`cifar_10_images`'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cifar_10_images`'
- en: '`cifar_10_images/data1`'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cifar_10_images/data1`'
- en: '`cifar_10_images/data2`'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cifar_10_images/data2`'
- en: '`cifar_10_images/data1/train`'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cifar_10_images/data1/train`'
- en: '`cifar_10_images/data1/valid`'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cifar_10_images/data1/valid`'
- en: '`cifar_10_images/data2/train`'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cifar_10_images/data2/train`'
- en: '`cifar_10_images/data2/valid`'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cifar_10_images/data2/valid`'
- en: 'This is the structure that Keras expects image data to be stored in. If you
    use this structure, then the images can be used to train a model in Keras. In
    the first part of the code, we create these directories:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 Keras 期望图像数据存储的结构。如果您使用此结构，则可以将图像用于在 Keras 中训练模型。在代码的第一部分，我们创建了这些目录：
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Under each of the train and valid directories, a separate directory is used
    for each category. We save the images for 8 classes under the `data1` folder,
    and save the images for 2 classes under the `data2` folder:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个 train 和 valid 目录下，都为每个类别使用一个单独的目录。我们将 8 个类别的图像保存在 `data1` 文件夹下，将 2 个类别的图像保存在
    `data2` 文件夹下：
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Once we have created the directories, the next step is to save the images in
    the correct directories, which we will do in the following code:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们创建了目录，下一步就是将图像保存到正确的目录中，我们将在以下代码中完成此操作：
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Finally, as we have done previously, we will do a validation check to ensure
    that our images are correct. Let''s load in 9 images from one category. We want
    to check that the images display correctly and that they are from the same class:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，像之前做的那样，我们将进行验证检查，确保我们的图像是正确的。让我们加载 9 张来自同一类别的图像。我们想检查这些图像是否正确显示，并且它们是否来自同一类别：
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This produces the following plot:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成以下图表：
- en: '![](img/eca7b405-c020-4861-8ca1-966e7b3653b0.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](img/eca7b405-c020-4861-8ca1-966e7b3653b0.png)'
- en: 'Figure 11.1: Sample CIFAR10 images'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.1：样本 CIFAR10 图像
- en: This looks good! The images display correctly and we can see that these images
    all appear to be of the same class, which is cars. The images are out of focus,
    but that is because they are only thumbnail images of size 32 x 32.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来不错！图像显示正确，我们可以看到这些图像似乎都属于同一个类别，即汽车。图像有些模糊，但那是因为它们仅是 32 x 32 的缩略图。
- en: Building the deep learning model
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建深度学习模型
- en: 'Once you have run the script from the preceding section, you should have 40,000
    images for training in the `cifar_10_images/data1/train` directory and 8,000 images
    for validation in the `cifar_10_images/data1/valid` directory. We will train a
    model with this data. The code for this section is in the `Chapter11/build_cifar10_model.R`
    folder. The first section creates the model definition, which should be familiar
    to you:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你运行了前面部分的脚本，你应该会在 `cifar_10_images/data1/train` 目录中拥有 40,000 张训练图像，在 `cifar_10_images/data1/valid`
    目录中拥有 8,000 张验证图像。我们将使用这些数据训练一个模型。此部分的代码位于 `Chapter11/build_cifar10_model.R` 文件夹中。第一部分创建了模型定义，您应该已经很熟悉：
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The model definition was adapted from the VGG16 architecture, which we will
    see later. I used a smaller number of blocks and fewer nodes. Note that the final
    dense layer must have 8 nodes, because there are only 8, not 10 classes in the
    `data1` folder.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 模型定义是基于 VGG16 架构进行修改的，我们将在后面看到它。我使用了更少的块和节点。请注意，最终的密集层必须有 8 个节点，因为 `data1` 文件夹中只有
    8 个类别，而不是 10 个。
- en: 'The next part sets up a data generator; the purpose of this is to load batches
    of image files into the model as it is being trained. We can also apply data augmentation
    to the train dataset in the data generator. We will select to create artificial
    data by randomly flipping the images horizontally, shifting images horizontally/vertically,
    and rotating the images by up to 15 degrees. We saw in Chapter 6, *Tuning and
    Optimizing Models,* that data augmentation can significantly improve existing
    models:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 下一部分设置了数据生成器；其目的是在模型训练时将图像文件批次加载到模型中。我们还可以在数据生成器中对训练数据集应用数据增强。我们将选择通过随机水平翻转图像、水平/垂直平移图像和旋转图像最多15度来创建人工数据。我们在第6章
    *模型调优与优化* 中看到，数据增强可以显著改善现有模型：
- en: '[PRE5]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Once the data generators have been set up, we will also use two callback functions.
    Callback functions allow you to run custom code after a specific number of batches
    / epochs have executed. You can write your own callbacks or use some predefined
    callback functions. Previously, we used callbacks for logging metrics, but here
    the callbacks will implement model checkpointing and early stopping, which are
    are often used when building complex deep learning models.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据生成器设置完毕，我们还将使用两个回调函数。回调函数允许你在执行特定数量的批次/周期后运行自定义代码。你可以编写自己的回调函数，或者使用一些预定义的回调函数。之前我们使用回调函数来记录指标，但在这里，回调函数将实现模型检查点和提前停止，这些通常在构建复杂深度学习模型时使用。
- en: Model checkpointing is used to save the model weights to disk. You can then
    load the model from disk into memory and use it for predicting new data, or you
    can continue training the model from the point it was saved to disk. You can save
    the weights after every epoch, this might be useful if you are using cloud resources
    and are worried about the machine terminating suddenly. Here, we use it to keep
    the best model we have seen so far in training. After every epoch, it checks the
    validation loss, and if it is lower than the validation loss in the existing file,
    it saves the model.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 模型检查点用于将模型权重保存到磁盘。然后，你可以从磁盘加载模型到内存中，使用它来预测新的数据，或者你可以从保存到磁盘的地方继续训练模型。你可以在每个训练周期后保存权重，这在使用云资源并担心机器突然终止时可能非常有用。在这里，我们用它来保存到目前为止在训练过程中看到的最佳模型。每个训练周期后，它会检查验证损失，如果验证损失低于现有文件中的验证损失，则保存模型。
- en: 'Early stopping allows you to stop training a model when the performance no
    longer improves. Some people refer to it as a form of regularization because early
    stopping can prevent a model from overfitting. While it can avoid overfitting,
    it works very differently to the regularization techniques, such as L1, L2, weight
    decay, and dropout, that we saw in [Chapter 3](6e6dd858-9f00-454a-8434-a95c59e85b25.xhtml)*,
    Deep Learning Fundamentals*. When using early stopping, you usually would allow
    the model to continue for a few epochs even if performance is no longer improving,
    the number of epochs allowed before stopping training is known as *patience* in
    Keras. Here we set it to 10, that is, if we have 10 epochs where the model has
    failed to improve, we stop training. Here is the code to create the callbacks
    that we will use in our model:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 提前停止允许你在模型的性能不再提高时停止训练。有些人称之为一种正则化方法，因为提前停止可以防止模型过拟合。尽管它可以避免过拟合，但它与我们在[第3章](6e6dd858-9f00-454a-8434-a95c59e85b25.xhtml)*深度学习基础*中看到的正则化技术（如L1、L2、权重衰减和丢弃法）非常不同。使用提前停止时，你通常会允许模型继续训练几个周期，即使性能不再提升，停止训练前允许的周期数在Keras中被称为*耐心*。在这里，我们将其设置为10，也就是说，如果模型在10个周期内没有提升，我们将停止训练。以下是我们将在模型中使用的回调函数代码：
- en: '[PRE6]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Here is the code to train the model:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这是训练模型的代码：
- en: '[PRE7]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: One thing to note here is that we have to manage the steps per epoch for the
    train and validation generators. When you set up a generator, you don't know how
    much data is actually there, so we need to set the number of steps for each epoch.
    This is simply the number of records divided by the batch size.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一点需要注意的是，我们必须管理训练和验证生成器的每个周期的步数。当你设置一个生成器时，你并不知道实际有多少数据，所以我们需要为每个周期设置步数。这只是记录数除以批次大小的结果。
- en: 'This model should take less than an hour to train on a GPU and significantly
    longer if training on a CPU. As the model is training, the best model is saved
    in `cifar_model.h5`. The best result on my machine was after epoch 64, when the
    validation accuracy was about 0.80\. The model continued to train for another
    10 epochs after this but failed to improve. Here is a plot of the training metrics:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型在 GPU 上训练应少于一小时，而在 CPU 上训练则会显著更长。随着模型的训练，最佳模型会保存在`cifar_model.h5`文件中。我机器上最佳的结果是在第
    64 轮时，验证准确率约为 0.80。此后，模型继续训练了另外 10 个轮次，但未能提升性能。以下是训练指标的图表：
- en: '![](img/649c0029-c744-46ad-a55b-c07d56855380.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](img/649c0029-c744-46ad-a55b-c07d56855380.png)'
- en: 'Figure 11.2: Output metrics during model training'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.2：模型训练期间的输出指标
- en: Using the saved deep learning model
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用已保存的深度学习模型
- en: 'Now that we have built our deep learning model, we can restart R and reload
    the model from disk. The code for this section is in the `Chapter11/use_cifar10_model.R`
    folder. We will load the model that was created in the previous section by using
    the following code:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经构建了深度学习模型，可以重新启动 R 并从磁盘重新加载模型。本节的代码位于`Chapter11/use_cifar10_model.R`文件夹中。我们将使用以下代码加载上一节中创建的模型：
- en: '[PRE8]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We will use this model to generate a prediction for an image file from the
    validation set. We will pick the first directory in the validation folder and
    then pick the 7th file from that folder. We load the image and apply the same
    preprocessing to it as we did when preprocessing the images during training, which
    is to normalize the data by dividing the pixel values by 255.0\. Here is the code
    that loads the image and generates the prediction:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用该模型为验证集中的图像文件生成预测。我们将选择验证文件夹中的第一个目录，然后从该文件夹中选择第7个文件。我们加载图像并对其进行与训练期间相同的预处理，即通过将像素值除以
    255.0 来对数据进行归一化处理。以下是加载图像并生成预测的代码：
- en: '[PRE9]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The model predicts that the input is from the first class with 99.7% certainty.
    Since we chose the first directory in the validation set, the prediction is correct.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 模型预测输入来自第一类，且置信度为 99.7%。由于我们选择了验证集中的第一个目录，预测是正确的。
- en: 'The final thing we will do with our model is to evaluate it on a directory
    of image files. We will also show how to generate predictions for an entire directory
    of image files. This code loads the images from the directories using data generators,
    similar to how we trained the model. Here is the code that evaluates and predicts
    categories by using the model for the validation images we saved to disk:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用模型做的最后一件事是评估它在图像文件目录上的表现。我们还将展示如何为整个图像文件目录生成预测。该代码通过数据生成器加载来自目录的图像，类似于我们训练模型的方式。以下是评估并使用模型对我们保存到磁盘的验证图像进行类别预测的代码：
- en: '[PRE10]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The validation accuracy is `80.86%`, which is similar to what we observed during
    model training, this confirms that the model was saved correctly to disk. Here
    is the code that generates predictions for all 8,000 validation images:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 验证准确率为`80.86%`，这与我们在模型训练过程中观察到的相似，确认了模型已正确保存到磁盘。以下是为所有 8,000 个验证图像生成预测的代码：
- en: '[PRE11]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We can see that our prediction output has 8,000 rows and 8 columns, so for each
    validation image, there is a probability for each category. We can see that the
    sum for each row is 1.0 and that there is usually one class that has a significant
    probability. For example, the model is predicting that the first image is in class
    7 with a probability of 99.9%.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，预测输出有 8,000 行和 8 列，因此对于每个验证图像，每个类别都有一个概率。我们可以看到每行的总和为 1.0，并且通常会有一个类别的概率显著较大。例如，模型预测第一张图像属于第
    7 类，概率为 99.9%。
- en: We have now built a complete image classification solution using image files.
    This template can be reused for other tasks once the image data is stored in the
    same directory structure. If the new task had a different number of categories,
    then all you would need to change is the number of nodes in the last dense layer
    and possibly the softmax activation. However, if you did have a new image classification
    task that involved real-life images, then you probably would get better results
    by using an existing model and using transfer learning. Before I explain how to
    do that, I will provide some background on the ImageNet dataset, which is often
    used to train complex models which are then used in transfer learning.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: The ImageNet dataset
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'From 2010, an annual image classification competition has been run called the
    **ImageNet Large Scale Visual Recognition Challenge** (**ILSVRC**). The image
    set consists of over 14 million images that have been labelled with over 1,000
    categories. Without this dataset, there would not be the huge interest in deep
    learning that there is today. It has provided the stimulus for research in deep
    learning through the competition. The models and weights learnt on the Imagenet
    dataset have then been used in thousands of other deep learning models through
    transfer learning. The actual history of ImageNet is an interesting story. The
    following link ([https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world/](https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world/))
    explains how the project originally got little attention, but that changed with
    a number of linked events:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: The ILSVRC became the benchmark for image classification for researchers.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NVIDIA had released libraries that allowed access to **graphical processing
    units** (**GPUs**). GPUs are designed to do massive parallel matrix operations,
    which is exactly what is needed to create deep neural networks.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Geoffrey Hinton, Ilya Sutskever, and Alex Krizhevsky from the University of
    Toronto created a deep convolutional neural network architecture called **AlexNet**
    that won the competition in 2012\. Although this was not the first use of convolutional
    neural networks, their submission beat the next approach by a huge margin.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Researchers noticed that when they trained models using the ImageNet dataset,
    they could use them on other classification tasks. They almost always got much
    better performance from using the ImageNet model and then using transfer learning than
    just training a model from scratch on the original dataset.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The advances in image classification can be tracked with some notable entries
    in the ILSVRC competition:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '| **Team** | **Year** | **Error rate** |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
- en: '| 2011 ILSVRC winner (not deep learning) | 2011 | 25.8% |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
- en: '| AlexNet (7 layers) | 2012 | 15.3% |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
- en: '| VGG Net (16 layers) | 2014 | 7.32% |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
- en: '| GoogLeNet / Inception (19 layers) | 2014 | 6.67% |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
- en: '| ResNet (152 layers) | 2015 | 3.57% |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
- en: VGGNet, Inception, and Resnet are all available in Keras. A complete list of
    available networks can be found at [https://keras.rstudio.com/reference/index.html#section-applications](https://keras.rstudio.com/reference/index.html#section-applications).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: VGGNet、Inception和Resnet都可以在Keras中使用。可以在[https://keras.rstudio.com/reference/index.html#section-applications](https://keras.rstudio.com/reference/index.html#section-applications)找到可用网络的完整列表。
- en: The models for these networks can be loaded in Keras and used to classify a
    new image into one of the 1,000 categories in ImageNet. We will look at this next.
    If you have a new classification task with a different set of images, then you
    can also use these networks and then use transfer learning, which we will look
    at later in this chapter. The number of categories can be different; you do not
    need to have 1,000 categories for your task.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这些网络的模型可以在Keras中加载，并用来将新图像分类到ImageNet的1,000个类别之一。我们接下来会讨论这个问题。如果你有一个新的分类任务，并且使用不同的图像集，你也可以使用这些网络，然后使用迁移学习，我们将在本章后面讨论迁移学习。类别的数量可以不同；你不需要为你的任务拥有1,000个类别。
- en: Perhaps the simplest model to begin with is VGGNet, as it is not that different
    to what we saw in [Chapter 5](1c0b9897-b0cc-4a8f-9ce8-e6409c347f4f.xhtml), *Image
    Classification Using Convolutional Neural Networks*.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 也许最简单的模型是VGGNet，因为它与我们在[第5章](1c0b9897-b0cc-4a8f-9ce8-e6409c347f4f.xhtml)中看到的*使用卷积神经网络进行图像分类*并没有太大区别。
- en: Loading an existing model
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载现有模型
- en: 'In this section, we will load an existing model (VGGNet) in Keras and use it
    to classify a new image. The code for this section can be found in the `Chapter11/vgg_model.R`.
    We will begin by loading the model and looking at its architecture:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将加载一个现有的模型（VGGNet）并用它来分类一张新图片。本节的代码可以在`Chapter11/vgg_model.R`中找到。我们将从加载模型并查看其架构开始：
- en: '[PRE12]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This model looks complicated, but when you look at it in detail, there is nothing
    that we haven't seen before. There are two blocks with two convolutional layers,
    which are then followed by a max pooling layer. These are followed by three blocks
    with three convolutional layers, which are then followed by a max pooling layer.
    Finally, we have a flatten layer and three dense layers. The last dense layer
    has 1,000 nodes, which is the number of categories in the ImageNet dataset.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型看起来很复杂，但当你仔细看时，实际上没有什么是我们之前没有见过的。它有两个包含两个卷积层的模块，后面跟着一个最大池化层。然后是三个包含三个卷积层的模块，后面也跟着一个最大池化层。最后，我们有一个扁平层和三个全连接层。最后一个全连接层有1,000个节点，这是ImageNet数据集中类别的数量。
- en: 'Let''s use this model to make a prediction for a new image. This image is a
    bicycle, albeit an unusual one – it is a time trial bicycle:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用这个模型对一张新图像进行预测。这张图像是一辆自行车，尽管它有些不寻常——它是一辆计时赛自行车：
- en: '![](img/6c765554-eb64-4046-9290-bd8fbd86f830.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6c765554-eb64-4046-9290-bd8fbd86f830.jpg)'
- en: 'Figure 11.3: Test image for classification'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.3：分类测试图像
- en: 'The following code block processes the image into a suitable format to use
    in the VGG model. It loads the image and resizes it to the dimensions of the images
    used to train the model `(224, 224)`. We then have to preprocess the image data
    before calling the `predict` function. Finally, there is a helper function in
    Keras called `imagenet_decode_predictions` that we can use to get the prediction
    categories and the probabilities:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码块将图像处理成适合在VGG模型中使用的格式。它加载图像并将其调整为训练模型时使用的图像尺寸`(224, 224)`。然后，我们需要在调用`predict`函数之前对图像数据进行预处理。最后，Keras中有一个名为`imagenet_decode_predictions`的辅助函数，我们可以用它来获取预测类别和概率：
- en: '[PRE13]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The top prediction is `bicycle-built-for-two` at just over 30%, and the second
    best prediction is `mountain_bike` at 16.5%. ImageNet has a category for a tricycle
    and unicycle (and even a `Model_T` car!), but does not seem to have a category
    for a bicycle, so this prediction is a not a bad result. However, `mountain_bike` is
    probably a more accurate category for this image as it definitely is not a bicycle
    for two people!
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 最好的预测是`bicycle-built-for-two`，概率略高于30%，第二好的预测是`mountain_bike`，概率为16.5%。ImageNet有三轮车和独轮车（甚至还有`Model_T`汽车！）的类别，但似乎没有自行车的类别，因此这个预测结果不算差。不过，`mountain_bike`可能是这个图像的更准确类别，因为它显然不是一辆双人自行车！
- en: Transfer learning
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 迁移学习
- en: One of the few disadvantages deep learning has over traditional machine learning
    is that it requires lots of data. Transfer learning is one way to overcome this,
    by using the weights of a previously trained model (usually trained on ImageNet
    data) and then applying them to a new problem set.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习相较于传统机器学习的一个少数缺点是它需要大量数据。迁移学习是克服这一问题的一种方式，方法是使用一个之前训练好的模型的权重（通常是训练在ImageNet数据上的）并将其应用到新的问题集上。
- en: The ImageNet dataset consists of 15 million images in 1,000 classes. Since we
    can reuse parts of a model that has been trained on this amount of data, it may
    be possible to train the new model with just a few hundred images per category.
    This would depend on the images being somewhat related to the data used in the
    original model. For example, trying to use transfer learning from ImageNet models
    (which is trained on photographs) on data from other domains (for example, satellite
    or medical scans), would be more difficult and would require much more data. Some
    of the concerns we raised in [Chapter 6](13e9a742-84df-48e5-bbfd-ade33dcdd01a.xhtml), *Tuning
    and Optimizing Models*, about different data sources also applies. If the data
    is from a different type of data distribution, for example, mobile images, off-center
    photos, different lighting conditions, and so on, this will also matter. This
    is where creating more synthetic data through data augmentation can make a big
    difference.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: ImageNet数据集包含1,500万张图片，分为1,000个类别。由于我们可以复用已在如此大量数据上训练过的模型的部分内容，可能只需每个类别几百张图片就能训练新模型。这取决于新数据与原始模型训练数据的相关性。例如，尝试将ImageNet模型（其训练数据为照片）上的迁移学习应用到其他领域的数据（例如，卫星图像或医学扫描）上，将会更加困难，并且需要更多的数据。我们在[第6章](13e9a742-84df-48e5-bbfd-ade33dcdd01a.xhtml)中关于不同数据源的讨论，也同样适用。如果数据来自不同类型的数据分布，例如，移动设备拍摄的图像、偏离中心的照片、不同的光照条件等，这也会产生影响。这时，通过数据增强创建更多合成数据将会起到很大的作用。
- en: 'We will now apply transfer learning using the model we built in the *Building
    the deep learning model* section. Recall that we only used 8/10 of the classes
    in building and evaluating this model. We will now build a new model using transfer
    learning that will differentiate between the 2 remaining classes. The code for
    this section can be found in the `Chapter11/cifar_txr.R` folder:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将应用迁移学习，使用在*构建深度学习模型*部分中构建的模型。回想一下，在构建和评估该模型时，我们仅使用了8/10的类别。现在我们将使用迁移学习构建一个新模型，用于区分剩下的2个类别。本部分的代码可以在`Chapter11/cifar_txr.R`文件夹中找到：
- en: 'We will use the model we built in the previous section and load it using the
    following code:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用前一部分中构建的模型，并通过以下代码加载它：
- en: '[PRE14]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Next, we will call `trainable_weights` on the model object to get the number
    of trainable layers. This will count all the non-activation layers in our model.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将调用模型对象上的`trainable_weights`来获取可训练层的数量。这将计算模型中所有非激活层的数量。
- en: '[PRE15]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Next, we freeze the early layers in our model. Freezing the layers in a model
    means that the weights will not be updated during back-propagation. We freeze
    the convolutional blocks, but do not freeze the dense layers at the end of the
    model. We use the names we set in the model definition to set the first and last
    layers to freeze.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将冻结模型中的早期层。冻结模型中的层意味着在反向传播过程中这些层的权重不会更新。我们冻结卷积块，但不冻结模型末尾的全连接层。我们使用在模型定义中设置的名称来指定冻结的第一层和最后一层。
- en: 'We then call `trainable_weights` on the model once more to confirm that the
    number changed from the preceding value, `14`, to `6`. Here is the code for freezing the
    layers:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们再次调用模型的`trainable_weights`，以确认数量已从之前的`14`变为`6`。这是冻结层的代码：
- en: '[PRE16]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Next, we will remove the last dense layer and last activation layer from our
    model by calling the `pop_layer` function twice in the following code. We need
    to do this because our new task has 2 classes and not 8:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将通过在以下代码中调用`pop_layer`函数两次，从模型中移除最后的全连接层和激活层。我们需要这么做，因为我们的新任务有2个类别，而不是8个：
- en: '[PRE17]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now, we can add a new layer with 2 nodes (because we have 2 classes in the new
    task) by using the following code:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以通过以下代码添加一个包含2个节点的新层（因为在新任务中我们有2个类别）：
- en: '[PRE18]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The following code block compiles the model again and sets up the generators
    to load the data. This is similar to what we saw when we built the model. One
    difference is that we do not use data augmentation here:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下代码块会重新编译模型并设置生成器以加载数据。这与我们在构建模型时所看到的类似。不同之处在于这里没有使用数据增强：
- en: '[PRE19]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Finally, we can train the model by using the following code:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们可以通过以下代码训练模型：
- en: '[PRE20]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The best accuracy was on epoch 9 when we got `96.55%` accuracy. This is significantly
    better than what we got on the multi-classification model (approximately 81%),
    but binary classification tasks are much easier than multi-classification tasks.
    We can also see that the model was very quick to train, because it only had to
    update the weights in the last few layers.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳的准确率出现在第 9 个训练周期（epoch），当时我们得到了 `96.55%` 的准确率。这比我们在多分类模型中得到的准确率（大约 81%）要高得多，但二分类任务比多分类任务要容易得多。我们还可以看到，模型的训练速度非常快，因为它只需要更新最后几层的权重。
- en: Deploying TensorFlow models
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署 TensorFlow 模型
- en: Historically, one of the perceived disadvantages of using R for data science
    projects was the difficulty in deploying machine learning models built in R. This often
    meant that companies used R mainly as a prototyping tool to build models which
    were then rewritten in another language, such as Java and .NET. It is also one
    of the main reasons cited for companies switching to Python for data science as
    Python has more *glue code*, which allows it to interface with other programming
    languages.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 从历史上看，使用 R 进行数据科学项目的一个被认为的缺点是，部署在 R 中构建的机器学习模型的难度。这通常意味着公司主要将 R 用作原型设计工具，先构建模型，然后将其用
    Java 或 .NET 等其他语言重写。这也是公司转向使用 Python 进行数据科学的主要原因之一，因为 Python 具有更多的*粘合代码*，使得它可以与其他编程语言进行接口对接。
- en: Thankfully, this is changing. One interesting new product from RStudio, called RStudio Connect,
    allows companies to create a platform for sharing R-Shiny applications, reports
    in R Markdown, dashboards, and models. This allows companies to serve machine
    learning models using a REST interface.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，这种情况正在发生变化。RStudio 发布了一个名为 RStudio Connect 的有趣新产品，它允许公司创建一个平台，用于共享 R-Shiny
    应用程序、R Markdown 报告、仪表盘和模型。这使得公司能够通过 REST 接口提供机器学习模型。
- en: The TensorFlow (and Keras) models we have created in this book can be deployed
    without any runtime dependency on either R or Python. One way of doing this is TensorFlow
    Serving, which is an open source software library for serving TensorFlow models.
    Another option is to use the Google CloudML interface that we saw in [Chapter
    10](2ea4d422-70f7-47af-a330-f0901f6f5fd3.xhtml)*, Running Deep Learning Models
    in the Cloud*. This allows you to create a publicly available REST API that can
    be called from your applications. TensorFlow models can also be deployed to iPhones
    and Android mobile phones.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中创建的 TensorFlow（以及 Keras）模型可以部署，而不依赖于 R 或 Python 的任何运行时环境。一种方式是使用 TensorFlow
    Serving，它是一个开源软件库，用于为 TensorFlow 模型提供服务。另一种选择是使用我们在[第 10 章](2ea4d422-70f7-47af-a330-f0901f6f5fd3.xhtml)*“在云端运行深度学习模型”*中看到的
    Google CloudML 接口。这使你可以创建一个公开的 REST API，供你的应用程序调用。TensorFlow 模型也可以部署到 iPhone 和
    Android 手机上。
- en: 'There are two basic options for scoring models in production:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产环境中有两种基本的评分模型选项：
- en: '**Batch mode**: In batch mode, a set of data is scored offline and the prediction
    results are stored and used elsewhere'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**批处理模式**：在批处理模式下，一组数据在离线状态下进行评分，预测结果会被存储并在其他地方使用。'
- en: '**Real-time mode**: In real-time mode, the data is scored immediately, usually
    a record at a time, and the results are immediately used.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实时模式**：在实时模式下，数据会立即进行评分，通常是一次处理一条记录，并且结果会立即使用。'
- en: For a lot of applications, batch mode is more than adequate. You should carefully consider
    if you really need a real-time prediction system as it is requires more resources
    and needs constant monitoring. It is much more efficient to score records in a
    batch rather than individually. Another advantage of batch mode is that you know
    the demand on the application beforehand and can plan resources accordingly. With
    real-time systems, a spike in demand or a denial of service attack can cause problems
    with your prediction model.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 对于许多应用程序来说，批处理模式已经足够。你应该仔细考虑自己是否真的需要实时预测系统，因为它需要更多的资源并且需要持续监控。批量处理记录比分别处理要高效得多。批处理模式的另一个优势是你事先知道应用程序的需求，可以相应地规划资源。而实时系统中，需求激增或拒绝服务攻击可能会导致预测模型出现问题。
- en: 'We have already seen batch mode for a saved model in the *Using the saved deep
    learning model* section in this chapter. So, let''s look at how we can build a
    REST interface to get a prediction on new data from a deep learning model in real-time.
    This will use the `tfdeploy` package. The code for this section can be found in
    the `Chapter11/deploy_model.R`. We are going to build a simple model based on
    the MNIST dataset and then create a web interface where we can submit a new image
    for classification. Here is the first part of the code that builds the model and
    prints out the predictions for the first 5 rows in the test set:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'There is nothing new about this code. Next, we will create a JSON file for
    one image file in the test set. JSON stands for JavaScript Object Notation, and
    is the accepted standard for serializing and sending data over a network connection.
    If HTML is the language for computers-to-human web communication, JSON is the
    language for computers-to-computers web communication. It is heavily used in microservice
    architecture, which is a framework for building a complex web ecosystem from lots
    of small web services. The data in the JSON file must have the same preprocessing
    applied as what was done during training – since we normalized the training data,
    we must also normalize the test data. The following code creates a JSON file with
    the values for the first instance in the testset and saves the file to `json_image.json`:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Now that we have a JSON file, let''s create a REST web interface for our model:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Once you do this, a new web page should pop up that is similar to the following:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a936938e-a122-4b20-ba84-3ca27b978e20.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.4: Swagger UI for the TensorFlow model REST web service'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a Swagger UI page showing the RESTful web services for the TensorFlow
    model. This allows us to test our API. While we could try to use this interface,
    it is easier to use the JSON file we just created. Open up Command Prompt on your
    machine, browse to the `Chapter11` code directory, and run the following command:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'You should get the following response:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/67891d57-0caf-4506-956a-8f71e9589c86.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
- en: The REST web interface returns another JSON string with these results. We can
    see that the 8th entry in the list is 1.0 and that all the other numbers are extremely
    small. This matches the prediction for the first row that we saw in the code at
    the start of this section.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: I imagine that half of the people reading this are very excited about this and
    the other half couldn't care less! The half that really like this can see how
    R can be used to serve model predictions that interface with web applications.
    This opens up huge possibilities for using R, where beforehand it was believed
    that you either had to use Python or you had to redevelop models in other languages.
    The half that couldn't care less probably never had to deal with these issues
    with R, but in time they will see how important this is as well!
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: Other deep learning topics
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Two topics that get a lot of attention in deep learning are **Generative Adversarial
    Networks (GANs)** and reinforcement learning. We only briefly introduce both topics,
    there is no code for this section for a couple of reasons. Firstly both topics
    are very advanced and trying to create a use-case that is non-trivial would require
    a few chapters for each topic. Secondly, reinforcement learning is not well supported
    in R, so creating an example would be difficult. Despite this, I include both
    of these topics in the book because I believe they are important emerging areas
    in deep learning that you should definitely be aware of.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: Generative adversarial networks
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Generative Adversarial Networks have been called *the coolest thing since sliced
    bread* by Yann LeCunn, one of the most prominent people in deep learning. If he
    believes that, then we should all take notice!
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: Most of our models in this book have been discriminative models, that is, we
    try to differentiate one class from another. However in [Chapter 9](e0045e3c-8afd-4e59-be9f-29e652a9a8b1.xhtml),
    *Anomaly Detection and Recommendation Systems* we created a generative model in
    the anomaly detection use-case. This model could create new data, albeit a different
    representation of the input data. Creating complex generative models is a very
    hot research topic in deep learning. Many believe that generative models can solve
    many problems in deep learning, including one of the biggest, which is the lack
    of correctly labelled data. However before GANs, it was difficult to judge how
    good a generative model actually was. A group of researchers led by Ian Goodfellow
    proposed Generative Adversarial Networks (GANs) (Goodfellow, Ian, et al. *Generative
    adversarial nets.* Advances in neural information processing systems. 2014) that
    could be used to create realistic artificial data.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: In GANs, two models are trained together, the first is a generative model G
    that creates new data. The second model is a discriminative model D that tries
    to predict if an example is from the real dataset, or has been created by the
    generative model G. The basic GAN idea is for the generative model to try to fool the
    discriminative model, while the discriminative model must try to tell the differences
    from fake data and real data. The generator keeps creating new data and refining
    its process until the discriminative model can no longer tell the difference between
    the generated data and the real training data.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: In the paper, the process is compared to a team of counterfeiters creating fake
    currency (the generative model) and the police who are trying to detect the counterfeit
    currency (the discriminative model). Both models improve incrementally until it
    is impossible to differentiate between the counterfeit currency and the real currency.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: 'GANs are notoriously hard to train. One paper that documented a working approach
    to training GANs on image data called their approach deep convolutional generative adversarial
    networks (Radford, Alec, Luke Metz, and Soumith Chintala. *Unsupervised representation
    learning with deep convolutional generative adversarial networks*. arXiv preprint
    arXiv:1511.06434 (2015)). In this paper, they recommended a number of guidelines
    to train stable deep convolutional generative adversarial networks (DCGANs):'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: Replace any pooling layers with strided convolutions (discriminator) and fractional-strided
    convolutions (generator).
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use batchnorm for both models.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remove fully connected hidden layers for deep architectures.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the generator, use tanh activation in the output layer and ReLU elsewhere.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the discriminator, use LeakyReLU activation for all layers.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Training DCGANs is an iterative process, the following steps are repeated:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: First the generator creates some new examples.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The discriminator is trained using real data and generated data.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After the discriminator has been trained, both models are trained together.
    The discriminator's weights are frozen, but its gradients are used in the generator
    model so that the generator can update it's weights.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: During this loop, it is vital that one model does not dominate the other model,
    they should both improve together. If the discriminator is too smart and is very
    confident that the instances from the generator are fakes, then there is no signal
    passed back to the generator and it can no longer improve. Similarly, if the generator
    finds a clever trick to fool the discriminator, it may generate images that are
    too similar, or of only one input category and the GAN again fails to improve.
    This shows the difficulty in training any GAN's, you have to find a set of parameters
    that works for the data and keeps two models synchronized. A good reference from
    one of the authors of the DCGAN paper on advice to make GANs work is [https://github.com/soumith/ganhacks](https://github.com/soumith/ganhacks).
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: GANs have many potential use-cases including being able to train with less data.
    They also could be used to predict missing data, e.g. add definition to blurred
    images / videos. They in reinforcement learning, which we discuss in the next
    section.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement learning
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Reinforcement learning has a deceptively simple definition: an agent interacts
    with its environment and changes its behaviors based on the the consequences of
    its actions. This is actually how humans and animals behave in the real world
    and is why many people believe that reinforcement learning is the key to achieving
    artificial general intelligence (AGI).'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: 'Artificial general intelligence (AGI) will be achieved if and when computers
    can perform complex tasks as well as people. This also requires that computers
    be able to adapt their current knowledge to new problems, just as humans do. Experts
    disagree on whether AGI is even possible. If we take the very first image from
    [Chapter 1](00c01383-1886-46d0-9435-29dfb3e08055.xhtml)*, Getting Started with
    Deep Learning*, we can see that the definition of artificial intelligence (*...
    performing functions that require intelligence when performed by people*) closely
    resembles the definition of reinforcement learning:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7c6cc2bc-45b6-48ae-ac40-0278d97af008.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
- en: Figure 11.5: The relationship between artificial intelligence, machine learning,
    and deep learning
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: 'David Silver, one of the most prominent people in reinforcement learning and
    one of the main people involved in AlphaGo, coined the following formula:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '*Artificial intelligence = Reinforcement learning + Deep learning*'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: One well-known example of reinforcement learning is an algorithm that can play
    a number of Atari 2600 video games better than most people by just using image
    pixels as input to the algorithm. The reinforcement learning algorithm learns
    by playing the game thousands, maybe millions of times, and learns what actions
    it needs to take to achieve rewards, which could be to collect points or to keep
    its avatar alive as long as possible. Perhaps the best known example in reinforcement
    learning is AlphaGo, which defeated one of the best players in the world in Go.
    AlphaGo is a hybrid artificial system that was composed of neural networks, reinforcement
    learning, and heuristic search algorithms. It is much harder to program a computer
    to win in a game of Go than other games, such as chess, because brute-force approaches
    are not feasible. An additional problem in Go is the difficulty in evaluating
    the current position.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: A formal definition of reinforcement learning is where an agent observes a state
    *s[t]* at timestep *t*. When in state *s[t]*, the agent interacts with its environment
    by taking action, which means that the agent transitions to the new state *s[t+1]*.
    The movement into a new state is linked with a reward, and the goal of the agent
    is to learn a policy that maximizes the expected rewards. The rewards could be
    cumulative and/or discounted; for example, near-time rewards are worth more than
    far-off returns. The value function is the prediction of the future reward. If
    the new state *s[t+1]* is dependent only on the previous state *s[t]* and the
    action *a[t]*, then it becomes a Markov process. However, one of the major problems
    in reinforcement learning is that rewards may be sparse and that there may a long
    delay between an action and achieving the reward. There is also the problem where
    an immediate reward might cause the agent to go down a path that could ultimately
    be destructive. For example, in a computer game, the agent could take an immediate
    step of trying to maximize a score, but this ultimately means that the character
    *dies* sooner. In a more real-life scenario, for example, a self-driving car,
    if the goal is to get to a location quickly, then the agent might decide to drive
    dangerously, putting passengers and other road users at risk.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: 'The core elements in reinforcement learning include the following:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: Rewards are the gains that an agent can achieve in the near-term.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A value function is the expected reward an agent can expect to achieve from
    the current state. The value function looks at the long-term rewards / goals,
    so this may mean taking actions that do not maximize rewards in the short-term.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A policy guides the actions that an agent can take, it maps the states to possible
    actions from that state.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is encapsulation of the environment that the agent interacts with.
    As such it is an incomplete representation of the physical world, but as long
    as it can accurately simulate the next step given an action, and calculate the
    reward, then it is an adequate representation that can be used for reinforcement
    learning.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other important mechanisms in reinforcement learning include multi-label classification,
    memory, unsupervised learning, knowledge transfer (using knowledge learned from
    one problem to solve related problems), search (to select the next best action
    by looking at all possible permutations *x* moves ahead), multi-agent RL, and
    learning to learn. We will not go into detail on these tasks, some may already
    be familiar to you. However, this list does highlight the complexity involved
    in reinforcement learning.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning can be used as a component in reinforcement learning to work on
    subtasks, such as object detection, speech recognition, NLP, and so on. Deep learning
    can also be an integral part of reinforcement learning when it is used in the
    key components of reinforcement learning, which are the value function, policy,
    and the environmental model. This is called deep reinforcement learning (deep
    RL). For example, by using recurrent connections between hidden units, Hausknecht
    and Stone built a deep recurrent Q-network (DRQN) that could predict the speed
    of the ball in the computer game **Pong**. Another research area in linking deep
    learning with RL is for imitation learning. In imitation learning, an agent learns
    by observing an *expert*. It is especially useful where there are delayed rewards
    and evaluating the current position is hard. But imitation learning can be costly,
    so one approach is to use GANs to produce artificial data to be used in reinforcement
    learning.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: Even though AlphaGo managed to beat the world champion in Go, it is nowhere
    near solving the problem of artificial general intelligence. DeepMind are a dedicated
    artificial intelligence company who combined experts in reinforcement learning,
    supervised learning and tree search functions and huge hardware resources to solve
    a single problem. AlphaGo was trained on a dataset of 30 million game states and
    simulated millions of games. The version that beat one of the best players in
    the world in Go used almost 2,000 CPUs and 300 GPUs. Before it could beat the
    world champion, it was coached by the European champion, although the early version
    did beat him first. However, AlphaGo solves only one problem, it cannot even generalize
    to other board games. Therefore, it does not come anywhere near solving artificial
    general intelligence.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the more honest appraisals of AlphaGo is from Andrej Karpathy, who is
    a distinguished researcher in deep learning and currently is director of artificial
    intelligence at Tesla. He posted a blog called **AlphaGo, in context** ([https://medium.com/@karpathy/alphago-in-context-c47718cb95a5](https://medium.com/@karpathy/alphago-in-context-c47718cb95a5))
    after AlphaGo defeated the number one ranked player in 2017\. Karpathy listed
    the following limitations of Go compared to other artificial intelligence tasks:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: The game is fully deterministic, that is, rules are fixed and fully known beforehand.
    In comparison, most real-world problems are not
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The game is fully observable, that is, complete information is known to all
    parties, there are no hidden variables or states.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The games has a discrete action space, that is, there is a fixed number of allowable
    actions
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A perfect simulator exists, that is, you can model millions of examples in a
    safe space. Real-life artificial intelligence does not have this.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The game is relatively short.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are historical datasets from previous games
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we consider self-driving cars as an artificial intelligence task, it probably
    does not match any of these properties.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: One unusual quirk in AlphaGo games with the world champion is that it sometimes
    passed on moves that would have captured board space. As humans, when we play
    games, we sometimes crave immediate feedback and therefore make moves to achieve
    short-term rewards. AlphaGo was programmed to win the game, regardless of the
    margin, so was quite content to pass on making such moves during the games. It
    is interesting that some expert Go players believe that they can improve by studying
    the strategies of AlphaGo. We have come full circle – humans trying to imitate
    the actions of computers, which in turn are modeled on the actions of humans.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: Additional deep learning resources
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section consists of some recommendations if you wish to continue your development
    in deep learning. My first recommendation is that you ensure that you have run
    all the code examples in this book. You are getting less than 50% of the benefit
    if you just read this book without running the code. Go through the examples,
    change the code to try and beat the results I got, re-write the MXNet code to
    Keras code, and so on.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: 'I strongly recommend *Deep Learning Specialization* on Coursera by Andrew Ng
    ([https://www.coursera.org/specializations/deep-learning](https://www.coursera.org/specializations/deep-learning)).
    Unfortunately, it is in Python, but it still is a great resource. Also in Python
    are two excellent courses on fast.ai ([http://www.fast.ai/](http://www.fast.ai/))
    from Jeremy Howard. These two options take opposite approaches: the *Deep Learning*
    specialization on Coursera takes a bottom-up approach that goes from theory to
    practice, and the fast.ai courses show you practical examples from the start and
    only afterwards shows you the theory.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: Another excellent resource is Kaggle ([https://www.kaggle.com/competitions](https://www.kaggle.com/competitions)).
    Kaggle hosts competitions where data scientists compete to get the best score
    in machine learning competitions. Many of these tasks are computer vision tasks.
    I am not a huge fan of the competitions, because I think that they ignore a lot
    of the work in preparing and acquiring datasets and also ignore how models are
    deployed. However, two notable features in Kaggle are its Kernels and forums/blogs.
    Kernels are Python or R scripts from other people. These scripts often have very
    interesting approaches to machine learning tasks. It is well worth following a
    competition and just looking at how other competitors approach these problems.
    The second notable feature is the forums/blogs on Kaggle. Again, some interesting
    approaches are discussed on the competition forums, and after every competition,
    there's usually a blog post from one of the winning competitions discussing their
    approach in winning the competition.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: 'Going back to R, another fantastic resource is the RStudio website. These guys
    do fantastic work in keeping R relevant to data science and machine learning.
    RStudio put a lot of output back into the R ecosystem; for example, the excellent
    work by Hadley Wickham, their Chief Scientist. The founder of RStudio (J.J. Allaire)
    is the author of the R API''s to TensorFlow and Keras. We have used some of their
    excellent tools in this book, including RStudio IDE, RShiny, RMarkdown, the tidy
    universe of packages, and so on. Here are some links with examples that you should
    check out:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: '[https://keras.rstudio.com/](https://keras.rstudio.com/)'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://keras.rstudio.com/articles/examples/index.html](https://keras.rstudio.com/articles/examples/index.html)'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://tensorflow.rstudio.com/](https://tensorflow.rstudio.com/)'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://tensorflow.rstudio.com/tfestimators/](https://tensorflow.rstudio.com/tfestimators/)'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://tensorflow.rstudio.com/tensorflow/](https://tensorflow.rstudio.com/tensorflow/)'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://tensorflow.rstudio.com/tools/](https://tensorflow.rstudio.com/tools/)'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://tensorflow.rstudio.com/learn/resources.html](https://tensorflow.rstudio.com/learn/resources.html)'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'My final suggestion is looking at research papers. Here are a number of good
    papers to begin with:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. *ImageNet Classification
    with Deep Convolutional Neural Networks*. Advances in neural information processing
    systems. 2012.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Szegedy, Christian, et al. *Going Deeper with Convolutions*. Cvpr, 2015.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'LeCun, Yann, et al. *Learning Algorithms for Classification: A Comparison on
    Handwritten Digit Recognition*. Neural networks: the statistical mechanics perspective
    261 (1995): 276.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zeiler, Matthew D., and Rob Fergus. *Visualizing and Understanding Convolutional
    Networks*. European conference on computer vision. Springer, Cham, 2014.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Srivastava, Nitish, et al. *Dropout: A Simple Way to Prevent Neural Networks
    from Overfitting*. The Journal of Machine Learning Research 15.1 (2014): 1929-1958.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simonyan, Karen, and Andrew Zisserman. *Very deep convolutional networks for
    large-scale image recognition*. arXiv preprint arXiv:1409.1556 (2014).
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Szegedy, Christian, et al. *Going deeper with convolutions*. Proceedings of
    the IEEE conference on computer vision and pattern recognition. 2015.
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He, Kaiming, et al. *Deep residual learning for image recognition*. Proceedings
    of the IEEE conference on computer vision and pattern recognition. 2016.
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goodfellow, Ian, et al. *Generative adversarial nets*. Advances in neural information
    processing systems. 2014.
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. Deep learning. nature 521.7553
    (2015): 436.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Goldberg, Yoav. *A primer on neural network models for natural language processing*. Journal
    of Artificial Intelligence Research 57 (2016): 345-420.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, the reader has seen some advanced deep learning techniques.
    First, we looked at some image classification models and looked at some historical
    models. Next, we loaded an existing model with pre-trained weights into R and
    used it to classify a new image. We looked at transfer learning, which allows
    us to reuse an existing model as a base on which to build a deep learning model
    for new data. We built an image classifier model that could train on image files.
    This model also showed us how to use data augmentation and callbacks, which are
    used in many deep learning models. Finally, we demonstrated how we can build a
    model in R and create a REST endpoint for a prediction API that can be used from
    other applications or across the web.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: We have come to the end of the book, and I really hope it was useful to you.
    R is a great language for data science and I believe it is easier to use and allows
    you to develop machine learning prototypes faster than the main alternative, Python.
    Now that it has support for some excellent deep learning frameworks in MXNet,
    Keras and TensorFlow, I believe that R will continue to be an excellent choice
    for data scientists and machine learning practioners.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
