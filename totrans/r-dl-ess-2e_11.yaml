- en: The Next Level in Deep Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have almost come to the end of our journey in deep learning with R. This
    chapter is a bit of a mixed bag of topics. We will begin this chapter by revisiting
    an image classification task and building a complete image classification solution
    image files rather than tabular data. We will then move on to explaining transfer
    learning, where you can use an existing model on a new dataset. Next we discuss
    an important consideration in any machine learning project - how will your model
    be used in deployment, that is, production? We will show how to create a REST
    API that allows any programming language to call a deep learning model in R to
    predict on new data. We will then move on to briefly discussing two other deep
    learning topics: Generative Adversarial Networks and reinforcement learning. Finally,
    we will close this chapter and the book by providing a few other resources that
    you may be interested in.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Building a complete image classification solution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ImageNet dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transfer learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying TensorFlow models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generative adversarial networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reinforcement learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Additional deep learning resources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image classification models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We covered image classification in Chapter 5,* Image Classification Using Convolutional
    Neural Networks*. In that chapter, we described convolutional and pooling layers
    that are essential for deep learning tasks involving images. We also built a number
    of models on a simple dataset, the MNIST dataset. Here, we are going to look at
    some advanced topics in image classification. First, we will build a complete
    image classification model using image files as input. We will look at callbacks,
    which are a great aid in building complex deep learning models. A call-back function will
    be used to persist (save) a model to file, which will be loaded back later. We
    then use this model in our next example, which is transfer learning. This is where
    you use some of the layers in a pre-trained model on new data.
  prefs: []
  type: TYPE_NORMAL
- en: Building a complete image classification solution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have built a few image classification models, but they used the MNIST dataset
    that was loaded from Keras or from CSV files. The data was always in tabular format.
    Obviously that is not how images are stored in most situations. This section looks
    at how to build an image classification model using a collection of image files. The
    first task is to acquire a set of image files. We are going to load the `CIFAR10`
    data that is included in Keras and save the data as image files. We will then
    use those files to build a deep learning model. After this exercise, you will
    know how to create a deep learning image classification task with your own image
    files.
  prefs: []
  type: TYPE_NORMAL
- en: The deep learning model in this chapter is not a complex model. The focus is
    to show how the data pipeline for an image classification task is structured.
    We look at how to arrange the image files, how to use data augmentation and how
    callbacks can be used during training.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the image data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first step is to create the image files. The code for this section is in
    the `Chapter11/gen_cifar10_data.R` folder. We will load the `CIFAR10` data and
    save the image files in the data directory. The first step is to create the directory
    structure. There are 10 classes in the `CIFAR10` dataset: we will save 8 classes
    for building a model and we will use 2 classes in a later section (*Transfer learning*).
    The following code creates the following directories under `data`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`cifar_10_images`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cifar_10_images/data1`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cifar_10_images/data2`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cifar_10_images/data1/train`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cifar_10_images/data1/valid`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cifar_10_images/data2/train`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cifar_10_images/data2/valid`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This is the structure that Keras expects image data to be stored in. If you
    use this structure, then the images can be used to train a model in Keras. In
    the first part of the code, we create these directories:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Under each of the train and valid directories, a separate directory is used
    for each category. We save the images for 8 classes under the `data1` folder,
    and save the images for 2 classes under the `data2` folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we have created the directories, the next step is to save the images in
    the correct directories, which we will do in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, as we have done previously, we will do a validation check to ensure
    that our images are correct. Let''s load in 9 images from one category. We want
    to check that the images display correctly and that they are from the same class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'This produces the following plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/eca7b405-c020-4861-8ca1-966e7b3653b0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.1: Sample CIFAR10 images'
  prefs: []
  type: TYPE_NORMAL
- en: This looks good! The images display correctly and we can see that these images
    all appear to be of the same class, which is cars. The images are out of focus,
    but that is because they are only thumbnail images of size 32 x 32.
  prefs: []
  type: TYPE_NORMAL
- en: Building the deep learning model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once you have run the script from the preceding section, you should have 40,000
    images for training in the `cifar_10_images/data1/train` directory and 8,000 images
    for validation in the `cifar_10_images/data1/valid` directory. We will train a
    model with this data. The code for this section is in the `Chapter11/build_cifar10_model.R`
    folder. The first section creates the model definition, which should be familiar
    to you:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The model definition was adapted from the VGG16 architecture, which we will
    see later. I used a smaller number of blocks and fewer nodes. Note that the final
    dense layer must have 8 nodes, because there are only 8, not 10 classes in the
    `data1` folder.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next part sets up a data generator; the purpose of this is to load batches
    of image files into the model as it is being trained. We can also apply data augmentation
    to the train dataset in the data generator. We will select to create artificial
    data by randomly flipping the images horizontally, shifting images horizontally/vertically,
    and rotating the images by up to 15 degrees. We saw in Chapter 6, *Tuning and
    Optimizing Models,* that data augmentation can significantly improve existing
    models:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Once the data generators have been set up, we will also use two callback functions.
    Callback functions allow you to run custom code after a specific number of batches
    / epochs have executed. You can write your own callbacks or use some predefined
    callback functions. Previously, we used callbacks for logging metrics, but here
    the callbacks will implement model checkpointing and early stopping, which are
    are often used when building complex deep learning models.
  prefs: []
  type: TYPE_NORMAL
- en: Model checkpointing is used to save the model weights to disk. You can then
    load the model from disk into memory and use it for predicting new data, or you
    can continue training the model from the point it was saved to disk. You can save
    the weights after every epoch, this might be useful if you are using cloud resources
    and are worried about the machine terminating suddenly. Here, we use it to keep
    the best model we have seen so far in training. After every epoch, it checks the
    validation loss, and if it is lower than the validation loss in the existing file,
    it saves the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Early stopping allows you to stop training a model when the performance no
    longer improves. Some people refer to it as a form of regularization because early
    stopping can prevent a model from overfitting. While it can avoid overfitting,
    it works very differently to the regularization techniques, such as L1, L2, weight
    decay, and dropout, that we saw in [Chapter 3](6e6dd858-9f00-454a-8434-a95c59e85b25.xhtml)*,
    Deep Learning Fundamentals*. When using early stopping, you usually would allow
    the model to continue for a few epochs even if performance is no longer improving,
    the number of epochs allowed before stopping training is known as *patience* in
    Keras. Here we set it to 10, that is, if we have 10 epochs where the model has
    failed to improve, we stop training. Here is the code to create the callbacks
    that we will use in our model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the code to train the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: One thing to note here is that we have to manage the steps per epoch for the
    train and validation generators. When you set up a generator, you don't know how
    much data is actually there, so we need to set the number of steps for each epoch.
    This is simply the number of records divided by the batch size.
  prefs: []
  type: TYPE_NORMAL
- en: 'This model should take less than an hour to train on a GPU and significantly
    longer if training on a CPU. As the model is training, the best model is saved
    in `cifar_model.h5`. The best result on my machine was after epoch 64, when the
    validation accuracy was about 0.80\. The model continued to train for another
    10 epochs after this but failed to improve. Here is a plot of the training metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/649c0029-c744-46ad-a55b-c07d56855380.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.2: Output metrics during model training'
  prefs: []
  type: TYPE_NORMAL
- en: Using the saved deep learning model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have built our deep learning model, we can restart R and reload
    the model from disk. The code for this section is in the `Chapter11/use_cifar10_model.R`
    folder. We will load the model that was created in the previous section by using
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We will use this model to generate a prediction for an image file from the
    validation set. We will pick the first directory in the validation folder and
    then pick the 7th file from that folder. We load the image and apply the same
    preprocessing to it as we did when preprocessing the images during training, which
    is to normalize the data by dividing the pixel values by 255.0\. Here is the code
    that loads the image and generates the prediction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The model predicts that the input is from the first class with 99.7% certainty.
    Since we chose the first directory in the validation set, the prediction is correct.
  prefs: []
  type: TYPE_NORMAL
- en: 'The final thing we will do with our model is to evaluate it on a directory
    of image files. We will also show how to generate predictions for an entire directory
    of image files. This code loads the images from the directories using data generators,
    similar to how we trained the model. Here is the code that evaluates and predicts
    categories by using the model for the validation images we saved to disk:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The validation accuracy is `80.86%`, which is similar to what we observed during
    model training, this confirms that the model was saved correctly to disk. Here
    is the code that generates predictions for all 8,000 validation images:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: We can see that our prediction output has 8,000 rows and 8 columns, so for each
    validation image, there is a probability for each category. We can see that the
    sum for each row is 1.0 and that there is usually one class that has a significant
    probability. For example, the model is predicting that the first image is in class
    7 with a probability of 99.9%.
  prefs: []
  type: TYPE_NORMAL
- en: We have now built a complete image classification solution using image files.
    This template can be reused for other tasks once the image data is stored in the
    same directory structure. If the new task had a different number of categories,
    then all you would need to change is the number of nodes in the last dense layer
    and possibly the softmax activation. However, if you did have a new image classification
    task that involved real-life images, then you probably would get better results
    by using an existing model and using transfer learning. Before I explain how to
    do that, I will provide some background on the ImageNet dataset, which is often
    used to train complex models which are then used in transfer learning.
  prefs: []
  type: TYPE_NORMAL
- en: The ImageNet dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'From 2010, an annual image classification competition has been run called the
    **ImageNet Large Scale Visual Recognition Challenge** (**ILSVRC**). The image
    set consists of over 14 million images that have been labelled with over 1,000
    categories. Without this dataset, there would not be the huge interest in deep
    learning that there is today. It has provided the stimulus for research in deep
    learning through the competition. The models and weights learnt on the Imagenet
    dataset have then been used in thousands of other deep learning models through
    transfer learning. The actual history of ImageNet is an interesting story. The
    following link ([https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world/](https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world/))
    explains how the project originally got little attention, but that changed with
    a number of linked events:'
  prefs: []
  type: TYPE_NORMAL
- en: The ILSVRC became the benchmark for image classification for researchers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NVIDIA had released libraries that allowed access to **graphical processing
    units** (**GPUs**). GPUs are designed to do massive parallel matrix operations,
    which is exactly what is needed to create deep neural networks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Geoffrey Hinton, Ilya Sutskever, and Alex Krizhevsky from the University of
    Toronto created a deep convolutional neural network architecture called **AlexNet**
    that won the competition in 2012\. Although this was not the first use of convolutional
    neural networks, their submission beat the next approach by a huge margin.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Researchers noticed that when they trained models using the ImageNet dataset,
    they could use them on other classification tasks. They almost always got much
    better performance from using the ImageNet model and then using transfer learning than
    just training a model from scratch on the original dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The advances in image classification can be tracked with some notable entries
    in the ILSVRC competition:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Team** | **Year** | **Error rate** |'
  prefs: []
  type: TYPE_TB
- en: '| 2011 ILSVRC winner (not deep learning) | 2011 | 25.8% |'
  prefs: []
  type: TYPE_TB
- en: '| AlexNet (7 layers) | 2012 | 15.3% |'
  prefs: []
  type: TYPE_TB
- en: '| VGG Net (16 layers) | 2014 | 7.32% |'
  prefs: []
  type: TYPE_TB
- en: '| GoogLeNet / Inception (19 layers) | 2014 | 6.67% |'
  prefs: []
  type: TYPE_TB
- en: '| ResNet (152 layers) | 2015 | 3.57% |'
  prefs: []
  type: TYPE_TB
- en: VGGNet, Inception, and Resnet are all available in Keras. A complete list of
    available networks can be found at [https://keras.rstudio.com/reference/index.html#section-applications](https://keras.rstudio.com/reference/index.html#section-applications).
  prefs: []
  type: TYPE_NORMAL
- en: The models for these networks can be loaded in Keras and used to classify a
    new image into one of the 1,000 categories in ImageNet. We will look at this next.
    If you have a new classification task with a different set of images, then you
    can also use these networks and then use transfer learning, which we will look
    at later in this chapter. The number of categories can be different; you do not
    need to have 1,000 categories for your task.
  prefs: []
  type: TYPE_NORMAL
- en: Perhaps the simplest model to begin with is VGGNet, as it is not that different
    to what we saw in [Chapter 5](1c0b9897-b0cc-4a8f-9ce8-e6409c347f4f.xhtml), *Image
    Classification Using Convolutional Neural Networks*.
  prefs: []
  type: TYPE_NORMAL
- en: Loading an existing model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will load an existing model (VGGNet) in Keras and use it
    to classify a new image. The code for this section can be found in the `Chapter11/vgg_model.R`.
    We will begin by loading the model and looking at its architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This model looks complicated, but when you look at it in detail, there is nothing
    that we haven't seen before. There are two blocks with two convolutional layers,
    which are then followed by a max pooling layer. These are followed by three blocks
    with three convolutional layers, which are then followed by a max pooling layer.
    Finally, we have a flatten layer and three dense layers. The last dense layer
    has 1,000 nodes, which is the number of categories in the ImageNet dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s use this model to make a prediction for a new image. This image is a
    bicycle, albeit an unusual one – it is a time trial bicycle:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6c765554-eb64-4046-9290-bd8fbd86f830.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.3: Test image for classification'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code block processes the image into a suitable format to use
    in the VGG model. It loads the image and resizes it to the dimensions of the images
    used to train the model `(224, 224)`. We then have to preprocess the image data
    before calling the `predict` function. Finally, there is a helper function in
    Keras called `imagenet_decode_predictions` that we can use to get the prediction
    categories and the probabilities:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The top prediction is `bicycle-built-for-two` at just over 30%, and the second
    best prediction is `mountain_bike` at 16.5%. ImageNet has a category for a tricycle
    and unicycle (and even a `Model_T` car!), but does not seem to have a category
    for a bicycle, so this prediction is a not a bad result. However, `mountain_bike` is
    probably a more accurate category for this image as it definitely is not a bicycle
    for two people!
  prefs: []
  type: TYPE_NORMAL
- en: Transfer learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the few disadvantages deep learning has over traditional machine learning
    is that it requires lots of data. Transfer learning is one way to overcome this,
    by using the weights of a previously trained model (usually trained on ImageNet
    data) and then applying them to a new problem set.
  prefs: []
  type: TYPE_NORMAL
- en: The ImageNet dataset consists of 15 million images in 1,000 classes. Since we
    can reuse parts of a model that has been trained on this amount of data, it may
    be possible to train the new model with just a few hundred images per category.
    This would depend on the images being somewhat related to the data used in the
    original model. For example, trying to use transfer learning from ImageNet models
    (which is trained on photographs) on data from other domains (for example, satellite
    or medical scans), would be more difficult and would require much more data. Some
    of the concerns we raised in [Chapter 6](13e9a742-84df-48e5-bbfd-ade33dcdd01a.xhtml), *Tuning
    and Optimizing Models*, about different data sources also applies. If the data
    is from a different type of data distribution, for example, mobile images, off-center
    photos, different lighting conditions, and so on, this will also matter. This
    is where creating more synthetic data through data augmentation can make a big
    difference.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now apply transfer learning using the model we built in the *Building
    the deep learning model* section. Recall that we only used 8/10 of the classes
    in building and evaluating this model. We will now build a new model using transfer
    learning that will differentiate between the 2 remaining classes. The code for
    this section can be found in the `Chapter11/cifar_txr.R` folder:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the model we built in the previous section and load it using the
    following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Next, we will call `trainable_weights` on the model object to get the number
    of trainable layers. This will count all the non-activation layers in our model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Next, we freeze the early layers in our model. Freezing the layers in a model
    means that the weights will not be updated during back-propagation. We freeze
    the convolutional blocks, but do not freeze the dense layers at the end of the
    model. We use the names we set in the model definition to set the first and last
    layers to freeze.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We then call `trainable_weights` on the model once more to confirm that the
    number changed from the preceding value, `14`, to `6`. Here is the code for freezing the
    layers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will remove the last dense layer and last activation layer from our
    model by calling the `pop_layer` function twice in the following code. We need
    to do this because our new task has 2 classes and not 8:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can add a new layer with 2 nodes (because we have 2 classes in the new
    task) by using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code block compiles the model again and sets up the generators
    to load the data. This is similar to what we saw when we built the model. One
    difference is that we do not use data augmentation here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we can train the model by using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The best accuracy was on epoch 9 when we got `96.55%` accuracy. This is significantly
    better than what we got on the multi-classification model (approximately 81%),
    but binary classification tasks are much easier than multi-classification tasks.
    We can also see that the model was very quick to train, because it only had to
    update the weights in the last few layers.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying TensorFlow models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Historically, one of the perceived disadvantages of using R for data science
    projects was the difficulty in deploying machine learning models built in R. This often
    meant that companies used R mainly as a prototyping tool to build models which
    were then rewritten in another language, such as Java and .NET. It is also one
    of the main reasons cited for companies switching to Python for data science as
    Python has more *glue code*, which allows it to interface with other programming
    languages.
  prefs: []
  type: TYPE_NORMAL
- en: Thankfully, this is changing. One interesting new product from RStudio, called RStudio Connect,
    allows companies to create a platform for sharing R-Shiny applications, reports
    in R Markdown, dashboards, and models. This allows companies to serve machine
    learning models using a REST interface.
  prefs: []
  type: TYPE_NORMAL
- en: The TensorFlow (and Keras) models we have created in this book can be deployed
    without any runtime dependency on either R or Python. One way of doing this is TensorFlow
    Serving, which is an open source software library for serving TensorFlow models.
    Another option is to use the Google CloudML interface that we saw in [Chapter
    10](2ea4d422-70f7-47af-a330-f0901f6f5fd3.xhtml)*, Running Deep Learning Models
    in the Cloud*. This allows you to create a publicly available REST API that can
    be called from your applications. TensorFlow models can also be deployed to iPhones
    and Android mobile phones.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two basic options for scoring models in production:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Batch mode**: In batch mode, a set of data is scored offline and the prediction
    results are stored and used elsewhere'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Real-time mode**: In real-time mode, the data is scored immediately, usually
    a record at a time, and the results are immediately used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For a lot of applications, batch mode is more than adequate. You should carefully consider
    if you really need a real-time prediction system as it is requires more resources
    and needs constant monitoring. It is much more efficient to score records in a
    batch rather than individually. Another advantage of batch mode is that you know
    the demand on the application beforehand and can plan resources accordingly. With
    real-time systems, a spike in demand or a denial of service attack can cause problems
    with your prediction model.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have already seen batch mode for a saved model in the *Using the saved deep
    learning model* section in this chapter. So, let''s look at how we can build a
    REST interface to get a prediction on new data from a deep learning model in real-time.
    This will use the `tfdeploy` package. The code for this section can be found in
    the `Chapter11/deploy_model.R`. We are going to build a simple model based on
    the MNIST dataset and then create a web interface where we can submit a new image
    for classification. Here is the first part of the code that builds the model and
    prints out the predictions for the first 5 rows in the test set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'There is nothing new about this code. Next, we will create a JSON file for
    one image file in the test set. JSON stands for JavaScript Object Notation, and
    is the accepted standard for serializing and sending data over a network connection.
    If HTML is the language for computers-to-human web communication, JSON is the
    language for computers-to-computers web communication. It is heavily used in microservice
    architecture, which is a framework for building a complex web ecosystem from lots
    of small web services. The data in the JSON file must have the same preprocessing
    applied as what was done during training – since we normalized the training data,
    we must also normalize the test data. The following code creates a JSON file with
    the values for the first instance in the testset and saves the file to `json_image.json`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have a JSON file, let''s create a REST web interface for our model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Once you do this, a new web page should pop up that is similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a936938e-a122-4b20-ba84-3ca27b978e20.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.4: Swagger UI for the TensorFlow model REST web service'
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a Swagger UI page showing the RESTful web services for the TensorFlow
    model. This allows us to test our API. While we could try to use this interface,
    it is easier to use the JSON file we just created. Open up Command Prompt on your
    machine, browse to the `Chapter11` code directory, and run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'You should get the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/67891d57-0caf-4506-956a-8f71e9589c86.png)'
  prefs: []
  type: TYPE_IMG
- en: The REST web interface returns another JSON string with these results. We can
    see that the 8th entry in the list is 1.0 and that all the other numbers are extremely
    small. This matches the prediction for the first row that we saw in the code at
    the start of this section.
  prefs: []
  type: TYPE_NORMAL
- en: I imagine that half of the people reading this are very excited about this and
    the other half couldn't care less! The half that really like this can see how
    R can be used to serve model predictions that interface with web applications.
    This opens up huge possibilities for using R, where beforehand it was believed
    that you either had to use Python or you had to redevelop models in other languages.
    The half that couldn't care less probably never had to deal with these issues
    with R, but in time they will see how important this is as well!
  prefs: []
  type: TYPE_NORMAL
- en: Other deep learning topics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Two topics that get a lot of attention in deep learning are **Generative Adversarial
    Networks (GANs)** and reinforcement learning. We only briefly introduce both topics,
    there is no code for this section for a couple of reasons. Firstly both topics
    are very advanced and trying to create a use-case that is non-trivial would require
    a few chapters for each topic. Secondly, reinforcement learning is not well supported
    in R, so creating an example would be difficult. Despite this, I include both
    of these topics in the book because I believe they are important emerging areas
    in deep learning that you should definitely be aware of.
  prefs: []
  type: TYPE_NORMAL
- en: Generative adversarial networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Generative Adversarial Networks have been called *the coolest thing since sliced
    bread* by Yann LeCunn, one of the most prominent people in deep learning. If he
    believes that, then we should all take notice!
  prefs: []
  type: TYPE_NORMAL
- en: Most of our models in this book have been discriminative models, that is, we
    try to differentiate one class from another. However in [Chapter 9](e0045e3c-8afd-4e59-be9f-29e652a9a8b1.xhtml),
    *Anomaly Detection and Recommendation Systems* we created a generative model in
    the anomaly detection use-case. This model could create new data, albeit a different
    representation of the input data. Creating complex generative models is a very
    hot research topic in deep learning. Many believe that generative models can solve
    many problems in deep learning, including one of the biggest, which is the lack
    of correctly labelled data. However before GANs, it was difficult to judge how
    good a generative model actually was. A group of researchers led by Ian Goodfellow
    proposed Generative Adversarial Networks (GANs) (Goodfellow, Ian, et al. *Generative
    adversarial nets.* Advances in neural information processing systems. 2014) that
    could be used to create realistic artificial data.
  prefs: []
  type: TYPE_NORMAL
- en: In GANs, two models are trained together, the first is a generative model G
    that creates new data. The second model is a discriminative model D that tries
    to predict if an example is from the real dataset, or has been created by the
    generative model G. The basic GAN idea is for the generative model to try to fool the
    discriminative model, while the discriminative model must try to tell the differences
    from fake data and real data. The generator keeps creating new data and refining
    its process until the discriminative model can no longer tell the difference between
    the generated data and the real training data.
  prefs: []
  type: TYPE_NORMAL
- en: In the paper, the process is compared to a team of counterfeiters creating fake
    currency (the generative model) and the police who are trying to detect the counterfeit
    currency (the discriminative model). Both models improve incrementally until it
    is impossible to differentiate between the counterfeit currency and the real currency.
  prefs: []
  type: TYPE_NORMAL
- en: 'GANs are notoriously hard to train. One paper that documented a working approach
    to training GANs on image data called their approach deep convolutional generative adversarial
    networks (Radford, Alec, Luke Metz, and Soumith Chintala. *Unsupervised representation
    learning with deep convolutional generative adversarial networks*. arXiv preprint
    arXiv:1511.06434 (2015)). In this paper, they recommended a number of guidelines
    to train stable deep convolutional generative adversarial networks (DCGANs):'
  prefs: []
  type: TYPE_NORMAL
- en: Replace any pooling layers with strided convolutions (discriminator) and fractional-strided
    convolutions (generator).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use batchnorm for both models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remove fully connected hidden layers for deep architectures.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the generator, use tanh activation in the output layer and ReLU elsewhere.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the discriminator, use LeakyReLU activation for all layers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Training DCGANs is an iterative process, the following steps are repeated:'
  prefs: []
  type: TYPE_NORMAL
- en: First the generator creates some new examples.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The discriminator is trained using real data and generated data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After the discriminator has been trained, both models are trained together.
    The discriminator's weights are frozen, but its gradients are used in the generator
    model so that the generator can update it's weights.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: During this loop, it is vital that one model does not dominate the other model,
    they should both improve together. If the discriminator is too smart and is very
    confident that the instances from the generator are fakes, then there is no signal
    passed back to the generator and it can no longer improve. Similarly, if the generator
    finds a clever trick to fool the discriminator, it may generate images that are
    too similar, or of only one input category and the GAN again fails to improve.
    This shows the difficulty in training any GAN's, you have to find a set of parameters
    that works for the data and keeps two models synchronized. A good reference from
    one of the authors of the DCGAN paper on advice to make GANs work is [https://github.com/soumith/ganhacks](https://github.com/soumith/ganhacks).
  prefs: []
  type: TYPE_NORMAL
- en: GANs have many potential use-cases including being able to train with less data.
    They also could be used to predict missing data, e.g. add definition to blurred
    images / videos. They in reinforcement learning, which we discuss in the next
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Reinforcement learning has a deceptively simple definition: an agent interacts
    with its environment and changes its behaviors based on the the consequences of
    its actions. This is actually how humans and animals behave in the real world
    and is why many people believe that reinforcement learning is the key to achieving
    artificial general intelligence (AGI).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Artificial general intelligence (AGI) will be achieved if and when computers
    can perform complex tasks as well as people. This also requires that computers
    be able to adapt their current knowledge to new problems, just as humans do. Experts
    disagree on whether AGI is even possible. If we take the very first image from
    [Chapter 1](00c01383-1886-46d0-9435-29dfb3e08055.xhtml)*, Getting Started with
    Deep Learning*, we can see that the definition of artificial intelligence (*...
    performing functions that require intelligence when performed by people*) closely
    resembles the definition of reinforcement learning:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7c6cc2bc-45b6-48ae-ac40-0278d97af008.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.5: The relationship between artificial intelligence, machine learning,
    and deep learning
  prefs: []
  type: TYPE_NORMAL
- en: 'David Silver, one of the most prominent people in reinforcement learning and
    one of the main people involved in AlphaGo, coined the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Artificial intelligence = Reinforcement learning + Deep learning*'
  prefs: []
  type: TYPE_NORMAL
- en: One well-known example of reinforcement learning is an algorithm that can play
    a number of Atari 2600 video games better than most people by just using image
    pixels as input to the algorithm. The reinforcement learning algorithm learns
    by playing the game thousands, maybe millions of times, and learns what actions
    it needs to take to achieve rewards, which could be to collect points or to keep
    its avatar alive as long as possible. Perhaps the best known example in reinforcement
    learning is AlphaGo, which defeated one of the best players in the world in Go.
    AlphaGo is a hybrid artificial system that was composed of neural networks, reinforcement
    learning, and heuristic search algorithms. It is much harder to program a computer
    to win in a game of Go than other games, such as chess, because brute-force approaches
    are not feasible. An additional problem in Go is the difficulty in evaluating
    the current position.
  prefs: []
  type: TYPE_NORMAL
- en: A formal definition of reinforcement learning is where an agent observes a state
    *s[t]* at timestep *t*. When in state *s[t]*, the agent interacts with its environment
    by taking action, which means that the agent transitions to the new state *s[t+1]*.
    The movement into a new state is linked with a reward, and the goal of the agent
    is to learn a policy that maximizes the expected rewards. The rewards could be
    cumulative and/or discounted; for example, near-time rewards are worth more than
    far-off returns. The value function is the prediction of the future reward. If
    the new state *s[t+1]* is dependent only on the previous state *s[t]* and the
    action *a[t]*, then it becomes a Markov process. However, one of the major problems
    in reinforcement learning is that rewards may be sparse and that there may a long
    delay between an action and achieving the reward. There is also the problem where
    an immediate reward might cause the agent to go down a path that could ultimately
    be destructive. For example, in a computer game, the agent could take an immediate
    step of trying to maximize a score, but this ultimately means that the character
    *dies* sooner. In a more real-life scenario, for example, a self-driving car,
    if the goal is to get to a location quickly, then the agent might decide to drive
    dangerously, putting passengers and other road users at risk.
  prefs: []
  type: TYPE_NORMAL
- en: 'The core elements in reinforcement learning include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Rewards are the gains that an agent can achieve in the near-term.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A value function is the expected reward an agent can expect to achieve from
    the current state. The value function looks at the long-term rewards / goals,
    so this may mean taking actions that do not maximize rewards in the short-term.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A policy guides the actions that an agent can take, it maps the states to possible
    actions from that state.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is encapsulation of the environment that the agent interacts with.
    As such it is an incomplete representation of the physical world, but as long
    as it can accurately simulate the next step given an action, and calculate the
    reward, then it is an adequate representation that can be used for reinforcement
    learning.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other important mechanisms in reinforcement learning include multi-label classification,
    memory, unsupervised learning, knowledge transfer (using knowledge learned from
    one problem to solve related problems), search (to select the next best action
    by looking at all possible permutations *x* moves ahead), multi-agent RL, and
    learning to learn. We will not go into detail on these tasks, some may already
    be familiar to you. However, this list does highlight the complexity involved
    in reinforcement learning.
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning can be used as a component in reinforcement learning to work on
    subtasks, such as object detection, speech recognition, NLP, and so on. Deep learning
    can also be an integral part of reinforcement learning when it is used in the
    key components of reinforcement learning, which are the value function, policy,
    and the environmental model. This is called deep reinforcement learning (deep
    RL). For example, by using recurrent connections between hidden units, Hausknecht
    and Stone built a deep recurrent Q-network (DRQN) that could predict the speed
    of the ball in the computer game **Pong**. Another research area in linking deep
    learning with RL is for imitation learning. In imitation learning, an agent learns
    by observing an *expert*. It is especially useful where there are delayed rewards
    and evaluating the current position is hard. But imitation learning can be costly,
    so one approach is to use GANs to produce artificial data to be used in reinforcement
    learning.
  prefs: []
  type: TYPE_NORMAL
- en: Even though AlphaGo managed to beat the world champion in Go, it is nowhere
    near solving the problem of artificial general intelligence. DeepMind are a dedicated
    artificial intelligence company who combined experts in reinforcement learning,
    supervised learning and tree search functions and huge hardware resources to solve
    a single problem. AlphaGo was trained on a dataset of 30 million game states and
    simulated millions of games. The version that beat one of the best players in
    the world in Go used almost 2,000 CPUs and 300 GPUs. Before it could beat the
    world champion, it was coached by the European champion, although the early version
    did beat him first. However, AlphaGo solves only one problem, it cannot even generalize
    to other board games. Therefore, it does not come anywhere near solving artificial
    general intelligence.
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the more honest appraisals of AlphaGo is from Andrej Karpathy, who is
    a distinguished researcher in deep learning and currently is director of artificial
    intelligence at Tesla. He posted a blog called **AlphaGo, in context** ([https://medium.com/@karpathy/alphago-in-context-c47718cb95a5](https://medium.com/@karpathy/alphago-in-context-c47718cb95a5))
    after AlphaGo defeated the number one ranked player in 2017\. Karpathy listed
    the following limitations of Go compared to other artificial intelligence tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: The game is fully deterministic, that is, rules are fixed and fully known beforehand.
    In comparison, most real-world problems are not
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The game is fully observable, that is, complete information is known to all
    parties, there are no hidden variables or states.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The games has a discrete action space, that is, there is a fixed number of allowable
    actions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A perfect simulator exists, that is, you can model millions of examples in a
    safe space. Real-life artificial intelligence does not have this.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The game is relatively short.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are historical datasets from previous games
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we consider self-driving cars as an artificial intelligence task, it probably
    does not match any of these properties.
  prefs: []
  type: TYPE_NORMAL
- en: One unusual quirk in AlphaGo games with the world champion is that it sometimes
    passed on moves that would have captured board space. As humans, when we play
    games, we sometimes crave immediate feedback and therefore make moves to achieve
    short-term rewards. AlphaGo was programmed to win the game, regardless of the
    margin, so was quite content to pass on making such moves during the games. It
    is interesting that some expert Go players believe that they can improve by studying
    the strategies of AlphaGo. We have come full circle – humans trying to imitate
    the actions of computers, which in turn are modeled on the actions of humans.
  prefs: []
  type: TYPE_NORMAL
- en: Additional deep learning resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section consists of some recommendations if you wish to continue your development
    in deep learning. My first recommendation is that you ensure that you have run
    all the code examples in this book. You are getting less than 50% of the benefit
    if you just read this book without running the code. Go through the examples,
    change the code to try and beat the results I got, re-write the MXNet code to
    Keras code, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'I strongly recommend *Deep Learning Specialization* on Coursera by Andrew Ng
    ([https://www.coursera.org/specializations/deep-learning](https://www.coursera.org/specializations/deep-learning)).
    Unfortunately, it is in Python, but it still is a great resource. Also in Python
    are two excellent courses on fast.ai ([http://www.fast.ai/](http://www.fast.ai/))
    from Jeremy Howard. These two options take opposite approaches: the *Deep Learning*
    specialization on Coursera takes a bottom-up approach that goes from theory to
    practice, and the fast.ai courses show you practical examples from the start and
    only afterwards shows you the theory.'
  prefs: []
  type: TYPE_NORMAL
- en: Another excellent resource is Kaggle ([https://www.kaggle.com/competitions](https://www.kaggle.com/competitions)).
    Kaggle hosts competitions where data scientists compete to get the best score
    in machine learning competitions. Many of these tasks are computer vision tasks.
    I am not a huge fan of the competitions, because I think that they ignore a lot
    of the work in preparing and acquiring datasets and also ignore how models are
    deployed. However, two notable features in Kaggle are its Kernels and forums/blogs.
    Kernels are Python or R scripts from other people. These scripts often have very
    interesting approaches to machine learning tasks. It is well worth following a
    competition and just looking at how other competitors approach these problems.
    The second notable feature is the forums/blogs on Kaggle. Again, some interesting
    approaches are discussed on the competition forums, and after every competition,
    there's usually a blog post from one of the winning competitions discussing their
    approach in winning the competition.
  prefs: []
  type: TYPE_NORMAL
- en: 'Going back to R, another fantastic resource is the RStudio website. These guys
    do fantastic work in keeping R relevant to data science and machine learning.
    RStudio put a lot of output back into the R ecosystem; for example, the excellent
    work by Hadley Wickham, their Chief Scientist. The founder of RStudio (J.J. Allaire)
    is the author of the R API''s to TensorFlow and Keras. We have used some of their
    excellent tools in this book, including RStudio IDE, RShiny, RMarkdown, the tidy
    universe of packages, and so on. Here are some links with examples that you should
    check out:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://keras.rstudio.com/](https://keras.rstudio.com/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://keras.rstudio.com/articles/examples/index.html](https://keras.rstudio.com/articles/examples/index.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://tensorflow.rstudio.com/](https://tensorflow.rstudio.com/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://tensorflow.rstudio.com/tfestimators/](https://tensorflow.rstudio.com/tfestimators/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://tensorflow.rstudio.com/tensorflow/](https://tensorflow.rstudio.com/tensorflow/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://tensorflow.rstudio.com/tools/](https://tensorflow.rstudio.com/tools/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://tensorflow.rstudio.com/learn/resources.html](https://tensorflow.rstudio.com/learn/resources.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'My final suggestion is looking at research papers. Here are a number of good
    papers to begin with:'
  prefs: []
  type: TYPE_NORMAL
- en: Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. *ImageNet Classification
    with Deep Convolutional Neural Networks*. Advances in neural information processing
    systems. 2012.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Szegedy, Christian, et al. *Going Deeper with Convolutions*. Cvpr, 2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'LeCun, Yann, et al. *Learning Algorithms for Classification: A Comparison on
    Handwritten Digit Recognition*. Neural networks: the statistical mechanics perspective
    261 (1995): 276.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zeiler, Matthew D., and Rob Fergus. *Visualizing and Understanding Convolutional
    Networks*. European conference on computer vision. Springer, Cham, 2014.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Srivastava, Nitish, et al. *Dropout: A Simple Way to Prevent Neural Networks
    from Overfitting*. The Journal of Machine Learning Research 15.1 (2014): 1929-1958.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simonyan, Karen, and Andrew Zisserman. *Very deep convolutional networks for
    large-scale image recognition*. arXiv preprint arXiv:1409.1556 (2014).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Szegedy, Christian, et al. *Going deeper with convolutions*. Proceedings of
    the IEEE conference on computer vision and pattern recognition. 2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He, Kaiming, et al. *Deep residual learning for image recognition*. Proceedings
    of the IEEE conference on computer vision and pattern recognition. 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goodfellow, Ian, et al. *Generative adversarial nets*. Advances in neural information
    processing systems. 2014.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. Deep learning. nature 521.7553
    (2015): 436.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Goldberg, Yoav. *A primer on neural network models for natural language processing*. Journal
    of Artificial Intelligence Research 57 (2016): 345-420.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, the reader has seen some advanced deep learning techniques.
    First, we looked at some image classification models and looked at some historical
    models. Next, we loaded an existing model with pre-trained weights into R and
    used it to classify a new image. We looked at transfer learning, which allows
    us to reuse an existing model as a base on which to build a deep learning model
    for new data. We built an image classifier model that could train on image files.
    This model also showed us how to use data augmentation and callbacks, which are
    used in many deep learning models. Finally, we demonstrated how we can build a
    model in R and create a REST endpoint for a prediction API that can be used from
    other applications or across the web.
  prefs: []
  type: TYPE_NORMAL
- en: We have come to the end of the book, and I really hope it was useful to you.
    R is a great language for data science and I believe it is easier to use and allows
    you to develop machine learning prototypes faster than the main alternative, Python.
    Now that it has support for some excellent deep learning frameworks in MXNet,
    Keras and TensorFlow, I believe that R will continue to be an excellent choice
    for data scientists and machine learning practioners.
  prefs: []
  type: TYPE_NORMAL
