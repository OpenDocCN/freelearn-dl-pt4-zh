<html><head></head><body><div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Deep Feedforward Networks</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">In t<span class="calibre14">he first chapter, you learned about the mathematics which drives the logic behind all kinds of neural networks. In this chapter, we are going to focus on the most fundamental neutral networks, which are called <strong class="calibre7">feedforward neural networks</strong>. We will also look at deep feedforward networks with multiple hidden layers to improve the accuracy of the model.</span></p>
<p class="calibre4">We will be covering the following topics:</p>
<ul class="calibre20">
<li class="calibre21">Defining feedforward networks</li>
<li class="calibre21">Understanding backpropagation</li>
<li class="calibre21">Implementing feedforward networks in TensorFlow</li>
<li class="calibre21">Analyzing the Iris dataset</li>
<li class="calibre21">Creating feedforward networks for image classification</li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Defining feedforward networks</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">Deep feedforward networks, also called feedforward neural networks, are sometimes also referred to as <strong class="calibre7">Multilayer Perceptrons</strong> (<strong class="calibre7">MLPs</strong>). The goal of a feedforward network is to approximate the function of <em class="calibre17">f∗</em>. For example, for a classifier, <em class="calibre17">y=f∗(x)</em> maps an input <em class="calibre17">x</em> to a label <em class="calibre17">y.</em> A feedforward network defines a mapping from input to label <em class="calibre17">y=f(x;θ)</em>. It learns the value of the parameter <em class="calibre17">θ</em> that results in the best function approximation.</p>
<p class="calibre4">We discuss RNNs in <a href="5f7c0191-1c53-462e-aa51-634572f20214.xhtml" target="_blank" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2">Chapter 5</a>, <em class="calibre17">Recurrent Neural Networks</em>. Feedforward networks are a conceptual stepping stone on the path to recurrent networks, which power many natural language applications. Feedforward neural networks are called networks because they compose together many different functions which represent them. These functions are composed in a directed acyclic graph.</p>
<p class="calibre4">The model is associated with a directed acyclic graph describing how the functions are composed together. For example, there are three functions <em class="calibre17">f(1)</em>, <em class="calibre17">f(2)</em>, and <em class="calibre17">f(3)</em> connected to form <em class="calibre17">f(x) =f(3)(f(2)(f(1)(x)))</em>. These chain structures are the most commonly used structures of neural networks. In this case, <em class="calibre17">f(1)</em> i<em class="calibre17">s</em> called the <strong class="calibre7">first layer</strong> of the network, <em class="calibre17">f(2)</em> is called the <strong class="calibre7">second layer</strong>, and so on. The overall length of the chain gives the depth of the model. It is from this terminology that the name deep learning arises. The final layer of a feedforward network is called the <strong class="calibre7">output layer</strong>.</p>
<div class="mce-root"><img src="Images/e7e58a6b-8f57-4648-9ee4-024e28d62900.png" width="756" height="218" class="calibre63"/></div>
<div class="mce-root3">Diagram showing various functions activated on input x to form a neural network</div>
<p class="calibre4">These networks are called neural because they are inspired by neuroscience. Each hidden layer is a vector. The dimensionality of these hidden layers determines the width of the model.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Understanding backpropagation</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">When a feedforward neural network is used to accept an input <em class="calibre17">x</em> and produce an output <em class="calibre17">yˆ</em>, information flows forward through the network elements. The input <em class="calibre17">x</em> provides the information that then propagates up to the hidden units at each layer and produces <em class="calibre17">yˆ</em>. This is called <strong class="calibre7">forward propagation</strong>. During training, forward propagation continues onward until it produces a scalar cost <em class="calibre17">J(θ)</em>. The backpropagation algorithm, often called backprop, allows the information from the cost to then flow backward through the network in order to compute the gradient.</p>
<p class="calibre4">Computing an analytical expression for the gradient is straightforward, but numerically evaluating such an expression can be computationally expensive. The backpropagation algorithm does so using a simple and inexpensive procedure.</p>
<div class="packt_tip">Backpropagation refers only to the method to compute the gradient, while another algorithm, such as stochastic gradient descent, refers to the actual mechanism.</div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Implementing feedforward networks with TensorFlow</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">Feedforward networks can be easily implemented using TensorFlow by defining placeholders for hidden layers, computing the activation values, and using them to calculate predictions. Let's take an example of classification with a feedforward network:</p>
<pre class="calibre26">X = tf.placeholder("float", shape=[None, x_size])<br class="calibre2"/>y = tf.placeholder("float", shape=[None, y_size])<br class="calibre2"/>weights_1 = initialize_weights((x_size, hidden_size), stddev)<br class="calibre2"/>weights_2 = initialize_weights((hidden_size, y_size), stddev)<br class="calibre2"/>sigmoid = tf.nn.sigmoid(tf.matmul(X, weights_1))<br class="calibre2"/>y = tf.matmul(sigmoid, weights_2)</pre>
<p class="calibre4">Once the predicted value tensor has been defined, we calculate the <kbd class="calibre18">cost</kbd> function:</p>
<pre class="calibre26">cost = tf.reduce_mean(tf.nn.OPERATION_NAME(labels=&lt;actual value&gt;, logits=&lt;predicted value&gt;))<br class="calibre2"/>updates_sgd = tf.train.GradientDescentOptimizer(sgd_step).minimize(cost)</pre>
<p class="calibre4">Here, <kbd class="calibre18">OPERATION_NAME</kbd> could be one of the following:</p>
<ul class="calibre20">
<li class="calibre21"><kbd class="calibre18">tf.nn.sigmoid_cross_entropy_with_logits</kbd>: Calculates sigmoid cross entropy on incoming <kbd class="calibre18">logits</kbd> and <kbd class="calibre18">labels</kbd>:</li>
</ul>
<pre class="calibre64">sigmoid_cross_entropy_with_logits(<br class="calibre2"/>  _sentinel=None,<br class="calibre2"/>  labels=None,<br class="calibre2"/>  logits=None,<br class="calibre2"/>  name=None<br class="calibre2"/>)Formula implemented is max(x, 0) - x * z + log(1 + exp(-abs(x)))</pre>
<p class="calibre65"><kbd class="calibre18">_sentinel</kbd>: Used to prevent positional parameters. Internal, do not use.<br class="calibre25"/>
<kbd class="calibre18">labels</kbd>: A tensor of the same type and shape as logits.<br class="calibre25"/>
<kbd class="calibre18">logits</kbd>: A tensor of type <kbd class="calibre18">float32</kbd> or <kbd class="calibre18">float64</kbd>. The formula implemented is ( <em class="calibre17">x = logits</em>, <em class="calibre17">z = labels</em>) <kbd class="calibre18">max(x, 0) - x * z + log(1 + exp(-abs(x)))</kbd><span class="calibre14">.</span></p>
<ul class="calibre20">
<li class="calibre21"><kbd class="calibre18">tf.nn.softmax</kbd>: Performs <kbd class="calibre18">softmax</kbd> activation on the incoming tensor. This only normalizes to make sure all the probabilities in a tensor row add up to one. It cannot be directly used in a classification.</li>
</ul>
<pre class="calibre64">softmax = exp(logits) / reduce_sum(exp(logits), dim)</pre>
<p class="calibre65"><kbd class="calibre18">logits</kbd>: A non-empty tensor. Must be one of the following types--half, <kbd class="calibre18">float32</kbd>, or <kbd class="calibre18">float64</kbd>.<br class="calibre25"/>
<kbd class="calibre18">dim</kbd>: The dimension <kbd class="calibre18">softmax</kbd> will be performed on. The default is <kbd class="calibre18">-1</kbd>, which indicates the last dimension.<br class="calibre25"/>
<kbd class="calibre18">name</kbd>: A name for the operation (optional).<br class="calibre25"/>
<kbd class="calibre18">tf.nn.log_softmax</kbd>: Calculates the log of the <kbd class="calibre18">softmax</kbd> function and helps in normalizing underfitting. This function is also just a normalization function.</p>
<pre class="calibre64">log_softmax(<br class="calibre2"/> logits,<br class="calibre2"/> dim=-1,<br class="calibre2"/> name=None<br class="calibre2"/>)</pre>
<p class="calibre65"><kbd class="calibre18">logits</kbd>: A non-empty tensor. Must be one of the following types--half, <kbd class="calibre18">float32</kbd>, or <kbd class="calibre18">float64</kbd>.<br class="calibre25"/>
<kbd class="calibre18">dim</kbd>: The dimension <kbd class="calibre18">softmax</kbd> will be performed on. The default is <kbd class="calibre18">-1</kbd>, which indicates the last dimension.<br class="calibre25"/>
<kbd class="calibre18">name</kbd>: A name for the operation (optional).</p>
<ul class="calibre20">
<li class="calibre21"><kbd class="calibre18">tf.nn.softmax_cross_entropy_with_logits</kbd></li>
</ul>
<pre class="calibre64">softmax_cross_entropy_with_logits(<br class="calibre2"/>  _sentinel=None,<br class="calibre2"/>  labels=None,<br class="calibre2"/>  logits=None,<br class="calibre2"/>  dim=-1,<br class="calibre2"/>  name=None<br class="calibre2"/>)</pre>
<p class="calibre65"><kbd class="calibre18">_sentinel</kbd><span class="calibre14">: Used to prevent positional parameters. For internal use only.</span><br class="calibre25"/>
<kbd class="calibre18">labels</kbd><span class="calibre14">: Each rows</span> <kbd class="calibre18">labels[i]</kbd> <span class="calibre14">must be a valid probability distribution.</span><br class="calibre25"/>
<kbd class="calibre18">logits</kbd><span class="calibre14">: Unscaled log probabilities.</span><br class="calibre25"/>
<kbd class="calibre18">dim</kbd><span class="calibre14">: The class dimension. Defaulted to <kbd class="calibre18">-1</kbd>, which is the last dimension.</span><br class="calibre25"/>
<kbd class="calibre18">name</kbd><span class="calibre14">: A name for the operation (optional).</span></p>
<p class="calibre65">The preceding code snippet computes <kbd class="calibre18">softmax</kbd> cross entropy between <kbd class="calibre18">logits</kbd> and <kbd class="calibre18">labels.</kbd> While the classes are mutually exclusive, their probabilities need not be. All that is required is that each row of labels is a valid probability distribution. For exclusive labels, use (where one and only one class is true at a time) <kbd class="calibre18">sparse_softmax_cross_entropy_with_logits</kbd>.</p>
<ul class="calibre20">
<li class="calibre21"><kbd class="calibre18">tf.nn.sparse_softmax_cross_entropy_with_logits</kbd></li>
</ul>
<pre class="calibre64"><span class="calibre5">sparse_softmax_cross_entropy_with_logits(</span><br class="calibre2"/><span class="calibre5">  _sentinel=None,</span><br class="calibre2"/><span class="calibre5">  labels=None,</span><br class="calibre2"/><span class="calibre5">  logits=None,</span><br class="calibre2"/><span class="calibre5">  name=None</span><br class="calibre2"/><span class="calibre5">)</span></pre>
<p class="calibre66"><kbd class="calibre18">labels</kbd>: Tensor of shape [<em class="calibre17">d_0</em>, <em class="calibre17">d_1</em>, <em class="calibre17">...</em>, <em class="calibre17">d_(r-1)</em>] (where <em class="calibre17">r</em> is the rank of labels and result) and <kbd class="calibre18">dtype</kbd>, <kbd class="calibre18">int32</kbd>, or <kbd class="calibre18">int64</kbd>. Each entry in labels must be an index in [<em class="calibre17">0</em>, <kbd class="calibre18">num_classes</kbd>). Other values will raise an exception when this operation is run on the CPU and return NaN for corresponding loss and gradient rows on the GPU.<br class="calibre25"/>
<kbd class="calibre18">logits</kbd>: Unscaled log probabilities of shape [<em class="calibre17">d_0</em>, <em class="calibre17">d_1</em>, <em class="calibre17">...</em>, <em class="calibre17">d_(r-1)</em>, <kbd class="calibre18">num_classes</kbd>] and <kbd class="calibre18">dtype</kbd>, <kbd class="calibre18">float32</kbd>, or <kbd class="calibre18">float64</kbd>.</p>
<p class="calibre66">The preceding code computes sparse <kbd class="calibre18">softmax</kbd> cross entropy between <kbd class="calibre18">logits</kbd> and <kbd class="calibre18">labels</kbd>. The probability of a given label is considered exclusive. Soft classes are not allowed, and the label's vector must provide a single specific index for the true class for each row of <kbd class="calibre18">logits</kbd>.</p>
<ul class="calibre20">
<li class="calibre21"><kbd class="calibre18">tf.nn.weighted_cross_entropy_with_logits</kbd></li>
</ul>
<pre class="calibre64">weighted_cross_entropy_with_logits(<br class="calibre2"/>  targets,<br class="calibre2"/>  logits,<br class="calibre2"/>  pos_weight,<br class="calibre2"/>  name=None<br class="calibre2"/>)</pre>
<p class="calibre66"><kbd class="calibre18">targets</kbd>: A tensor of the same type and shape as logits.<br class="calibre25"/>
<kbd class="calibre18">logits</kbd>: A tensor of type <kbd class="calibre18">float32</kbd> or <kbd class="calibre18">float64</kbd>.<br class="calibre25"/>
<kbd class="calibre18">pos_weight</kbd>: A coefficient to use on the positive examples.</p>
<p class="calibre66">This is similar to <kbd class="calibre18">sigmoid_cross_entropy_with_logits()</kbd> except that <kbd class="calibre18">pos_weight</kbd> allows a trade-off of recall and precision by up or down weighting the cost of a positive error relative to a negative error.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Analyzing the Iris dataset</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">Let's look at a feedforward example using the Iris dataset.</p>
<div class="packt_infobox">You can download the dataset from <a href="https://github.com/ml-resources/neuralnetwork-programming/blob/ed1/ch02/iris/iris.csv" target="_blank" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre31">https://github.com/ml-resources/neuralnetwork-programming/blob/ed1/ch02/iris/iris.csv</a> and the target labels from <a href="https://github.com/ml-resources/neuralnetwork-programming/blob/ed1/ch02/iris/target.csv" target="_blank" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre31">https://github.com/ml-resources/neuralnetwork-programming/blob/ed1/ch02/iris/target.csv</a>.</div>
<p class="calibre4">In the Iris dataset, we will use 150 rows of data made up of 50 samples from each of three Iris species: Iris setosa, Iris virginica, and Iris versicolor.</p>
<p class="calibre4">Petal geometry compared from three iris species:<br class="calibre25"/>
<strong class="calibre7">Iris Setosa</strong>, <strong class="calibre7">Iris Virginica</strong>, and <strong class="calibre7">Iris Versicolor</strong>.</p>
<div class="mce-root"><img src="Images/ca899bdb-1bb7-4491-b8b4-79db174760e5.png" width="1532" height="566" class="calibre67"/></div>
<p class="calibre4">In the dataset, each row contains data for each flower sample: sepal length, sepal width, petal length, petal width, and flower species. Flower species are stored as integers, with 0 denoting Iris setosa, 1 denoting Iris versicolor, and 2 denoting Iris virginica.</p>
<p class="calibre4">First, we will create a <kbd class="calibre18">run()</kbd> function that takes three parameters--hidden layer size <kbd class="calibre18">h_size</kbd>, standard deviation for weights <kbd class="calibre18">stddev</kbd>, and Step size of Stochastic Gradient Descent <kbd class="calibre18">sgd_step</kbd>:</p>
<pre class="calibre26">def run(h_size, stddev, sgd_step)</pre>
<p class="calibre4">Input data loading is done using the <kbd class="calibre18">genfromtxt</kbd> function in <kbd class="calibre18">numpy</kbd>. The Iris data loaded has a shape of L: 150 and W: 4. Data is loaded in the <kbd class="calibre18">all_X</kbd> <span class="calibre14">variable.</span> Target labels are loaded from <kbd class="calibre18">target.csv</kbd> in <kbd class="calibre18">all_Y</kbd> with the shape of L: 150, W:3:</p>
<pre class="calibre26">def load_iris_data():<br class="calibre2"/>    from numpy import genfromtxt<br class="calibre2"/>    data = genfromtxt('iris.csv', delimiter=',')<br class="calibre2"/>    target = genfromtxt('target.csv', delimiter=',').astype(int)<br class="calibre2"/>    # Prepend the column of 1s for bias<br class="calibre2"/>    L, W  = data.shape<br class="calibre2"/>    all_X = np.ones((L, W + 1))<br class="calibre2"/>    all_X[:, 1:] = data<br class="calibre2"/>    num_labels = len(np.unique(target))<br class="calibre2"/>    all_y = np.eye(num_labels)[target]<br class="calibre2"/>    return train_test_split(all_X, all_y, test_size=0.33, random_state=RANDOMSEED)</pre>
<p class="calibre4">Once data is loaded, we initialize the weights matrix based on <kbd class="calibre18">x_size</kbd>, <kbd class="calibre18">y_size</kbd>, and <kbd class="calibre18">h_size</kbd> with standard deviation passed to the <kbd class="calibre18">run()</kbd> method:</p>
<ul class="calibre20">
<li class="calibre21"><kbd class="calibre18">x_size</kbd>= 5</li>
<li class="calibre21"><kbd class="calibre18">y_size</kbd>= 3</li>
<li class="calibre21"><kbd class="calibre18">h_size</kbd>= 128 (or any other number chosen for neurons in the hidden layer)</li>
</ul>
<pre class="calibre26"># Size of Layers<br class="calibre2"/>x_size = train_x.shape[1] # Input nodes: 4 features and 1 bias<br class="calibre2"/>y_size = train_y.shape[1] # Outcomes (3 iris flowers)<br class="calibre2"/># variables<br class="calibre2"/>X = tf.placeholder("float", shape=[None, x_size])<br class="calibre2"/>y = tf.placeholder("float", shape=[None, y_size])<br class="calibre2"/>weights_1 = initialize_weights((x_size, h_size), stddev)<br class="calibre2"/>weights_2 = initialize_weights((h_size, y_size), stddev)</pre>
<p class="calibre4">Next, we make the prediction using <kbd class="calibre18">sigmoid</kbd> as the activation function defined in the <kbd class="calibre18">forward_propagration()</kbd> function:</p>
<pre class="calibre26">def forward_propagation(X, weights_1, weights_2):<br class="calibre2"/>    sigmoid = tf.nn.sigmoid(tf.matmul(X, weights_1))<br class="calibre2"/>    y = tf.matmul(sigmoid, weights_2)<br class="calibre2"/>    return y</pre>
<p class="calibre4">First, <kbd class="calibre18">sigmoid</kbd> output is calculated from input <kbd class="calibre18">X</kbd> and <kbd class="calibre18">weights_1</kbd>. This is then used to calculate <kbd class="calibre18">y</kbd> as a matrix multiplication of <kbd class="calibre18">sigmoid</kbd> and <kbd class="calibre18">weights_2</kbd>:</p>
<pre class="calibre26">y_pred = forward_propagation(X, weights_1, weights_2)<br class="calibre2"/>predict = tf.argmax(y_pred, dimension=1)</pre>
<p class="calibre4">Next, we define the cost function and optimization using gradient descent. Let's look at the <kbd class="calibre18">GradientDescentOptimizer</kbd> being used. It is defined in the <kbd class="calibre18">tf.train.GradientDescentOptimizer</kbd> <span class="calibre14">class</span> and implements the gradient descent algorithm.</p>
<p class="calibre4">To construct an instance, we use the following constructor and pass <kbd class="calibre18">sgd_step</kbd> as a parameter:</p>
<pre class="calibre26"># constructor for GradientDescentOptimizer<br class="calibre2"/>__init__(<br class="calibre2"/>  learning_rate,<br class="calibre2"/>  use_locking=False,<br class="calibre2"/>  name='GradientDescent'<br class="calibre2"/>)</pre>
<p class="calibre4">Arguments passed are explained here:</p>
<ul class="calibre20">
<li class="calibre21"><kbd class="calibre18">learning_rate</kbd>: A tensor or a floating point value. The learning rate to use.</li>
<li class="calibre21"><kbd class="calibre18">use_locking</kbd>: If True, use locks for update operations.</li>
<li class="calibre21"><kbd class="calibre18">name</kbd>: Optional name prefix for the operations created when applying gradients. The default name is <kbd class="calibre18">"GradientDescent"</kbd>.</li>
</ul>
<p class="calibre4">The following list shows the code to implement the <kbd class="calibre18">cost</kbd> function:</p>
<pre class="calibre26">cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_pred))<br class="calibre2"/>updates_sgd = tf.train.GradientDescentOptimizer(sgd_step).minimize(cost)</pre>
<p class="calibre4">Next, we will implement the following steps:</p>
<ol class="calibre23">
<li class="chapter">Initialize the TensorFlow session:</li>
</ol>
<pre class="calibre64">sess = tf.Session()</pre>
<ol start="2" class="calibre23">
<li class="chapter">Initialize all the variables using <kbd class="calibre18">tf.initialize_all_variables()</kbd>; the return object is used to instantiate the session.</li>
<li class="chapter">Iterate over <kbd class="calibre18">steps</kbd> (1 to 50).</li>
<li class="chapter">For each step in <kbd class="calibre18">train_x</kbd> and <kbd class="calibre18">train_y</kbd>, execute <kbd class="calibre18">updates_sgd</kbd>.</li>
<li class="chapter">Calculate the <kbd class="calibre18">train_accuracy</kbd> and <kbd class="calibre18">test_accuracy</kbd>.</li>
</ol>
<p class="calibre4">We stored the accuracy for each step in a list so that we could plot a graph:</p>
<pre class="calibre26">    init = tf.initialize_all_variables()<br class="calibre2"/>    steps = 50<br class="calibre2"/>    sess.run(init)<br class="calibre2"/>    x  = np.arange(steps)<br class="calibre2"/>    test_acc = []<br class="calibre2"/>    train_acc = []<br class="calibre2"/>    print("Step, train accuracy, test accuracy")<br class="calibre2"/>    for step in range(steps):<br class="calibre2"/>        # Train with each example<br class="calibre2"/>        for i in range(len(train_x)):<br class="calibre2"/>            sess.run(updates_sgd, feed_dict={X: train_x[i: i + 1], y: train_y[i: i + 1]})<br class="calibre2"/><br class="calibre2"/>        train_accuracy = np.mean(np.argmax(train_y, axis=1) ==<br class="calibre2"/>                                 sess.run(predict, feed_dict={X: train_x, y: train_y}))<br class="calibre2"/>        test_accuracy = np.mean(np.argmax(test_y, axis=1) ==<br class="calibre2"/>                                sess.run(predict, feed_dict={X: test_x, y: test_y}))<br class="calibre2"/><br class="calibre2"/>        print("%d, %.2f%%, %.2f%%"<br class="calibre2"/>              % (step + 1, 100. * train_accuracy, 100. * test_accuracy))<br class="calibre2"/>      <br class="calibre2"/>        test_acc.append(100. * test_accuracy)<br class="calibre2"/>        train_acc.append(100. * train_accuracy)</pre>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Code execution</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">Let's run this code for <kbd class="calibre18">h_size</kbd> of <kbd class="calibre18">128</kbd>, standard deviation of <kbd class="calibre18">0.1</kbd>, and <kbd class="calibre18">sgd_step</kbd> of <kbd class="calibre18">0.01</kbd>:</p>
<pre class="calibre26">def run(h_size, stddev, sgd_step):<br class="calibre2"/> ...<br class="calibre2"/><br class="calibre2"/>def main():<br class="calibre2"/>run(128,0.1,0.01)<br class="calibre2"/><br class="calibre2"/>if __name__ == '__main__':<br class="calibre2"/>main()</pre>
<p class="calibre4">The preceding code outputs the following graph, which plots the steps versus the test and train accuracy:</p>
<div class="mce-root"><img src="Images/6ae79ae5-fae3-4cf2-88ff-a77d94bf6a8e.png" width="1170" height="931" class="calibre68"/></div>
<p class="calibre4">Let's compare the change in SGD steps and its effect on training accuracy. The following code is very similar to the previous code example, but we will rerun it for multiple SGD steps to see how SGD steps affect accuracy levels.</p>
<pre class="calibre26">def run(h_size, stddev, sgd_steps):<br class="calibre2"/>    ....<br class="calibre2"/>    test_accs = []<br class="calibre2"/>    train_accs = []<br class="calibre2"/>    time_taken_summary = []<br class="calibre2"/>    for sgd_step in sgd_steps:<br class="calibre2"/>        start_time = time.time()<br class="calibre2"/>        updates_sgd = tf.train.GradientDescentOptimizer(sgd_step).minimize(cost)<br class="calibre2"/>        sess = tf.Session()<br class="calibre2"/>        init = tf.initialize_all_variables()<br class="calibre2"/>        steps = 50<br class="calibre2"/>        sess.run(init)<br class="calibre2"/>        x  = np.arange(steps)<br class="calibre2"/>        test_acc = []<br class="calibre2"/>        train_acc = []<br class="calibre2"/><br class="calibre2"/>        print("Step, train accuracy, test accuracy")<br class="calibre2"/><br class="calibre2"/><br class="calibre2"/>        for step in range(steps):<br class="calibre2"/>                # Train with each example<br class="calibre2"/>                for i in range(len(train_x)):<br class="calibre2"/>                    sess.run(updates_sgd, feed_dict={X: train_x[i: i + 1], <br class="calibre2"/>                              y: train_y[i: i + 1]})<br class="calibre2"/><br class="calibre2"/>                train_accuracy = np.mean(np.argmax(train_y, axis=1) ==<br class="calibre2"/>                                         sess.run(predict, <br class="calibre2"/>                                         feed_dict={X: train_x, y: train_y}))<br class="calibre2"/>                test_accuracy = np.mean(np.argmax(test_y, axis=1) ==<br class="calibre2"/>                                        sess.run(predict, <br class="calibre2"/>                                        feed_dict={X: test_x, y: test_y}))<br class="calibre2"/><br class="calibre2"/>                print("%d, %.2f%%, %.2f%%"<br class="calibre2"/>                      % (step + 1, 100. * train_accuracy, 100. * test_accuracy))<br class="calibre2"/>                #x.append(step)<br class="calibre2"/>                test_acc.append(100. * test_accuracy)<br class="calibre2"/>                train_acc.append(100. * train_accuracy)<br class="calibre2"/>        end_time = time.time()<br class="calibre2"/>        diff = end_time -start_time<br class="calibre2"/>        time_taken_summary.append((sgd_step,diff))<br class="calibre2"/>        t = [np.array(test_acc)]<br class="calibre2"/>        t.append(train_acc)<br class="calibre2"/>        train_accs.append(train_acc)</pre>
<p class="calibre4">Output of the preceding code will be an array with training and test accuracy for each SGD step value. In our example, we called the function <kbd class="calibre18">sgd_steps</kbd> for an SGD step value of <kbd class="calibre18">[0.01, 0.02, 0.03]</kbd>:</p>
<pre class="calibre26">def main():<br class="calibre2"/>    sgd_steps = [0.01,0.02,0.03]<br class="calibre2"/>    run(128,0.1,sgd_steps)<br class="calibre2"/><br class="calibre2"/>if __name__ == '__main__':<br class="calibre2"/>    main()</pre>
<p class="calibre4">This is the plot showing how training accuracy changes with <kbd class="calibre18">sgd_steps</kbd>. For an SGD value of <kbd class="calibre18">0.03</kbd>, it reaches a higher accuracy faster as the step size is larger.</p>
<div class="mce-root"><img src="Images/a3106868-376b-44e2-bbe3-c544ef83747d.png" width="1129" height="939" class="calibre69"/></div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Implementing feedforward networks with images</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">Now we will look at how to use feedforward networks to classify images. We will be using <kbd class="calibre18">notMNIST</kbd> data. The dataset consists of images for nine letters, A to I.</p>
<p class="calibre4">NotMNIST dataset is similar to MNIST dataset but focuses on Alphabets instead of numbers (<a href="http://yaroslavvb.blogspot.in/2011/09/notmnist-dataset.html" target="_blank" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2">http://yaroslavvb.blogspot.in/2011/09/notmnist-dataset.html</a>)</p>
<p class="calibre4">We have reduced the original dataset to a smaller version for the training so that you can easily get started. Download the ZIP files and extract them to the folder where the dataset is contained, <a href="https://1drv.ms/f/s!Av6fk5nQi2j-kniw-8GtP8sdWejs" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2">https://1drv.ms/f/s!Av6fk5nQi2j-kniw-8GtP8sdWejs</a>.</p>
<div class="packt_infobox">The pickle module of python implements an algorithm for serializing and de-serializing a Python object structure. <strong class="calibre3">Pickling</strong> is the process in which a Python object hierarchy is converted into a byte stream, unpickling is the inverse operation, where a byte stream is converted back into an object hierarchy. Pickling (and unpickling) is alternatively known as <strong class="calibre3">serialization</strong>, <strong class="calibre3">marshaling</strong>, [1] or <strong class="calibre3">flattening</strong>.</div>
<p class="calibre4">First, we load the images in <kbd class="calibre18">numpy.ndarray</kbd> from the following list of folders using the <kbd class="calibre18">maybe_pickle(..)</kbd> method:</p>
<pre class="calibre26">test_folders = ['./notMNIST_small/A', './notMNIST_small/B', './notMNIST_small/C', './notMNIST_small/D',<br class="calibre2"/>'./notMNIST_small/E', './notMNIST_small/F', './notMNIST_small/G', './notMNIST_small/H', <br class="calibre2"/>'./notMNIST_small/I', './notMNIST_small/J']<br class="calibre2"/>train_folders = ['./notMNIST_large_v2/A', './notMNIST_large_v2/B', './notMNIST_large_v2/C', './notMNIST_large_v2/D',<br class="calibre2"/>'./notMNIST_large_v2/E', './notMNIST_large_v2/F', './notMNIST_large_v2/G', './notMNIST_large_v2/H',<br class="calibre2"/>'./notMNIST_large_v2/I', './notMNIST_large_v2/J']<br class="calibre2"/>maybe_pickle(data_folders, min_num_images_per_class, force=False):</pre>
<p class="calibre4">The <kbd class="calibre18">maybe_pickle</kbd> uses the <kbd class="calibre18">load_letter</kbd> method to load the image to <kbd class="calibre18">ndarray</kbd> from a single folder:</p>
<pre class="calibre26">def load_letter(folder, min_num_images):<br class="calibre2"/>  image_files = os.listdir(folder)<br class="calibre2"/>  dataset = np.ndarray(shape=(len(image_files), image_size, image_size),<br class="calibre2"/>                         dtype=np.float32)<br class="calibre2"/>  num_images = 0<br class="calibre2"/>  for image in image_files:<br class="calibre2"/>    image_file = os.path.join(folder, image)<br class="calibre2"/>    try:<br class="calibre2"/>      image_data = (ndimage.imread(image_file).astype(float) - <br class="calibre2"/>                    pixel_depth / 2) / pixel_depth<br class="calibre2"/>      if image_data.shape != (image_size, image_size):<br class="calibre2"/>        raise Exception('Unexpected image shape: %s' % str(image_data.shape))<br class="calibre2"/>      dataset[num_images, :, :] = image_data<br class="calibre2"/>      num_images = num_images + 1<br class="calibre2"/>    except IOError as e:<br class="calibre2"/>      print('Could not read:', image_file, ':', e, '- it\'s ok, skipping.')<br class="calibre2"/>    <br class="calibre2"/>  dataset = dataset[0:num_images, :, :]<br class="calibre2"/>  if num_images &lt; min_num_images:<br class="calibre2"/>    raise Exception('Fewer images than expected: %d &lt; %d' %<br class="calibre2"/>                    (num_images, min_num_images))<br class="calibre2"/>    <br class="calibre2"/>  print('Dataset tensor:', dataset.shape)<br class="calibre2"/>  print('Mean:', np.mean(dataset))<br class="calibre2"/>  print('Standard deviation:', np.std(dataset))<br class="calibre2"/>  return dataset</pre>
<p class="calibre4">The <kbd class="calibre18">maybe_pickle</kbd> <span class="calibre14">method</span> is called for two sets of folders, <kbd class="calibre18">train_folders</kbd> and <kbd class="calibre18">test_folders</kbd>:</p>
<pre class="calibre26">train_datasets = maybe_pickle(train_folders, 100)<br class="calibre2"/>test_datasets = maybe_pickle(test_folders, 50)</pre>
<p class="calibre4">Output is similar to the following screenshot.</p>
<p class="calibre4">The first screenshot shows the <kbd class="calibre18">dataset_names</kbd> list variable value:</p>
<div class="mce-root"><img src="Images/fe21686e-bc89-45c9-b244-e2bfd65e636f.png" width="618" height="456" class="calibre70"/></div>
<p class="calibre4">The following screenshot shows the value of the <kbd class="calibre18">dataset_names</kbd> <span class="calibre14">variable</span> for the <kbd class="calibre18">notMNIST_small</kbd> dataset:</p>
<div class="mce-root"><img src="Images/d87bb91f-bc8b-4f5c-865c-ce0aa3ab5400.png" width="637" height="531" class="calibre71"/></div>
<p class="calibre4">Next, <kbd class="calibre18">merge_datasets</kbd> is called, where pickle files from each character are combined into the following <kbd class="calibre18">ndarray</kbd>:</p>
<ul class="calibre20">
<li class="calibre21"><kbd class="calibre18">valid_dataset</kbd></li>
<li class="calibre21"><kbd class="calibre18">valid_labels</kbd></li>
<li class="calibre21"><kbd class="calibre18">train_dataset</kbd></li>
<li class="calibre21"><kbd class="calibre18">train_labels</kbd></li>
</ul>
<pre class="calibre26">train_size = 1000<br class="calibre2"/>valid_size = 500<br class="calibre2"/>test_size = 500<br class="calibre2"/><br class="calibre2"/>valid_dataset, valid_labels, train_dataset, train_labels = merge_datasets(<br class="calibre2"/>    train_datasets, train_size, valid_size)<br class="calibre2"/>  _, _, test_dataset, test_labels = merge_datasets(test_datasets, test_size)</pre>
<p class="calibre4">Output of the preceding code is listed as follows:</p>
<pre class="calibre26">Training dataset and labels shape: (1000, 28, 28) (1000,)<br class="calibre2"/>Validation dataset and labels shape: (500, 28, 28) (500,)<br class="calibre2"/>Testing dataset and labels shape: (500, 28, 28) (500,)</pre>
<p class="calibre4">Finally, the <kbd class="calibre18">noMNIST.pickle</kbd> file is created by storing each of these <kbd class="calibre18">ndarray</kbd> in key-value pairs where the keys are <kbd class="calibre18">train_dataset</kbd>, <kbd class="calibre18">train_labels</kbd>, <kbd class="calibre18">valid_dataset</kbd>, <kbd class="calibre18">valid_labels</kbd>, <kbd class="calibre18">test_dataset</kbd>, and <kbd class="calibre18">test_labels</kbd>, and values are the respective <kbd class="calibre18">ndarray</kbd>, as shown in the following code:</p>
<pre class="calibre26"><br class="calibre2"/>  try:<br class="calibre2"/>    f = open(pickle_file, 'wb')<br class="calibre2"/>    save = {<br class="calibre2"/>      'train_dataset': train_dataset,<br class="calibre2"/>      'train_labels': train_labels,<br class="calibre2"/>      'valid_dataset': valid_dataset,<br class="calibre2"/>      'valid_labels': valid_labels,<br class="calibre2"/>      'test_dataset': test_dataset,<br class="calibre2"/>      'test_labels': test_labels,<br class="calibre2"/>    }<br class="calibre2"/>    pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)<br class="calibre2"/>    f.close()<br class="calibre2"/>  except Exception as e:<br class="calibre2"/>    print('Unable to save data to', pickle_file, ':', e)<br class="calibre2"/>    raise</pre>
<p class="calibre4">This is the full code for generating the <kbd class="calibre18">notMNIST.pickle</kbd> file:</p>
<pre class="calibre26">from __future__ import print_function<br class="calibre2"/>import numpy as np<br class="calibre2"/>import os<br class="calibre2"/>from scipy import ndimage<br class="calibre2"/>from six.moves import cPickle as pickle<br class="calibre2"/><br class="calibre2"/>data_root = '.' # Change me to store data elsewhere<br class="calibre2"/><br class="calibre2"/>num_classes = 10<br class="calibre2"/>np.random.seed(133)<br class="calibre2"/><br class="calibre2"/>test_folders = ['./notMNIST_small/A', './notMNIST_small/B', './notMNIST_small/C', './notMNIST_small/D',<br class="calibre2"/>                './notMNIST_small/E', './notMNIST_small/F', './notMNIST_small/G', './notMNIST_small/H', <br class="calibre2"/>                './notMNIST_small/I', './notMNIST_small/J']<br class="calibre2"/>train_folders = ['./notMNIST_large_v2/A', './notMNIST_large_v2/B', './notMNIST_large_v2/C', './notMNIST_large_v2/D',<br class="calibre2"/>                 './notMNIST_large_v2/E', './notMNIST_large_v2/F', './notMNIST_large_v2/G', './notMNIST_large_v2/H',<br class="calibre2"/>                 './notMNIST_large_v2/I', './notMNIST_large_v2/J']<br class="calibre2"/><br class="calibre2"/>image_size = 28  # Pixel width and height.<br class="calibre2"/>pixel_depth = 255.0<br class="calibre2"/><br class="calibre2"/>def load_letter(folder, min_num_images):<br class="calibre2"/>  image_files = os.listdir(folder)<br class="calibre2"/>  dataset = np.ndarray(shape=(len(image_files), image_size, image_size),<br class="calibre2"/>                         dtype=np.float32)<br class="calibre2"/>  num_images = 0<br class="calibre2"/>  for image in image_files:<br class="calibre2"/>    image_file = os.path.join(folder, image)<br class="calibre2"/>    try:<br class="calibre2"/>      image_data = (ndimage.imread(image_file).astype(float) - <br class="calibre2"/>                    pixel_depth / 2) / pixel_depth<br class="calibre2"/>      if image_data.shape != (image_size, image_size):<br class="calibre2"/>        raise Exception('Unexpected image shape: %s' % str(image_data.shape))<br class="calibre2"/>      dataset[num_images, :, :] = image_data<br class="calibre2"/>      num_images = num_images + 1<br class="calibre2"/>    except IOError as e:<br class="calibre2"/>      print('Could not read:', image_file, ':', e, '- it\'s ok, skipping.')<br class="calibre2"/>    <br class="calibre2"/>  dataset = dataset[0:num_images, :, :]<br class="calibre2"/>  if num_images &lt; min_num_images:<br class="calibre2"/>    raise Exception('Fewer images than expected: %d &lt; %d' %<br class="calibre2"/>                    (num_images, min_num_images))<br class="calibre2"/>    <br class="calibre2"/>  print('Dataset tensor:', dataset.shape)<br class="calibre2"/>  print('Mean:', np.mean(dataset))<br class="calibre2"/>  print('Standard deviation:', np.std(dataset))<br class="calibre2"/>  return dataset<br class="calibre2"/>        <br class="calibre2"/>def maybe_pickle(data_folders, min_num_images_per_class, force=False):<br class="calibre2"/>  dataset_names = []<br class="calibre2"/>  for folder in data_folders:<br class="calibre2"/>    set_filename = folder + '.pickle'<br class="calibre2"/>    dataset_names.append(set_filename)<br class="calibre2"/>    if os.path.exists(set_filename) and not force:<br class="calibre2"/>      print('%s already present - Skipping pickling.' % set_filename)<br class="calibre2"/>    else:<br class="calibre2"/>      print('Pickling %s.' % set_filename)<br class="calibre2"/>      dataset = load_letter(folder, min_num_images_per_class)<br class="calibre2"/>      try:<br class="calibre2"/>        with open(set_filename, 'wb') as f:<br class="calibre2"/>          #pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)<br class="calibre2"/>          print(pickle.HIGHEST_PROTOCOL)<br class="calibre2"/>          pickle.dump(dataset, f, 2)<br class="calibre2"/>      except Exception as e:<br class="calibre2"/>        print('Unable to save data to', set_filename, ':', e)<br class="calibre2"/>  <br class="calibre2"/>  return dataset_names<br class="calibre2"/><br class="calibre2"/>def make_arrays(nb_rows, img_size):<br class="calibre2"/>  if nb_rows:<br class="calibre2"/>    dataset = np.ndarray((nb_rows, img_size, img_size), dtype=np.float32)<br class="calibre2"/>    labels = np.ndarray(nb_rows, dtype=np.int32)<br class="calibre2"/>  else:<br class="calibre2"/>    dataset, labels = None, None</pre>
<p class="calibre4">Let's look at how the pickle file created earlier loads data and runs a network with one hidden layer.</p>
<p class="calibre4">First, we will load the training, testing, and validation datasets (<kbd class="calibre18">ndarray</kbd>) from the <kbd class="calibre18">notMNIST.pickle</kbd> file:</p>
<pre class="calibre26">with open(pickle_file, 'rb') as f:<br class="calibre2"/> save = pickle.load(f)<br class="calibre2"/> training_dataset = save['train_dataset']<br class="calibre2"/> training_labels = save['train_labels']<br class="calibre2"/> validation_dataset = save['valid_dataset']<br class="calibre2"/> validation_labels = save['valid_labels']<br class="calibre2"/> test_dataset = save['test_dataset']<br class="calibre2"/> test_labels = save['test_labels']<br class="calibre2"/><br class="calibre2"/>print 'Training set', training_dataset.shape, training_labels.shape<br class="calibre2"/>print 'Validation set', validation_dataset.shape, validation_labels.shape<br class="calibre2"/>print 'Test set', test_dataset.shape, test_labels.shape</pre>
<p class="calibre4">You will see an output similar to the following listing:</p>
<pre class="calibre26">Training set (1000, 28, 28) (1000,)<br class="calibre2"/>Validation set (500, 28, 28) (500,)<br class="calibre2"/>Test set (500, 28, 28) (500,)</pre>
<p class="calibre4">Next, we <kbd class="calibre18">reformat</kbd> the <kbd class="calibre18">dataset</kbd> into a two-dimensional array so that data is easier to process with TensorFlow:</p>
<pre class="calibre26">def reformat(dataset, labels):<br class="calibre2"/> dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)<br class="calibre2"/> # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]<br class="calibre2"/> labels = (np.arange(num_of_labels) == labels[:, None]).astype(np.float32)<br class="calibre2"/> return dataset, labels<br class="calibre2"/>train_dataset, train_labels = reformat(training_dataset, training_labels)<br class="calibre2"/> valid_dataset, valid_labels = reformat(validation_dataset, validation_labels)<br class="calibre2"/> test_dataset, test_labels = reformat(test_dataset, test_labels)<br class="calibre2"/><br class="calibre2"/> print 'Training dataset shape', train_dataset.shape, train_labels.shape<br class="calibre2"/> print 'Validation dataset shape', valid_dataset.shape, valid_labels.shape<br class="calibre2"/> print 'Test dataset shape', test_dataset.shape, test_labels.shape</pre>
<p class="calibre4">You will see the following output:</p>
<pre class="calibre26">Training dataset shape (1000, 784) (1000, 10)<br class="calibre2"/>Validation dataset shape (500, 784) (500, 10)<br class="calibre2"/>Test dataset shape (500, 784) (500, 10)</pre>
<p class="calibre4">Next, we define the graph that will return the content to which all the variables will be loaded.</p>
<p class="calibre4">The size of each weight and bias is listed here, where <kbd class="calibre18">image_size</kbd> = 28 and <kbd class="calibre18">no_of_neurons</kbd> = 1024.</p>
<div class="packt_infobox"><span class="calibre5">Number of neurons in the hidden layer should be optimal. Too few neurons leads to lower accuracy, while too high a number leads to overfitting.</span></div>
<table class="calibre72">
<tbody class="calibre10">
<tr class="calibre11">
<td class="calibre12">
<p class="calibre13"><strong class="calibre7">Layer in the neural network</strong></p>
</td>
<td class="calibre12">
<p class="calibre13"><strong class="calibre7">Weight</strong></p>
</td>
<td class="calibre12">
<p class="calibre13"><strong class="calibre7">Bias</strong></p>
</td>
</tr>
<tr class="calibre15">
<td class="calibre12">
<p class="calibre13">1</p>
</td>
<td class="calibre12">
<p class="calibre13">row = 28 x 28 = 784</p>
<p class="cdpalignleft1">columns = 1024</p>
</td>
<td class="calibre12">
<p class="cdpalignright">1024</p>
</td>
</tr>
<tr class="calibre73">
<td class="calibre12">
<p class="calibre13">2</p>
</td>
<td class="calibre12">
<p class="calibre13">row = 1024</p>
<p class="calibre13">columns = 10</p>
</td>
<td class="calibre12">
<p class="cdpalignright">10</p>
</td>
</tr>
</tbody>
</table>
<p class="calibre4">We will initialize the TensorFlow graph and initialize placeholder variables from training, validation, and test the datasets and labels.</p>
<p class="calibre4">We will also define weights and biases for two layers:</p>
<pre class="calibre26">graph = tf.Graph()<br class="calibre2"/> no_of_neurons = 1024<br class="calibre2"/> with graph.as_default():<br class="calibre2"/>   # Placeholder that will be fed<br class="calibre2"/>   # at run time with a training minibatch in the session<br class="calibre2"/>   tf_train_dataset = tf.placeholder(tf.float32,<br class="calibre2"/>     shape=(batch_size, image_size * image_size))<br class="calibre2"/>   tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_of_labels))<br class="calibre2"/>   tf_valid_dataset = tf.constant(valid_dataset)<br class="calibre2"/>   tf_test_dataset = tf.constant(test_dataset)<br class="calibre2"/><br class="calibre2"/>   # Variables.<br class="calibre2"/>   w1 = tf.Variable(tf.truncated_normal([image_size * image_size, no_of_neurons]))<br class="calibre2"/>   b1 = tf.Variable(tf.zeros([no_of_neurons]))<br class="calibre2"/><br class="calibre2"/>   w2 = tf.Variable(<br class="calibre2"/>   tf.truncated_normal([no_of_neurons, num_of_labels]))<br class="calibre2"/>   b2 = tf.Variable(tf.zeros([num_of_labels]))</pre>
<p class="calibre4">Next, we define the hidden layer tensor and the calculated logit:</p>
<pre class="calibre26">hidden1 = tf.nn.relu(tf.matmul(tf_train_dataset, w1) + b1)<br class="calibre2"/>logits = tf.matmul(hidden1, w2) + b2</pre>
<p class="calibre4">Loss function for our network is going to be based on the <kbd class="calibre18">softmax</kbd> function applied over cross entropy with <kbd class="calibre18">logits</kbd>:</p>
<pre class="calibre26">loss = tf.reduce_mean(<br class="calibre2"/>     tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels))<br class="calibre2"/># Training computation.<br class="calibre2"/><br class="calibre2"/>loss = tf.reduce_mean(<br class="calibre2"/>     tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels))<br class="calibre2"/><br class="calibre2"/>   # Optimizer.<br class="calibre2"/>   optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)</pre>
<p class="calibre4">Next, we calculate the <kbd class="calibre18">logits</kbd> (predicted values); note that we are using <kbd class="calibre18">softmax</kbd> to normalize the <kbd class="calibre18">logits</kbd>:</p>
<pre class="calibre26">train_prediction = tf.nn.softmax(logits)</pre>
<p class="calibre4">Calculate the test and validation predictions. Notice the activation function <kbd class="calibre18">RELU</kbd> being used here to calculate <kbd class="calibre18">w1</kbd> and <kbd class="calibre18">b1</kbd>:</p>
<pre class="calibre26">tf.nn.relu(tf.matmul(tf_valid_dataset, w1) + b1)<br class="calibre2"/> valid_prediction = tf.nn.softmax(<br class="calibre2"/>     tf.matmul( tf.nn.relu(tf.matmul(tf_valid_dataset, w1) + b1), <br class="calibre2"/>                w2<br class="calibre2"/>              ) + b2)<br class="calibre2"/> test_prediction = tf.nn.softmax(<br class="calibre2"/>     tf.matmul(tf.nn.relu(tf.matmul(tf_test_dataset, w1) + b1), w2) + b2)</pre>
<p class="calibre4">Now we will create a TensorFlow session and pass the datasets loaded through the neural network created:</p>
<pre class="calibre26">with tf.Session(graph=graph) as session:<br class="calibre2"/>  tf.initialize_all_variables().run()<br class="calibre2"/>  print("Initialized")<br class="calibre2"/>  for step in xrange(num_steps):<br class="calibre2"/>   offset = (step * batch_size) % (train_labels.shape[0] - batch_size)<br class="calibre2"/>   # Generate a minibatch.<br class="calibre2"/>   batch_data = train_dataset[offset:(offset + batch_size), :]<br class="calibre2"/>   batch_labels = train_labels[offset:(offset + batch_size), :]<br class="calibre2"/>   feed_dict = {tf_train_dataset: batch_data, tf_train_labels: batch_labels}<br class="calibre2"/>   _, l, predictions = session.run(<br class="calibre2"/>     [optimizer, loss, train_prediction], feed_dict=feed_dict)<br class="calibre2"/>   minibatch_accuracy = accuracy(predictions, batch_labels)<br class="calibre2"/>   validation_accuracy = accuracy(<br class="calibre2"/>    valid_prediction.eval(), valid_labels)<br class="calibre2"/>   if (step % 10 == 0):<br class="calibre2"/>     print("Minibatch loss at step", step, ":", l)<br class="calibre2"/>     print("Minibatch accuracy: %.1f%%" % accuracy(predictions, batch_labels))<br class="calibre2"/>     print("Validation accuracy: %.1f%%" % validation_accuracy)<br class="calibre2"/>minibatch_acc.append( minibatch_accuracy)<br class="calibre2"/>validation_acc.append( validation_accuracy)<br class="calibre2"/>t = [np.array(minibatch_acc)]<br class="calibre2"/>t.append(validation_acc)</pre>
<div class="packt_infobox">The full code can be found at <a href="https://github.com/rajdeepd/neuralnetwork-programming/blob/ed1/ch02/nomnist/singlelayer-neural_network.py" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre31">https://github.com/rajdeepd/neuralnetwork-programming/blob/ed1/ch02/nomnist/singlelayer-neural_network.py</a>.</div>
<p class="calibre4">The complete code can be found at the preceding GitHub link. Notice that we are appending the validation and minibatch accuracy to an array that we will plot:</p>
<pre class="calibre26"> print("Test accuracy: %.1f%%" % accuracy(test_prediction.eval(), test_labels))<br class="calibre2"/> title = "NotMNIST DataSet - Single Hidden Layer - 1024 neurons Activation function: RELU"<br class="calibre2"/> label = ['Minibatch Accuracy', 'Validation Accuracy']<br class="calibre2"/> draw_plot(x, t, title, label)<br class="calibre2"/><br class="calibre2"/></pre>
<p class="calibre4">Let's look at the plot generated by the preceding code:</p>
<div class="mce-root"><img src="Images/80586153-ad97-4844-b423-d2a50c9046e3.png" width="1306" height="926" class="calibre74"/></div>
<p class="calibre4">Minibatch accuracy reaches 100 by iteration number 8- while validation accuracy stops at 60.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Analyzing the effect of activation functions on the feedforward networks accuracy</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">In the previous example, we used <kbd class="calibre18">RELU</kbd> as the activation function. TensorFlow supports multiple activation functions. Let's look at how each of these activation functions affects validation accuracy. We will generate some random values:</p>
<pre class="calibre26">x_val = np.linspace(start=-10., stop=10., num=1000)</pre>
<p class="calibre4">Then generate the activation output:</p>
<pre class="calibre26"> # ReLU activation<br class="calibre2"/>  y_relu = session.run(tf.nn.relu(x_val))<br class="calibre2"/>  # ReLU-6 activation<br class="calibre2"/>  y_relu6 = session.run(tf.nn.relu6(x_val))<br class="calibre2"/>  # Sigmoid activation<br class="calibre2"/>  y_sigmoid = session.run(tf.nn.sigmoid(x_val))<br class="calibre2"/>  # Hyper Tangent activation<br class="calibre2"/>  y_tanh = session.run(tf.nn.tanh(x_val))<br class="calibre2"/>  # Softsign activation<br class="calibre2"/>  y_softsign = session.run(tf.nn.softsign(x_val))<br class="calibre2"/><br class="calibre2"/>  # Softplus activation<br class="calibre2"/>  y_softplus = session.run(tf.nn.softplus(x_val))<br class="calibre2"/>  # Exponential linear activation<br class="calibre2"/>  y_elu = session.run(tf.nn.elu(x_val))</pre>
<p class="calibre4">Plot the activation against <kbd class="calibre18">x_val</kbd>:</p>
<pre class="calibre26">plt.plot(x_val, y_softplus, 'r--', label='Softplus', linewidth=2)<br class="calibre2"/>plt.plot(x_val, y_relu, 'b:', label='RELU', linewidth=2)<br class="calibre2"/>plt.plot(x_val, y_relu6, 'g-.', label='RELU6', linewidth=2)<br class="calibre2"/>plt.plot(x_val, y_elu, 'k-', label='ELU', linewidth=1)<br class="calibre2"/>plt.ylim([-1.5,7])<br class="calibre2"/>plt.legend(loc='top left')<br class="calibre2"/>plt.title('Activation functions', y=1.05)<br class="calibre2"/>plt.show()<br class="calibre2"/>plt.plot(x_val, y_sigmoid, 'r--', label='Sigmoid', linewidth=2)<br class="calibre2"/>plt.plot(x_val, y_tanh, 'b:', label='tanh', linewidth=2)<br class="calibre2"/>plt.plot(x_val, y_softsign, 'g-.', label='Softsign', linewidth=2)<br class="calibre2"/>plt.ylim([-1.5,1.5])<br class="calibre2"/>plt.legend(loc='top left')<br class="calibre2"/>plt.title('Activation functions with Vanishing Gradient', y=1.05)<br class="calibre2"/>plt.show()</pre>
<p class="calibre4">Plots are shown in the following screenshot:</p>
<div class="mce-root"><img src="Images/331e4f58-6df4-42eb-9a67-6618c6f7a212.png" width="1115" height="923" class="calibre75"/></div>
<p class="calibre4">The plot comparing <strong class="calibre7">Activation functions with Vanishing Gradient</strong> is as follows:</p>
<div class="mce-root"><img src="Images/4ed73c91-5b7d-42ac-b254-e7b90f3765c2.png" width="1138" height="932" class="calibre76"/></div>
<p class="calibre4">Now let's look at the activation function and how it affects validation accuracy for NotMNIST data.</p>
<p class="calibre4">We have modified the previous example so that we can pass the activation function as a parameter in <kbd class="calibre18">main()</kbd>:</p>
<pre class="calibre26">RELU = 'RELU'<br class="calibre2"/>RELU6 = 'RELU6'<br class="calibre2"/>CRELU = 'CRELU'<br class="calibre2"/>SIGMOID = 'SIGMOID'<br class="calibre2"/>ELU = 'ELU'<br class="calibre2"/>SOFTPLUS = 'SOFTPLUS'<br class="calibre2"/>def activation(name, features):<br class="calibre2"/>  if name == RELU:<br class="calibre2"/>    return tf.nn.relu(features)<br class="calibre2"/>  if name == RELU6:<br class="calibre2"/>    return tf.nn.relu6(features)<br class="calibre2"/>  if name == SIGMOID:<br class="calibre2"/>    return tf.nn.sigmoid(features)<br class="calibre2"/>  if name == CRELU:<br class="calibre2"/>    return tf.nn.crelu(features)<br class="calibre2"/>  if name == ELU:<br class="calibre2"/>    return tf.nn.elu(features)<br class="calibre2"/>  if name == SOFTPLUS:<br class="calibre2"/>    return tf.nn.softplus(features)</pre>
<p class="calibre4">The <kbd class="calibre18">run()</kbd> function definition encompasses the login that we defined earlier:</p>
<pre class="calibre26">batch_size = 128<br class="calibre2"/>#activations = [RELU, RELU6, SIGMOID, CRELU, ELU, SOFTPLUS]<br class="calibre2"/>activations = [RELU, RELU6, SIGMOID, ELU, SOFTPLUS]<br class="calibre2"/>plot_loss = False<br class="calibre2"/>def run(name):<br class="calibre2"/> print(name)<br class="calibre2"/> with open(pickle_file, 'rb') as f:<br class="calibre2"/>   save = pickle.load(f)<br class="calibre2"/>   training_dataset = save['train_dataset']<br class="calibre2"/>   training_labels = save['train_labels']<br class="calibre2"/>   validation_dataset = save['valid_dataset']<br class="calibre2"/>   validation_labels = save['valid_labels']<br class="calibre2"/>   test_dataset = save['test_dataset']<br class="calibre2"/>   test_labels = save['test_labels'] <br class="calibre2"/> train_dataset, train_labels = reformat(training_dataset, training_labels)<br class="calibre2"/> valid_dataset, valid_labels = reformat(validation_dataset, <br class="calibre2"/>    validation_labels)<br class="calibre2"/> test_dataset, test_labels = reformat(test_dataset, test_labels)<br class="calibre2"/>   <br class="calibre2"/> graph = tf.Graph()<br class="calibre2"/> no_of_neurons = 1024<br class="calibre2"/> with graph.as_default():<br class="calibre2"/><br class="calibre2"/> tf_train_dataset = tf.placeholder(tf.float32,<br class="calibre2"/> shape=(batch_size, image_size * image_size))<br class="calibre2"/> tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, <br class="calibre2"/>   num_of_labels))<br class="calibre2"/> tf_valid_dataset = tf.constant(valid_dataset)<br class="calibre2"/> tf_test_dataset = tf.constant(test_dataset)<br class="calibre2"/> # Define Variables.<br class="calibre2"/> # Training computation...<br class="calibre2"/> # Optimizer ..<br class="calibre2"/> # Predictions for the training, validation, and test data.<br class="calibre2"/> train_prediction = tf.nn.softmax(logits)<br class="calibre2"/> valid_prediction = tf.nn.softmax(<br class="calibre2"/> tf.matmul(activation(name,tf.matmul(tf_valid_dataset, w1) + b1), w2) + b2)<br class="calibre2"/> test_prediction = tf.nn.softmax(<br class="calibre2"/> tf.matmul(activation(name,tf.matmul(tf_test_dataset, w1) + b1), w2) + b2)<br class="calibre2"/><br class="calibre2"/> num_steps = 101<br class="calibre2"/> minibatch_acc = []<br class="calibre2"/> validation_acc = []<br class="calibre2"/> loss_array = []<br class="calibre2"/> with tf.Session(graph=graph) as session:<br class="calibre2"/>   tf.initialize_all_variables().run()<br class="calibre2"/>   print("Initialized")<br class="calibre2"/>   for step in xrange(num_steps):<br class="calibre2"/>     offset = (step * batch_size) % (train_labels.shape[0] - batch_size)<br class="calibre2"/>     # Generate a minibatch.<br class="calibre2"/>     batch_data = train_dataset[offset:(offset + batch_size), :]<br class="calibre2"/>     batch_labels = train_labels[offset:(offset + batch_size), :]<br class="calibre2"/>     feed_dict = {tf_train_dataset: batch_data, tf_train_labels: batch_labels}<br class="calibre2"/> <br class="calibre2"/>     _, l, predictions = session.run(<br class="calibre2"/>      [optimizer, loss, train_prediction], feed_dict=feed_dict)<br class="calibre2"/>     minibatch_accuracy = accuracy(predictions, batch_labels)<br class="calibre2"/>     validation_accuracy = accuracy(<br class="calibre2"/>      valid_prediction.eval(), valid_labels)<br class="calibre2"/>     if (step % 10 == 0):<br class="calibre2"/>       print("Minibatch loss at step", step, ":", l)<br class="calibre2"/>       print("Minibatch accuracy: %.1f%%" % accuracy(predictions,<br class="calibre2"/>         batch_labels))<br class="calibre2"/>       print("Validation accuracy: %.1f%%" % accuracy(<br class="calibre2"/>     valid_prediction.eval(), valid_labels))<br class="calibre2"/>     minibatch_acc.append(minibatch_accuracy)<br class="calibre2"/>     validation_acc.append(validation_accuracy)<br class="calibre2"/>     loss_array.append(l)<br class="calibre2"/>     print("Test accuracy: %.1f%%" % accuracy(test_prediction.eval(),<br class="calibre2"/>       test_labels))<br class="calibre2"/>     return validation_acc, loss_array</pre>
<p class="calibre4">Plots from the preceding list are shown in the following screenshot:</p>
<div class="mce-root"><img src="Images/64631b8e-2376-4387-bb86-1321549ddfc8.png" class="calibre77"/></div>
<div class="mce-root3">Validation accuracy for various activation functions</div>
<p class="calibre4">As can be seen in the preceding graphs, <span class="calibre14">RELU</span> and <span class="calibre14">RELU6</span> provide maximum validation accuracy, which is close to 60 percent. Now let's look at how training loss behaves as we progress through the steps for various activations:</p>
<div class="mce-root"><img src="Images/214cb862-ba33-41ed-adab-3925dd4ac740.png" width="1146" height="932" class="calibre78"/></div>
<div class="mce-root3">Training loss for various activations as a function of steps</div>
<p class="cdpalignleft1">Training loss converges to zero for most of the activation functions, though <span class="calibre14">RELU</span> is the least effective in the short-term.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">In this chapter, we built our first neural network, which was feedforward only, and used it for classification with the Iris dataset and later the NotMNIST dataset. You learned how various activation functions like affect the validation accuracy of the prediction.</p>
<p class="calibre4">In the next chapter, we will explore a convoluted neural network, which is more advanced and effective for an image dataset.</p>
<p class="calibre4"/>


            </article>

            
        </section>
    </div>



  </body></html>