["```py\n    import numpy as np\n    np.random.seed(0)\n    A = np.array([\n        [1, 1, 1, 1],\n        [1, 1, 0, 0],\n        [1, 0, 1, 1],\n        [1, 0, 1, 1]\n    ])\n    array([[1, 1, 1, 1],\n           [1, 1, 0, 0],\n           [1, 0, 1, 1],\n           [1, 0, 1, 1]])\n    ```", "```py\n    X = np.random.uniform(-1, 1, (4, 4))\n    array([[ 0.0976270,  0.4303787,  0.2055267,  0.0897663],\n           [-0.1526904,  0.2917882, -0.1248255,  0.783546 ],\n           [ 0.9273255, -0.2331169,  0.5834500,  0.0577898],\n           [ 0.1360891,  0.8511932, -0.8579278, -0.8257414]])\n    ```", "```py\nW = np.random.uniform(-1, 1, (2, 4))\narray([[-0.9595632,  0.6652396,  0.556313 ,  0.740024 ],\n       [ 0.9572366,  0.5983171, -0.0770412,  0.5610583]])\n```", "```py\n    W_att = np.random.uniform(-1, 1, (1, 4))\n    array([[-0.7634511,  0.2798420, -0.7132934,  0.8893378]])\n    ```", "```py\n    connections = np.where(A > 0)\n    (array([0, 0, 0, 0, 1, 1, 2, 2, 2, 3, 3, 3]),\n     array([0, 1, 2, 3, 0, 1, 0, 2, 3, 0, 2, 3]))\n    ```", "```py\n    np.concatenate([(X @ W.T)[connections[0]], (X @ W.T)[connections[1]]], axis=1)\n    array([[ 0.3733923,  0.3854852,  0.3733923,  0.3854852],\n           [ 0.3733923,  0.3854852,  0.8510261,  0.4776527],\n           [ 0.3733923,  0.3854852, -0.6775590,  0.7356658],\n           [ 0.3733923,  0.3854852, -0.6526841,  0.2423597],\n           [ 0.8510261,  0.4776527,  0.3733923,  0.3854852],\n           [ 0.8510261,  0.4776527,  0.8510261,  0.4776527],\n           [-0.6775590,  0.7356658,  0.3733923,  0.3854852],\n           [-0.6775590,  0.7356658, -0.6775590,  0.7356658],\n           [-0.6775590,  0.7356658, -0.6526841,  0.2423597],\n           [-0.6526841,  0.2423597,  0.3733923,  0.3854852],\n           [-0.6526841,  0.2423597, -0.6775590,  0.7356658],\n           [-0.6526841,  0.2423597, -0.6526841,  0.2423597]])\n    ```", "```py\n    a = W_att @ np.concatenate([(X @ W.T)[connections[0]], (X @ W.T)[connections[1]]], axis=1).T\n    array([[-0.1007035 , -0.35942847,  0.96036209,  0.50390318, -0.43956122, -0.69828618,  0.79964181,  1.8607074 ,  1.40424849,  0.64260322, 1.70366881,  1.2472099 ]])\n    ```", "```py\n    def leaky_relu(x, alpha=0.2):\n        return np.maximum(alpha*x, x)\n    e = leaky_relu(a)\n    array([[-0.0201407 , -0.07188569,  0.96036209,  0.50390318, -0.08791224,  -0.13965724,  0.79964181,  1.8607074 ,  1.40424849,  0.64260322,  1.70366881,  1.2472099 ]])\n    ```", "```py\n    E = np.zeros(A.shape)\n    E[connections[0], connections[1]] = e[0]\n    array([[-0.020140 , -0.0718856,  0.9603620,  0.5039031],\n           [-0.0879122, -0.1396572,  0.       ,  0.       ],\n           [ 0.7996418,  0.       ,  1.8607074,  1.4042484],\n           [ 0.6426032,  0.       ,  1.7036688,  1.247209 ]])\n    ```", "```py\n    def softmax2D(x, axis):\n        e = np.exp(x - np.expand_dims(np.max(x, axis=axis), axis))\n        sum = np.expand_dims(np.sum(e, axis=axis), axis)\n        return e / sum\n    W_alpha = softmax2D(E, 1)\n    array([[0.15862414, 0.15062488, 0.42285965, 0.26789133],\n           [0.24193418, 0.22973368, 0.26416607, 0.26416607],\n           [0.16208847, 0.07285714, 0.46834625, 0.29670814],\n           [0.16010498, 0.08420266, 0.46261506, 0.2930773 ]])\n    ```", "```py\n    H = A.T @ W_alpha @ X @ W.T\n    array([[-1.10126376,  1.99749693],\n           [-0.33950544,  0.97045933],\n           [-1.03570438,  1.53614075],\n           [-1.03570438,  1.53614075]])\n    ```", "```py\n    from torch_geometric.datasets import Planetoid\n    dataset = Planetoid(root=\".\", name=\"Cora\")\n    data = dataset[0]\n    Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n    ```", "```py\n    import torch\n    import torch.nn.functional as F\n    from torch_geometric.nn import GATv2Conv\n    from torch.nn import Linear, Dropout\n    ```", "```py\n    def accuracy(y_pred, y_true):\n        return torch.sum(y_pred == y_true) / len(y_true)\n    ```", "```py\n    class GAT(torch.nn.Module):\n        def __init__(self, dim_in, dim_h, dim_out, heads=8):\n            super().__init__()\n            self.gat1 = GATv2Conv(dim_in, dim_h, heads=heads)\n            self.gat2 = GATv2Conv(dim_h*heads, dim_out, heads=1)\n    ```", "```py\n        def forward(self, x, edge_index):\n            h = F.dropout(x, p=0.6, training=self.training)\n            h = self.gat1(h, edge_index)\n            h = F.elu(h)\n            h = F.dropout(h, p=0.6, training=self.training)\n            h = self.gat2(h, edge_index)\n            return F.log_softmax(h, dim=1)\n    ```", "```py\n        def fit(self, data, epochs):\n            criterion = torch.nn.CrossEntropyLoss()\n            optimizer = torch.optim.Adam(self.parameters(), lr=0.01, weight_decay=0.01)\n            self.train()\n            for epoch in range(epochs+1):\n                optimizer.zero_grad()\n                out = self(data.x, data.edge_index)\n                loss = criterion(out[data.train_mask], data.y[data.train_mask])\n                acc = accuracy(out[data.train_mask].argmax(dim=1), data.y[data.train_mask])\n                loss.backward()\n                optimizer.step()\n                if(epoch % 20 == 0):\n                    val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n                    val_acc = accuracy(out[data.val_mask].argmax(dim=1), data.y[data.val_mask])\n                    print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc: {acc*100:>5.2f}% | Val Loss: {val_loss:.2f} | Val Acc: {val_acc*100:.2f}%')\n    ```", "```py\n        @torch.no_grad()\n        def test(self, data):\n            self.eval()\n            out = self(data.x, data.edge_index)\n            acc = accuracy(out.argmax(dim=1)[data.test_mask], data.y[data.test_mask])\n            return acc\n    ```", "```py\n    gat = GAT(dataset.num_features, 32, dataset.num_classes)\n    gat.fit(data, epochs=100)\n    GAT(\n      (gat1): GATv2Conv(1433, 32, heads=8)\n      (gat2): GATv2Conv(256, 7, heads=1)\n    )\n    Epoch 0 | Train Loss: 1.978 | Train Acc: 12.86% | Val Loss: 1.94 | Val Acc: 13.80%\n    Epoch 20 | Train Loss: 0.238 | Train Acc: 96.43% | Val Loss: 1.04 | Val Acc: 67.40%\n    Epoch 40 | Train Loss: 0.165 | Train Acc: 98.57% | Val Loss: 0.95 | Val Acc: 71.00%\n    Epoch 60 | Train Loss: 0.209 | Train Acc: 96.43% | Val Loss: 0.91 | Val Acc: 71.80%\n    Epoch 80 | Train Loss: 0.172 | Train Acc: 100.00% | Val Loss: 0.93 | Val Acc: 70.80%\n    Epoch 100 | Train Loss: 0.190 | Train Acc: 97.86% | Val Loss: 0.96 | Val Acc: 70.80%\n    ```", "```py\n    acc = gat.test(data)\n    print(f'GAT test accuracy: {acc*100:.2f}%')\n    GAT test accuracy: 81.10%\n    ```", "```py\n    dataset = Planetoid(root=\".\", name=\"CiteSeer\")\n    data = dataset[0]\n    Data(x=[3327, 3703], edge_index=[2, 9104], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327])\n    ```", "```py\n    import matplotlib.pyplot as plt\n    from torch_geometric.utils import degree\n    from collections import Counter\n    degrees = degree(dataset[0].edge_index[0]).numpy()\n    numbers = Counter(degrees)\n    fig, ax = plt.subplots(dpi=300)\n    ax.set_xlabel('Node degree')\n    ax.set_ylabel('Number of nodes')\n    plt.bar(numbers.keys(), numbers.values())\n    ```", "```py\n    gat = GAT(dataset.num_features, 16, dataset.num_classes)\n    gat.fit(data, epochs=100)\n    Epoch   0 | Train Loss: 1.815 | Train Acc: 15.00% | Val Loss: 1.81 | Val Acc: 14.20%\n    Epoch  20 | Train Loss: 0.173 | Train Acc: 99.17% | Val Loss: 1.15 | Val Acc: 63.80%\n    Epoch  40 | Train Loss: 0.113 | Train Acc: 99.17% | Val Loss: 1.12 | Val Acc: 64.80%\n    Epoch  60 | Train Loss: 0.099 | Train Acc: 98.33% | Val Loss: 1.12 | Val Acc: 62.40%\n    Epoch  80 | Train Loss: 0.130 | Train Acc: 98.33% | Val Loss: 1.19 | Val Acc: 62.20%\n    Epoch 100 | Train Loss: 0.158 | Train Acc: 98.33% | Val Loss: 1.10 | Val Acc: 64.60%\n    ```", "```py\n    acc = gat.test(data)\n    print(f'GAT test accuracy: {acc*100:.2f}%')\n    GAT test accuracy: 68.10%\n    ```", "```py\n    out = gat(data.x, data.edge_index)\n    ```", "```py\n    degrees = degree(data.edge_index[0]).numpy()\n    ```", "```py\n    accuracies = []\n    sizes = []\n    ```", "```py\n    for i in range(0, 6):\n        mask = np.where(degrees == i)[0]\n        accuracies.append(accuracy(out.argmax(dim=1)[mask], data.y[mask]))\n        sizes.append(len(mask))\n    ```", "```py\n    mask = np.where(degrees > 5)[0]\n    accuracies.append(accuracy(out.argmax(dim=1)[mask], data.y[mask]))\n    sizes.append(len(mask))\n    ```", "```py\n    fig, ax = plt.subplots(dpi=300)\n    ax.set_xlabel('Node degree')\n    ax.set_ylabel('Accuracy score')\n    plt.bar(['0','1','2','3','4','5','6+'], accuracies)\n    for i in range(0, 7):\n        plt.text(i, accuracies[i], f'{accuracies[i]*100:.2f}%', ha='center', color='black')\n    for i in range(0, 7):\n        plt.text(i, accuracies[i]//2, sizes[i], ha='center', color='white')\n    ```"]