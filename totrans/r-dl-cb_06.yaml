- en: Recurrent Neural Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The current chapter will introduce Recurrent Neural Networks used for the modeling
    of sequential datasets. In this chapter, we will cover:'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up a basic Recurrent Neural Network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up a bidirectional RNN model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up a deep RNN model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up a Long short-term memory based sequence model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up a basic Recurrent Neural Network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Recurrent Neural Networks** (**RNN**) are used for sequential modeling on
    datasets where high autocorrelation exists among observations. For example, predicting
    patient journeys using their historical dataset or predicting the next words in
    given sentences. The main commonality among these problem statements is that input
    length is not constant and there is a sequential dependence. Standard neural network
    and deep learning models are constrained by fixed size input and produce a fixed
    length output. For example, deep learning neural networks built on occupancy datasets
    have six input features and a binomial outcome.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Generative models in machine learning domains are referred to as models that
    have an ability to generate observable data values. For example, training a generative
    model on an images repository to generate new images like it. All generative models
    aim to compute the joint distribution over given datasets, either implicitly or
    explicitly:'
  prefs: []
  type: TYPE_NORMAL
- en: Install and set up TensorFlow.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Load required packages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The section will provide steps to set-up an RNN model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Load the `MNIST` dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Reset the graph and start an interactive session:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Reduce image size to 16 x 16 pixels using the `reduceImage` function from [Chapter
    4](part0166.html#4U9TC1-a0a93989f17f4d6cb68b8cfd331bc5ab), *Data Representation
    using Autoencoders*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Extract labels for the defined `train` and `valid` datasets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Define model parameters such as size of input pixels (`n_input`), step size
    (`step_size`), number of hidden layers (`n.hidden`), and number of outcome classes
    (`n.classes`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Define training parameters such as learning rate (`lr`), number of inputs per
    batch run (`batch`), and number of iterations (`iteration`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Define a function `rnn` that takes in batch input dataset (`x`), weight matrix
    (`weight`), and bias vector (`bias`); and returns a final outcome predicted vector
    of a most basic RNN:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Define `placeholder` variables (`x` and `y`) and initialize weight matrix and
    bias vector:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Generate the predicted labels:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the optimization post initializing a session using the global variables
    initializer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Get the mean accuracy on `valid_data`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Any changes to the structure require model retraining. However, these assumptions
    may not be valid for a lot of sequential datasets, such as text-based classifications
    that may have varying input and output. RNN architecture helps to address the
    issue of variable input length.
  prefs: []
  type: TYPE_NORMAL
- en: 'The standard architecture for RNN with input and output is shown in the following
    figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00135.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Recurrent Neural Network architecture
  prefs: []
  type: TYPE_NORMAL
- en: 'The RNN architecture can be formulated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00129.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Where ![](img/00070.jpeg) is state at time/index *t* and ![](img/00096.jpeg)
    is input at time/index *t*. The matrix *W* represents weights to connect hidden
    nodes and *S* connects input with the hidden layer. The output node at time/index
    *t* is related to state *h[t]* as shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00019.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: In the previous Equations layer, weights remain constant across state and time.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up a bidirectional RNN model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Recurrent Neural Networks focus on capturing the sequential information at time
    *t* by using historical states only. However, bidirectional RNN train the model
    from both directions using two RNN layers with one moving forwards from start
    to end and another RNN layer moving backwards from end to start of sequence.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, the model is dependent on historical and future data. The bidirectional
    RNN models are useful where causal structure exists such as in text and speech.
    The unfolded structure of bidirectional RNN is shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00033.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Unfolded bidirectional RNN architecture
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Install and set up TensorFlow:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Load required packages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Load `MNIST` dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The image from `MNIST` dataset is reduced to 16 x 16 pixels and normalized (Details
    are discussed in the *Setting-up RNN model* section)`.`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section covers the steps to set-up a bidirectional RNN model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Reset the graph and start an interactive session:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Reduce image size to 16 x 16 pixels using the `reduceImage` function from [Chapter
    4](part0166.html#4U9TC1-a0a93989f17f4d6cb68b8cfd331bc5ab), *Data Representation
    using Autoencoders*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Extract labels for the defined `train` and `valid` datasets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Define model parameters such as the size of input pixels (`n_input`), step
    size (`step_size`), number of hidden layers (`n.hidden`), and number of outcome
    classes (`n.classes`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Define training parameters such as learning rate (`lr`), number of inputs per
    batch run (`batch`), and number of iterations (`iteration`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Define a function to perform `bidirectional` Recurrent Neural Network:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Define an `eval_func` function to evaluate mean accuracy using actual (`y`)
    and predicted labels (`yhat`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Define `placeholder` variables (`x` and `y`) and initialize weight matrix and
    bias vector:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Generate the predicted labels:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Define the loss function and optimizer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the optimization post initializing a session using global variables initializer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Get the mean accuracy on valid data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The convergence of cost function for RNN is shown in the following figure:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/00154.gif)'
  prefs: []
  type: TYPE_IMG
- en: Bidirectional Recurrent Neural Network convergence plot on MNIST dataset
  prefs: []
  type: TYPE_NORMAL
- en: Setting up a deep RNN model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The RNN architecture is composed of input, hidden, and output layers. A RNN
    network can be made deep by decomposing the hidden layer into multiple groups
    or by adding computational nodes within RNN architecture such as including model
    computation such as multilayer perceptron for micro learning. The computational
    nodes can be added between input-hidden, hidden-hidden, and hidden-output connection.
    An example of a multilayer deep RNN model is shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00093.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: An example of two-layer Deep Recurrent Neural Network architecture
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The RNN models in TensorFlow can easily be extended to Deep RNN models by using
    `MultiRNNCell`. The previous `rnn` function can be replaced with the `stacked_rnn`function
    to achieve a deep RNN architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Define the number of layers in the deep RNN architecture:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Define a `stacked_rnn` function to perform multi-hidden layers deep RNN:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Setting up a Long short-term memory based sequence model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In sequence learning the objective is to capture short-term and long-term memory.
    The short-term memory is captured very well by standard RNN, however, they are
    not very effective in capturing long-term dependencies as the gradient vanishes
    (or explodes rarely) within an RNN chain over time.
  prefs: []
  type: TYPE_NORMAL
- en: The gradient vanishes when the weights have small values that on multiplication
    vanish over time, whereas in contrast, scenarios where weights have large values
    keep increasing over time and lead to divergence in the learning process. To deal
    with the issue **Long Short Term Memory** (**LSTM**) is proposed.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The RNN models in TensorFlow can easily be extended to LSTM models by using
    `BasicLSTMCell`. The previous `rnn` function can be replaced with the `lstm` function
    to achieve an LSTM architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: For brevity the other parts of the code are not replicated.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The LSTM has a similar structure to RNN, however, the basic cell is very different
    as traditional RNN uses single **multi-layer perceptron** (**MLP**), whereas a
    single cell of LSTM includes four input layers interacting with each other. These
    three layers are:'
  prefs: []
  type: TYPE_NORMAL
- en: forget gate
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: input gate
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: output gate
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *forget gate* in LSTM decides which information to throw away and it depends
    on the last hidden state output *h[t-1]*, *X[t]*, which represents input at time
    *t.*
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00131.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Illustration of forget gate
  prefs: []
  type: TYPE_NORMAL
- en: 'In the earlier figure, *C[t]* represents cell state at time *t*. The input
    data is represented by *X[t]* and the hidden state is represented as *h[t-1]*.
    The earlier layer can be formulated as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00141.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The *input gate* decides update values and decides the candidate values of
    the memory cell and updates the cell state, as shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00098.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Illustration of input gate
  prefs: []
  type: TYPE_NORMAL
- en: 'The input *i[t]* at time *t* is updated as:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/00049.jpeg)![](img/00100.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The expected value of current state ![](img/00136.jpeg) and the output from
    input gate ![](img/00017.jpeg) is used to update the current state ![](img/00024.jpeg)
    at time *t* as:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/00036.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The output gates, as shown in the following figure, compute the output from
    the LSTM cell based on input *X[t]* , previous layer output *h[t-1],* and current
    state *C[t]*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00109.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Illustration of output gate
  prefs: []
  type: TYPE_NORMAL
- en: 'The output based on *output gate* can be computed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00094.jpeg)![](img/00143.jpeg)'
  prefs: []
  type: TYPE_IMG
