<html><head></head><body>
        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">FastText in Python</h1>
                
            
            <article>
                
<p class="calibre2">The use of fastText is specifically to transform words and sentences into efficient vector representations. Although fastText is written in C++, there are community-written Python bindings to train and use the models. Along with that, Python is one of the most popular languages used for NLP, and hence there are many other popular libraries in Python that support fastText models and the training of fastText models. Gensim and Spacy are two popular libraries that make it easy to load these vectors, transform, lemmatize, and perform other NLP tasks efficiently. This chapter will focus on how to use fastText with Python and its popular libraries. This chapter will also focus on showing you some common tasks that the two libraries can do to work with fastText models.</p>
<p class="calibre2">The topics that are covered in this chapter are as follows:</p>
<ul class="calibre10">
<li class="calibre11">FastText official bindings</li>
<li class="calibre11">PyBind</li>
<li class="calibre11">Preprocessed data</li>
<li class="calibre11">Unsupervised learning</li>
<li class="calibre11">Supervised learning</li>
<li class="calibre11">Gensim</li>
<li class="calibre11">Training a fastText model</li>
<li class="calibre11">Machine translation using Gensim</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">FastText official bindings</h1>
                
            
            <article>
                
<p class="calibre2">The steps to install the official bindings for Python are covered in the first chapter. In this section, we will cover how to use the official fastText Python package to train, load, and use the models.</p>
<p class="calibre2">Using the Python fastText library, you will be able to implement all the necessary features that can be done using the command line. Lets take a look at the ways to implement unsupervised and supervised learning using Python fastText.</p>
<div class="packt_infobox">Note: In this chapter, we will be using Python3 and so the code examples will be in that. For users who are using Python2, please take a look at the <em class="calibre20">Appendix</em> for notes on the considerations that you need to bear in mind when using Python2.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">PyBind</h1>
                
            
            <article>
                
<p class="calibre2">Python bindings for fastText are made using the excellent PyBind library. PyBind is a lightweight library meant to expose C++ types in Python and vice versa, making it an excellent choice for creating the Python bindings for fastText. It supports almost all the popular C++ compilers such as Clang, GCC, Visual Studio, and so on. Also, the creators of PyBind claim that the binaries that are generated are smaller.</p>
<div class="packt_infobox">The Python-fastText library uses the fastText C++ API.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Preprocessing data</h1>
                
            
            <article>
                
<p class="calibre2">Although the performance of fastText is quite good on raw text, it's <span class="calibre5">still</span><span class="calibre5"> </span><span class="calibre5">advisable to preprocess the data before running t</span>he unsupervised algorithms or the classifier. Some points to be remembered are as follows:</p>
<ul class="calibre10">
<li class="calibre11">To train fastText, the encoding needs to be in UTF-8. PyBind does an excellent job of converting almost all text to UTF-8 if it's a string in Python3. If you are using Python2, then there is an extra technical detail that you need to take care of: you have to encode all of the string that you are using in UTF-8.</li>
<li class="calibre11">Implementing some basic string processing and normalizing should make the model perform better.</li>
</ul>
<p class="calibre2">The following is a simple function that can be used for normalizing your documents. This function is used in Python fastText notebooks:</p>
<pre class="calibre17"><span>def</span> <span>normalize</span><span>(</span><span>s</span><span>):</span>
    <span>"""</span>
<span>    Given a text, cleans and normalizes it. Feel free to add your own stuff.</span>
<span>    """</span>
    <span>s</span> <span>=</span> <span>s</span><span>.</span><span>lower</span><span>()</span>
    <span># Replace ips</span>
    <span>s</span> <span>=</span> <span>re</span><span>.</span><span>sub</span><span>(</span><span>r</span><span>'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}'</span><span>,</span> <span>' _ip_ '</span><span>,</span> <span>s</span><span>)</span>
    <span># Isolate punctuation</span>
    <span>s</span> <span>=</span> <span>re</span><span>.</span><span>sub</span><span>(</span><span>r</span><span>'([</span><span>\'</span><span>\"\.\(\)\!\?\-</span><span>\\</span><span>\/\,])'</span><span>,</span> <span>r</span><span>' \1 '</span><span>,</span> <span>s</span><span>)</span>
    <span># Remove some special characters</span>
    <span>s</span> <span>=</span> <span>re</span><span>.</span><span>sub</span><span>(</span><span>r</span><span>'([\;\:\|•«\n])'</span><span>,</span> <span>' '</span><span>,</span> <span>s</span><span>)</span>
    <span># Replace numbers and symbols with language</span>
    <span>s</span> <span>=</span> <span>s</span><span>.</span><span>replace</span><span>(</span><span>'&amp;'</span><span>,</span> <span>' and '</span><span>)</span>
    <span>s</span> <span>=</span> <span>s</span><span>.</span><span>replace</span><span>(</span><span>'@'</span><span>,</span> <span>' at '</span><span>)</span>
    <span>s</span> <span>=</span> <span>s</span><span>.</span><span>replace</span><span>(</span><span>'0'</span><span>,</span> <span>' zero '</span><span>)</span>
    <span>s</span> <span>=</span> <span>s</span><span>.</span><span>replace</span><span>(</span><span>'1'</span><span>,</span> <span>' one '</span><span>)</span>
    <span>s</span> <span>=</span> <span>s</span><span>.</span><span>replace</span><span>(</span><span>'2'</span><span>,</span> <span>' two '</span><span>)</span>
    <span>s</span> <span>=</span> <span>s</span><span>.</span><span>replace</span><span>(</span><span>'3'</span><span>,</span> <span>' three '</span><span>)</span>
    <span>s</span> <span>=</span> <span>s</span><span>.</span><span>replace</span><span>(</span><span>'4'</span><span>,</span> <span>' four '</span><span>)</span>
    <span>s</span> <span>=</span> <span>s</span><span>.</span><span>replace</span><span>(</span><span>'5'</span><span>,</span> <span>' five '</span><span>)</span>
    <span>s</span> <span>=</span> <span>s</span><span>.</span><span>replace</span><span>(</span><span>'6'</span><span>,</span> <span>' six '</span><span>)</span>
    <span>s</span> <span>=</span> <span>s</span><span>.</span><span>replace</span><span>(</span><span>'7'</span><span>,</span> <span>' seven '</span><span>)</span>
    <span>s</span> <span>=</span> <span>s</span><span>.</span><span>replace</span><span>(</span><span>'8'</span><span>,</span> <span>' eight '</span><span>)</span>
    <span>s</span> <span>=</span> <span>s</span><span>.</span><span>replace</span><span>(</span><span>'9'</span><span>,</span> <span>' nine '</span><span>)</span>
    <span>return</span> <span>s</span></pre>
<p class="calibre2">If you are using pandas to extract text from your dataset and clean it, you can also replace the missing text values in your dataset with an <kbd class="calibre12">_empty_</kbd> label:</p>
<pre class="calibre17"><span>train</span> <span>=</span> <span>pd</span><span>.</span><span>read_csv</span><span>(</span><span>'train.csv'</span><span>)</span>
<span>test</span> <span>=</span> <span>pd</span><span>.</span><span>read_csv</span><span>(</span><span>'test.csv'</span><span>)</span>
<span>train</span><span>[</span><span>'Text'</span><span>]</span> <span>=</span> <span>train</span><span>[</span><span>'Text'</span><span>]</span><span>.</span><span>fillna</span><span>(</span><span>'_empty_'</span><span>)</span>
<span>test</span><span>[</span><span>'Text'</span><span>]</span> <span>=</span> <span>test</span><span>[</span><span>'Text'</span><span>]</span><span>.</span><span>fillna</span><span>(</span><span>'_empty_'</span><span>)</span></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Unsupervised learning</h1>
                
            
            <article>
                
<p class="calibre2">The fastText command line implements two algorithms, <kbd class="calibre12">cbow</kbd> and <kbd class="calibre12">skip-gram</kbd>. Using the Python library, you should be able to train your models in both algorithms.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Training in fastText</h1>
                
            
            <article>
                
<p class="calibre2">Training in fastText is done using the <kbd class="calibre12">train_unsupervised</kbd> function. You can choose which algorithm to use from the <kbd class="calibre12">model</kbd> parameter.</p>
<p class="calibre2">Then, you can train a <kbd class="calibre12">skipgram</kbd> model using the following Python code:</p>
<pre class="calibre17">sg_model = fastText.train_unsupervised(input='data.txt', model='skipgram')</pre>
<p class="calibre2">This is similar to the command line:</p>
<pre class="calibre17">./fasttext skipgram -input data.train -output model</pre>
<p class="calibre2">Similarly, to train a <kbd class="calibre12">cbow</kbd> model you can use the following Python code:</p>
<pre class="calibre17">cbow_model = fastText.train_unsupervised(input='data.txt', model='cbow')</pre>
<p class="calibre2">The equivalent statement on the command line is:</p>
<pre class="calibre17">./fasttext cbow -input data.train -output model</pre>
<p class="calibre2">The difference between the Python code and the command line is that the command line will save the model in a file, while in the Python code, the model will be in memory, referenced by the variable. To save the model, you will need to pass explicit commands in your Python app, for example:</p>
<pre class="calibre17">sg_model.save_model("sg_model.bin")</pre>
<p class="calibre2">You should be able to pass all the other training parameters as well. The parameters, as well as the default values, are listed here:</p>
<pre class="calibre17">sg_model = fastText.train_unsupervised(input, model='skipgram', lr=0.05, dim=100, ws=5, epoch=5, minCount=5, minCountLabel=0, minn=3, maxn=6, neg=5, wordNgrams=1, loss="ns", bucket=2000000, thread=12, lrUpdateRate=100, t=1e-4, label="__label__", verbose=2, pretrainedVectors="")</pre>
<p class="calibre2">These parameters hold the same meaning that you have seen while exploring the command line.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Evaluating the model</h1>
                
            
            <article>
                
<p class="calibre2">The lack of labels in the case of unsupervised learning makes evaluation a bit problematic as there is nothing to meaningfully compare the results of the model with. In the case of word embeddings, we have the same problem, but since this is a somewhat narrow domain, we can make some subjective claims. The fastText command line gives us the options of nearest neighbors and finding word similarities, which we can replicate in the Python library as we will see later.</p>
<p class="calibre2">Other techniques include using the syntactic and semantic performance of words based on the question—<kbd class="calibre12">words.txt</kbd> released by Google and the morphological similarity of rare words using the Stanford rare word database. Please keep in mind if you are creating word representations for a niche domain that these exact model evaluation techniques may not give good results, but the techniques should hold.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Word vectors</h1>
                
            
            <article>
                
<p class="calibre2">By default, the word vectors that are created are of 100 dimensions. They are saved in memory as NumPy arrays. So, you should be able to see the word vectors using the <kbd class="calibre12">get_word_vector</kbd> method:</p>
<div class="title-page-name">
<pre class="calibre17"><span>&gt;&gt;&gt; model.get_word_vector('targetword')</span><br class="title-page-name"/>array([ 0.09973086,  ...  0.14613365], dtype=float32)</pre></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Nearest neighbor queries</h1>
                
            
            <article>
                
<p class="calibre2"><span class="calibre5">Generally k nearest neighbors are used to rate differentiate between models. The vector representation of a target word is taken, the neighbors of the vectors are found and then it is seen if the neighbors are closer to its meaning</span>. Since fastText representations are meant to be distributional, this assumption should hold true.</p>
<p class="calibre2">The fastText command line gives us a tool to get the nearest neighbors easily, but there is no easy way to find them in Python. There is a <kbd class="calibre12">find_nearest_neighbor</kbd> function in <kbd class="calibre12">util</kbd>, but it takes vectors as input. Hence, we will need to write some code to create a function that takes in words and the target model, and gives back the nearest neighbors according to the model. You can take a look at <kbd class="calibre12">python fastText unsupervised learning.ipynb</kbd> for the code to get the nearest neighbors:</p>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<pre class="calibre17"><span>&gt;&gt;&gt; nn</span><span>(</span><span>sg_model</span><span>,</span> <span>[</span><span>'dog'</span><span>,</span> <span>'pizza'</span><span>,</span> <span>'hungry'</span><span>],</span> <span>k</span><span>=</span><span>5</span><span>)<br class="title-page-name"/></span>words similar to dog:
dogs
pup
treats
puppy
dogie
#########################################
words similar to pizza:
pizza;
pizza"
pizzas
"pizza
bread
#########################################
words similar to hungry:
hungry";
hungrygirl
&gt;hungry
hungry-girl
hungries
#########################################</pre>
<p class="calibre2">The output may be refined with some pre-normalization on the data.</p>
</div>
</div>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Word similarity</h1>
                
            
            <article>
                
<p class="calibre2">There are various ways to find the similarity between words. In the case of fastText, one way of finding the similarity between words is to find the cosine distance between the words in the vector space. However, this method will probably not find the similarity between synonyms and antonyms, and other minute language constructs, but will solely give you a similarity score based on the context in which they are used. The words "water" and "cup" do not necessarily have anything that is similar between the two, but in context they are generally taken together and hence you may find the similarity score between them to be high.</p>
<p class="calibre2">In the Python library, you can write a small function to get the cosine similarity:</p>
<pre class="calibre17"><span>def</span> <span>similarity</span><span>(</span><span>v1</span><span>,</span> <span>v2</span><span>):</span>
    <span>n1</span> <span>=</span> <span>np</span><span>.</span><span>linalg</span><span>.</span><span>norm</span><span>(</span><span>v1</span><span>)</span>
    <span>n2</span> <span>=</span> <span>np</span><span>.</span><span>linalg</span><span>.</span><span>norm</span><span>(</span><span>v2</span><span>)</span>
    <span>return</span> <span>np</span><span>.</span><span>dot</span><span>(</span><span>v1</span><span>,</span> <span>v2</span><span>)</span> <span>/</span> <span>n1</span> <span>/</span> <span>n2</span>

<span>v1</span> <span>=</span> <span>sg_model</span><span>.</span><span>get_word_vector</span><span>(</span><span>'drink'</span><span>)</span>
<span>v2</span> <span>=</span> <span>sg_model</span><span>.</span><span>get_word_vector</span><span>(</span><span>'drinks'</span><span>)</span>
<span>print</span><span>(</span><span>similarity</span><span>(</span><span>v1</span><span>,</span> <span>v2</span><span>))</span></pre>
<p class="calibre2">In essence, you find the word vectors of the two target words using the <kbd class="calibre12">get_word_vector</kbd> <span class="calibre5">method,</span><span class="calibre5"> </span><span class="calibre5">and then find the cosine between them.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Model performance</h1>
                
            
            <article>
                
<p class="calibre2">You can find the performance of the model using the rare words dataset that was released by Stanford NLP. Using the <kbd class="calibre12">compute_similarity</kbd> function that is shared in the examples folder, we can change the function a little bit so that it works in a Python app. The implementation of the function can be seen in the unsupervised notebook. Download the rare words dataset, the link to which you will find in the references, unzip it, and then pass the text file as the first argument and the model as the second argument. You should be able to see how well your model has been able to evaluate the rare words:</p>
<pre class="calibre17"><span>&gt;&gt;&gt; dataset</span><span>,</span> <span>corr</span><span>,</span> <span>oov</span> <span>=</span> <span>compute_similarity</span><span>(</span><span>'data/rw/rw.txt'</span><span>,</span> <span>sg_model</span><span>)</span>
<span>&gt;&gt;&gt; print</span><span>(</span><span>"</span><span>{0:20s}</span><span>: </span><span>{1:2.0f}</span><span>  (OOV: </span><span>{2:2.0f}</span><span>%)"</span><span>.</span><span>format</span><span>(</span><span>dataset</span><span>,</span> <span>corr</span><span>,</span> <span>0</span><span>))<br class="title-page-name"/><span>rw.txt              : 32  (OOV:  0%)</span></span></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Model visualization</h1>
                
            
            <article>
                
<p class="calibre2">Visualizing how the word vectors happen in space is an effective way to understand the distributional properties of the model. Since the dimensions of the vectors are quite high, you will need a good dimensionality reduction technique so that the vectors can be shown in a two-dimensional frame.</p>
<p class="calibre2">The t-SNE is popular technique for dimensionality reduction that is well suited for the visualization of high-dimensional datasets. The idea in this case is to keep similar words as close together as possible, while maximizing the distance between dissimilar words. The unsupervised notebook shows the code for the t-SNE model. In our case, we have taken some words and plotted them in the graph:</p>
<div class="cdpaligncenter"><img src="../images/00083.jpeg" class="calibre49"/></div>
<div class="mce-root">Words plotted on a graph</div>
<p class="calibre2">As you can see, "water" and "cup" are together, as they are generally used in the same context. Another two vectors that are together are "drink" and "tea." Using t-SNE to understand your model will give you a good idea of how good your model is.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Supervised learning</h1>
                
            
            <article>
                
<p class="calibre2">Similar to unsupervised learning, the fastText library provides access to the internal API for running supervised learning as well. Hence, running the fastText supervised Python API will also create the same model, which can be trained using the command line app. The advantage is that you will be able to leverage all the Python data science tools available for building an NLP classifier.</p>
<p class="calibre2">To show how to leverage the fastText classifier can be trained in Python, you can take a look at the <kbd class="calibre12">python fastText supervised learning.ipynb</kbd> notebook in the code. The dataset consists of reviews of fine foods from Amazon and can be downloaded from the Kaggle website, the links for which are given in the notebook.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Data preprocessing and normalization</h1>
                
            
            <article>
                
<p class="calibre2">The data preprocessing and normalization steps are similar to what you have seen in the case of unsupervised learning. In this case though, the major difference is that you will need to prefix the label with the <kbd class="calibre12">__label__</kbd> prefix or a label prefix of your choice. Also, it has to be saved in the fastText file in a format that is similar to the fastText command line. Since this is a classifier, you will need to actually create two files, one for training and one for model validation. One of the popular ways to split a dataset into training and testing is using the scikit-learn <kbd class="calibre12">train_test_split</kbd> function.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Training the model</h1>
                
            
            <article>
                
<p class="calibre2">To train the model, you will need to use the <kbd class="calibre12">train_supervised</kbd> method on the training file:</p>
<pre class="calibre17">&gt;&gt;&gt; su_model = fastText.train_supervised(input=train_file, epoch=25, lr=1.0, wordNgrams=2, verbose=2, minCount=1)</pre>
<p class="calibre2">This is similar to running this on the command line:</p>
<pre class="calibre17"><strong class="calibre1">$ ./fasttext supervised -input train_file -output su_model</strong></pre>
<p class="calibre2">The hyperparameters are the same as what you pass in the case of supervised learning. The only difference with the unsupervised case is that the default loss function is <kbd class="calibre12">softmax</kbd> instead of <kbd class="calibre12">ns</kbd> and there is an additional <kbd class="calibre12">label</kbd> parameter:</p>
<pre class="calibre17">&gt;&gt;&gt; su_model = fastText.train_supervised(input=train_file, lr=0.1, dim=100, ws=5, epoch=5, minCount=1, minCountLabel=0, minn=0, maxn=0, neg=5, wordNgrams=1, loss="softmax", bucket=2000000, thread=12,  lrUpdateRate=100, t=1e-4, label="__label__", verbose=2, pretrainedVectors="")</pre>
<p class="calibre2">Similar to the case of unsupervised learning, the Python code will not save the model to a file but will save it to the variable that you defined, <kbd class="calibre12">su_model</kbd> in this case. This variable, <kbd class="calibre12">su_model</kbd>, is a Python NumPy matrix and hence we can manipulate it in standard ways.</p>
<p class="calibre2">To save the model, you will need to invoke the <kbd class="calibre12">save_model</kbd> method:</p>
<pre class="calibre17">&gt;&gt;&gt; su_model.save_model("su_model.bin")</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Prediction</h1>
                
            
            <article>
                
<p class="calibre2">You can get the word vector of the word using the <kbd class="calibre12">get_word_vector</kbd> method, the sentence vector of a document using the <kbd class="calibre12">get_sentence_vector</kbd> method, and the predicted label of a model using the predict method:</p>
<pre class="calibre17">&gt;&gt;&gt; su_model.get_word_vector('restaurant')<br class="title-page-name"/>array([ 0.9739366 , ..., -0.17078586], dtype=float32)<br class="title-page-name"/>&gt;&gt;&gt; su_model.get_sentence_vector('I love this restaurant')<br class="title-page-name"/>array([ 0.31301185,  ... , -0.21543942], dtype=float32)<br class="title-page-name"/>&gt;&gt;&gt; su_model.predict('I love this restaurant')<br class="title-page-name"/>(('__label__5',), array([1.00001001]))</pre>
<p class="calibre2">You can also perform predict probabilities on your test document:</p>
<pre class="calibre17">&gt;&gt;&gt; su_model.predict("I love this restaurant", k=3)</pre>
<pre class="calibre17">(('__label__5', '__label__2', '__label__3'),
 array([1.00001001e+00, 1.00000034e-05, 1.00000034e-05]))</pre>
<p class="calibre2">This is similar to this on the command line:</p>
<pre class="calibre17"><strong class="calibre1">$ echo "I love this restaurant" | ./fasttext predict-prob su_model.bin - 3</strong><br class="title-page-name"/><strong class="calibre1">__label__5 1.00001 __label__2 1e-05 __label__3 1e-05</strong></pre>
<p class="calibre2"/>
<p class="calibre2"/>
<p class="calibre2"/>
<p class="calibre2"/>
<p class="calibre2"/>
<p class="calibre2"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Testing the model</h1>
                
            
            <article>
                
<p class="calibre2">Getting the precision and recall of your model is similar to what was seen using the command line. Similar to the command line, you will need to pass the test file and the number of labels that you need to find the precision of and recall against.</p>
<p class="calibre2">In the following example, <kbd class="calibre12">test_file</kbd> contains the path to the test file, and the second argument is the number of labels:</p>
<pre class="calibre17"><span>&gt;&gt;&gt; n</span><span>,</span><span> </span><span>p</span><span>,</span><span> </span><span>r</span><span> </span><span>=</span><span> </span><span>su_model</span><span>.</span><span>test</span><span>(</span><span>test_file</span><span>,</span><span> </span><span>5</span><span>)</span><span><br class="title-page-name"/></span><span>&gt;&gt;&gt; print</span><span>(</span><span>"N</span><span>\t</span><span>"</span><span> </span><span>+</span><span> </span><span>str</span><span>(</span><span>n</span><span>))</span><span><br class="title-page-name"/></span><span>&gt;&gt;&gt; print</span><span>(</span><span>"P@</span><span>{}</span><span>\t</span><span>{:.3f}</span><span>"</span><span>.</span><span>format</span><span>(</span><span>5</span><span>,</span><span> </span><span>p</span><span>))</span><span><br class="title-page-name"/></span><span>&gt;&gt;&gt; print</span><span>(</span><span>"R@</span><span>{}</span><span>\t</span><span>{:.3f}</span><span>"</span><span>.</span><span>format</span><span>(</span><span>5</span><span>,</span><span> </span><span>r</span><span>))<br class="title-page-name"/><span>N 113691<br class="title-page-name"/>P@5 0.200<br class="title-page-name"/>R@5 1.000</span></span></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Confusion matrix</h1>
                
            
            <article>
                
<p class="calibre2">A confusion matrix is a nice way to visualize the performance of a supervised model, specifically a classifier. It also shines when understanding which classes are performing better in a multiclass classifier. When you are creating a confusion matrix, you are essentially describing the performance of the model classifier on a test set for which the ground truth is known. Since fastText supports a classifier, you can create a confusion matrix out of it.</p>
<p class="calibre2">How to get the confusion matrix is shown i<span class="calibre5">n the supervised notebook</span>. The <kbd class="calibre12">fasttext_confusion_matrix</kbd> <span class="calibre5">function </span><span class="calibre5">takes in a model variable, pandas test data, the label column name, and the text column name:</span></p>
<div class="cdpaligncenter"><img src="../images/00084.jpeg" class="calibre50"/></div>
<p class="calibre2">The predicted labels<span class="calibre5"> </span><span class="calibre5">are shown</span><span class="calibre5"> against the true values.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Gensim</h1>
                
            
            <article>
                
<p class="calibre2">Gensim is a popular open source library for processing raw, unstructured human-generated text created by Radim Řehůřek. Some of the features that Gensim boasts are:</p>
<ul class="calibre10">
<li class="calibre11">Memory independence is one of the core value propositions of Gensim, which is that it should be scalable and not hold all the document in the RAM. Hence, you will be able to train documents that are significantly larger than the memory of your machine.</li>
<li class="calibre11">Gensim has efficient implementations of various popular vector space algorithms. There has been a recent implementation of fastText in gensim as well.</li>
<li class="calibre11">There are IO/wrappers and converters around several popular data formats as well. Remember that fastText only supports UTF-8 formats and hence Gensim might be a good choice if you have data that is in different formats.</li>
<li class="calibre11">Different algorithms for similarity queries. So, you are not stuck with the ones that are available in fastText.</li>
</ul>
<p class="calibre2">There are two ways you can use fastText through Gensim: Using the Gensim's native implementation of fastText and by using Gensim's wrapper over fastText.</p>
<p class="calibre2">Now, let's take a look at how you can use Gensim to train a fastText model.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Training a fastText model</h1>
                
            
            <article>
                
<p class="calibre2">For the example that is shown here, we will be using the Lee Corpus for training your model. To get the required data, I would recommend that you clone the Gensim repository from GitHub.</p>
<p class="calibre2">In the code examples shown here, we will be taking a look at Gensim fastText using the fake news dataset from Kaggle. First, download the data and clean the text:</p>
<pre class="calibre17">In [1]: from gensim.models.fasttext import FastText<br class="title-page-name"/>   ...: from gensim.corpora import Dictionary<br class="title-page-name"/>   ...: import pandas as pd<br class="title-page-name"/>   ...: import re<br class="title-page-name"/>   ...: from gensim.parsing.preprocessing import remove_stopwords, strip_punctuation<br class="title-page-name"/>   ...: import numpy as np<br class="title-page-name"/>   ...: <br class="title-page-name"/><br class="title-page-name"/>In [2]: df_fake = pd.read_csv('fake.csv')<br class="title-page-name"/>   ...: df_fake[['title', 'text', 'language']].head()<br class="title-page-name"/>   ...: df_fake = df_fake.loc[(pd.notnull(df_fake.text)) &amp; (df_fake.language == 'english')]<br class="title-page-name"/>   ...: <br class="title-page-name"/><br class="title-page-name"/>In [3]: # remove stopwords and punctuations<br class="title-page-name"/>   ...: def preprocess(row):<br class="title-page-name"/>   ...: return strip_punctuation(remove_stopwords(row.lower()))<br class="title-page-name"/>   ...: <br class="title-page-name"/>   ...: df_fake['text'] = df_fake['text'].apply(preprocess)<br class="title-page-name"/>   ...: <br class="title-page-name"/><br class="title-page-name"/>In [4]: # Convert data to required input format by LDA<br class="title-page-name"/>   ...: texts = []<br class="title-page-name"/>   ...: for line in df_fake.text:<br class="title-page-name"/>   ...: lowered = line.lower()<br class="title-page-name"/>   ...: words = re.findall(r'\w+', lowered)<br class="title-page-name"/>   ...: texts.append(words)<br class="title-page-name"/>   ...: </pre>
<p class="calibre2">The first case we will take a look at is how to train the models using the fastText wrapper. To use the fastText wrapper, you will need to have fastText installed in your machine. You should have fastText installed if you have followed the instructions in <a target="_blank" href="part0021.html#K0RQ0-05950c18a75943d0a581d9ddc51f2755" class="calibre9">Chapter 1</a>, <em class="calibre16">Introducing FastText</em>. This wrapper is deprecated though, and the recommendation is to use the Gensim implementation of fastText:</p>
<pre class="calibre17">&gt;&gt;&gt; from gensim.models.wrappers.fasttext import FastText as FT_wrapper<br class="title-page-name"/><br class="title-page-name"/>&gt;&gt;&gt; # Set FastText home to the path to the FastText executable<br class="title-page-name"/>&gt;&gt;&gt; ft_home = '/usr/local/bin/fasttext'<br class="title-page-name"/><br class="title-page-name"/>&gt;&gt;&gt; # train the model<br class="title-page-name"/>&gt;&gt;&gt; model_wrapper = FT_wrapper.train(ft_home, lee_train_file)<br class="title-page-name"/><br class="title-page-name"/>&gt;&gt;&gt; print(model_wrapper)</pre>
<p class="calibre2">If you are interested in using the fastText implementation in Gensim, you will need to use the FastText class in <kbd class="calibre12">gensim.models</kbd>, which also, in addition to fastText, has word2vec and many other models that can be used:</p>
<pre class="calibre17">In [1]: <br class="title-page-name"/>   ...: import gensim<br class="title-page-name"/>   ...: import os<br class="title-page-name"/>   ...: from gensim.models.word2vec import LineSentence<br class="title-page-name"/>   ...: from gensim.models.fasttext import FastText<br class="title-page-name"/><br class="title-page-name"/>In [2]: # Set file names for train and test data<br class="title-page-name"/>   ...: data_dir = '{}'.format(os.sep).join([gensim.__path__[0], 'test', 'test_data']) + os.sep<br class="title-page-name"/>   ...: lee_train_file = data_dir + 'lee_background.cor'<br class="title-page-name"/>   ...: lee_data = LineSentence(lee_train_file)<br class="title-page-name"/><br class="title-page-name"/>In [3]: model = FastText(size=100)<br class="title-page-name"/><br class="title-page-name"/>In [4]: model.build_vocab(lee_data)<br class="title-page-name"/><br class="title-page-name"/>In [5]: # train the model<br class="title-page-name"/>   ...: model.train(lee_data, total_examples=model.corpus_count, epochs=model.epochs)<br class="title-page-name"/>   ...: print(model)<br class="title-page-name"/>FastText(vocab=1762, size=100, alpha=0.025)</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Hyperparameters</h1>
                
            
            <article>
                
<p class="calibre2">Gensim supports the same hyperparameters that are supported in the native implementation of fastText. You should be able to set most of the hyperparameters that are there in the Facebook fastText implementation. The defaults are also mostly there already. Some differences are listed here:</p>
<ul class="calibre10">
<li class="calibre11"><kbd class="calibre12">sentences</kbd>: This can be a list of list of tokens. In general, a stream of tokens is recommended, such as <kbd class="calibre12">LineSentence</kbd> from the word2vec module as you have seen already. In the Facebook fastText library, this is given by the path to the file and is given by the <kbd class="calibre12">-input</kbd> parameter.</li>
<li class="calibre11"><kbd class="calibre12">max_vocab_size</kbd>: This is to limit the RAM size. In case there are more unique words, then, this will prune the less frequent ones. This needs to be decided based on the RAM that you have. For example, if you have 2 GB memory, then the value of <kbd class="calibre12">max_vocab_size</kbd> is used as a parameter for that 2 GB of memory. Also, if you have not set it manually, then there is no limit set.</li>
<li class="calibre11"><kbd class="calibre12">cbow_mean</kbd>: There is a difference from the fastText command here. In the original implementation for cbow, the mean of the vectors is taken. But in this case, you have the option to use the sum by passing 0 and 1 in case you want to try out the mean.</li>
<li class="calibre11"><kbd class="calibre12">batch_words</kbd>: This is the target size of the batches that are passed. The default value is 10,000. This is similar to<kbd class="calibre12">-lrUpdateRate</kbd> in the command line, as the number of batches determines when the weights will be updated.</li>
<li class="calibre11"><kbd class="calibre12">callbacks</kbd>: A list of callback functions to be executed at specific stages of the training process.</li>
<li class="calibre11">There are no parallels for the <kbd class="calibre12">-supervised</kbd> and <kbd class="calibre12">-labels</kbd> parameters, as Gensim focuses on unsupervised learning only.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Model saving and loading</h1>
                
            
            <article>
                
<p class="calibre2">Gensim provides the save and load methods for all models, and this is implemented in the case of fastText as well:</p>
<pre class="calibre17">In [6]: # saving a model trained via Gensim's fastText implementation<br class="title-page-name"/>   ...: model.save('saved_model_gensim')<br class="title-page-name"/>   ...: loaded_model = FastText.load('saved_model_gensim')<br class="title-page-name"/>   ...: print(loaded_model)<br class="title-page-name"/>   ...: <br class="title-page-name"/>FastText(vocab=1762, size=100, alpha=0.025)<br class="title-page-name"/><br class="title-page-name"/>In [7]: import os; print(os.path.exists('saved_model_gensim'))<br class="title-page-name"/>True</pre>
<p class="calibre2">Loading a binary fastText model can also be achieved using the <kbd class="calibre12">load_fasttext_format</kbd> class method:</p>
<pre class="calibre17">In [1]: from gensim.models.fasttext import FastText<br class="title-page-name"/>In [2]: modelpath = "wiki.simple.bin"<br class="title-page-name"/>In [3]: model = FastText.load_fasttext_format(modelpath)<br class="title-page-name"/>In [4]: print(model)<br class="title-page-name"/>FastText(vocab=111051, size=300, alpha=0.025)</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Word vectors</h1>
                
            
            <article>
                
<p class="calibre2">In Gensim, you can check whether the words are present in the vocabulary and then get the word vectors for the words. Since fastText supports out-of-vector for the words, you should be able to get the word vectors even if the words are not present in the vocabulary. This will not work in cases where none of the character n-grams were present in the vocabulary:</p>
<pre class="calibre17">In [1]: import gensim<br class="title-page-name"/>   ...: import os<br class="title-page-name"/>   ...: from gensim.models.word2vec import LineSentence<br class="title-page-name"/>   ...: from gensim.models.fasttext import FastText<br class="title-page-name"/>   ...: <br class="title-page-name"/><br class="title-page-name"/>In [2]: # Set file names for train and test data<br class="title-page-name"/>   ...: data_dir = '{}'.format(os.sep).join([gensim.__path__[0], 'test', 'test_data']) + os.sep<br class="title-page-name"/>   ...: lee_train_file = data_dir + 'lee_background.cor'<br class="title-page-name"/>   ...: lee_data = LineSentence(lee_train_file)<br class="title-page-name"/>   ...: </pre>
<pre class="calibre17"><br class="title-page-name"/>In [3]: model = FastText(size=100)<br class="title-page-name"/><br class="title-page-name"/>In [4]: # build the vocabulary<br class="title-page-name"/>   ...: model.build_vocab(lee_data)<br class="title-page-name"/><br class="title-page-name"/>In [5]: # train the model<br class="title-page-name"/>   ...: model.train(lee_data, total_examples=model.corpus_count, epochs=model.epochs)<br class="title-page-name"/><br class="title-page-name"/>In [6]: print('night' in model.wv.vocab)<br class="title-page-name"/>True<br class="title-page-name"/><br class="title-page-name"/>In [7]: print('nights' in model.wv.vocab) # this is not present<br class="title-page-name"/>False<br class="title-page-name"/><br class="title-page-name"/>In [8]: print(model.wv['night'])<br class="title-page-name"/>[-0.02308581 ... 0.15816787]<br class="title-page-name"/><br class="title-page-name"/>In [9]: print(model.wv['nights'])<br class="title-page-name"/>[-0.02073629 ... 0.1486301 ]<br class="title-page-name"/><br class="title-page-name"/>In [10]: # Raises a KeyError since none of the character ngrams of the word `axe` are present in the training data<br class="title-page-name"/>    ...: model.wv['axe']<br class="title-page-name"/>---------------------------------------------------------------------------<br class="title-page-name"/>KeyError Traceback (most recent call last)<br class="title-page-name"/>&lt;ipython-input-10-902d47f807a0&gt; in &lt;module&gt;()<br class="title-page-name"/>      1 # Raises a KeyError since none of the character ngrams of the word `axe` are present in the training data<br class="title-page-name"/>----&gt; 2 model.wv['axe']<br class="title-page-name"/><br class="title-page-name"/>...<br class="title-page-name"/><br class="title-page-name"/>KeyError: 'all ngrams for word axe absent from model'</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Model Evaluation</h1>
                
            
            <article>
                
<p class="calibre2">Since Gensim implements an unsupervised algorithm, there is no direct way of measuring how good the resulting model is. Evaluating models depends on your use case and how well it's working out in your end applications.</p>
<p class="calibre2">Gensim fastText has various methods that you can use for finding the similarity between words. The following results were received by loading the <kbd class="calibre12">wiki.simple.bin</kbd> model.</p>
<p class="calibre2">The easiest way to calculate the similarity between two words is using the <kbd class="calibre12">similarity</kbd> method:</p>
<pre class="calibre17">In []: model.wv.similarity('night', 'nights')<br class="title-page-name"/>Out[]: 0.9999931241743173</pre>
<p class="calibre2">FastText computes sentence or document vectors only during supervised learning. Depending on the task, simple average word embeddings of all the normalized words in the sentence should suffice.</p>
<p class="calibre2">You can get the similarities between two documents using the<span class="calibre5"> </span><kbd class="calibre12">n_similarity</kbd><span class="calibre5"> </span>method. According to the Gensim documentation, this method will give the cosine similarity between the two documents. Those documents need to be passed as a list:</p>
<pre class="calibre17">In []: model.wv.n_similarity(['sushi', 'shop'], ['japanese', 'restaurant'])<br class="title-page-name"/>Out[]: 0.6041413398970296<br class="title-page-name"/><br class="title-page-name"/>In []: model.wv.n_similarity('Obama speaks to the media in Illinois'.lower().split(), 'The president greets the press in Chicago'.lower().spl<br class="title-page-name"/>    ...: it())<br class="title-page-name"/>Out[]: 0.7653119647179297</pre>
<p class="calibre2">Gensim gives you ability to search for the most irrelevant document as well, kind of like finding the odd man out:</p>
<pre class="calibre17">In []: model.wv.doesnt_match("breakfast cereal dinner lunch".split())<br class="title-page-name"/>Out[]: 'cereal'</pre>
<p class="calibre2">The <kbd class="calibre12">most_similar</kbd> method will give you the most similar words according to the model:</p>
<pre class="calibre17">In []: model.wv.most_similar('food')<br class="title-page-name"/>Out[]: <br class="title-page-name"/>[('foods', 0.6859725713729858),<br class="title-page-name"/> ('foodstuffs', 0.679445743560791),<br class="title-page-name"/> ('seafood', 0.6695178151130676),<br class="title-page-name"/> ('eat', 0.5922832489013672),<br class="title-page-name"/> ('meals', 0.5820232629776001),<br class="title-page-name"/> ('meat', 0.5773770213127136),<br class="title-page-name"/> ('eaten', 0.5611693263053894),<br class="title-page-name"/> ('nutritious', 0.5602636337280273),<br class="title-page-name"/> ('snacks', 0.5574883818626404),<br class="title-page-name"/> ('cooked', 0.5470614433288574)]<br class="title-page-name"/>=</pre>
<p class="calibre2">Gensim provides an easy-to-use method to evaluate the model on the WordSim 353 benchmark. This dataset is a standard dataset for evaluating vector space models. There is no context around each word and the rating between the similarity of the words is on a scale of 0 to 10 in increasing order. You can find the file in <span class="calibre5"><kbd class="calibre12">gensim/test/test_data/wordsim353.tsv</kbd></span> in the Gensim GitHub repository:</p>
<pre class="calibre17">In []: model.wv.evaluate_word_pairs('wordsim353.tsv')<br class="title-page-name"/>Out[]: <br class="title-page-name"/>((0.6645467362164186, 2.4591009701535706e-46),<br class="title-page-name"/> SpearmanrResult(correlation=0.7179229895090848, pvalue=3.58449522917263e-57),<br class="title-page-name"/> 0.0)</pre>
<p class="calibre2">The first result is the Pearson correlation coefficient (which is the normal correlation coefficient that we know of) and the second result is the Spearman coefficient.</p>
<p class="calibre2"><span class="calibre5">You can also use the <kbd class="calibre12">most_similar</kbd> method to get queries of the type of <em class="calibre16">A - B + C:</em></span></p>
<pre class="calibre17">In []: model.wv.most_similar(positive=['story', 'dove'], negative=['stories'])  # Vector('story') - Vector('stories') + Vector('dove')<br class="title-page-name"/>Out[]: <br class="title-page-name"/>[('doves', 0.5111404657363892),<br class="title-page-name"/> ('dovepaw', 0.5014846324920654),<br class="title-page-name"/> ('turtledove', 0.4434218406677246),<br class="title-page-name"/> ('dovecote', 0.4430897831916809),<br class="title-page-name"/> ('warbler', 0.43106675148010254),<br class="title-page-name"/> ('warble', 0.40401384234428406),<br class="title-page-name"/> ('asshole', 0.4017521142959595),<br class="title-page-name"/> ('dovre', 0.39799436926841736),<br class="title-page-name"/> ('nothofagus', 0.389825701713562),<br class="title-page-name"/> ('moriarty', 0.388924241065979)]</pre>
<p class="calibre2">Similar to this type of syntactic and semantic similarity test, if you are creating word vectors in English, you can use the <kbd class="calibre12">question-words.txt</kbd> task that has been prepared and released by Google. You can find the text file in <kbd class="calibre12">gensim/docs/notebooks/datasets/question-words.txt</kbd>.</p>
<p class="calibre2">Now, you can run the following code. Also, set the logging to info so that you can get the accuracy in terms of percentages on the different fields. There are nine types of syntactic comparisons in the dataset, family, comparative, superlative, present-participle, nationality-adjective, past-tense, and plural:</p>
<pre class="calibre17">model.accuracy("question-words.txt")</pre>
<p class="calibre2">This will give you an output and show you where there is a mismatch where the answers don't match with the list of words. You can evaluate based on that. If you are training for a different language, then one good investment may be to create a similar <kbd class="calibre12">question-words.txt</kbd> in the target language, based on different grammatical focal points in that language.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Word Mover's Distance</h1>
                
            
            <article>
                
<p class="calibre2"><strong class="calibre4">Word Mover's Distance</strong> (<strong class="calibre4">WMD</strong>) is a good way of capturing two documents, even when there are no common words between them. <span class="calibre5">Take a look at the following example. Words like <strong class="calibre4">greet</strong> and <strong class="calibre4">speaks</strong> are fairly near to each other if we consider the WMD:</span></p>
<div class="mce-root"><img src="../images/00085.jpeg" class="calibre51"/></div>
<p class="packt_figref">Source: <a href="https://markroxor.github.io/gensim/static/notebooks/WMD_tutorial.html" class="calibre52">https://markroxor.github.io/gensim/static/notebooks/WMD_tutorial.html</a></p>
<p class="packt_figref"/>
<p class="calibre2">In Gensim, you can find the distance between two documents using the <kbd class="calibre12">wmdistance</kbd> method, shown as follows:</p>
<pre class="calibre17">In []: sentence_obama = 'Obama speaks to the media in Illinois'<br class="title-page-name"/>   ...: sentence_president = 'The president greets the press in Chicago'<br class="title-page-name"/>   ...: sentence_obama = sentence_obama.lower().split()<br class="title-page-name"/>   ...: sentence_president = sentence_president.lower().split()<br class="title-page-name"/>   ...: <br class="title-page-name"/><br class="title-page-name"/>In []: # Remove stopwords.<br class="title-page-name"/>   ...: stop_words = stopwords.words('english')<br class="title-page-name"/>   ...: sentence_obama = [w for w in sentence_obama if w not in stop_words]<br class="title-page-name"/>   ...: sentence_president = [w for w in sentence_president if w not in stop_words]</pre>
<pre class="calibre17"><br class="title-page-name"/>In []: distance = model.wv.wmdistance(sentence_obama, sentence_president)<br class="title-page-name"/>   ...: print('distance = %.4f' % distance)<br class="title-page-name"/>distance = 4.9691</pre>
<p class="calibre2">You can initialize a word mover similarity class on your corpus:</p>
<pre class="calibre17">from gensim.similarities import WmdSimilarity<br class="title-page-name"/>num_best = 10<br class="title-page-name"/>instance = WmdSimilarity(wmd_corpus, model, num_best=10)</pre>
<p class="calibre2">Here, <kbd class="calibre12">wmd_corpus</kbd> is your corpus and <kbd class="calibre12">model</kbd> is your trained fastText model. Now, you can run a query on the instance, which is simply a <em class="calibre16">lookup</em> on the class.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Getting more out of the training process</h1>
                
            
            <article>
                
<p class="calibre2">As we are going through the model training process, you will also be interested in knowing the progress and performance of the model. Understanding how the model learns can be very helpful and makes it easier to debug the model and improve it.</p>
<p class="calibre2">Another concern that may arise is training on large corpora. Training multiple epochs on large corpora may take a lot of time and hence you may want to save the model after the completion of each epoch.</p>
<p class="calibre2">In such scenarios, Gensim implements the callback parameter, which takes a sequence of subclasses of <kbd class="calibre12">CallbackAny2Vec</kbd><span class="calibre5"> </span>from<span class="calibre5"> </span><kbd class="calibre12">gensim.models.callbacks module</kbd>. Using this class, you can create classes that save the function at specific points in the training process:</p>
<pre class="calibre17">from gensim.test.utils import common_texts as sentences<br class="title-page-name"/>from gensim.models.callbacks import CallbackAny2Vec<br class="title-page-name"/>from gensim.models import Word2Vec<br class="title-page-name"/>from gensim.test.utils import get_tmpfile<br class="title-page-name"/><br class="title-page-name"/>class EpochSaver(CallbackAny2Vec):<br class="title-page-name"/>    "Callback to save model after every epoch"<br class="title-page-name"/>    def __init__(self, path_prefix):<br class="title-page-name"/>        self.path_prefix = path_prefix<br class="title-page-name"/>        self.epoch = 0<br class="title-page-name"/>    def on_epoch_end(self, model):<br class="title-page-name"/>        output_path = '{}_epoch{}.model'.format(self.path_prefix, self.epoch)<br class="title-page-name"/>        print("Save model to {}".format(output_path))<br class="title-page-name"/>        model.save(output_path)<br class="title-page-name"/>        self.epoch += 1</pre>
<pre class="calibre17"># to save the similarity scores<br class="title-page-name"/>similarity = []<br class="title-page-name"/><br class="title-page-name"/>class EpochLogger(CallbackAny2Vec):<br class="title-page-name"/>    "Callback to log information about training"<br class="title-page-name"/>    def __init__(self):<br class="title-page-name"/>        self.epoch = 0<br class="title-page-name"/>    def on_epoch_begin(self, model):<br class="title-page-name"/>        print("Epoch #{} start".format(self.epoch))<br class="title-page-name"/>    def on_epoch_end(self, model):<br class="title-page-name"/>        print("Epoch #{} end".format(self.epoch))<br class="title-page-name"/>        self.epoch += 1<br class="title-page-name"/>    def on_batch_begin(self, model):<br class="title-page-name"/>        similarity.append(model.wv.similarity('woman', 'man'))</pre>
<p class="calibre2">The <kbd class="calibre12">EpochSaver</kbd><span class="calibre5"> </span><span class="calibre5">class</span><span class="calibre5"> </span><span class="calibre5">saves the model at every ending of the epoch cycle. The</span> <kbd class="calibre12">EpochLogger</kbd><span class="calibre5"> </span><span class="calibre5">class</span><span class="calibre5"> </span><span class="calibre5">does two things. It prints the epoch start and stop, and whenever there is a batch begin cycle, it saves the similarity score to a list named similarity. We will use this list later for visualization.</span></p>
<p class="calibre2">Now, instantiate these classes and pass them to the model training process:</p>
<pre class="calibre17">import gensim<br class="title-page-name"/>from gensim.models.word2vec import LineSentence<br class="title-page-name"/>from gensim.models.fasttext import FastText<br class="title-page-name"/><br class="title-page-name"/># Set file names for train and test data<br class="title-page-name"/>lee_train_file = './gensim/gensim/test/test_data/lee_background.cor'<br class="title-page-name"/>lee_data = LineSentence(lee_train_file)<br class="title-page-name"/><br class="title-page-name"/>model_gensim = FastText(size=100)<br class="title-page-name"/><br class="title-page-name"/># build the vocabulary<br class="title-page-name"/>model_gensim.build_vocab(lee_data)<br class="title-page-name"/><br class="title-page-name"/># instantiate the callbacks<br class="title-page-name"/>epoch_saver = EpochSaver(get_tmpfile("temporary_model"))<br class="title-page-name"/>epoch_logger = EpochLogger()<br class="title-page-name"/><br class="title-page-name"/># train the model<br class="title-page-name"/>model_gensim.train(lee_data, <br class="title-page-name"/>                   total_examples=model_gensim.corpus_count,<br class="title-page-name"/>                   epochs=model_gensim.epochs,<br class="title-page-name"/>                   callbacks=[epoch_saver, epoch_logger])<br class="title-page-name"/><br class="title-page-name"/>print(model_gensim)</pre>
<p class="calibre2">When you run this code, you should be able to see the logger working and logging the epochs. Also, the different models will get saved onto disk.</p>
<p class="calibre2">To see how the similarity scores have progressed with the training, you can start a visdom server. Visdom is a visualization package by Facebook, which runs as a server. Its advantage is that you can send data to it, and the update parameters can be monitored using a web browser. To start a visdom server, you will need to have visdom installed and then you can run it from the command line:</p>
<pre class="calibre17"><strong class="calibre1">$ pip install visdom</strong><br class="title-page-name"/><strong class="calibre1">$ python -m visdom.server</strong></pre>
<p class="calibre2">Now, you can pass the similarity scores to the server:</p>
<pre class="calibre17">import visdom<br class="title-page-name"/>vis = visdom.Visdom()<br class="title-page-name"/><br class="title-page-name"/>trace = dict(x=list(range(len(similarity))), y=similarity, mode="markers+lines", type='custom',<br class="title-page-name"/>             marker={'color': 'red', 'symbol': 104, 'size': "10"},<br class="title-page-name"/>             text=["one", "two", "three"], name='1st Trace')<br class="title-page-name"/>layout = dict(title="First Plot", xaxis={'title': 'x1'}, yaxis={'title': 'x2'})<br class="title-page-name"/><br class="title-page-name"/>vis._send({'data': [trace], 'layout': layout, 'win': 'mywin'})</pre>
<p class="calibre2"/>
<p class="calibre2"/>
<p class="calibre2">If you open the server at <kbd class="calibre12">http://localhost:8097</kbd>, you should be able to see this graph:</p>
<div class="cdpaligncenter"><img src="../images/00086.jpeg" class="calibre53"/></div>
<div class="mce-root">An example of a generated visdom graph</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Machine translation using Gensim</h1>
                
            
            <article>
                
<p class="calibre2">According to Mikolov's 2013 paper, the link to which is given in the references, you can use the following method, which consists of two steps:</p>
<ol class="calibre13">
<li value="1" class="calibre11">First, monolingual models of languages are built using large amounts of text</li>
<li value="2" class="calibre11">A small bilingual dictionary is used to learn a linear projection between languages</li>
</ol>
<p class="calibre2">So for the first step, you can simply use the fastText models that are prebuilt and shared on the <a href="https://fasttext.cc/" class="calibre9">fasttext.cc</a> website. In this section, we will take a look at how to implement the second step using Gensim.</p>
<p class="calibre2">The aim is to train a translation matrix, which is essentially a linear transformation matrix that links the source word vectors and the target word vectors.</p>
<p class="calibre2"/>
<p class="calibre2"/>
<p class="calibre2"/>
<p class="calibre2"/>
<p class="calibre2"/>
<p class="calibre2">You can download the transformation file from source language to target language; a good source is the Facebook muse documentation and your languages of interest may be listed there. If not, then you will need to put the effort into creating the transformation file yourself. In the example for this section, which you can find in the repo, the <kbd class="calibre12">en-it.txt</kbd> file was used for the English to Italian translation and it had 103,612 similar words, and hence you should probably create similar word transformation files for your models to be somewhat good in performance. Once you have the models and the transformation file, load the transformation file to a <kbd class="calibre12">word_pair</kbd> tuple and load the vectors to respective source target models. Once done, you can run code that looks like the following:</p>
<pre class="calibre17"><span>transmat</span> <span>=</span> <span>translation_matrix</span><span>.</span><span>TranslationMatrix</span><span>(</span><span>source_word_vec</span><span>,</span> <span>target_word_vec</span><span>,</span> <span>word_pair</span><span>)</span>
<span>transmat</span><span>.</span><span>train</span><span>(</span><span>word_pair</span><span>)</span>
<span>print</span> <span>(</span><span>"the shape of translation matrix is: "</span><span>,</span> <span>transmat</span><span>.</span><span>translation_matrix</span><span>.</span><span>shape</span><span>)</span></pre>
<p class="calibre2">At prediction time, for any given new word, we can map it to the other language space by computing <em class="calibre16">z</em> = <em class="calibre16">Wx</em>, and then we find the word that is closest in representation to the <em class="calibre16">z</em> <span class="calibre5">vector</span><span class="calibre5"> </span><span class="calibre5">in the target language space. The distance metric that is considered is the cosine similarity. This works similarly to the code shown here: </span></p>
<pre class="calibre17"># The pair is in the form of (English, Italian), we can see whether the translated word is correct<br class="title-page-name"/>words = [("one", "uno"), ("two", "due"), ("three", "tre"), ("four", "quattro"), ("five", "cinque")]<br class="title-page-name"/>source_word, target_word = zip(*words)<br class="title-page-name"/>translated_word = transmat.translate(source_word, 5)<br class="title-page-name"/>for k, v in translated_word.iteritems():<br class="title-page-name"/>    print ("word ", k, " and translated word", v)</pre>
<p class="calibre2">You should be able to see an output that looks similar to the following code:</p>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<pre class="calibre17">('word ', 'one', ' and translated word', [u'solo', u'due', u'tre', u'cinque', u'quattro'])
('word ', 'two', ' and translated word', [u'due', u'tre', u'quattro', u'cinque', u'otto'])
('word ', 'three', ' and translated word', [u'tre', u'quattro', u'due', u'cinque', u'sette'])
('word ', 'four', ' and translated word', [u'tre', u'quattro', u'cinque', u'due', u'sette'])
('word ', 'five', ' and translated word', [u'cinque', u'tre', u'quattro', u'otto', u'dieci'])</pre></div>
</div>
</div>
</div>
<p class="calibre2"><span class="calibre5">We can see that the translations are convincing. </span>The vectors are plotted on the following graph:</p>
<div class="cdpaligncenter"><img src="../images/00087.jpeg" class="calibre54"/></div>
<div class="mce-root">Vectors plotted on graph</div>
<p class="calibre2">Code on model training and assessing the visualizations in more detail is shown in the Jupyter notebook <kbd class="calibre12">gensim translation matrix with fasttext.ipynb</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Summary</h1>
                
            
            <article>
                
<p class="calibre2">With this, we have come to the end of this chapter, where we discussed how to perform training, validation, and prediction in a Python environment. To achieve that, we focused on two packages, the official fastText Python package and the Gensim package.</p>
<p class="calibre2">In the next chapter, we will take a look at how to integrate fastText into a machine learning or a deep learning pipeline.</p>


            </article>

            
        </section>
    </body></html>