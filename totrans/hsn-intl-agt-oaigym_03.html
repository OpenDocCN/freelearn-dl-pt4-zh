<html><head></head><body>
        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Getting Started with OpenAI Gym and Deep Reinforcement Learning</h1>
                
            
            <article>
                
<p class="calibre2">The introduction chapters gave you a good insight into the OpenAI Gym toolkit and reinforcement learning in general. In this chapter, we will jump right in and get you and your computer ready with all the required preparation, installations, and configurations to start developing your agents. More importantly, you will also find instructions to access the book's code repositories, which contain all the code you will need to follow this book in its entirety, along with several other code examples, useful instructions, and updates.</p>
<p class="calibre2">In this chapter, we will cover the following topics:</p>
<ul class="calibre10">
<li class="calibre11">Accessing the code repository for this book</li>
<li class="calibre11">Creating an Anaconda environment for working through this book</li>
<li class="calibre11">How to install and configure OpenAI Gym and dependencies on your system</li>
<li class="calibre11">Installing tools, libraries, and dependencies for deep reinforcement learning</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Code repository, setup, and configuration</h1>
                
            
            <article>
                
<p class="calibre2">First of all, let's make sure you have all the information to access the code repository for this book. The source code provides you with all the necessary code samples that we will discuss in this book and provides additional details on how to set up and run the training or testing scripts for each chapter<span class="calibre5"> </span><span class="calibre5">specifically. To get started, head to the book's code repository on</span> GitHub<span class="calibre5"> at the following link: </span><a href="https://github.com/PacktPublishing/Hands-On-Intelligent-Agents-with-OpenAI-Gym" class="calibre9">https://github.com/PacktPublishing/Hands-On-Intelligent-Agents-with-OpenAI-Gym</a>.</p>
<p class="calibre2">Create a GitHub account if you do not already have one and fork the repository so that it is added to your own GitHub account. This is recommended as it allows you to make any changes to the code you prefer while following along, and also allow you to send a pull request when you have something cool to show and be featured on the book's blog!</p>
<p class="calibre2">You can clone the repository to a folder named <kbd class="calibre12">HOIAWOG</kbd> in your home directory using the following command:</p>
<pre class="calibre17"><strong class="calibre1">git clone https://github.com/PacktPublishing/Hands-On-Intelligent-Agents-with-OpenAI-Gym.git ~/HOIAWOG</strong></pre>
<p class="calibre2">Note that the book assumes that you have set up the code repository at this particular location: <kbd class="calibre12">~/HOIAWOG</kbd>. If you happen to change it for some reason, be sure to remember it and change some of the commands in the book accordingly. </p>
<p class="calibre2">If you are wondering why the directory name was chosen to be <kbd class="calibre12">HOIAWOG</kbd>, do not think anymore. It is an acronym for this book's title: <strong class="calibre4">Hands On Intelligent Agents With OpenAI Gym</strong> (<strong class="calibre4">HOIAWOG</strong>)!</p>
<p class="calibre2">The book's code repository will be kept up to date to take care of any changes in the external libraries or other software, so that the intelligent agent implementation code and other code samples are functional. Occasionally, new code and updates will also be added to help you explore developing intelligent agents further. To stay on top of the changes and be notified of updates, it is recommended you star the book's code repository from your GitHub account.</p>
<p class="calibre2">Toward the end of <a href="part0021.html#K0RQ0-22c7fc7f93b64d07be225c00ead6ce12" class="calibre9">Chapter 1</a>, <em class="calibre13">Introduction to Intelligent Agents and Learning Environments</em>, we did a quick install of OpenAI Gym to get a sneak peak into the Gym. That was a minimal install, to get us started quickly. In the next section, we will go over the installation step by step and make sure everything you need to develop agents using the Gym is installed and configured properly. We will go over the different levels and methods of installation here so that you are aware of the installation process in general. You may end up modifying your system, or using another system at home or work, or changing your computer altogether. This section will make sure that you can get everything set up in the right way. Feel free to pick the installation method that is suitable for your use cases.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Prerequisites</h1>
                
            
            <article>
                
<p class="calibre2">The only main prerequisite for using OpenAI Gym is Python 3.5+. To make further development easy and organized, we will use the Anaconda Python distribution. For those of you who are not familiar with Anaconda, it is a Python <span class="calibre5">distribution</span><span class="calibre5"> </span><span class="calibre5">(although a distribution for the R language is also available) that includes hundreds of popular machine learning and data science packages and comes with an easy-to-use package and virtual environment manager called</span> <em class="calibre13">conda.</em> <span class="calibre5">The good thing is that the Anaconda Python distribution is available for Linux, macOS, and Windows! Another main reason to use the Anaconda distribution is that it helps in easily creating, installing, managing, and upgrading an isolated Python virtual environment. This makes sure the code we learn about and develop in this book produces the same results, irrespective of the operating system we use. This will relieve you from solving dependency issues or library version mismatch issues that you would have had to handle manually if you were not using a Python distribution such as Anaconda. You will find that it just works, which is nice and cool. Let's get started and install the Anaconda Python distribution.</span></p>
<p class="calibre2">Open a command prompt or Terminal and enter the following:</p>
<pre class="calibre17"><strong class="calibre1"><span>praveen@ubuntu:~$</span>wget http://repo.continuum.io/archive/Anaconda3-4.3.0-Linux-x86_64.sh -O ~/anaconda.sh</strong></pre>
<p class="calibre2">This command uses the <kbd class="calibre12">wget</kbd> tool to fetch/download the installation script for Anaconda version 3-4.3 and saves it as <kbd class="calibre12">anaconda.sh</kbd> in your home directory. This command should work on macOS and Linux (Ubuntu, Kubuntu, and so on), which come with the <kbd class="calibre12">wget</kbd> tool pre-installed. Note that we are downloading a specific version of Anaconda (3-4.3). This will make sure we have the same configuration throughout this book. Do not worry if this is not the latest version available. You can always upgrade the distribution later using this command:</p>
<pre class="calibre17"><strong class="calibre1">conda update conda</strong></pre>
<p class="calibre2"><kbd class="calibre12">anaconda.sh</kbd> is a shell script that has all the things that are needed to install Anaconda on your system! If you are interested, you can open it using your favorite text editor to see how cleverly the binaries, the installation process instructions, and the shell commands have been all lumped together into a single file.</p>
<p class="calibre2">Let's now install the Anaconda Python distribution under your home directory. The following installation process is carefully laid out to make sure it works both on Linux and macOS systems. Before you enter the command, you should be aware of one thing. The following command will run the installer in <em class="calibre13">silent mode</em>. This means that it will use the default installation parameters and go ahead with the installation, without asking you yes/no for each and every configuration. This also means that you agree to the Anaconda distribution's licensing terms. In case you want to manually go through the installation process step by step, run the following command without the arguments <kbd class="calibre12">-b</kbd> and <kbd class="calibre12">-f</kbd>:</p>
<pre class="calibre17"><strong class="calibre1">praveen@ubuntu:~$bash ~/anaconda.sh -b -f -p $HOME/anaconda</strong></pre>
<p class="calibre2">Wait for the installation process to complete and then we are done!</p>
<p class="calibre2">To start using <em class="calibre13">conda</em> and the other goodness in the Anaconda Python distribution, we should make sure that your system knows where to find the Anaconda tools. Let's add the Anaconda binaries directory by appending its path to the <kbd class="calibre12">PATH</kbd> environment variable, as shown here:</p>
<pre class="calibre17"><strong class="calibre1">praveen@ubuntu:~$export PATH=$HOME/anaconda/bin:$PATH</strong></pre>
<p class="calibre2">I strongly advise you to add this line to the end of your <kbd class="calibre12">~/.bashrc</kbd> file so that whenever you open a new bash terminal, the Anaconda tools are accessible.</p>
<p class="calibre2"> You can type the following command to make sure the installation was successful:</p>
<pre class="calibre17"><strong class="calibre1">praveen@ubuntu:~$conda list</strong></pre>
<p class="calibre2">This command will just print the list of packages available in your default environment.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Creating the conda environment</h1>
                
            
            <article>
                
<p class="calibre2">Now that we have set up Anaconda, let's use conda to create a Python virtual environment, which we will use throughout this book.</p>
<div class="packt_tip">If you prefer a one-click install setup and do not want to go through the installation step by step, a greatly simplified way to create the environment with all the necessary packages installed is using the <kbd class="calibre28">conda_env.yaml</kbd> conda environment configuration file available in the book's code repository. You can simply run the following command from the book's code repository directory (<kbd class="calibre28">HOIAWOG</kbd>) which we created in the previous section:<br class="calibre42"/>
<kbd class="calibre28">praveen@ubuntu:~/HOIAWOG$ conda create -f conda_env.yaml -n rl_gym_book</kbd></div>
<p class="calibre2">At this point, we will just create a new minimal environment to proceed. Enter the following command in a Terminal:</p>
<pre class="calibre17"><strong class="calibre1">praveen@ubuntu:~$conda create --name rl_gym_book python=3.5</strong></pre>
<p class="calibre2">This will create a conda environment named <kbd class="calibre12">rl_gym_book</kbd> with a Python3 interpreter. It will print some information about what is going to be downloaded and the packages that will be installed. You may be prompted with a yes/no question as to whether you want to proceed. Type <kbd class="calibre12">y</kbd> and hit <em class="calibre13">Enter</em>. Once the environment creation process is complete, you can activate that environment using the following command:</p>
<pre class="calibre17"><strong class="calibre1">praveen@ubuntu:~$source activate rl_gym_book</strong></pre>
<p class="calibre2">You will now see your command prompt's prefix changing to look something like this, to signify that you are inside the <kbd class="calibre12">rl_gym_book</kbd> virtual environment:</p>
<pre class="calibre17"><strong class="calibre1">(rl_gym_book) praveen@ubuntu:~$</strong></pre>
<p class="calibre2">You can use this as an indicator as you progress through the chapters to know when commands have to be entered inside this environment and when commands can be entered outside the environment. To exit or deactivate the environment, you can simply type this:</p>
<pre class="calibre17"><strong class="calibre1">praveen@ubuntu:~$source deactivate</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Minimal install – the quick and easy way</h1>
                
            
            <article>
                
<p class="calibre2">The OpenAI Gym is a Python package and is available in the <strong class="calibre4">Python Package Index</strong> (<strong class="calibre4">PyPI</strong>) repository. You can use <kbd class="calibre12">easy_install</kbd> or <kbd class="calibre12">pip</kbd> to fetch and install packages from the PyPI repository. <kbd class="calibre12">Pip</kbd> is a package management tool for Python, which most of you might be familiar with if you have experience scripting in Python:</p>
<pre class="calibre17"><strong class="calibre1">(rl_gym_book) praveen@ubuntu:~$pip install gym</strong></pre>
<p class="calibre2">That's it!</p>
<p class="calibre2">Let's quickly check the installation actually went fine by running the following code. Create a <kbd class="calibre12">gym_install_test.py</kbd> file under the <kbd class="calibre12">~/rl_gym_book</kbd> directory, type/copy the following code into it, and save it. You can also download the <kbd class="calibre12">gym_quick_install_test.py</kbd> file from the book's code repository:</p>
<pre class="calibre17">#! /usr/bin/env python  <br class="title-page-name"/>import gym<br class="title-page-name"/>env = gym.make("MountainCar-v0") # Create a MountainCar environment<br class="title-page-name"/>env.reset()<br class="title-page-name"/>for _ in range(2000): # Run for 2000 steps<br class="title-page-name"/>    env.render()<br class="title-page-name"/>    env.step(env.action_space.sample()) # Send a random action</pre>
<p class="calibre2">Let's try running the script:</p>
<pre class="calibre17"><strong class="calibre1">(rl_gym_book) praveen@ubuntu:~/HOIAWOG$python gym_quick_install_test.py</strong></pre>
<p class="calibre2">This should pop up a new window showing a car/carton and a v-shaped mountain, and you should see the car moving left and right randomly. The mountain car window should look something like this screenshot:</p>
<div class="cdpaligncenter"><img src="../images/00106.jpeg" class="calibre43"/></div>
<p class="calibre2">You will also see some values printed out to the console/Terminal that look like this:</p>
<div class="cdpaligncenter"><img src="../images/00107.jpeg" class="calibre44"/></div>
<p class="calibre2">If you saw this happening, then rejoice! You now have a (minimal) setup of OpenAI Gym!</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Complete install of OpenAI Gym learning environments</h1>
                
            
            <article>
                
<p class="calibre2">Not all environments are usable with the minimal installation. To be able to use most or all the environments available in the Gym, we will go through the installation of the dependencies and build OpenAI Gym from the latest source code on the master branch.</p>
<p class="calibre2">To get started, we will need to install the required system packages first. Next, you will find instructions for both Ubuntu and macOS. Choose the set of instructions based on your development platform.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Instructions for Ubuntu </h1>
                
            
            <article>
                
<p class="calibre2">The following commands were tested on Ubuntu 14.04 LTS and on Ubuntu 16.04 LTS, but should work in other/future Ubuntu releases as well. </p>
<p class="calibre2">Let's install the system packages needed by running the following command on the Terminal/console:</p>
<pre class="calibre17"><strong class="calibre1">sudo apt-get update</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">sudo apt-get install -y build-essential cmake python-dev python-numpy python-opengl libboost-all-dev zlib1g-dev libsdl2-dev libav-tools xorg-dev libjpeg-dev swig</strong></pre>
<p class="calibre2">This command will install the prerequisite system packages. Note that the <kbd class="calibre12">-y</kbd> flag will automatically say yes to confirm the installation of the package, without asking you to confirm manually. If you want to review the packages that are going to be installed for some reason, you may run the command without the flag.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Instructions for macOS</h1>
                
            
            <article>
                
<p class="calibre2">On macOS, the number of additional system packages that need to be installed is less than with Ubuntu systems.</p>
<p class="calibre2">Run the following commands from a Terminal:</p>
<pre class="calibre17"><strong class="calibre1">brew install cmake boost sdl2 swig wget</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">brew install boost-python --with-python3</strong></pre>
<p class="calibre2">These commands will install the prerequisite system packages.</p>
<div class="packt_infobox">The robotics and control environment in OpenAI Gym make use of <strong class="calibre27">Multi-Joint dynamics with Contact</strong> (<strong class="calibre27">MuJoCo</strong>) as the physics engine to simulate the rigid body dynamics and other features. We briefly had a look at MuJoCo environments in <a href="part0021.html#K0RQ0-22c7fc7f93b64d07be225c00ead6ce12" class="calibre45">Chapter 1</a><span class="packt_screen">, </span><em class="calibre46">Introduction to Intelligent Agents and Learning Environments</em><span class="packt_screen"> </span><span class="packt_screen">and learned that you can develop algorithms</span><span class="packt_screen"> that can make a 2D robot walk, run, swim, or hop, or a 3D multi-legged robot walk or run using the MuJoCo environment. MuJoCo is a proprietary engine and therefore needs a license. Fortunately, we can get a free 30-day license!<br class="calibre42"/></span><span class="packt_screen">Also, if you are a student, they offer a 1 year free MuJoCo Pro personal license, which is even better! For others, after the 30 days, sadly it costs a hefty sum (~$500 USD) for a 1 -year license. We will not be using the MuJoCo environments in this book because not everyone may be able to get hold of a license. You can always apply what you learn in this book regarding other environments to the MuJoCo environments if you have a license. If you plan to use these environments, you will have to follow the instructions in the MuJoCo installation section next. If not, you can skip it and go to the next section to set up OpenAI Gym.</span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">MuJoCo installation</h1>
                
            
            <article>
                
<p class="calibre2">I hope you read the previous information box. MuJoCo is one odd library that we will encounter in this book because, unlike other libraries and software we use as part of this book, MuJoCo requires a license to use. The Python interface for MuJoCo, available in the Gym library, is compatible only with MuJoCo version 1.31 as of the time this chapter was written, even though the latest available MuJoCo version is higher (1.50 at the time of writing this chapter). Follow these two steps to set up MuJoCo for use with OpenAI Gym environments:</p>
<ol class="calibre14">
<li value="1" class="calibre11">Download MuJoCo 1.31 for your platform (Linux/macOS) from this URL: <a href="https://www.roboti.us/index.html" class="calibre9">https://www.roboti.us/index.html</a></li>
<li value="2" class="calibre11">Obtain a MuJoCo Pro license from this URL: <a href="https://www.roboti.us/license.html" class="calibre9">https://www.roboti.us/license.html</a></li>
</ol>
<p class="calibre2"> </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Completing the OpenAI Gym setup</h1>
                
            
            <article>
                
<p class="calibre2">Let's update our version of pip first:</p>
<pre class="calibre17"><strong class="calibre1"><span>(rl_gym_book) praveen@ubuntu:~$</span><span> pip install --ignore-installed pip</span></strong></pre>
<p class="calibre2">Then, let's download the source code of OpenAI Gym from the GitHub repository into our home folder:</p>
<pre class="calibre17"><strong class="calibre1">(rl_gym_book) praveen@ubuntu:~$cd ~</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">(rl_gym_book) praveen@ubuntu:~$git clone https://github.com/openai/gym.git</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">(rl_gym_book) praveen@ubuntu:~$cd gym</strong></pre>
<div class="packt_tip">If you get an error saying <kbd class="calibre28">git command not found</kbd> or something similar, you might have to install Git. On Ubuntu systems, you can install it by running this command, <kbd class="calibre28">sudo apt-get install git</kbd>. On macOS, if you don't have Git installed already, it will prompt you to install it when you run the <kbd class="calibre28">git clone</kbd> command.</div>
<p class="calibre2">We are now in the final stage of a complete Gym installation! If you got a MuJoCo license and followed the MuJoCo installation instructions successfully, then you can go ahead and complete a full installation by running the following command:</p>
<pre class="calibre17"><strong class="calibre1">(rl_gym_book) praveen@ubuntu:~/gym$pip install -e '.[all]'</strong></pre>
<p class="calibre2">If you did not install MuJoCo, then this command will return errors. We will be installing the Gym environments that we will be using, other than MuJoCo (which requires a license to use). Make sure that you are still in the <kbd class="calibre12">gym</kbd><em class="calibre13"> </em>directory under your <kbd class="calibre12">home</kbd> folder, and also make sure that you are still inside the <kbd class="calibre12">rl_gym_book</kbd> conda environment. Your prompt should include the <kbd class="calibre12">rl_gym_book</kbd><strong class="calibre4"> </strong>prefix as follows, where <kbd class="calibre12">~/gym</kbd> means that the prompt is at the gym directory under the home folder:</p>
<pre class="calibre17"><span><span>(rl_gym_book) praveen@ubuntu:~/gym$<br class="title-page-name"/></span></span></pre>
<p class="calibre2"><span class="calibre5">Here is a table summarizing the installation commands for installing the environments that have been discussed in </span><a href="part0021.html#K0RQ0-22c7fc7f93b64d07be225c00ead6ce12" class="calibre9">Chapter 1</a><span class="calibre5">,</span><span class="calibre5"> </span><em class="calibre13">Introduction to Intelligent Agents and Learning Environments</em><span class="calibre5">.</span></p>
<table border="1" class="calibre47">
<tbody class="calibre36">
<tr class="calibre37">
<td class="calibre48"><strong class="calibre1">Environment</strong></td>
<td class="calibre48"><strong class="calibre1">Installation command</strong></td>
</tr>
<tr class="calibre37">
<td class="calibre48">Atari</td>
<td class="calibre48"><kbd class="calibre12">pip install -e '.[atari]'</kbd></td>
</tr>
<tr class="calibre37">
<td class="calibre48">Box2D</td>
<td class="calibre48">
<p class="calibre2"><kbd class="calibre12"><span>pip install -e '.[box2d]'</span></kbd></p>
<p class="calibre2"><kbd class="calibre12">conda install -c https://conda.anaconda.org/kne pybox2d</kbd></p>
</td>
</tr>
<tr class="calibre37">
<td class="calibre48">Classic control</td>
<td class="calibre48">
<p class="calibre2"><kbd class="calibre12"><span><span>pip install -e '.[classic_control]'</span></span></kbd></p>
</td>
</tr>
<tr class="calibre37">
<td class="calibre48">MuJoCo (requires license)</td>
<td class="calibre48"><kbd class="calibre12">pip install -e '.[mujoco]'</kbd></td>
</tr>
<tr class="calibre37">
<td class="calibre48">Robotics (requires license)</td>
<td class="calibre48">
<p class="calibre2"><kbd class="calibre12">pip install -e '.[robotics]'</kbd></p>
</td>
</tr>
</tbody>
</table>
<p class="calibre2">Let's go ahead and install the environments we do not need a license to use. Run the following commands to install Atarti, Box2D, and the classic control environments:</p>
<pre class="calibre17"><strong class="calibre1">(rl_gym_book) praveen@ubuntu:~/gym$pip install -e '.[atari]'</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">(rl_gym_book) praveen@ubuntu:~/gym$pip install -e '.[box2d]'</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">(rl_gym_book) praveen@ubuntu:~/gym$conda install -c https://conda.anaconda.org/kne pybox2d</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">(rl_gym_book) praveen@ubuntu:~/gym$pip install -e '.[classic_control]'</strong></pre>
<p class="calibre2">We are all set! We'll quickly run a check to make sure the installation went fine. Copy and paste the following code snippet into a file named <kbd class="calibre12">test_box2d.py</kbd><strong class="calibre4"> </strong>under the <kbd class="calibre12">~/rl_gym_book</kbd> directory:</p>
<pre class="calibre17">#!/usr/bin/env python<br class="title-page-name"/>import gym<br class="title-page-name"/>env = gym.make('BipedalWalker-v2')<br class="title-page-name"/>env.reset()<br class="title-page-name"/>for _ in range(1000):<br class="title-page-name"/>    env.render()<br class="title-page-name"/>    env.step(env.action_space.sample())</pre>
<p class="calibre2">Run that code using the following commands:</p>
<pre class="calibre17"><strong class="calibre1">(rl_gym_book) praveen@ubuntu:~/gym$cd ~/rl_gym_book</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">(rl_gym_book) praveen@ubuntu:~/rl_gym_book$python test_box2d.py</strong></pre>
<p class="calibre2">You will see a window pop up that shows the BipedalWalker-v2 environment and the walker trying to randomly perform some actions:</p>
<div class="cdpaligncenter"><img src="../images/00108.jpeg" class="calibre49"/></div>
<p class="calibre2">So, we have the Gym environment set up. What's next, you may ask. In the next section, we will set up the tools and libraries we need to develop deep reinforcement learning agents to train in these environments!</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Installing tools and libraries needed for deep reinforcement learning</h1>
                
            
            <article>
                
<p class="calibre2"><a href="part0033.html#VF2I0-22c7fc7f93b64d07be225c00ead6ce12" class="calibre9">Chapter 2</a>, <em class="calibre13">Reinforcement Learning and Deep Reinforcement Learning</em>, prepped you with the basics of reinforcement learning. With that theoretical background, we will be able to implement some cool algorithms. Before that, we will make sure we have the required tools and libraries at our disposal. </p>
<p class="calibre2">We can actually write cool reinforcement learning algorithms in Python without using any higher-level libraries. However, when we start to use function approximators for the value functions or the policy, and especially if we use deep neural networks as the function approximators, it is better to use highly optimized deep learning libraries instead of writing our own routines. A deep learning library is the major tool/library that we will need to install. There are different libraries out there today: PyTorch, TensorFlow, Caffe, Chainer, MxNet, and CNTK, to name a few. Each library has its own philosophy, merits, and demerits, depending on the use cases. We will be using PyTorch for developing the deep reinforcement learning algorithms in this book, due to its simplicity of use and dynamic graph definition. The algorithms we will discuss and the way we approach the implementation in this book will be explained in such a way that you can easily re-implement them using the framework of your choice.</p>
<p class="calibre2">If you do not have a GPU on your machine, or if you do not plan to use your GPU for training, you may skip the GPU driver installation steps and can install a CPU-only binary version of PyTorch using the following conda command:</p>
<pre class="calibre17"><strong class="calibre1">(rl_gym_book) praveen@ubuntu:~$ conda install pytorch-cpu torchvision -c pytorch</strong></pre>
<p class="calibre2">Note that you will <em class="calibre13">not</em><strong class="calibre4"> </strong>be able to accelerate the training of some of the agents we will develop as part of this book, which can utilize a GPU for faster training.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Installing prerequisite system packages</h1>
                
            
            <article>
                
<p class="calibre2">Let's begin by making sure we have the latest package versions from the Ubuntu upstream repositories. We can do that by running the following commands:</p>
<pre class="calibre17"><strong class="calibre1">sudo apt-get update</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">sudo apt-get upgrade</strong></pre>
<p class="calibre2">Next, we will install the prerequisite packages. Note</p>
<p class="calibre2">hat some of these packages may already have been installed on your system, but it is good to make sure we have them all:</p>
<pre class="calibre17"><strong class="calibre1">sudo apt-get install -y gfortran pkg-config software-properties-common</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Installing Compute Unified Device Architecture (CUDA)</h1>
                
            
            <article>
                
<p class="calibre2">If you do not have an Nvidia GPU or if you have an older Nvidia GPU that does not support CUDA, you can skip this step and move on to the next section, where we go over the PyTorch installation:</p>
<ol class="calibre14">
<li value="1" class="calibre11">Download the latest CUDA driver for your Nvidia GPU from the official Nvidia website here: <a href="https://developer.nvidia.com/cuda-downloads" class="calibre9">https://developer.nvidia.com/cuda-downloads</a>.</li>
<li value="2" class="calibre11">Choose <span>Linux</span> under the operating system and your architecture (mostly x86_64), and then choose your Linux OS distribution (Ubuntu) version 14.04, 16.04, or 18.04, depending on your version, and select <span>deb(local)</span> as the installer type. That will download the cuda local installation file, named something like <kbd class="calibre12">cuda-repo-ubuntu1604-8-0-local_8.0.44-1_amd64</kbd>. Note your cuda version (8.0 in this case). We will use this CUDA version later while installing PyTorch.</li>
<li value="3" class="calibre11">You can then follow the instructions or run the following command to install CUDA:</li>
</ol>
<pre class="calibre17"><strong class="calibre1">sudo dpkg -i cuda-repo-ubuntu*.deb</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">sudo apt-get update</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">sudo apt-get install -y cuda</strong></pre>
<p class="calibre2">If all goes well, you should now have Cuda successfully installed. To quickly check to see that everything went fine, run the following command:</p>
<pre class="calibre17"><strong class="calibre1">nvcc -V</strong></pre>
<p class="calibre2">This will print out the Cuda version information, similar to the output shown in the following screenshot. Note that your output may be different, depending on the version of Cuda you installed:</p>
<div class="cdpaligncenter"><img src="../images/00109.jpeg" class="calibre50"/></div>
<p class="calibre2">If you got an output similar to this, it's good news! </p>
<p class="calibre2">You may go ahead and install the latest <strong class="calibre4">CUDA Deep Neural Network</strong> (<strong class="calibre4">cuDNN</strong>) on your system. We will not cover the installation steps in this book, but the installation steps are straightforward and listed on the Nvidia official CuDNN download page here: <a href="https://developer.nvidia.com/rdp/form/cudnn-download-survey" class="calibre9">https://developer.nvidia.com/rdp/form/cudnn-download-survey</a>. Note that you need to register for a free Nvidia developer account to download it.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Installing PyTorch</h1>
                
            
            <article>
                
<p class="calibre2">We are now ready to install PyTorch! Fortunately, it is as simple as running the following command inside our <kbd class="calibre12">rl_gym_book</kbd><strong class="calibre4"> </strong>conda environment:</p>
<pre class="calibre17"><strong class="calibre1">(rl_gym_book) praveen@ubuntu:~$ conda install pytorch torchvision -c pytorch</strong></pre>
<p class="calibre2">Note that this command will install <span class="calibre5">PyTorch</span> with CUDA 8.0. You noted the CUDA version that you installed before, and the command may change slightly depending on which CUDA version you installed. For example, if you installed CUDA 9.1, the command to install will be this:</p>
<p class="calibre2"><kbd class="calibre12">conda install pytorch torchvision cuda91 -c pytorch</kbd></p>
<p class="calibre2">You can find the updated command to install at <a href="http://pytorch.org" class="calibre9">http://pytorch.org</a> based on your OS, package manager (conda or pip or from source), Python version (we use 3.5), and CUDA version.</p>
<p class="calibre2">That's it! Let's quickly try importing the PyTorch library and make sure it works. Type or copy the following lines of code into a file named <kbd class="calibre12">pytorch_test.py</kbd><strong class="calibre4"> </strong>under the <kbd class="calibre12">~/rl_gym_book</kbd> directory:</p>
<pre class="calibre17">#!/usr/bin/env python<br class="title-page-name"/>import torch<br class="title-page-name"/>t = torch.Tensor(3,3) # Create a 3,3 Tensor<br class="title-page-name"/>print(t)</pre>
<p class="calibre2">Run this script inside the <kbd class="calibre12">rl_gym_book</kbd><strong class="calibre4"> </strong>conda environment. The following screenshot is provided as an example:</p>
<div class="cdpaligncenter"><img src="../images/00110.jpeg" class="calibre51"/></div>
<p class="calibre2">Note that you may see different values for the tensor, and you may see different values when you run the script another time. It is because of the torch. The <kbd class="calibre12">Tensor()</kbd> function generates a random tensor of the given shape, (3, 3) in our case. PyTorch follows similar syntax to NumPy. If you are familiar with NumPy, you can pick up PyTorch easily. If you are not familiar with NumPy or PyTorch, it is advised that you follow the official PyTorch tutorial to get yourself acquainted with it. </p>
<div class="packt_infobox">You may notice that the folder name used in some of the sample console screenshots is <kbd class="calibre28">read rl_gym_book</kbd> rather than HOIAWOG. Both these directory names are interchangeable. In fact, they are symbolic links pointing to the same directory.</div>
<p class="calibre2"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Summary</h1>
                
            
            <article>
                
<p class="calibre2">In this chapter, we went through the <span class="calibre5">step-by-step</span><span class="calibre5"> </span><span class="calibre5">setup process to install and configure our development environment using conda, OpenAI Gym, and Pytorch! This chapter helped us make sure that we have all the required tools and libraries installed to start developing our agents in Gym environments. In the next chapter, we will explore the features of Gym environments to understand how they work, and how we can use them to train our agents. In</span> <a href="part0078.html#2ACBS0-22c7fc7f93b64d07be225c00ead6ce12" class="calibre9">Chapter 5</a><span class="calibre5">, <em class="calibre13">Implementing Your First Learning Agent – Solving the Mountain Car Problem</em>, we will jump right into developing our first reinforcement learning agent to solve the mountain car problem! We will then gradually move on and implement more sophisticated reinforcement learning algorithms in the subsequent chapters.</span></p>


            </article>

            
        </section>
    </body></html>