["```py\n    import matplotlib.pyplot as plt\n    import torch.nn.functional as F\n    from torch.nn import Linear, Sequential, BatchNorm1d, ReLU, Dropout\n    from torch_geometric.datasets import TUDataset\n    from torch_geometric.loader import DataLoader\n    from torch_geometric.nn import GINConv, global_add_pool, GNNExplainer\n    ```", "```py\n    dataset = TUDataset(root='.', name='MUTAG').shuffle()\n    ```", "```py\n    train_dataset = dataset[:int(len(dataset)*0.8)]\n    val_dataset   = dataset[int(len(dataset)*0.8):int(len(dataset)*0.9)]\n    test_dataset  = dataset[int(len(dataset)*0.9):]\n    ```", "```py\n    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n    val_loader   = DataLoader(val_dataset, batch_size=64, shuffle=True)\n    test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=True)\n    ```", "```py\n    class GIN(torch.nn.Module):\n    ...\n    model = GIN(dim_h=32)\n    ```", "```py\n    def train(model, loader):\n     ...\n    model = train(model, train_loader)\n    test_loss, test_acc = test(model, test_loader)\n    print(f'Test Loss: {test_loss:.2f} | Test Acc: {test_acc*100:.2f}%')\n    Test Loss: 0.48 | Test Acc: 84.21%\n    ```", "```py\n    explainer = GNNExplainer(model, epochs=100, num_hops=1)\n    ```", "```py\n    data = dataset[-1]\n    feature_mask, edge_mask = explainer.explain_graph(data.x, data.edge_index)\n    ```", "```py\n    feature_mask\n    tensor([0.7401, 0.7375, 0.7203, 0.2692, 0.2587, 0.7516, 0.2872])\n    ```", "```py\n    ax, G = explainer.visualize_subgraph(-1, data.edge_index, edge_mask, y=data.y)\n    plt.show()\n    ```", "```py\n    !pip install captum\n    ```", "```py\n    import numpy as np\n    import matplotlib.pyplot as plt\n    import torch.nn.functional as F\n    from captum.attr import IntegratedGradients\n    import torch_geometric.transforms as T\n    from torch_geometric.datasets import Twitch\n    from torch_geometric.nn import Explainer, GCNConv, to_captum\n    ```", "```py\n    torch.manual_seed(0)\n    np.random.seed(0)\n    ```", "```py\n    dataset = Twitch('.', name=\"EN\")\n    data = dataset[0]\n    ```", "```py\n    class GCN(torch.nn.Module):\n        def __init__(self, dim_h):\n            super().__init__()\n            self.conv1 = GCNConv(dataset.num_features, dim_h)\n            self.conv2 = GCNConv(dim_h, dataset.num_classes)\n        def forward(self, x, edge_index):\n            h = self.conv1(x, edge_index).relu()\n            h = F.dropout(h, p=0.5, training=self.training)\n            h = self.conv2(h, edge_index)\n            return F.log_softmax(h, dim=1)\n    ```", "```py\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model = GCN(64).to(device)\n    data = data.to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n    ```", "```py\n    for epoch in range(200):\n        model.train()\n        optimizer.zero_grad()\n        log_logits = model(data.x, data.edge_index)\n        loss = F.nll_loss(log_logits, data.y)\n        loss.backward()\n        optimizer.step()\n    ```", "```py\n    def accuracy(pred_y, y):\n        return ((pred_y == y).sum() / len(y)).item()\n    @torch.no_grad()\n    def test(model, data):\n        model.eval()\n        out = model(data.x, data.edge_index)\n        acc = accuracy(out.argmax(dim=1), data.y)\n        return acc\n    acc = test(model, data)\n    print(f'Accuracy: {acc*100:.2f}%')\n    Accuracy: 79.75%\n    ```", "```py\n    node_idx = 0\n    captum_model = to_captum(model, mask_type='node_and_edge', output_idx=node_idx)\n    ```", "```py\n    ig = IntegratedGradients(captum_model)\n    ```", "```py\n    edge_mask = torch.ones(data.num_edges, requires_grad=True, device=device)\n    ```", "```py\n    attr_node, attr_edge = ig.attribute(\n        (data.x.unsqueeze(0), edge_mask.unsqueeze(0)),\n        target=int(data.y[node_idx]),\n        additional_forward_args=(data.edge_index),\n        internal_batch_size=1)\n    ```", "```py\n    attr_node = attr_node.squeeze(0).abs().sum(dim=1)\n    attr_node /= attr_node.max()\n    attr_edge = attr_edge.squeeze(0).abs()\n    attr_edge /= attr_edge.max()\n    ```", "```py\n    explainer = Explainer(model)\n    ax, G = explainer.visualize_subgraph(node_idx, data.edge_index, attr_edge, node_alpha=attr_node, y=data.y)\n    plt.show()\n    ```"]