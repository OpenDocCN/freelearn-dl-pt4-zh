- en: Generative Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Generative models are the family of machine learning models that are used to
    describe how data is generated. To train a generative model we first accumulate
    a vast amount of data in any domain and later train a model to create or generate
    data like it.
  prefs: []
  type: TYPE_NORMAL
- en: In other words, these are the models that can learn to create data that is similar
    to data that we give them. One such approach is using **Generative Adversarial
    Networks (GANs)**, which will be discussed as part of this chapter in detail.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to generative models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GANs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generative models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are two kinds of machine learning models: generative models and discriminative
    models. Let''s examine the following list of classifiers: decision trees, neural
    networks, random forests, generalized boosted models, logistic regression, naive
    bayes, and **Support Vector Machine** (**SVM**). Most of these are classifiers
    and ensemble models. The odd one out here is Naive Bayes. It''s the only generative
    model in the list. The others are examples of discriminative models.'
  prefs: []
  type: TYPE_NORMAL
- en: The fundamental difference between generative and discriminative models lies
    in the underlying probability inference structure. In this chapter, we will study
    the key concepts of generative models like types and GANs, but before that, let's
    go through some of the key differences between generative and discriminative models.
  prefs: []
  type: TYPE_NORMAL
- en: Discriminative versus generative models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Discriminative models learn *P(Y|X),* which is the conditional relationship
    between the target variable *Y* and features *X*. This is how least squares regression
    works, and it is the kind of inference pattern that gets used. It is an approach
    to sort out the relationship among variables.
  prefs: []
  type: TYPE_NORMAL
- en: Generative models aim for a complete probabilistic description of the dataset.
    With generative models, the goal is to develop the joint probability distribution
    *P(X, Y)*, either directly or by computing *P(Y | X)* and *P(X)* and then inferring
    the conditional probabilities required to classify newer data. This method requires
    more solid probabilistic thought than regression demands, but it provides a complete
    model of the probabilistic structure of the data. Knowing the joint distribution
    enables you to generate the data; hence, Naive Bayes is a generative model.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose we have a supervised learning task, where *x[i]* is the given features
    of the data points and *y[i]* is the corresponding labels. One way to predict
    *y* on future *x* is to learn a function *f()* from *(x[i],y[i])* that takes in
    *x* and outputs the most likely *y*. Such models fall in the category of discriminative
    models, as you are learning how to discriminate between *x*'s from different classes.
    Methods like SVMs and neural networks fall into this category. Even if you're
    able to classify the data very accurately, you have no notion of how the data
    might have been generated.
  prefs: []
  type: TYPE_NORMAL
- en: The second approach is to model how the data might have been generated and learn
    a function *f(x,y)* that gives a score to the configuration determined by *x*
    and *y* together. Then you can predict *y* for a new *x* by finding the *y* for
    which the score *f(x,y)* is maximum. A canonical example of this is Gaussian mixture
    models.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another example of this is: you can imagine *x* to be an image and *y* to be
    a kind of object like a dog, namely in the image. The probability written as *p(y|x)*
    tells us how much the model believes that there is a dog, given an input image
    compared to all possibilities it knows about. Algorithms that try to model this
    probability map directly are called **discriminative models**.'
  prefs: []
  type: TYPE_NORMAL
- en: Generative models, on the other hand, try to learn a function called the joint
    probability *p(y, x)*. We can read this as how much the model believes that *x*
    is an image and there is a dog *y* in it at the same time. These two probabilities
    are related and that could be written as *p(y, x) = p(x) p(y|x)*, with *p(x)*
    being how likely it is that the input *x* is an image. The *p(x)* probability
    is usually called a **density function** in literature.
  prefs: []
  type: TYPE_NORMAL
- en: The main reason to call these models generative ultimately connects to the fact
    that the model has access to the probability of both input and output at the same
    time. Using this, we can generate images of animals by sampling animal kinds *y*
    and new images *x* from *p(y, x)*.
  prefs: []
  type: TYPE_NORMAL
- en: We can mainly learn the density function *p(x)* which only depends on the input
    space.
  prefs: []
  type: TYPE_NORMAL
- en: Both models are useful; however, comparatively, generative models have an interesting
    advantage over discriminative models, namely, they have the potential to understand
    and explain the underlying structure of the input data even when there are no
    labels available. This is very desirable when working in the real world.
  prefs: []
  type: TYPE_NORMAL
- en: Types of generative models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Discriminative models have been at the forefront of the recent success in the
    field of machine learning. Models make predictions that depend on a given input,
    although they are not able to generate new samples or data.
  prefs: []
  type: TYPE_NORMAL
- en: The idea behind the recent progress of generative modeling is to convert the
    generation problem to a prediction one and use deep learning algorithms to learn
    such a problem.
  prefs: []
  type: TYPE_NORMAL
- en: Autoencoders
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One way to convert a generative to a discriminative problem can be by learning
    the mapping from the input space itself. For example, we want to learn an identity
    map that, for each image *x*, would ideally predict the same image, namely, *x
    = f(x)*, where *f* is the predictive model.
  prefs: []
  type: TYPE_NORMAL
- en: This model may not be of use in its current form, but from this, we can create
    a generative model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we create a model formed of two main components: an encoder model *q(h|x)*
    that maps the input to another space, which is referred to as hidden or the latent
    space represented by *h*, and a decoder model *q(x|h)* that learns the opposite
    mapping from the hidden input space.'
  prefs: []
  type: TYPE_NORMAL
- en: These components--encoder and decoder--are connected together to create an end-to-end
    trainable model. Both the encoder and decoder models are neural networks of different
    architectures, for example, RNNs and Attention Nets, to get desired outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: As the model is learned, we can remove the decoder from the encoder and then
    use them separately. To generate a new data sample, we can first generate a sample
    from the latent space and then feed that to the decoder to create a new sample
    from the output space.
  prefs: []
  type: TYPE_NORMAL
- en: Autoencoders are covered in more detail in [Chapter 8](130cc1c9-51d3-4ba5-95d3-12bb53dee5bd.xhtml),
    *Autoencoders* .
  prefs: []
  type: TYPE_NORMAL
- en: GAN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As seen with autoencoders, we can think of a general concept to create networks
    that will work together in a relationship, and training them will help us learn
    the latent spaces that allow us to generate new data samples.
  prefs: []
  type: TYPE_NORMAL
- en: Another type of generative network is GAN, where we have a generator model *q(x|h)*
    to map the small dimensional latent space of *h* (which is usually represented
    as noise samples from a simple distribution) to the input space of *x*. This is
    quite similar to the role of decoders in autoencoders.
  prefs: []
  type: TYPE_NORMAL
- en: The deal is now to introduce a discriminative model *p(y| x),* which tries to
    associate an input instance *x* to a yes/no binary answer *y*, about whether the
    generator model generated the input or was a genuine sample from the dataset we
    were training on.
  prefs: []
  type: TYPE_NORMAL
- en: Let's use the image example done previously. Assume that the generator model
    creates a new image, and we also have the real image from our actual dataset.
    If the generator model was right, the discriminator model would not be able to
    distinguish between the two images easily. If the generator model was poor, it
    would be very simple to tell which one was a fake or fraud and which one was real.
  prefs: []
  type: TYPE_NORMAL
- en: When both these models are coupled, we can train them end to end by assuring
    that the generator model is getting better over time to fool the discriminator
    model, while the discriminator model is trained to work on the harder problem
    of detecting frauds. Finally, we desire a generator model with outputs that are
    indistinguishable from the real data that we used for the training.
  prefs: []
  type: TYPE_NORMAL
- en: 'Through the initial parts of the training, the discriminator model can easily
    detect the samples coming from the actual dataset versus the ones generated synthetically
    by the generator model, which is just beginning to learn. As the generator gets
    better at modeling the dataset, we begin to see more and more generated samples
    that look similar to the dataset. The following example depicts the generated
    images of a GAN model learning over time:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ba581ac8-3fa3-42cc-ac63-18e7597d0d06.png)'
  prefs: []
  type: TYPE_IMG
- en: In the upcoming sections, we will discuss GANs in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Sequence models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If the data is temporal in nature, then we can use specialized algorithms called
    **Sequence Models**. These models can learn the probability of the form *p(y|x_n,
    x_1)*, where *i* is an index signifying the location in the sequence and *x_i*
    is the *i^(th)* input sample.
  prefs: []
  type: TYPE_NORMAL
- en: As an example, we can consider each word as a series of characters, each sentence
    as a series of words, and each paragraph as a series of sentences. Output *y*
    could be the sentiment of the sentence.
  prefs: []
  type: TYPE_NORMAL
- en: Using a similar trick from autoencoders, we can replace *y* with the next item
    in the series or sequence, namely *y =x_n + 1*, allowing the model to learn.
  prefs: []
  type: TYPE_NORMAL
- en: GANs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'GANs were introduced by a group of researchers at the University of Montreal
    led by *Ian Goodfellow*. The core idea behind a GAN model is to have two competing
    neural network models. One network takes the noise as input and generates samples
    (hence known as **generator**). The second model (known as **discriminator**)
    gets samples from both the generator and the actual training data, and should
    be able to differentiate between the two sources. Generative and discriminative
    networks are playing a continuous game, where the generator model is learning
    to generate more realistic samples or examples, and the discriminator is learning
    to get better and better at differentiating generated data from the real data.
    The two networks are trained simultaneously, and the goal is that the competition
    will make the generated samples indistinguishable from the real data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/746e5e26-9573-47b6-8569-d28866ce5966.png)'
  prefs: []
  type: TYPE_IMG
- en: The analogy used to describe GANs is that the generator is like a forger that
    is attempting to produce some forged material, and the discriminator model is
    the police trying to detect the forged items. This may seem somewhat similar to
    reinforcement learning where the generator is getting a reward from the discriminator,
    allowing it to know whether the generated data is accurate or not. The key distinction
    with GANs is that we can backpropagate gradient information from the discriminator
    network back to the generator network, such that the generator knows how to adapt
    its parameters in order to generate output data that can fool the discriminator.
  prefs: []
  type: TYPE_NORMAL
- en: As of today, GANs have been mainly applied to model natural images. They provide
    best results in image generation tasks and also in generating images that are
    sharper than the ones trained using other generative methods based on maximum
    likelihood training objectives.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some examples of images generated by GANs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2a4a2461-6921-4252-ad7b-9bbc56cf8ce4.png)'
  prefs: []
  type: TYPE_IMG
- en: GAN with an example
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For a deeper understanding of how GANs work, we'll use a GAN to solve a simple
    problem in TensorFlow, namely, learning to approximate a one-dimensional Gaussian
    distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will create the actual data distribution, a simple Gaussian with
    a mean of four and standard deviation of 0.5\. It has a sample function that returns
    a given number of samples (sorted by value) from the distribution. The data distribution
    that we learn will look like the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/066437dd-ffad-443b-8b62-c1429b9d428b.png)'
  prefs: []
  type: TYPE_IMG
- en: Generator input noise distribution is also defined with a similar sample function
    used for actual data.
  prefs: []
  type: TYPE_NORMAL
- en: Both generator and discriminator networks are very simple. Generator is a linear
    transformation passed through a non linearity (`softplus` function), followed
    by another linear transformation.
  prefs: []
  type: TYPE_NORMAL
- en: We kept the discriminator stronger than the generator; otherwise, it would not
    have enough capacity to learn to be able to differentiate accurately between generated
    and real samples. Hence, we made it a deeper neural network with a higher number
    of dimensions. We use *tanh* non linearities in all layers except the final one,
    which is a sigmoid (the output of which can be described as a probability).
  prefs: []
  type: TYPE_NORMAL
- en: We connect these networks as part of the TensorFlow graph and define loss functions
    for each of the networks so that the generator network will be simply fooling
    the discriminator network. The Gradient Descent Optimizer from TensorFlow with
    exponential learning rate decay is used as an optimizer.
  prefs: []
  type: TYPE_NORMAL
- en: To train the model, we draw samples from the data distribution and the noise
    distribution, and alternate between optimizing the parameters of the discriminator
    and the generator.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will see that, at the start of the training method, the generator was generating
    a very different distribution to the real data. The network slowly learns to approximate
    it quite closely before converging to a narrower distribution focused on the mean
    of the input distribution. After training the networks, the two distributions
    look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fdf1eb31-e0b5-4821-ab33-1801f9c0fd20.png)'
  prefs: []
  type: TYPE_IMG
- en: The problem of the generator network falling to a param setting where it generates
    a very narrow distribution or pattern of points is one of the major failures of
    GANs. The solution will be to allow the discriminator to look at multiple samples
    at once, a technique that we call minibatch discrimination. Minibatch discrimination
    is a method wherein the discriminator can glance at an entire batch of samples
    to determine whether they come from the generator network or from the actual data.
  prefs: []
  type: TYPE_NORMAL
- en: 'A summary of the method is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Take the output of any intermediate layer of the discriminator network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiply this output by a 3D tensor to generate a matrix of size *numOfKernels
    ** *kernelDim*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calculate the L1-distance between rows in this matrix across all samples in
    a batch, and then apply a negative exponential
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minibatch features or properties for a sample are then the sum of these exponentiated
    distances
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Concatenate the actual input to the mini batch layer, that is, output of the
    previous or former discriminator layer with the created minibatch features, and
    then pass this as input to the next layer of the discriminator network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Minibatch discrimination makes the batch size as important as a hyperparameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Output Listing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Types of GANs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The following section shows different types of GANs, for example, Vanilla GAN,
    Conditional GAN etc. Refer to [https://arxiv.org](https://arxiv.org) for further
    information on the papers. The following description about each GAN network is
    taken from the respective paper on [https://arxiv.org](https://arxiv.org).
  prefs: []
  type: TYPE_NORMAL
- en: Vanilla GAN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Vanilla GANs has two networks called generator network and a discriminator network.
    Both the networks are trained at the same time and compete or battle against each
    other in a minimax play. Generator network is trained or prepared such that it
    can fool the discriminator network by creating the real images as per the input,
    and the discriminator is trained not to be fooled by the generator network.
  prefs: []
  type: TYPE_NORMAL
- en: For further reading on Vanilla GAN refer to [https://arxiv.org/abs/1406.2661](https://arxiv.org/abs/1406.2661).
  prefs: []
  type: TYPE_NORMAL
- en: Conditional GAN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GANs was started as a novel way of generative training models. These are GAN
    networks that utilize extra label data. It results in excellent quality images
    and being able to control to an extent how generated images will look. This model
    can be used to learn a multi-modal model.
  prefs: []
  type: TYPE_NORMAL
- en: For further reading on Conditional GAN refer to [https://arxiv.org/abs/1411.1784.](https://arxiv.org/abs/1411.1784.)
  prefs: []
  type: TYPE_NORMAL
- en: Info GAN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GANs that can encode or learn important image features or disentangled representations
    in an unsupervised manner. An example is to encode the rotation of a digit. Info
    GANs also maximizes the mutual information between a small subset of the latent
    variables and the observation.
  prefs: []
  type: TYPE_NORMAL
- en: For further reading on Info GAN refer to [https://arxiv.org/abs/1606.03657](https://arxiv.org/abs/1606.03657)
  prefs: []
  type: TYPE_NORMAL
- en: Wasserstein GAN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: WGAN is an option to regular GAN training. WGANs have loss functions that correlate
    with image quality. Additionally, the stability of the training improves and is
    not as dependent on the architecture and provide significant learning curves useful
    for debugging.
  prefs: []
  type: TYPE_NORMAL
- en: For further reading on Wasserstein GAN refer to [https://arxiv.org/abs/1701.07875](https://arxiv.org/abs/1701.07875)
  prefs: []
  type: TYPE_NORMAL
- en: Coupled GAN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Coupled GANs is used for generating sets of like images in two separate domains.
    It consists of set of GANs each accountable for generating images in the single
    domain. The Coupled GANs learns a joint distribution from images in the two domains
    which are drawn separately from the marginal distributions of the unique domains.
  prefs: []
  type: TYPE_NORMAL
- en: For further reading on Coupled GAN refer to [https://arxiv.org/abs/1606.07536](https://arxiv.org/abs/1606.07536)
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Generative models are a fast advancing area of study and research. As we proceed
    to advance these models and grow the training and datasets, we can expect to generate
    data examples that depict completely believable images, finally. This can be used
    in several applications such as image denoising, painting, structured prediction,
    and exploration in reinforcement learning.
  prefs: []
  type: TYPE_NORMAL
- en: The deeper promise of this effort is that, in the process of building generative
    models, we will enrich the computer with an understanding of the world and what
    elements it is made up of.
  prefs: []
  type: TYPE_NORMAL
