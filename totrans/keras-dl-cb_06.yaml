- en: Generative Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成模型
- en: Generative models are the family of machine learning models that are used to
    describe how data is generated. To train a generative model we first accumulate
    a vast amount of data in any domain and later train a model to create or generate
    data like it.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型是机器学习模型的一类，用于描述数据是如何生成的。为了训练一个生成模型，我们首先收集大量的领域数据，然后训练一个模型来生成类似的数据。
- en: In other words, these are the models that can learn to create data that is similar
    to data that we give them. One such approach is using **Generative Adversarial
    Networks (GANs)**, which will be discussed as part of this chapter in detail.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，这些模型可以学习生成与我们提供的数据相似的数据。一个这样的方式是使用**生成对抗网络（GANs）**，本章将详细讨论这一部分内容。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Introduction to generative models
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成模型简介
- en: GANs
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GANs
- en: Generative models
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成模型
- en: 'There are two kinds of machine learning models: generative models and discriminative
    models. Let''s examine the following list of classifiers: decision trees, neural
    networks, random forests, generalized boosted models, logistic regression, naive
    bayes, and **Support Vector Machine** (**SVM**). Most of these are classifiers
    and ensemble models. The odd one out here is Naive Bayes. It''s the only generative
    model in the list. The others are examples of discriminative models.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型有两种类型：生成模型和判别模型。我们来看以下分类器的列表：决策树、神经网络、随机森林、广义增强模型、逻辑回归、朴素贝叶斯和**支持向量机（SVM）**。其中大多数是分类器和集成模型，唯一的例外是朴素贝叶斯，它是列表中的唯一生成模型。其他的则是判别模型的例子。
- en: The fundamental difference between generative and discriminative models lies
    in the underlying probability inference structure. In this chapter, we will study
    the key concepts of generative models like types and GANs, but before that, let's
    go through some of the key differences between generative and discriminative models.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型和判别模型的根本区别在于它们的概率推理结构。在本章中，我们将学习生成模型的关键概念，如类型和 GANs，但在此之前，让我们先了解一下生成模型和判别模型之间的一些关键区别。
- en: Discriminative versus generative models
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 判别模型与生成模型的区别
- en: Discriminative models learn *P(Y|X),* which is the conditional relationship
    between the target variable *Y* and features *X*. This is how least squares regression
    works, and it is the kind of inference pattern that gets used. It is an approach
    to sort out the relationship among variables.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 判别模型学习 *P(Y|X)*，即目标变量 *Y* 和特征 *X* 之间的条件关系。这就是最小二乘回归的工作原理，也是使用的推理模式。它是一种用于解决变量之间关系的推理方法。
- en: Generative models aim for a complete probabilistic description of the dataset.
    With generative models, the goal is to develop the joint probability distribution
    *P(X, Y)*, either directly or by computing *P(Y | X)* and *P(X)* and then inferring
    the conditional probabilities required to classify newer data. This method requires
    more solid probabilistic thought than regression demands, but it provides a complete
    model of the probabilistic structure of the data. Knowing the joint distribution
    enables you to generate the data; hence, Naive Bayes is a generative model.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型旨在对数据集进行完整的概率描述。使用生成模型时，目标是开发联合概率分布 *P(X, Y)*，可以直接计算 *P(Y | X)* 和 *P(X)*，然后推断分类新数据所需的条件概率。与回归模型相比，这种方法需要更为扎实的概率思维，但它提供了数据概率结构的完整模型。了解联合分布后，你可以生成数据；因此，朴素贝叶斯就是一个生成模型。
- en: Suppose we have a supervised learning task, where *x[i]* is the given features
    of the data points and *y[i]* is the corresponding labels. One way to predict
    *y* on future *x* is to learn a function *f()* from *(x[i],y[i])* that takes in
    *x* and outputs the most likely *y*. Such models fall in the category of discriminative
    models, as you are learning how to discriminate between *x*'s from different classes.
    Methods like SVMs and neural networks fall into this category. Even if you're
    able to classify the data very accurately, you have no notion of how the data
    might have been generated.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个监督学习任务，其中 *x[i]* 是数据点的给定特征，*y[i]* 是对应的标签。预测未来 *x* 上的 *y* 的一种方法是学习一个函数
    *f()*，它从 *(x[i], y[i])* 中获取 *x* 并输出最可能的 *y*。这样的模型属于判别模型，因为你正在学习如何区分来自不同类别的 *x*。像
    SVM 和神经网络这样的算法就属于这一类。即使你能够非常准确地分类数据，你也无法知道数据是如何生成的。
- en: The second approach is to model how the data might have been generated and learn
    a function *f(x,y)* that gives a score to the configuration determined by *x*
    and *y* together. Then you can predict *y* for a new *x* by finding the *y* for
    which the score *f(x,y)* is maximum. A canonical example of this is Gaussian mixture
    models.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: 'Another example of this is: you can imagine *x* to be an image and *y* to be
    a kind of object like a dog, namely in the image. The probability written as *p(y|x)*
    tells us how much the model believes that there is a dog, given an input image
    compared to all possibilities it knows about. Algorithms that try to model this
    probability map directly are called **discriminative models**.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Generative models, on the other hand, try to learn a function called the joint
    probability *p(y, x)*. We can read this as how much the model believes that *x*
    is an image and there is a dog *y* in it at the same time. These two probabilities
    are related and that could be written as *p(y, x) = p(x) p(y|x)*, with *p(x)*
    being how likely it is that the input *x* is an image. The *p(x)* probability
    is usually called a **density function** in literature.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: The main reason to call these models generative ultimately connects to the fact
    that the model has access to the probability of both input and output at the same
    time. Using this, we can generate images of animals by sampling animal kinds *y*
    and new images *x* from *p(y, x)*.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: We can mainly learn the density function *p(x)* which only depends on the input
    space.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Both models are useful; however, comparatively, generative models have an interesting
    advantage over discriminative models, namely, they have the potential to understand
    and explain the underlying structure of the input data even when there are no
    labels available. This is very desirable when working in the real world.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: Types of generative models
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Discriminative models have been at the forefront of the recent success in the
    field of machine learning. Models make predictions that depend on a given input,
    although they are not able to generate new samples or data.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: The idea behind the recent progress of generative modeling is to convert the
    generation problem to a prediction one and use deep learning algorithms to learn
    such a problem.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: Autoencoders
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One way to convert a generative to a discriminative problem can be by learning
    the mapping from the input space itself. For example, we want to learn an identity
    map that, for each image *x*, would ideally predict the same image, namely, *x
    = f(x)*, where *f* is the predictive model.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: This model may not be of use in its current form, but from this, we can create
    a generative model.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we create a model formed of two main components: an encoder model *q(h|x)*
    that maps the input to another space, which is referred to as hidden or the latent
    space represented by *h*, and a decoder model *q(x|h)* that learns the opposite
    mapping from the hidden input space.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: These components--encoder and decoder--are connected together to create an end-to-end
    trainable model. Both the encoder and decoder models are neural networks of different
    architectures, for example, RNNs and Attention Nets, to get desired outcomes.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: As the model is learned, we can remove the decoder from the encoder and then
    use them separately. To generate a new data sample, we can first generate a sample
    from the latent space and then feed that to the decoder to create a new sample
    from the output space.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: Autoencoders are covered in more detail in [Chapter 8](130cc1c9-51d3-4ba5-95d3-12bb53dee5bd.xhtml),
    *Autoencoders* .
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: GAN
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As seen with autoencoders, we can think of a general concept to create networks
    that will work together in a relationship, and training them will help us learn
    the latent spaces that allow us to generate new data samples.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: Another type of generative network is GAN, where we have a generator model *q(x|h)*
    to map the small dimensional latent space of *h* (which is usually represented
    as noise samples from a simple distribution) to the input space of *x*. This is
    quite similar to the role of decoders in autoencoders.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: The deal is now to introduce a discriminative model *p(y| x),* which tries to
    associate an input instance *x* to a yes/no binary answer *y*, about whether the
    generator model generated the input or was a genuine sample from the dataset we
    were training on.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: Let's use the image example done previously. Assume that the generator model
    creates a new image, and we also have the real image from our actual dataset.
    If the generator model was right, the discriminator model would not be able to
    distinguish between the two images easily. If the generator model was poor, it
    would be very simple to tell which one was a fake or fraud and which one was real.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: When both these models are coupled, we can train them end to end by assuring
    that the generator model is getting better over time to fool the discriminator
    model, while the discriminator model is trained to work on the harder problem
    of detecting frauds. Finally, we desire a generator model with outputs that are
    indistinguishable from the real data that we used for the training.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: 'Through the initial parts of the training, the discriminator model can easily
    detect the samples coming from the actual dataset versus the ones generated synthetically
    by the generator model, which is just beginning to learn. As the generator gets
    better at modeling the dataset, we begin to see more and more generated samples
    that look similar to the dataset. The following example depicts the generated
    images of a GAN model learning over time:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ba581ac8-3fa3-42cc-ac63-18e7597d0d06.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
- en: In the upcoming sections, we will discuss GANs in detail.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: Sequence models
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If the data is temporal in nature, then we can use specialized algorithms called
    **Sequence Models**. These models can learn the probability of the form *p(y|x_n,
    x_1)*, where *i* is an index signifying the location in the sequence and *x_i*
    is the *i^(th)* input sample.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据具有时间性，我们可以使用专门的算法，称为**序列模型**。这些模型可以学习形式为*p(y|x_n, x_1)*的概率，其中*i*是表示序列中位置的索引，*x_i*是第*i*个输入样本。
- en: As an example, we can consider each word as a series of characters, each sentence
    as a series of words, and each paragraph as a series of sentences. Output *y*
    could be the sentiment of the sentence.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个例子，我们可以将每个单词看作是一系列字符，每个句子看作是一系列单词，每个段落看作是一系列句子。输出*y*可以是句子的情感。
- en: Using a similar trick from autoencoders, we can replace *y* with the next item
    in the series or sequence, namely *y =x_n + 1*, allowing the model to learn.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 使用自编码器中的类似技巧，我们可以将*y*替换为序列或序列中的下一个项，即*y = x_n + 1*，从而让模型学习。
- en: GANs
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GAN
- en: 'GANs were introduced by a group of researchers at the University of Montreal
    led by *Ian Goodfellow*. The core idea behind a GAN model is to have two competing
    neural network models. One network takes the noise as input and generates samples
    (hence known as **generator**). The second model (known as **discriminator**)
    gets samples from both the generator and the actual training data, and should
    be able to differentiate between the two sources. Generative and discriminative
    networks are playing a continuous game, where the generator model is learning
    to generate more realistic samples or examples, and the discriminator is learning
    to get better and better at differentiating generated data from the real data.
    The two networks are trained simultaneously, and the goal is that the competition
    will make the generated samples indistinguishable from the real data:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: GAN是由蒙特利尔大学的一组研究人员提出的，该团队由*Ian Goodfellow*领导。GAN模型的核心思想是有两个相互竞争的神经网络模型。一个网络以噪声为输入并生成样本（因此被称为**生成器**）。第二个模型（称为**判别器**）从生成器和实际的训练数据中获取样本，并应能区分这两种来源。生成模型和判别模型在不断地进行博弈，生成器学习生成更真实的样本，而判别器则学习更好地区分生成的数据和真实数据。这两个网络同时训练，目标是通过这种竞争，使得生成的样本与真实数据无法区分：
- en: '![](img/746e5e26-9573-47b6-8569-d28866ce5966.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/746e5e26-9573-47b6-8569-d28866ce5966.png)'
- en: The analogy used to describe GANs is that the generator is like a forger that
    is attempting to produce some forged material, and the discriminator model is
    the police trying to detect the forged items. This may seem somewhat similar to
    reinforcement learning where the generator is getting a reward from the discriminator,
    allowing it to know whether the generated data is accurate or not. The key distinction
    with GANs is that we can backpropagate gradient information from the discriminator
    network back to the generator network, such that the generator knows how to adapt
    its parameters in order to generate output data that can fool the discriminator.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 用来描述GAN的类比是：生成器就像一个伪造者，试图制造一些伪造的物品，而判别器模型则像警察，试图检测伪造的物品。这可能看起来与强化学习有些相似，在强化学习中，生成器从判别器那里获得奖励，帮助它知道生成的数据是否准确。GAN的关键区别在于，我们可以将来自判别器网络的梯度信息反向传播到生成器网络，从而让生成器知道如何调整其参数，生成能够欺骗判别器的输出数据。
- en: As of today, GANs have been mainly applied to model natural images. They provide
    best results in image generation tasks and also in generating images that are
    sharper than the ones trained using other generative methods based on maximum
    likelihood training objectives.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 截至今天，GAN主要被应用于建模自然图像。它们在图像生成任务中提供了最佳的结果，且在生成比其他基于最大似然训练目标的生成方法更清晰的图像方面也表现出色。
- en: 'Here are some examples of images generated by GANs:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一些由GAN生成的图像示例：
- en: '![](img/2a4a2461-6921-4252-ad7b-9bbc56cf8ce4.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2a4a2461-6921-4252-ad7b-9bbc56cf8ce4.png)'
- en: GAN with an example
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GAN 示例
- en: For a deeper understanding of how GANs work, we'll use a GAN to solve a simple
    problem in TensorFlow, namely, learning to approximate a one-dimensional Gaussian
    distribution.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更深入理解GAN是如何工作的，我们将使用一个GAN在TensorFlow中解决一个简单的问题，即学习近似一维高斯分布。
- en: 'First, we will create the actual data distribution, a simple Gaussian with
    a mean of four and standard deviation of 0.5\. It has a sample function that returns
    a given number of samples (sorted by value) from the distribution. The data distribution
    that we learn will look like the following diagram:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/066437dd-ffad-443b-8b62-c1429b9d428b.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
- en: Generator input noise distribution is also defined with a similar sample function
    used for actual data.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: Both generator and discriminator networks are very simple. Generator is a linear
    transformation passed through a non linearity (`softplus` function), followed
    by another linear transformation.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: We kept the discriminator stronger than the generator; otherwise, it would not
    have enough capacity to learn to be able to differentiate accurately between generated
    and real samples. Hence, we made it a deeper neural network with a higher number
    of dimensions. We use *tanh* non linearities in all layers except the final one,
    which is a sigmoid (the output of which can be described as a probability).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: We connect these networks as part of the TensorFlow graph and define loss functions
    for each of the networks so that the generator network will be simply fooling
    the discriminator network. The Gradient Descent Optimizer from TensorFlow with
    exponential learning rate decay is used as an optimizer.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: To train the model, we draw samples from the data distribution and the noise
    distribution, and alternate between optimizing the parameters of the discriminator
    and the generator.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: 'We will see that, at the start of the training method, the generator was generating
    a very different distribution to the real data. The network slowly learns to approximate
    it quite closely before converging to a narrower distribution focused on the mean
    of the input distribution. After training the networks, the two distributions
    look something like this:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fdf1eb31-e0b5-4821-ab33-1801f9c0fd20.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
- en: The problem of the generator network falling to a param setting where it generates
    a very narrow distribution or pattern of points is one of the major failures of
    GANs. The solution will be to allow the discriminator to look at multiple samples
    at once, a technique that we call minibatch discrimination. Minibatch discrimination
    is a method wherein the discriminator can glance at an entire batch of samples
    to determine whether they come from the generator network or from the actual data.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: 'A summary of the method is as follows:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: Take the output of any intermediate layer of the discriminator network
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiply this output by a 3D tensor to generate a matrix of size *numOfKernels
    ** *kernelDim*
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calculate the L1-distance between rows in this matrix across all samples in
    a batch, and then apply a negative exponential
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minibatch features or properties for a sample are then the sum of these exponentiated
    distances
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Concatenate the actual input to the mini batch layer, that is, output of the
    previous or former discriminator layer with the created minibatch features, and
    then pass this as input to the next layer of the discriminator network
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Minibatch discrimination makes the batch size as important as a hyperparameter:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Output Listing:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Types of GANs
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The following section shows different types of GANs, for example, Vanilla GAN,
    Conditional GAN etc. Refer to [https://arxiv.org](https://arxiv.org) for further
    information on the papers. The following description about each GAN network is
    taken from the respective paper on [https://arxiv.org](https://arxiv.org).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: Vanilla GAN
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Vanilla GANs has two networks called generator network and a discriminator network.
    Both the networks are trained at the same time and compete or battle against each
    other in a minimax play. Generator network is trained or prepared such that it
    can fool the discriminator network by creating the real images as per the input,
    and the discriminator is trained not to be fooled by the generator network.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: For further reading on Vanilla GAN refer to [https://arxiv.org/abs/1406.2661](https://arxiv.org/abs/1406.2661).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: Conditional GAN
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GANs was started as a novel way of generative training models. These are GAN
    networks that utilize extra label data. It results in excellent quality images
    and being able to control to an extent how generated images will look. This model
    can be used to learn a multi-modal model.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: For further reading on Conditional GAN refer to [https://arxiv.org/abs/1411.1784.](https://arxiv.org/abs/1411.1784.)
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: Info GAN
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GANs that can encode or learn important image features or disentangled representations
    in an unsupervised manner. An example is to encode the rotation of a digit. Info
    GANs also maximizes the mutual information between a small subset of the latent
    variables and the observation.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: For further reading on Info GAN refer to [https://arxiv.org/abs/1606.03657](https://arxiv.org/abs/1606.03657)
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: Wasserstein GAN
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: WGAN is an option to regular GAN training. WGANs have loss functions that correlate
    with image quality. Additionally, the stability of the training improves and is
    not as dependent on the architecture and provide significant learning curves useful
    for debugging.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: For further reading on Wasserstein GAN refer to [https://arxiv.org/abs/1701.07875](https://arxiv.org/abs/1701.07875)
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: Coupled GAN
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Coupled GANs is used for generating sets of like images in two separate domains.
    It consists of set of GANs each accountable for generating images in the single
    domain. The Coupled GANs learns a joint distribution from images in the two domains
    which are drawn separately from the marginal distributions of the unique domains.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: For further reading on Coupled GAN refer to [https://arxiv.org/abs/1606.07536](https://arxiv.org/abs/1606.07536)
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Generative models are a fast advancing area of study and research. As we proceed
    to advance these models and grow the training and datasets, we can expect to generate
    data examples that depict completely believable images, finally. This can be used
    in several applications such as image denoising, painting, structured prediction,
    and exploration in reinforcement learning.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型是一个快速发展的研究领域。随着我们推进这些模型并扩展训练和数据集，我们可以期待最终生成出完全可信的图像数据示例。这可以应用于多种场景，如图像去噪、绘画、结构化预测以及强化学习中的探索。
- en: The deeper promise of this effort is that, in the process of building generative
    models, we will enrich the computer with an understanding of the world and what
    elements it is made up of.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这项努力的更深层次承诺是，在构建生成模型的过程中，我们将赋予计算机对世界及其组成元素的理解。
