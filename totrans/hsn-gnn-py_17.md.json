["```py\nfrom io import BytesIO\nfrom urllib.request import urlopen\nfrom zipfile import ZipFile\nurl = 'http://www2.informatik.uni-freiburg.de/~cziegler/BX/BX-CSV-Dump.zip'\nwith urlopen(url) as zurl:\n    with ZipFile(BytesIO(zurl.read())) as zfile:\n        zfile.extractall('.')\n```", "```py\n    import pandas as pd\n    ratings = pd.read_csv('BX-Book-Ratings.csv', sep=';', encoding='latin-1')\n    users = pd.read_csv('BX-Users.csv', sep=';', encoding='latin-1')\n    books = pd.read_csv('BX-Books.csv', sep=';', encoding='latin-1', error_bad_lines=False)\n    ```", "```py\n    ratings\n               User-ID    ISBN            Book-Rating\n    0          276725     034545104X      0\n    1          276726     0155061224      5\n    ...        ...        ...             ...\n    1149777    276709     0515107662      10\n    1149778    276721     0590442449      10\n    1149779    276723     05162443314     8\n    1149780 rows × 3 columns\n    ```", "```py\n    users\n    User-ID         Location                         Age\n    0       1       nyc, new york, usa               NaN\n    1       2       stockton, california, usa        18.0\n    2       3       moscow, yukon territory, russia  NaN\n    ...     ...     ...                              ...\n    278855  278856  brampton, ontario, canada        NaN\n    278856  278857  knoxville, tennessee, usa  NaN\n    278857  278858  dublin, n/a, ireland  NaN\n    278858 rows × 3 columns\n    ```", "```py\n    list(books.columns)\n    ['ISBN', 'Book-Title', 'Book-Author', 'Year-Of-Publication', 'Publisher', 'Image-URL-S', 'Image-URL-M', 'Image-URL-L']\n    ```", "```py\n    import matplotlib.pyplot as plt\n    import seaborn as sns\n    sns.countplot(x=ratings['Book-Rating'])\n    ```", "```py\n    print(len(ratings['User-ID'].unique()))\n    print(len(ratings['ISBN'].unique()))\n    105283\n    340556\n    ```", "```py\n    isbn_counts = ratings.groupby('ISBN').size()\n    ```", "```py\n    count_occurrences = isbn_counts.value_counts()\n    ```", "```py\n    count_occurrences[:15].plot(kind='bar')\n    plt.xlabel(\"Number of occurrences of an ISBN number\")\n    plt.ylabel(\"Count\")\n    ```", "```py\n    userid_counts = ratings.groupby('User-ID').size()\n    count_occurrences = userid_counts.value_counts()\n    count_occurrences[:15].plot(kind='bar')\n    plt.xlabel(\"Number of occurrences of a User-ID\")\n    plt.ylabel(\"Count\")\n    ```", "```py\n    import numpy as np\n    from sklearn.model_selection import train_test_split\n    import torch\n    import torch.nn.functional as F\n    from torch import nn, optim, Tensor\n    from torch_geometric.utils import structured_negative_sampling\n    from torch_geometric.nn.conv.gcn_conv import gcn_norm\n    from torch_geometric.nn import LGConv\n    ```", "```py\n    df = pd.read_csv('BX-Book-Ratings.csv', sep=';', encoding='latin-1')\n    users = pd.read_csv('BX-Users.csv', sep=';', encoding='latin-1')\n    books = pd.read_csv('BX-Books.csv', sep=';', encoding='latin-1', error_bad_lines=False)\n    ```", "```py\n    df = df.loc[df['ISBN'].isin(books['ISBN'].unique()) & df['User-ID'].isin(users['User-ID'].unique())]\n    ```", "```py\n    df = df[df['Book-Rating'] >= 8].iloc[:100000]\n    ```", "```py\n    user_mapping = {userid: i for i, userid in enumerate(df['User-ID'].unique())}\n    item_mapping = {isbn: i for i, isbn in enumerate(df['ISBN'].unique())}\n    ```", "```py\n    num_users = len(user_mapping)\n    num_items = len(item_mapping)\n    num_total = num_users + num_items\n    ```", "```py\n    user_ids = torch.LongTensor([user_mapping[i] for i in df['User-ID']])\n    item_ids = torch.LongTensor([item_mapping[i] for i in df['ISBN']])\n    edge_index = torch.stack((user_ids, item_ids))\n    ```", "```py\n    train_index, test_index = train_test_split(range(len(df)), test_size=0.2, random_state=0)\n    val_index, test_index = train_test_split(test_index, test_size=0.5, random_state=0)\n    ```", "```py\n    def sample_mini_batch(edge_index):\n        index = np.random.choice(range(edge_index.shape[1]), size=BATCH_SIZE)\n    ```", "```py\n        edge_index = structured_negative_sampling(edge_index)\n        edge_index = torch.stack(edge_index, dim=0)\n    ```", "```py\n        user_index = edge_index[0, index]\n        pos_item_index = edge_index[1, index]\n        neg_item_index = edge_index[2, index]\n        return user_index, pos_item_index, neg_item_index\n    ```", "```py\n    class LightGCN(nn.Module):\n        def __init__(self, num_users, num_items, num_layers=4, dim_h=64):\n            super().__init__()\n    ```", "```py\n            self.num_users = num_users\n            self.num_items = num_items\n            self.emb_users = nn.Embedding(num_embeddings=self.num_users, embedding_dim=dim_h)\n            self.emb_items = nn.Embedding(num_embeddings=self.num_items, embedding_dim=dim_h)\n    ```", "```py\n            self.convs = nn.ModuleList(LGConv() for _ in range(num_layers))\n    ```", "```py\n            nn.init.normal_(self.emb_users.weight, std=0.01)\n            nn.init.normal_(self.emb_items.weight, std=0.01)\n    ```", "```py\n        def forward(self, edge_index):\n            emb = torch.cat([self.emb_users.weight, self.emb_items.weight])\n            embs = [emb]\n    ```", "```py\n            for conv in self.convs:\n                emb = conv(x=emb, edge_index=edge_index)\n                embs.append(emb)\n    ```", "```py\n    emb_final = torch.mean(torch.stack(embs, dim=1), dim=1)\n    ```", "```py\n            emb_users_final, emb_items_final = torch.split(emb_final, [self.num_users, self.num_items])\n            return emb_users_final, self.emb_users.weight, emb_items_final, self.emb_items.weight\n    ```", "```py\n    model = LightGCN(num_users, num_items)\n    ```", "```py\n    def bpr_loss(emb_users_final, emb_users, emb_pos_items_final, emb_pos_items, emb_neg_items_final, emb_neg_items):\n        reg_loss = LAMBDA * (emb_users.norm().pow(2) +\n                            emb_pos_items.norm().pow(2) +\n                            emb_neg_items.norm().pow(2))\n    ```", "```py\n        pos_ratings = torch.mul(emb_users_final, emb_pos_items_final).sum(dim=-1)\n        neg_ratings = torch.mul(emb_users_final, emb_neg_items_final).sum(dim=-1)\n    ```", "```py\n        bpr_loss = torch.mean(torch.nn.functional.softplus(pos_ratings - neg_ratings))\n    ```", "```py\n        return -bpr_loss + reg_loss\n    ```", "```py\n    K = 20\n    LAMBDA = 1e-6\n    BATCH_SIZE = 1024\n    ```", "```py\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model = model.to(device)\n    edge_index = edge_index.to(device)\n    train_edge_index = train_edge_index.to(device)\n    val_edge_index = val_edge_index.to(device)\n    ```", "```py\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    ```", "```py\n    num_batch = int(len(train_index)/BATCH_SIZE)\n    for epoch in range(31):\n        model.train()\n        for _ in range(num_batch):\n    ```", "```py\n            optimizer.zero_grad()\n            emb_users_final, emb_users, emb_items_final, emb_items = model.forward(train_edge_index)\n    ```", "```py\n            user_indices, pos_item_indices, neg_item_indices = sample_mini_batch(train_edge_index)\n    ```", "```py\n        emb_users_final, emb_users = emb_users_final[user_indices], emb_users[user_indices]\n        emb_pos_items_final, emb_pos_items = emb_items_final[pos_item_indices], emb_items[pos_item_indices]\n        emb_neg_items_final, emb_neg_items = emb_items_final[neg_item_indices], emb_items[neg_item_indices]\n    ```", "```py\n        train_loss = bpr_loss(emb_users_final, emb_users, emb_pos_items_final, emb_pos_items, emb_neg_items_final, emb_neg_items)\n    ```", "```py\n        train_loss.backward()\n        optimizer.step()\n    ```", "```py\n        if epoch % 5 == 0:\n            model.eval()\n            val_loss, recall, ndcg = test(model, val_edge_index, [train_edge_index])\n            print(f\"Epoch {epoch} | Train loss: {train_loss.item():.5f} | Val loss: {val_loss:.5f} | Val recall@{K}: {recall:.5f} | Val ndcg@{K}: {ndcg:.5f}\")\n    ```", "```py\n    Epoch 0 | Train loss: -0.69320 | Val loss: -0.69302 | Val recall@20: 0.00700 | Val ndcg@20: 0.00388\n    Epoch 5 | Train loss: -0.70283 | Val loss: -0.68329 | Val recall@20: 0.01159 | Val ndcg@20: 0.00631\n    Epoch 10 | Train loss: -0.73299 | Val loss: -0.64598 | Val recall@20: 0.01341 | Val ndcg@20: 0.00999\n    ...\n    Epoch 25 | Train loss: -1.53056 | Val loss: -0.19498 | Val recall@20: 0.01507 | Val ndcg@20: 0.01016\n    Epoch 30 | Train loss: -1.95703 | Val loss: 0.06340 | Val recall@20: 0.01410 | Val ndcg@20: 0.00950\n    ```", "```py\n    test_loss, test_recall, test_ndcg = test(model, test_edge_index.to(device), [train_edge_index, val_edge_index])\n    print(f\"Test loss: {test_loss:.5f} | Test recall@{K}: {test_recall:.5f} | Test ndcg@{K}: {test_ndcg:.5f}\")\n    Test loss: 0.06827 | Test recall@20: 0.01936 | Test ndcg@20: 0.01119\n    ```", "```py\n    def recommend(user_id, num_recs):\n    ```", "```py\n        user = user_mapping[user_id]\n    ```", "```py\n        emb_user = model.emb_users.weight[user]\n    ```", "```py\n        ratings = model.emb_items.weight @ emb_user\n    ```", "```py\n        values, indices = torch.topk(ratings, k=100)\n    ```", "```py\n        ids = [index.cpu().item() for index in indices if index in user_items[user]][:num_recs]\n    ```", "```py\n        item_isbns = [list(item_mapping.keys())[list(item_mapping.values()).index(book)] for book in ids]\n    ```", "```py\n        titles = [bookid_title[id] for id in item_isbns]\n        authors = [bookid_author[id] for id in item_isbns]\n    ```", "```py\n        print(f'Favorite books from user n°{user_id}:')\n        for i in range(len(item_isbns)):\n            print(f'- {titles[i]}, by {authors[i]}')\n    ```", "```py\n        ids = [index.cpu().item() for index in indices if index not in user_pos_items[user]][:num_recs]\n        item_isbns = [list(item_mapping.keys())[list(item_mapping.values()).index(book)] for book in ids]\n        titles = [bookid_title[id] for id in item_isbns]\n        authors = [bookid_author[id] for id in item_isbns]\n        print(f'\\nRecommended books for user n°{user_id}')\n        for i in range(num_recs):\n            print(f'- {titles[i]}, by {authors[i]}')\n    ```", "```py\n    recommend(277427, 5)\n    ```", "```py\n    Favorite books from user n°277427:\n    - The Da Vinci Code, by Dan Brown\n    - Lord of the Flies, by William Gerald Golding\n    - The Cardinal of the Kremlin (Jack Ryan Novels), by Tom Clancy\n    - Into the Wild, by Jon Krakauer\n    Recommended books for user n°277427\n    - The Lovely Bones: A Novel, by Alice Sebold\n    - The Secret Life of Bees, by Sue Monk Kidd\n    - The Red Tent (Bestselling Backlist), by Anita Diamant\n    - Harry Potter and the Sorcerer's Stone (Harry Potter (Paperback)), by J. K. Rowling\n    - To Kill a Mockingbird, by Harper Lee\n    ```"]