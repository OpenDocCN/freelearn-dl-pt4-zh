["```py\nspark = SparkSession.builder \\\n    .master(\"local\") \\\n    .appName(\"StockMarket\") \\\n    .config(\"spark.executor.memory\", \"6gb\") \\\n    .getOrCreate()\n```", "```py\ndf =spark.read.format('com.databricks.spark.csv')\\\n   .options(header='true', inferschema='true')\\\n   .load('AAPL.csv')\n```", "```py\nimport pyspark.sql.functions as f\ndf = df.withColumn('date', f.to_date('Date'))\n```", "```py\ndate_breakdown = ['year', 'month', 'day']\nfor i in enumerate(date_breakdown):\n    index = i[0]\n    name = i[1]\n    df = df.withColumn(name, f.split('date', '-')[index])\n```", "```py\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\ndf_plot.set_index('year', inplace=True)\ndf_plot.plot(figsize=(16, 6), grid=True)\nplt.title('Apple stock')\nplt.ylabel('Stock Quote ($)')\nplt.show()\n```", "```py\ndf.select('Open', 'High', 'Low', 'Close', 'Adj Close').describe().show()\n```", "```py\ndf.groupBy(['year']).agg({'Adj Close':'count'})\\\n     .withColumnRenamed('count(Adj Close)', 'Row Count')\\\n     .orderBy([\"year\"],ascending=False)\\\n     .show()\n```", "```py\ntrainDF = df[df.year < 2017]\ntestDF = df[df.year > 2016]\n```", "```py\ntrainDF.toPandas().shape\ntestDF.toPandas().shape\n```", "```py\ntrainDF_plot = trainDF.select('year', 'Adj Close').toPandas()\ntrainDF_plot.set_index('year', inplace=True)\ntrainDF_plot.plot(figsize=(16, 6), grid=True)\nplt.title('Apple Stock 2000-2016')\nplt.ylabel('Stock Quote ($)')\nplt.show()\n\ntestDF_plot = testDF.select('year', 'Adj Close').toPandas()\ntestDF_plot.set_index('year', inplace=True)\ntestDF_plot.plot(figsize=(16, 6), grid=True)\nplt.title('Apple Stock 2017-2018')\nplt.ylabel('Stock Quote ($)')\nplt.show()\n```", "```py\nimport numpy as np\ntrainArray = np.array(trainDF.select('Open', 'High', 'Low',                     'Close','Volume', 'Adj Close' ).collect())\ntestArray = np.array(testDF.select('Open', 'High', 'Low', 'Close','Volume',     'Adj Close' ).collect())\n```", "```py\nfrom sklearn.preprocessing import MinMaxScaler\nminMaxScale = MinMaxScaler()\n```", "```py\nminMaxScale.fit(trainArray)\n\ntestingArray = minMaxScale.transform(testArray)\ntrainingArray = minMaxScale.transform(trainArray)\n```", "```py\nxtrain = trainingArray[:, 0:-1]\nxtest = testingArray[:, 0:-1]\nytrain = trainingArray[:, -1:]\nytest = testingArray[:, -1:]\n```", "```py\nprint('xtrain shape = {}'.format(xtrain.shape))\nprint('xtest shape = {}'.format(xtest.shape))\nprint('ytrain shape = {}'.format(ytrain.shape))\nprint('ytest shape = {}'.format(ytest.shape))\n```", "```py\nplt.figure(figsize=(16,6))\nplt.plot(xtrain[:,0],color='red', label='open')\nplt.plot(xtrain[:,1],color='blue', label='high')\nplt.plot(xtrain[:,2],color='green', label='low')\nplt.plot(xtrain[:,3],color='purple', label='close')\nplt.legend(loc = 'upper left')\nplt.title('Open, High, Low, and Close by Day')\nplt.xlabel('Days')\nplt.ylabel('Scaled Quotes')\nplt.show()\n```", "```py\nplt.figure(figsize=(16,6))\nplt.plot(xtrain[:,4],color='black', label='volume')\nplt.legend(loc = 'upper right')\nplt.title('Volume by Day')\nplt.xlabel('Days')\nplt.ylabel('Scaled Volume')\nplt.show()\n```", "```py\nfrom keras import models\nfrom keras import layers\n```", "```py\nfrom keras import models, layers\n```", "```py\nmodel = models.Sequential()\nmodel.add(layers.LSTM(1, input_shape=(1,5)))\nmodel.add(layers.Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\n```", "```py\nxtrain = xtrain.reshape((xtrain.shape[0], 1, xtrain.shape[1]))\nxtest = xtest.reshape((xtest.shape[0], 1, xtest.shape[1]))\n```", "```py\nloss = model.fit(xtrain, ytrain, batch_size=10, epochs=100)\n```", "```py\npredicted = model.predict(xtest)\n```", "```py\ncombined_array = np.concatenate((ytest, predicted), axis = 1)\n```", "```py\nimport sklearn.metrics as metrics\n```", "```py\nplt.figure(figsize=(16,6))\nplt.plot(combined_array[:,0],color='red', label='actual')\nplt.plot(combined_array[:,1],color='blue', label='predicted')\nplt.legend(loc = 'lower right')\nplt.title('2017 Actual vs. Predicted APPL Stock')\nplt.xlabel('Days')\nplt.ylabel('Scaled Quotes')\nplt.show()\n```", "```py\nimport sklearn.metrics as metrics\nnp.sqrt(metrics.mean_squared_error(ytest,predicted))\n```"]