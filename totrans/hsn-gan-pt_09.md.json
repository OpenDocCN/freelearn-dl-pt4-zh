["```py\nfrom .pixelshuffle import PixelShuffle\n```", "```py\npixel_shuffle = _add_docstr(torch.pixel_shuffle, r\"\"\"\n...\n\"\"\")\n```", "```py\n$ grep -r --include \\*.cpp pixel_shuffle .\n```", "```py\nimport math\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn\nimport torchvision.models as models\n\nclass ResidualBlock(nn.Module):\n    def __init__(self, channels):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3,  \n          padding=1)\n        self.bn1 = nn.BatchNorm2d(channels)\n        self.prelu = nn.PReLU()\n        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, \n          padding=1)\n        self.bn2 = nn.BatchNorm2d(channels)\n\n    def forward(self, x):\n        residual = self.conv1(x)\n        residual = self.bn1(residual)\n        residual = self.prelu(residual)\n        residual = self.conv2(residual)\n        residual = self.bn2(residual)\n        return x + residual\n```", "```py\nclass UpsampleBLock(nn.Module):\n    def __init__(self, in_channels, up_scale):\n        super(UpsampleBLock, self).__init__()\n        self.conv = nn.Conv2d(in_channels, in_channels * up_scale **  \n          2, kernel_size=3, padding=1)\n        self.pixel_shuffle = nn.PixelShuffle(up_scale)\n        self.prelu = nn.PReLU()\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.pixel_shuffle(x)\n        x = self.prelu(x)\n        return x\n```", "```py\nclass Generator(nn.Module):\n    def __init__(self, scale_factor):\n        upsample_block_num = int(math.log(scale_factor, 2))\n\n        super(Generator, self).__init__()\n        self.block1 = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=9, padding=4),\n            nn.PReLU()\n        )\n        self.block2 = ResidualBlock(64)\n        self.block3 = ResidualBlock(64)\n        self.block4 = ResidualBlock(64)\n        self.block5 = ResidualBlock(64)\n        self.block6 = ResidualBlock(64)\n        self.block7 = nn.Sequential(\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64)\n        )\n        block8 = [UpsampleBLock(64, 2) for _ in \n          range(upsample_block_num)]\n        block8.append(nn.Conv2d(64, 3, kernel_size=9, padding=4))\n        self.block8 = nn.Sequential(*block8)\n\n    def forward(self, x):\n        block1 = self.block1(x)\n        block2 = self.block2(block1)\n        block3 = self.block3(block2)\n        block4 = self.block4(block3)\n        block5 = self.block5(block4)\n        block6 = self.block6(block5)\n        block7 = self.block7(block6)\n        block8 = self.block8(block1 + block7)\n\n        return (torch.tanh(block8) + 1) / 2\n```", "```py\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.net = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n            nn.LeakyReLU(0.2),\n\n            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n            nn.BatchNorm2d(64),\n            nn.LeakyReLU(0.2),\n\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2),\n\n            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2),\n\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(0.2),\n\n            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(0.2),\n\n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(0.2),\n\n            nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(0.2),\n\n            nn.AdaptiveAvgPool2d(1),\n            nn.Conv2d(512, 1024, kernel_size=1),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(1024, 1, kernel_size=1)\n        )\n\n    def forward(self, x):\n        batch_size = x.size(0)\n        return torch.sigmoid(self.net(x).view(batch_size))\n```", "```py\nclass GeneratorLoss(nn.Module):\n    def __init__(self):\n        super(GeneratorLoss, self).__init__()\n        vgg = models.vgg16(pretrained=True)\n        loss_network = nn.Sequential(*list(vgg.features)[:31]).eval()\n        for param in loss_network.parameters():\n            param.requires_grad = False\n        self.loss_network = loss_network\n        self.mse_loss = nn.MSELoss()\n        self.l2_loss = L2Loss()\n\n    def forward(self, out_labels, out_images, target_images):\n        # adversarial Loss\n        adversarial_loss = torch.mean(1 - out_labels)\n        # vgg Loss\n        vgg_loss = self.mse_loss(self.loss_network(out_images), \n          self.loss_network(target_images))\n        # pixel-wise Loss\n        pixel_loss = self.mse_loss(out_images, target_images)\n        # regularization Loss\n        reg_loss = self.l2_loss(out_images)\n        return pixel_loss + 0.001 * adversarial_loss + 0.006 * vgg_loss \n         + 2e-8 * reg_loss\n```", "```py\nclass L2Loss(nn.Module):\n    def __init__(self, l2_loss_weight=1):\n        super(L2Loss, self).__init__()\n        self.l2_loss_weight = l2_loss_weight\n\n    def forward(self, x):\n        batch_size = x.size()[0]\n        h_x = x.size()[2]\n        w_x = x.size()[3]\n        count_h = self.tensor_size(x[:, :, 1:, :])\n        count_w = self.tensor_size(x[:, :, :, 1:])\n        h_l2 = torch.pow((x[:, :, 1:, :] - x[:, :, :h_x - 1, :]), 2).sum()\n        w_l2 = torch.pow((x[:, :, :, 1:] - x[:, :, :, :w_x - 1]), 2).sum()\n        return self.l2_loss_weight * 2 * (h_l2 / count_h + w_l2 / count_w) \n         / batch_size\n\n    @staticmethod\n    def tensor_size(t):\n        return t.size()[1] * t.size()[2] * t.size()[3]\n```", "```py\n# from loss import GeneratorLoss\n# from model import Generator, Discriminator\nfrom srgan1 import GeneratorLoss, Discriminator, Generator\n```", "```py\n$ pip install tqdm, pandas\n$ python train.py\n```", "```py\nclass data_prefetcher():\n def __init__(self, loader):\n self.loader = iter(loader)\n self.stream = torch.cuda.Stream()\n self.preload()\n\n def preload(self):\n try:\n self.next_input, self.next_target = next(self.loader)\n except StopIteration:\n self.next_input = None\n self.next_target = None\n return\n with torch.cuda.stream(self.stream):\n self.next_input = self.next_input.cuda(non_blocking=True)\n self.next_target = self.next_target.cuda(non_blocking=True)\n self.next_input = self.next_input.float()\n\n def next(self):\n torch.cuda.current_stream().wait_stream(self.stream)\n input = self.next_input\n target = self.next_target\n self.preload()\n return input, target\n```", "```py\nfor epoch in range(1, NUM_EPOCHS + 1):\n    train_bar = tqdm(train_loader)\n prefetcher = data_prefetcher(train_bar)\n data, target = prefetcher.next()\n    ...\n    while data is not None:\n        // train D\n        ...\n        // train G\n        ...\n        data, target = prefetcher.next()\n```", "```py\n$ pip install numpy, scipy\n```", "```py\nimport numpy as np\n\ndef conv2d_direct(x, w):\n    w = np.flip(np.flip(w, 0), 1)\n    rows = x.shape[0]\n    cols = x.shape[1]\n    kh = w.shape[0]\n    kw = w.shape[1]\n    rst = np.zeros((rows-kh+1, cols-kw+1))\n    for i in range(rst.shape[0]):\n        for j in range(rst.shape[1]):\n            tmp = 0.\n            for ki in range(kh):\n                for kj in range(kw):\n                    tmp += x[i+ki][j+kj] * w[ki][kj]\n            rst[i][j] = tmp\n    return rst\n```", "```py\nx = np.random.randn(512, 512)\nw = np.random.randn(5, 5)\n\nfrom timeit import default_timer as timer\nstart = timer()\nrst1 = conv2d_direct(x, w)\nend = timer()\nprint('Elapsed time (direct): {}'.format(end - start))\n# 3.868343267000455 seconds on an Intel Core i5-4590 CPU\n```", "```py\nfrom scipy import signal\n\nstart = timer()\nrst0 = signal.convolve2d(x, w, mode='valid')\nend = timer()\nprint('Elapsed time (reference): {}'.format(end - start))\n# 0.017827395000495017\n\nerror1 = np.max(np.abs(rst1 - rst0))\nprint('Error: {}'.format(error1))\n# 1.0658141036401503e-14\n```", "```py\ndef conv2d_fft(x, w):\n    # return signal.fftconvolve(x, w, mode='valid')\n    size = np.array(x.shape) + np.array(w.shape) - 1\n    fsize = 2 ** np.ceil(np.log2(size)).astype(int)\n    fslice = tuple([slice(kn-1, int(sz)-kn+1) for sz, kn in zip(size, w.shape)])\n    x_fft = np.fft.fft2(x , fsize)\n    w_fft = np.fft.fft2(w , fsize)\n    rst = np.fft.ifft2(x_fft * w_fft)\n    rst = rst[fslice].real\n    return rst\n```", "```py\nElapsed time (FFT): 0.17074442000011913\nError: 1.0658141036401503e-14\n```", "```py\ndef im2col(x, stride=1):\n    # https://stackoverflow.com/a/30110497/3829845\n    rows = x.shape[0]\n    cols = x.shape[1]\n    kh = w.shape[0]\n    kw = w.shape[1]\n    s0, s1 = x.strides\n    nrows = rows-kh+1\n    ncols = cols-kw+1\n    shape = kh, kw, nrows, ncols\n    slides = s0, s1, s0, s1\n    L = kh*kw\n\n    x_unfold = np.lib.stride_tricks.as_strided(x, shape=shape, strides=slides)\n    return x_unfold.reshape(L, -1)[:,::stride]\n\ndef conv2d_gemm(x, w, stride=1):\n    w = np.flip(np.flip(w, 0), 1)\n    rows = x.shape[0]\n    cols = x.shape[1]\n    kh = w.shape[0]\n    kw = w.shape[1]\n    L = kh*kw\n\n    x_unfold = im2col(x)\n    y_unfold = np.matmul(x_unfold.transpose(), w.reshape((L, 1)))\n    return y_unfold.reshape(rows-kh+1, cols-kw+1)\n```", "```py\nElapsed time (im2col): 0.014781345998926554\nError: 1.0658141036401503e-14\n```", "```py\nimport torch\n\ninp = torch.randn(1, 1, 512, 512)\nw = torch.randn(1, 1, 5, 5)\nstart = timer()\ninp_unf = torch.nn.functional.unfold(inp, (5, 5))\nout_unf = inp_unf.transpose(1, 2).matmul(w.view(w.size(0), -1).t()).transpose(1, 2)\nout = out_unf.view(1, 1, 508, 508)\n# Or using\n# out = torch.nn.functional.fold(out_unf, (508, 508), (1, 1))\nend = timer()\nprint('Elapsed time (nn.Unfold): {}'.format(end - start))\nerror4 = (torch.nn.functional.conv2d(inp, w) - out).abs().max()\nprint('Error: {}'.format(error4))\n```", "```py\nElapsed time (nn.Unfold): 0.021252065999760816\nError: 6.67572021484375e-06\n```"]