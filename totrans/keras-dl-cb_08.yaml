- en: Autoencoders
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An autoencoder is a type of neural network that is trained to attempt to copy
    its input to its output. It has a hidden layer (let''s call it *h*) that describes
    a code used to represent the input. The network may be viewed as consisting of
    two parts:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: '**Encoder function**: *h = f (x)*'
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Decoder that produces a reconstruction**: *r = g(h)*'
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following figure shows a basic autoencoder with input *n* and a hidden
    layer with neurons *m*:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/af478e87-a284-4b89-95bd-027cbdca7a02.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
- en: Basic representation of an autoencoder
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: Autoencoders are designed to be unable to learn to copy perfectly. They are
    restricted in ways that allow them to copy only approximately, and to copy only
    input that resembles the training data. As the model is forced to prioritize which
    aspects of the input should be copied, it often learns useful properties of the
    data.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: Autoencoder algorithms
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Under-complete autoencoders
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Basic autoencoders
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Additive Gaussian Noise autoencoders
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sparse autoencoders
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Autoencoder algorithms
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the following notation, `x` is the input, `y` is the encoded data, `z` is
    the decoded data, `σ` is a nonlinear activation function (sigmoid or hyperbolic
    tangent, usually), and `f(x;θ)` means a function of `x` parameterized by `θ`.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: 'The model can be summarized in the following way:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: 'The input data is mapped to the hidden layer (encoding). The mapping is usually
    an affine (allowing for or preserving parallel relationships.) transformation
    followed by a non-linearity:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The hidden layer is mapped to the output layer, which is also called **decoding**.
    The mapping is an affine transformation (affine transformation is a linear mapping
    method that preserves points, straight lines, and planes) optionally followed
    by a non linearity. The following equation explains this:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In order to reduce the size of the model, tied weights can be used, which means
    that the decoder weights matrix is constrained and can be the transpose of the
    encoder weights matrix, *θ'=θ^T*.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: The hidden layer can have a lower or higher dimensionality than that of the
    input/output layers.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: In the case of lower dimensionality, the decoder reconstructs the original input
    from a lower-dimensional representation of it (also called **under-complete representation**).
    For the overall algorithm to work, the encoder should learn to provide a low-dimensional
    representation that captures the essence of the data (that is, the main factors
    of variations in the distribution). It is forced to find a good way to summarize
    the data.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: 'Reference: [http://blackecho.github.io/blog/machine-learning/2016/02/29/denoising-autoencoder-tensorflow.html](http://blackecho.github.io/blog/machine-learning/2016/02/29/denoising-autoencoder-tensorflow.html).'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: Under-complete autoencoders
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the ways to obtain useful features from the autoencoder is done by constraining
    *h* to have a smaller dimension than input `x`. An autoencoder with a code dimension
    less than the input dimension is called under-complete.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: Learning a representation that is under-complete forces the autoencoder to capture
    the most salient features of the training data.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: The learning process is described as minimizing a loss function, `L(x, g(f(x)))`,
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: where `L` is a loss function penalizing `g(f (x))` for being dissimilar from
    `x`, such as the mean squared error.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: Dataset
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We are planning to use the MNIST dataset in the `idx3` format as input to train
    our autoencoders. We will be testing the autoencoder on the first 100 images.
    Let''s first plot the original images:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The output of the preceding is the following figure:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3ea4bce8-c710-41bb-9eed-3ba8deac2dde.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
- en: Plot of original MNIST images
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: Basic autoencoders
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s look at a basic example of an autoencoder that also happens to be a
    basic autoencoder. First, we will create an `AutoEncoder` class and initialize
    it with the following parameters passed to `__init__()`:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '`num_input`: Number of input samples'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_hidden`: Number of neurons in the hidden layer'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`transfer_function=tf.nn.softplus`: Transfer function'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`optimizer = tf.train.AdamOptimizer()`: Optimizer'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can either pass a custom `transfer_function` and `optimizer` or use the
    default one specified. In our example, we are using softplus as the default `transfer_function`
    (also called **activation function**): `f(x)=ln(1+e^x)`.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: Autoencoder initialization
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, we initialize the class variables and weights:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Here, the `_initialize_weigths()` function is a local function that initializes
    values for the `weights` dictionary:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '`w1` is a 2D tensor with shape `num_input X num_hidden`'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`b1` is a 1D tensor with shape `num_hidden`'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`w2` is a 2D tensor with shape `num_hidden X num_input`'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`b2` is a 2D tensor with shape `num_input`'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following code shows how weights are initialized as a dictionary of TensorFlow
    variables for two hidden layers:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Next, we define `x_var`, `hidden_layer`, and `reconstruction layer`:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](img/65f7a30e-20da-4026-b85e-8536e42987f3.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
- en: Cost function
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: Instantiate the global variables initializer and pass it to TensorFlow session.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: AutoEncoder class
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Th following code shows `AutoEncoder` class. This class with be instantiated
    for samples in next few sections to create autoencoders:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Basic autoencoders with MNIST data
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s use the autoencoder with MNIST data: `mnist = input_data.read_data_sets(''MNIST_data'',
    one_hot = True)`.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: 'Use StandardScalar from Scikit Learn''s `sklearn.``preprocessing` module to
    extract `testmnist.test.images` and training images `mnist.train.images`:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The preprocessing module provides a utility class, `StandardScaler`, which implements
    the Transformer API. This computes and transforms the mean and standard deviation
    of a training set. It reapplies the same transformation to the testing set. By
    default, Scalar centers the mean and makes the variance one.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: It is possible to disable either centering or scaling by passing `with_mean=False`
    or `with_std=False` to the constructor of StandardScaler.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we define an instance of the AutoEncoder class listed earlier:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Notice that the autoencoder includes the following:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: Number of input neurons is `784`
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Number of neurons in the hidden layer is `200`
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Activation function is `tf.nn.softplus`
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimizer is `tf.train.AdamOptimizer`
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Next, we iterate over the training data and display the cost function:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Print the total cost:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The output of the epochs is listed as follows; as expected, the cost converges
    with each iteration:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Basic autoencoder plot of weights
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once the training is done show the plot of weights using the Matplotlib library
    using code listing:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](img/8f561398-b0db-4d6f-b0eb-622b94e61396.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
- en: Basic autoencoder weights plot
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will look at how images are recreated using the weights
    shown in the preceding image.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: Basic autoencoder recreated images plot
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Having recreated the images, let''s plot them to get a feel of how they look.
    First, we will reconstruct the images using the `autoencoder` instance created
    earlier:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Let''s look at the created images from the neural network:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fcaccfd9-080c-4775-a79e-3f0756e2c92b.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
- en: Basic autoencoder plot of output images
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: Basic autoencoder full code listing
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The full code listing can be found here or can also be downloaded from GitHub--[https://github.com/rajdeepd/neuralnetwork-programming/blob/ed1/ch07/basic_autoencoder_example.py](https://github.com/rajdeepd/neuralnetwork-programming/blob/ed1/ch07/basic_autoencoder_example.py):'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Basic autoencoder summary
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The autoencoder created a basic approximation of MNSIT images using 200 neuron
    hidden layers. The following diagram shows nine images and how they were transformed
    into approximations using a basic autoencoder:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f98d20e7-7c2e-4a37-8e18-5fc0bc23ab87.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
- en: Basic autoencoder input and output representation
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will look at a more advanced autoencoder, an **Additive
    Gaussian Noise AutoEncoder**.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: Additive Gaussian Noise autoencoder
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What are Denoising autoencoders? They are very similar to the basic model we
    saw in previous sections, the difference is that, the input is corrupted before
    being passed to the network. By matching the original version (not the corrupted
    one) with the reconstruction at training time, this autoencoder gets trained to
    reconstruct the original input image from the corrupted image.  The ability to
    reconstruct original image from corrupted image makes autoencoder very smart.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: 'An additive noise autoencoder uses the following equation to add corruption
    to incoming data:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '*x[corr] = x + scale*random_normal(n)*'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the detail describe about the preceding equation:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: '*x* is the original image'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*scale* is the multiplier for a random normal number generated from *n*'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*n* is the number of training samples'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*x[corr]* is the corrupted output'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Autoencoder class
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We initialize the autoencoder defined in `class AdditiveGaussianNoiseAutoEncoder`
    by passing following parameters:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '`num_input`: Number of input samples'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_hidden`: Number of neurons in the hidden layer'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`transfer_function=tf.nn.sigmoid`: Transfer function'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`optimizer = tf.train.AdamOptimizer()`: Optimizer'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`scale=0.1`: Scale for corruption of the image'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Assign the passed parameters to the instance variables:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Initialize the hidden layer `hidden_layer` and the reconstruction layer `reconstruction`:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Define the cost function and the optimizer:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The cost function remains the same as the basic autoencoder
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/594dd7ad-8b38-4948-9df7-edea73778020.jpg)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
- en: Cost function of additive Gaussian autoencoder
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we initialize global variables, create a TensorFlow session, and run
    it to execute the `init` graph:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: In the next section, we will look at how this autoencoder will be used to encode
    MNIST data.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: Additive Gaussian Autoencoder with the MNIST dataset
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, we load the train and test datasets, `X_train` and `X_test`:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Define the variables for the number of samples, `n_samples`, `training_epoch`,
    and `batch_size` for each iteration of the training and `display_step`:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Instantiate the autoencoder and the optimizer. The autoencoder has 200 hidden
    units and uses sigmoid as the `transfer_function`:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Training the model
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once the neural network layers have been defined we train the model by calling
    method
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '`autoencoder.partial_fit(batch_xs)` for each batch of data:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The cost of each epoch is printed:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The total cost of training is as follows:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Plotting the weights
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s plot the weights visually and plot them using Matplotlib:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '![](img/02034b23-6d96-47a1-bd02-38459aaecc86.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
- en: Weights of the neurons in hidden layers for the Additive Gaussian Auto Encoder
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: Plotting the reconstructed images
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The last step is to print the reconstructed images to give us visual proof
    of how the encoder is able to reconstruct the images based on the weights:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '![](img/29d01b60-b0b1-4d30-b2f5-cdd4801808d6.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
- en: Reconstructed images using the Additive Gaussian Auto Encoder
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: Additive Gaussian autoencoder full code listing
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following is the code of the Additive Gaussian autoencoder:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Comparing basic encoder costs with the Additive Gaussian Noise autoencoder
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following graph shows the cost of two algorithms for each epoch. It can
    be inferred that the basic autoencoder is much more expensive compared to the
    Additive Gaussian Noise autoencoder:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5ce1b147-0a74-4a1d-a216-df06b6355f71.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
- en: 'Cost comparison: basic versus Additive Gaussian Noise autoencoder'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: Additive Gaussian Noise autoencoder summary
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You learned how to create an autoencoder with Gaussian noise, which helps in
    improving the accuracy of the model drastically when compared to the basic autoencoder.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 你学习了如何创建带有高斯噪声的自编码器，与基础自编码器相比，这大大提高了模型的准确性。
- en: Sparse autoencoder
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 稀疏自编码器
- en: In this section, we will look at how adding sparsity to the cost function helps
    in reducing the cost of training. Most of the code remains the same, but the primary
    changes are in the way the cost function is calculated.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，我们将研究如何通过向代价函数添加稀疏性来帮助降低训练代价。大多数代码保持不变，但主要的变化在于计算代价函数的方式。
- en: KL divergence
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: KL散度
- en: Let's first try to understand KL divergence, which is used to add sparsity to
    the cost function.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先尝试理解KL散度，它用于向代价函数添加稀疏性。
- en: We can think of a neuron as active (or *firing*) if a neuron's output value
    is close to one, and *inactive* if its output value is close to zero. We would
    like to constrain the neurons to be inactive most of the time. This discussion
    assumes a sigmoid activation function.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将一个神经元视为处于激活状态（或*发放*）当其输出值接近1时，处于*非激活*状态当其输出值接近零时。我们希望大多数时间神经元保持非激活状态。这个讨论假设使用sigmoid激活函数。
- en: Recall that *a^((2))[j]* denotes the activation of the hidden unit *j* in the
    autoencoder. This notation does not state explicitly what the input *x *was that
    led to this activation. We will write *a^((2))[j](x)* to denote the activation
    of the hidden unit when the network is given a specific input *x*. Further, let
    ![](img/10147870-75b0-464d-b1cf-2edc0807e4d2.jpg) be the average activation of
    the hidden unit *j* (averaged over the training set). We would like to (approximately)
    enforce the constraint ![](img/9971f609-c670-4c63-a7d8-381212c5620c.png), where
    [![](img/82da78e8-7a12-4a56-8037-b83b98326850.png)] is a sparsity parameter, typically
    a small value close to zero (say, = *0.05*). Our aim is that the average activation
    of each hidden neuron *j* be close to *0.05* (as an example). To satisfy the preceding
    constraint, the hidden unit's activation must mostly be close to zero.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，*a^((2))[j]*表示自编码器中隐藏单元*j*的激活值。这个符号没有明确说明导致此激活的输入*x*是什么。我们将写作 *a^((2))[j](x)*，表示当网络给定特定输入*x*时，隐藏单元的激活值。此外，令
    ![](img/10147870-75b0-464d-b1cf-2edc0807e4d2.jpg) 为隐藏单元*j*的平均激活值（在训练集上平均）。我们希望（大致）强制执行约束
    ![](img/9971f609-c670-4c63-a7d8-381212c5620c.png)，其中 [![](img/82da78e8-7a12-4a56-8037-b83b98326850.png)]
    是一个稀疏性参数，通常是一个接近零的小值（例如，= *0.05*）。我们的目标是让每个隐藏神经元*j*的平均激活值接近*0.05*（作为一个例子）。为了满足前述约束，隐藏单元的激活必须大部分时间接近零。
- en: 'To achieve this, an extra penalty term is added to the optimization objective
    that penalizes it, deviating significantly from[![](img/82da78e8-7a12-4a56-8037-b83b98326850.png)]:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，我们在优化目标中加入了一个额外的惩罚项，该惩罚项会惩罚与[![](img/82da78e8-7a12-4a56-8037-b83b98326850.png)]的偏差过大的情况：
- en: '![](img/6088760a-c222-4657-b2d1-7fcf511893dd.jpg)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6088760a-c222-4657-b2d1-7fcf511893dd.jpg)'
- en: 'Let''s take a look at how KL divergence varies as a function of the average
    activation:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看KL散度如何随平均激活值的变化而变化：
- en: '![](img/16a1258c-7aef-41ae-95dd-00965d51e402.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![](img/16a1258c-7aef-41ae-95dd-00965d51e402.png)'
- en: Average activation versus KL divergence plot
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 平均激活值与KL散度图
- en: KL divergence in TensorFlow
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow中的KL散度
- en: 'In our implementation of a sparse encoder, we defined KL divergence in a `kl_divergence`
    function in the `SparseEncoder` class, which is nothing but an implementation
    of the preceding formula:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们实现的稀疏编码器中，我们在`SparseEncoder`类中的`kl_divergence`函数里定义了KL散度，这只是前述公式的实现：
- en: '[PRE31]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Cost of a sparse autoencoder based on KL Divergence
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于KL散度的稀疏自编码器代价
- en: 'The cost function is redefined with two new parameters, `sparse_reg` and `kl_divergence`,
    when compared to the previous encoders discussed in this chapter:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 与本章讨论的先前编码器相比，代价函数在重新定义时引入了两个新参数，`sparse_reg`和`kl_divergence`：
- en: '[PRE32]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Complete code listing of the sparse autoencoder
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 稀疏自编码器的完整代码列表
- en: 'For reference, we have given the code listing for `SparseAutoEncoder` here,
    with the `kl_divergence` and `cost` discussed earlier:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 作为参考，下面给出了`SparseAutoEncoder`的代码列表，其中包括之前讨论过的`kl_divergence`和`cost`：
- en: '[PRE33]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: In the next section we will look at Sparse autoencoder applied to a specific
    dataset.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将研究稀疏自编码器在特定数据集上的应用。
- en: Sparse autoencoder on MNIST data
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在MNIST数据上的稀疏自编码器
- en: 'Let''s run this encoder on the same dataset that we used in the other examples
    and compare the results:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在与其他示例中使用相同的数据集上运行这个编码器，并比较结果：
- en: '[PRE34]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The output of the preceding code is as follows:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码的输出如下：
- en: '[PRE35]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: As can be seen, the cost is lower than other encoders, hence KL divergence and
    sparsity definitely help.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 如图所示，成本低于其他编码器，因此 KL 散度和稀疏性确实起到了帮助作用。
- en: Comparing the Sparse encoder with the Additive Gaussian Noise encoder
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 比较稀疏编码器和加性高斯噪声编码器
- en: 'The following graph shows how the costs compare for the Additive Gaussian Noise
    autoencoder and the Sparse autoencoder:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了加性高斯噪声自编码器和稀疏自编码器的成本比较：
- en: '![](img/7bafe3e7-94b6-4a06-96e7-8422a114d7ab.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7bafe3e7-94b6-4a06-96e7-8422a114d7ab.png)'
- en: Cost comparison of two autoencoders for five epochs on the MNIST dataset
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在 MNIST 数据集上运行五个周期的两个自编码器的成本比较
- en: Summary
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, you learned three different types of autoencoders: basic,
    Additive Gaussian Noise, and Sparse. We understood the use cases where they can
    be useful. We ran them against the MNIST dataset and also compared the cost of
    the three autoencoders. We also plotted the weights as well as the approximate
    output.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了三种不同类型的自编码器：基本自编码器、加性高斯噪声自编码器和稀疏自编码器。我们理解了它们的应用场景，并在 MNIST 数据集上运行了它们，同时比较了这三种自编码器的成本。我们还绘制了权重以及近似输出。
