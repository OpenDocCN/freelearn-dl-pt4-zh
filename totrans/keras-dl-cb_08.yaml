- en: Autoencoders
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An autoencoder is a type of neural network that is trained to attempt to copy
    its input to its output. It has a hidden layer (let''s call it *h*) that describes
    a code used to represent the input. The network may be viewed as consisting of
    two parts:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Encoder function**: *h = f (x)*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Decoder that produces a reconstruction**: *r = g(h)*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following figure shows a basic autoencoder with input *n* and a hidden
    layer with neurons *m*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/af478e87-a284-4b89-95bd-027cbdca7a02.png)'
  prefs: []
  type: TYPE_IMG
- en: Basic representation of an autoencoder
  prefs: []
  type: TYPE_NORMAL
- en: Autoencoders are designed to be unable to learn to copy perfectly. They are
    restricted in ways that allow them to copy only approximately, and to copy only
    input that resembles the training data. As the model is forced to prioritize which
    aspects of the input should be copied, it often learns useful properties of the
    data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Autoencoder algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Under-complete autoencoders
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Basic autoencoders
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Additive Gaussian Noise autoencoders
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sparse autoencoders
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Autoencoder algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the following notation, `x` is the input, `y` is the encoded data, `z` is
    the decoded data, `σ` is a nonlinear activation function (sigmoid or hyperbolic
    tangent, usually), and `f(x;θ)` means a function of `x` parameterized by `θ`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model can be summarized in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The input data is mapped to the hidden layer (encoding). The mapping is usually
    an affine (allowing for or preserving parallel relationships.) transformation
    followed by a non-linearity:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The hidden layer is mapped to the output layer, which is also called **decoding**.
    The mapping is an affine transformation (affine transformation is a linear mapping
    method that preserves points, straight lines, and planes) optionally followed
    by a non linearity. The following equation explains this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In order to reduce the size of the model, tied weights can be used, which means
    that the decoder weights matrix is constrained and can be the transpose of the
    encoder weights matrix, *θ'=θ^T*.
  prefs: []
  type: TYPE_NORMAL
- en: The hidden layer can have a lower or higher dimensionality than that of the
    input/output layers.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of lower dimensionality, the decoder reconstructs the original input
    from a lower-dimensional representation of it (also called **under-complete representation**).
    For the overall algorithm to work, the encoder should learn to provide a low-dimensional
    representation that captures the essence of the data (that is, the main factors
    of variations in the distribution). It is forced to find a good way to summarize
    the data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Reference: [http://blackecho.github.io/blog/machine-learning/2016/02/29/denoising-autoencoder-tensorflow.html](http://blackecho.github.io/blog/machine-learning/2016/02/29/denoising-autoencoder-tensorflow.html).'
  prefs: []
  type: TYPE_NORMAL
- en: Under-complete autoencoders
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the ways to obtain useful features from the autoencoder is done by constraining
    *h* to have a smaller dimension than input `x`. An autoencoder with a code dimension
    less than the input dimension is called under-complete.
  prefs: []
  type: TYPE_NORMAL
- en: Learning a representation that is under-complete forces the autoencoder to capture
    the most salient features of the training data.
  prefs: []
  type: TYPE_NORMAL
- en: The learning process is described as minimizing a loss function, `L(x, g(f(x)))`,
  prefs: []
  type: TYPE_NORMAL
- en: where `L` is a loss function penalizing `g(f (x))` for being dissimilar from
    `x`, such as the mean squared error.
  prefs: []
  type: TYPE_NORMAL
- en: Dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We are planning to use the MNIST dataset in the `idx3` format as input to train
    our autoencoders. We will be testing the autoencoder on the first 100 images.
    Let''s first plot the original images:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding is the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3ea4bce8-c710-41bb-9eed-3ba8deac2dde.png)'
  prefs: []
  type: TYPE_IMG
- en: Plot of original MNIST images
  prefs: []
  type: TYPE_NORMAL
- en: Basic autoencoders
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s look at a basic example of an autoencoder that also happens to be a
    basic autoencoder. First, we will create an `AutoEncoder` class and initialize
    it with the following parameters passed to `__init__()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`num_input`: Number of input samples'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_hidden`: Number of neurons in the hidden layer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`transfer_function=tf.nn.softplus`: Transfer function'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`optimizer = tf.train.AdamOptimizer()`: Optimizer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can either pass a custom `transfer_function` and `optimizer` or use the
    default one specified. In our example, we are using softplus as the default `transfer_function`
    (also called **activation function**): `f(x)=ln(1+e^x)`.'
  prefs: []
  type: TYPE_NORMAL
- en: Autoencoder initialization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, we initialize the class variables and weights:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, the `_initialize_weigths()` function is a local function that initializes
    values for the `weights` dictionary:'
  prefs: []
  type: TYPE_NORMAL
- en: '`w1` is a 2D tensor with shape `num_input X num_hidden`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`b1` is a 1D tensor with shape `num_hidden`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`w2` is a 2D tensor with shape `num_hidden X num_input`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`b2` is a 2D tensor with shape `num_input`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following code shows how weights are initialized as a dictionary of TensorFlow
    variables for two hidden layers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we define `x_var`, `hidden_layer`, and `reconstruction layer`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/65f7a30e-20da-4026-b85e-8536e42987f3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Cost function
  prefs: []
  type: TYPE_NORMAL
- en: Instantiate the global variables initializer and pass it to TensorFlow session.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: AutoEncoder class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Th following code shows `AutoEncoder` class. This class with be instantiated
    for samples in next few sections to create autoencoders:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Basic autoencoders with MNIST data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s use the autoencoder with MNIST data: `mnist = input_data.read_data_sets(''MNIST_data'',
    one_hot = True)`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use StandardScalar from Scikit Learn''s `sklearn.``preprocessing` module to
    extract `testmnist.test.images` and training images `mnist.train.images`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The preprocessing module provides a utility class, `StandardScaler`, which implements
    the Transformer API. This computes and transforms the mean and standard deviation
    of a training set. It reapplies the same transformation to the testing set. By
    default, Scalar centers the mean and makes the variance one.
  prefs: []
  type: TYPE_NORMAL
- en: It is possible to disable either centering or scaling by passing `with_mean=False`
    or `with_std=False` to the constructor of StandardScaler.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we define an instance of the AutoEncoder class listed earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice that the autoencoder includes the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Number of input neurons is `784`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Number of neurons in the hidden layer is `200`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Activation function is `tf.nn.softplus`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimizer is `tf.train.AdamOptimizer`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Next, we iterate over the training data and display the cost function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Print the total cost:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the epochs is listed as follows; as expected, the cost converges
    with each iteration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Basic autoencoder plot of weights
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once the training is done show the plot of weights using the Matplotlib library
    using code listing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/8f561398-b0db-4d6f-b0eb-622b94e61396.png)'
  prefs: []
  type: TYPE_IMG
- en: Basic autoencoder weights plot
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will look at how images are recreated using the weights
    shown in the preceding image.
  prefs: []
  type: TYPE_NORMAL
- en: Basic autoencoder recreated images plot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Having recreated the images, let''s plot them to get a feel of how they look.
    First, we will reconstruct the images using the `autoencoder` instance created
    earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s look at the created images from the neural network:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fcaccfd9-080c-4775-a79e-3f0756e2c92b.png)'
  prefs: []
  type: TYPE_IMG
- en: Basic autoencoder plot of output images
  prefs: []
  type: TYPE_NORMAL
- en: Basic autoencoder full code listing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The full code listing can be found here or can also be downloaded from GitHub--[https://github.com/rajdeepd/neuralnetwork-programming/blob/ed1/ch07/basic_autoencoder_example.py](https://github.com/rajdeepd/neuralnetwork-programming/blob/ed1/ch07/basic_autoencoder_example.py):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Basic autoencoder summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The autoencoder created a basic approximation of MNSIT images using 200 neuron
    hidden layers. The following diagram shows nine images and how they were transformed
    into approximations using a basic autoencoder:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f98d20e7-7c2e-4a37-8e18-5fc0bc23ab87.png)'
  prefs: []
  type: TYPE_IMG
- en: Basic autoencoder input and output representation
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will look at a more advanced autoencoder, an **Additive
    Gaussian Noise AutoEncoder**.
  prefs: []
  type: TYPE_NORMAL
- en: Additive Gaussian Noise autoencoder
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What are Denoising autoencoders? They are very similar to the basic model we
    saw in previous sections, the difference is that, the input is corrupted before
    being passed to the network. By matching the original version (not the corrupted
    one) with the reconstruction at training time, this autoencoder gets trained to
    reconstruct the original input image from the corrupted image.  The ability to
    reconstruct original image from corrupted image makes autoencoder very smart.
  prefs: []
  type: TYPE_NORMAL
- en: 'An additive noise autoencoder uses the following equation to add corruption
    to incoming data:'
  prefs: []
  type: TYPE_NORMAL
- en: '*x[corr] = x + scale*random_normal(n)*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the detail describe about the preceding equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '*x* is the original image'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*scale* is the multiplier for a random normal number generated from *n*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*n* is the number of training samples'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*x[corr]* is the corrupted output'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Autoencoder class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We initialize the autoencoder defined in `class AdditiveGaussianNoiseAutoEncoder`
    by passing following parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '`num_input`: Number of input samples'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_hidden`: Number of neurons in the hidden layer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`transfer_function=tf.nn.sigmoid`: Transfer function'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`optimizer = tf.train.AdamOptimizer()`: Optimizer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`scale=0.1`: Scale for corruption of the image'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Assign the passed parameters to the instance variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Initialize the hidden layer `hidden_layer` and the reconstruction layer `reconstruction`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Define the cost function and the optimizer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The cost function remains the same as the basic autoencoder
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/594dd7ad-8b38-4948-9df7-edea73778020.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Cost function of additive Gaussian autoencoder
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we initialize global variables, create a TensorFlow session, and run
    it to execute the `init` graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: In the next section, we will look at how this autoencoder will be used to encode
    MNIST data.
  prefs: []
  type: TYPE_NORMAL
- en: Additive Gaussian Autoencoder with the MNIST dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, we load the train and test datasets, `X_train` and `X_test`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Define the variables for the number of samples, `n_samples`, `training_epoch`,
    and `batch_size` for each iteration of the training and `display_step`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Instantiate the autoencoder and the optimizer. The autoencoder has 200 hidden
    units and uses sigmoid as the `transfer_function`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Training the model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once the neural network layers have been defined we train the model by calling
    method
  prefs: []
  type: TYPE_NORMAL
- en: '`autoencoder.partial_fit(batch_xs)` for each batch of data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The cost of each epoch is printed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The total cost of training is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Plotting the weights
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s plot the weights visually and plot them using Matplotlib:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/02034b23-6d96-47a1-bd02-38459aaecc86.png)'
  prefs: []
  type: TYPE_IMG
- en: Weights of the neurons in hidden layers for the Additive Gaussian Auto Encoder
  prefs: []
  type: TYPE_NORMAL
- en: Plotting the reconstructed images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The last step is to print the reconstructed images to give us visual proof
    of how the encoder is able to reconstruct the images based on the weights:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/29d01b60-b0b1-4d30-b2f5-cdd4801808d6.png)'
  prefs: []
  type: TYPE_IMG
- en: Reconstructed images using the Additive Gaussian Auto Encoder
  prefs: []
  type: TYPE_NORMAL
- en: Additive Gaussian autoencoder full code listing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following is the code of the Additive Gaussian autoencoder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Comparing basic encoder costs with the Additive Gaussian Noise autoencoder
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following graph shows the cost of two algorithms for each epoch. It can
    be inferred that the basic autoencoder is much more expensive compared to the
    Additive Gaussian Noise autoencoder:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5ce1b147-0a74-4a1d-a216-df06b6355f71.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Cost comparison: basic versus Additive Gaussian Noise autoencoder'
  prefs: []
  type: TYPE_NORMAL
- en: Additive Gaussian Noise autoencoder summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You learned how to create an autoencoder with Gaussian noise, which helps in
    improving the accuracy of the model drastically when compared to the basic autoencoder.
  prefs: []
  type: TYPE_NORMAL
- en: Sparse autoencoder
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will look at how adding sparsity to the cost function helps
    in reducing the cost of training. Most of the code remains the same, but the primary
    changes are in the way the cost function is calculated.
  prefs: []
  type: TYPE_NORMAL
- en: KL divergence
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's first try to understand KL divergence, which is used to add sparsity to
    the cost function.
  prefs: []
  type: TYPE_NORMAL
- en: We can think of a neuron as active (or *firing*) if a neuron's output value
    is close to one, and *inactive* if its output value is close to zero. We would
    like to constrain the neurons to be inactive most of the time. This discussion
    assumes a sigmoid activation function.
  prefs: []
  type: TYPE_NORMAL
- en: Recall that *a^((2))[j]* denotes the activation of the hidden unit *j* in the
    autoencoder. This notation does not state explicitly what the input *x *was that
    led to this activation. We will write *a^((2))[j](x)* to denote the activation
    of the hidden unit when the network is given a specific input *x*. Further, let
    ![](img/10147870-75b0-464d-b1cf-2edc0807e4d2.jpg) be the average activation of
    the hidden unit *j* (averaged over the training set). We would like to (approximately)
    enforce the constraint ![](img/9971f609-c670-4c63-a7d8-381212c5620c.png), where
    [![](img/82da78e8-7a12-4a56-8037-b83b98326850.png)] is a sparsity parameter, typically
    a small value close to zero (say, = *0.05*). Our aim is that the average activation
    of each hidden neuron *j* be close to *0.05* (as an example). To satisfy the preceding
    constraint, the hidden unit's activation must mostly be close to zero.
  prefs: []
  type: TYPE_NORMAL
- en: 'To achieve this, an extra penalty term is added to the optimization objective
    that penalizes it, deviating significantly from[![](img/82da78e8-7a12-4a56-8037-b83b98326850.png)]:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6088760a-c222-4657-b2d1-7fcf511893dd.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s take a look at how KL divergence varies as a function of the average
    activation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/16a1258c-7aef-41ae-95dd-00965d51e402.png)'
  prefs: []
  type: TYPE_IMG
- en: Average activation versus KL divergence plot
  prefs: []
  type: TYPE_NORMAL
- en: KL divergence in TensorFlow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In our implementation of a sparse encoder, we defined KL divergence in a `kl_divergence`
    function in the `SparseEncoder` class, which is nothing but an implementation
    of the preceding formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Cost of a sparse autoencoder based on KL Divergence
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The cost function is redefined with two new parameters, `sparse_reg` and `kl_divergence`,
    when compared to the previous encoders discussed in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Complete code listing of the sparse autoencoder
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For reference, we have given the code listing for `SparseAutoEncoder` here,
    with the `kl_divergence` and `cost` discussed earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: In the next section we will look at Sparse autoencoder applied to a specific
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Sparse autoencoder on MNIST data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s run this encoder on the same dataset that we used in the other examples
    and compare the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: As can be seen, the cost is lower than other encoders, hence KL divergence and
    sparsity definitely help.
  prefs: []
  type: TYPE_NORMAL
- en: Comparing the Sparse encoder with the Additive Gaussian Noise encoder
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following graph shows how the costs compare for the Additive Gaussian Noise
    autoencoder and the Sparse autoencoder:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7bafe3e7-94b6-4a06-96e7-8422a114d7ab.png)'
  prefs: []
  type: TYPE_IMG
- en: Cost comparison of two autoencoders for five epochs on the MNIST dataset
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, you learned three different types of autoencoders: basic,
    Additive Gaussian Noise, and Sparse. We understood the use cases where they can
    be useful. We ran them against the MNIST dataset and also compared the cost of
    the three autoencoders. We also plotted the weights as well as the approximate
    output.'
  prefs: []
  type: TYPE_NORMAL
