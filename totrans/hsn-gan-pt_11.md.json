["```py\nimport torch\nimport torch.nn as nn\n\nclass Generator(nn.Module):\n    def __init__(self, channels, latent_dim=100, embed_dim=1024, embed_out_dim=128):\n        super(Generator, self).__init__()\n        self.channels = channels\n        self.latent_dim = latent_dim\n        self.embed_dim = embed_dim\n        self.embed_out_dim = embed_out_dim\n\n        self.text_embedding = nn.Sequential(\n            nn.Linear(self.embed_dim, self.embed_out_dim),\n            nn.BatchNorm1d(self.embed_out_dim),\n            nn.LeakyReLU(0.2, inplace=True)\n        )\n\n        model = []\n        model += self._create_layer(self.latent_dim + self.embed_out_dim, 512, 4, stride=1, padding=0)\n        model += self._create_layer(512, 256, 4, stride=2, padding=1)\n        model += self._create_layer(256, 128, 4, stride=2, padding=1)\n        model += self._create_layer(128, 64, 4, stride=2, padding=1)\n        model += self._create_layer(64, self.channels, 4, stride=2, padding=1, output=True)\n\n        self.model = nn.Sequential(*model)\n\n    def _create_layer(self, size_in, size_out, kernel_size=4, stride=2, padding=1, output=False):\n        layers = [nn.ConvTranspose2d(size_in, size_out, kernel_size, stride=stride, padding=padding, bias=False)]\n        if output:\n            layers.append(nn.Tanh())\n        else:\n            layers += [nn.BatchNorm2d(size_out),\n                 nn.ReLU(True)]\n        return layers\n\n    def forward(self, noise, text):\n        text = self.text_embedding(text)\n        text = text.view(text.shape[0], text.shape[1], 1, 1)\n        z = torch.cat([text, noise], 1)\n        return self.model(z)\n```", "```py\nclass Embedding(nn.Module):\n    def __init__(self, size_in, size_out):\n        super(Embedding, self).__init__()\n        self.text_embedding = nn.Sequential(\n            nn.Linear(size_in, size_out),\n            nn.BatchNorm1d(size_out),\n            nn.LeakyReLU(0.2, inplace=True)\n        )\n\n    def forward(self, x, text):\n        embed_out = self.text_embedding(text)\n        embed_out_resize = embed_out.repeat(4, 4, 1, 1).permute(2, 3, 0, 1)\n        out = torch.cat([x, embed_out_resize], 1)\n        return out\n\nclass Discriminator(nn.Module):\n    def __init__(self, channels, embed_dim=1024, embed_out_dim=128):\n        super(Discriminator, self).__init__()\n        self.channels = channels\n        self.embed_dim = embed_dim\n        self.embed_out_dim = embed_out_dim\n\n        self.model = nn.Sequential(\n            *self._create_layer(self.channels, 64, 4, 2, 1, \n              normalize=False),\n            *self._create_layer(64, 128, 4, 2, 1),\n            *self._create_layer(128, 256, 4, 2, 1),\n            *self._create_layer(256, 512, 4, 2, 1)\n        )\n        self.text_embedding = Embedding(self.embed_dim, self.embed_out_dim)\n        self.output = nn.Sequential(\n            nn.Conv2d(512 + self.embed_out_dim, 1, 4, 1, 0, bias=False),\n            nn.Sigmoid()\n        )\n\n    def _create_layer(self, size_in, size_out, kernel_size=4, stride=2,  \n      padding=1, normalize=True):\n        layers = [nn.Conv2d(size_in, size_out, kernel_size=kernel_size, \n          stride=stride, padding=padding)]\n        if normalize:\n            layers.append(nn.BatchNorm2d(size_out))\n        layers.append(nn.LeakyReLU(0.2, inplace=True))\n        return layers\n\n    def forward(self, x, text):\n        x_out = self.model(x)\n        out = self.text_embedding(x_out, text)\n        out = self.output(out)\n        return out.squeeze(), x_out\n```", "```py\nimport os\nimport time\n\nimport torch\nimport torchvision.utils as vutils\n\nfrom gan import Generator as netG\nfrom gan import Discriminator as netD\n\ndef _weights_init(m):\n    # init weights in conv and batchnorm layers\n    ...\n\nclass Model(object):\n    def __init__(self, name, device, data_loader, channels, l1_coef, l2_coef):\n        # parse argument values\n        ...\n        self.netG = netG(self.channels)\n        self.netG.apply(_weights_init)\n        self.netG.to(self.device)\n        self.netD = netD(self.channels)\n        self.netD.apply(_weights_init)\n        self.netD.to(self.device)\n        self.loss_adv = torch.nn.BCELoss()\n        self.loss_l1 = torch.nn.L1Loss()\n        self.loss_l2 = torch.nn.MSELoss()\n        self.l1_coef = l1_coef\n        self.l2_coef = l2_coef\n```", "```py\n    def train(self, epochs, log_interval=100, out_dir='', verbose=True):\n        self.netG.train()\n        self.netD.train()\n        for epoch in range(epochs):\n            for batch_idx, data in enumerate(self.data_loader):\n                image = data['right_images'].to(self.device)\n                embed = data['right_embed'].to(self.device)\n\n                real_label = torch.ones((image.shape[0]), \n                 device=self.device)\n                fake_label = torch.zeros((image.shape[0]), \n                 device=self.device)\n\n                # Train D\n                self.optim_D.zero_grad()\n\n                out_real, _ = self.netD(image, embed)\n                loss_d_real = self.loss_adv(out_real, real_label)\n\n                noise = torch.randn((image.shape[0], 100, 1, 1), \n                 device=self.device)\n                image_fake = self.netG(noise, embed)\n                out_fake, _ = self.netD(image_fake, embed)\n                loss_d_fake = self.loss_adv(out_fake, fake_label)\n\n                d_loss = loss_d_real + loss_d_fake\n                d_loss.backward()\n                self.optim_D.step()\n\n                # Train G\n                self.optim_G.zero_grad()\n                noise = torch.randn((image.shape[0], 100, 1, 1), \n                 device=self.device)\n                image_fake = self.netG(noise, embed)\n                out_fake, act_fake = self.netD(image_fake, embed)\n                _, act_real = self.netD(image, embed)\n\n                l1_loss = self.loss_l1(torch.mean(act_fake, 0), \n                 torch.mean(act_real, 0).detach())\n                g_loss = self.loss_adv(out_fake, real_label) + \\\n                    self.l1_coef * l1_loss + \\\n                    self.l2_coef * self.loss_l2(image_fake, image)\n                g_loss.backward()\n                self.optim_G.step()\n```", "```py\nimport argparse\nimport os\nimport sys\n\nimport numpy as np\nimport torch\nimport torch.backends.cudnn as cudnn\nimport utils\n\nfrom torch.utils.data import DataLoader\nfrom build_gan import Model\nfrom txt2image_dataset import Text2ImageDataset\n\nFLAGS = None\n\ndef main():\n    ...\n    device = torch.device(\"cuda:0\" if FLAGS.cuda else \"cpu\")\n\n    print('Loading data...\\n')\n    dataloader = DataLoader(Text2ImageDataset(os.path.join(FLAGS.data_dir, '{}.hdf5'.format(FLAGS.dataset)), split=0),\n        batch_size=FLAGS.batch_size, shuffle=True, num_workers=8)\n\n    print('Creating model...\\n')\n    model = Model(FLAGS.model, device, dataloader, FLAGS.channels, FLAGS.l1_coef, FLAGS.l2_coef)\n\n    if FLAGS.train:\n        model.create_optim(FLAGS.lr)\n\n        print('Training...\\n')\n        model.train(FLAGS.epochs, FLAGS.log_interval, FLAGS.out_dir, True)\n\n        model.save_to('')\n    else:\n        ...\n```", "```py\n$ pip install pyyaml tensorboard-pytorch scipy python-dateutil easydict pandas torchfile\n```", "```py\n$ git clone https://github.com/hanzhanggit/StackGAN-v2 && cd StackGAN-v2\n```", "```py\n$ cd code && python main.py --cfg cfg/birds_3stages.yml --gpu 0\n```", "```py\n NET_G: '../output/birds_3stages_2019_07_16_23_57_11/Model/netG_220800.pth'\n```", "```py\n$ python main.py --cfg cfg/eval_birds.yml --gpu 0\n```"]