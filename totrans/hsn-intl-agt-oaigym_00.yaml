- en: Preface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This book will guide you through the process of implementing your own intelligent
    agents to solve both discrete- and continuous-valued sequential decision-making
    problems with all the essential building blocks to develop, debug, train, visualize,
    customize, and test your intelligent agent implementations in a variety of learning
    environments, ranging from the Mountain Car and Cart Pole problems to Atari games
    and CARLA – an advanced simulator for autonomous driving.
  prefs: []
  type: TYPE_NORMAL
- en: Who this book is for
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you're a student, a game/machine learning developer, or an AI enthusiast
    looking to get started building intelligent agents and algorithms to solve a variety
    of problems using learning environments with the OpenAI Gym interface, this book
    is for you. You will also find this book useful if you want to learn how to build
    deep reinforcement learning-based, artificially intelligent agents to solve problems
    in your domain of interest. Though the book covers all the basic concepts that
    you need to know, some working knowledge of Python will help you get the most
    out of it.
  prefs: []
  type: TYPE_NORMAL
- en: What this book covers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Chapter 1, *Introduction to Intelligent Agents and Learning Environments*, which
    enables the development of several AI systems. It sheds light on the important
    features of the toolkit, which provides you with endless opportunities to create
    autonomous intelligent agents to solve several algorithmic tasks, games, and control
    tasks. By the end of this chapter, you will know enough to create an instance
    of a Gym environment using Python yourself.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter 2, *Reinforcement Learning and Deep Reinforcement Learning*, provides
    a concise
  prefs: []
  type: TYPE_NORMAL
- en: explanation of the basic terminologies and concepts in reinforcement learning.
    The chapter
  prefs: []
  type: TYPE_NORMAL
- en: will give you a good understanding of the basic reinforcement learning framework
    for
  prefs: []
  type: TYPE_NORMAL
- en: developing AI agents. The chapter will also introduce deep reinforcement learning
    and
  prefs: []
  type: TYPE_NORMAL
- en: provide you with a flavor of the types of advanced problem the algorithms enable
    you to
  prefs: []
  type: TYPE_NORMAL
- en: solve.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter 3, *Getting Started with OpenAI Gym and Deep Reinforcement Learning*,
    jumps right in and gets your development machine/computer ready with all the required
    installations and configurations needed for using the learning environments as
    well as PyTorch for developing deep learning algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter 4, *Exploring the Gym and its Features*, walks you through the inventory
    of learning environments available with the Gym library starting with the overview
    of how the environments are classified and named which will help you choose the
    correct version and type of environments from the 700+ learning environments available.
    You will then learn to explore the Gym, test out any of the environment you would
    like to, understand the interface and description of various environments.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter 5, *Implementing your First Learning Agent – Solving the Mountain Car
    problem*, explains how to implement an AI agent using reinforcement learning to
    solve the mountain
  prefs: []
  type: TYPE_NORMAL
- en: car problem. You will implement the agent, train it, and see it improve on its
    own. The
  prefs: []
  type: TYPE_NORMAL
- en: implementation details will enable you to apply the concepts to develop and
    train an agent
  prefs: []
  type: TYPE_NORMAL
- en: to solve various other tasks and/or games.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter 6, *Implementing an Intelligent Agent for Optimal Control using Deep
    Q-Learning*, covers various methods to improve Q-learning including action-value
    function approximation using deep neural network, experience replay, target networks
    and also the necessary utilities and building-blocks that are useful for training
    and testing deep reinforcement learning agents in general. You will implement
    a DQN based intelligent agent for taking optimal discrete control actions and
    train it to play several Atari games and watch the agent's performance.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter 7, *Creating Custom OpenAI Gym Environments – Carla Driving Simulator*, will
    teach you how to convert a real-world problem into a learning environment with
    interfaces compatible with the OpenAI Gym. You will learn the anatomy of Gym environments
    and create your custom learning environment based on the Carla simulator that
    can be registered with the Gym and used for training agents that we develop.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter 8, *Implementing an Intelligent & Autonomous Car Driving Agent using
    Deep Actor-Critic Algorithm*, teaches you the fundamentals of the Policy Gradient
    based reinforcement learning algorithms and helps you intuitively understand the
    deep n-step advantage actor-critic algorithm. You will then learn to implement
    a super-intelligent agent that can drive a car autonomously in the Carla simulator
    using both the synchronous as well as asynchronous implementation of the deep
    n-step advantage actor-critic algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter 9, *Exploring the Learning Environment Landscape – Roboschool, Gym-Retro,
    StarCraft-II, DeepMindLab*, takes you beyond the Gym and shows you around other
    well developed suite of learning environments that you can use to train your intelligent
    agents. You will understand and learn to use the various Roboschool environments,
    the Gym Retro environments, the very popular Star Craft II environment and the
    DeepMind Lab environments.
  prefs: []
  type: TYPE_NORMAL
- en: 'Chapter 10, *Exploring the Learning Algorithm Landscape – DDPG (Actor-Critic),
    PPO (Policy-Gradient), Rainbow (Value-Based)**,* Provides insights into latest
    deep reinforcement learning algorithms with their fundamentals demystified based
    on what you learned in the previous chapters of this book. You will get a quick
    understanding of the core concepts behind the best algorithms in the three different
    classes of deep reinforcement learning algorithms namely: The actor-critic based
    Deep Deterministic Policy Gradient (DDPG) algorithm, the Policy Gradient based
    Proximal Policy Optimization (PPO) and the value based Rainbow algorithm.'
  prefs: []
  type: TYPE_NORMAL
- en: To get the most out of this book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following will be required:'
  prefs: []
  type: TYPE_NORMAL
- en: Some working knowledge of Python programming in order to understand the syntax,
    module imports, and library installations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some experience with Linux or macOS X command line for basic tasks, such as
    navigating the filesystem and running Python scripts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Download the example code files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can download the example code files for this book from your account at [www.packtpub.com](http://www.packtpub.com).
    If you purchased this book elsewhere, you can visit [www.packtpub.com/support](http://www.packtpub.com/support)
    and register to have the files emailed directly to you.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can download the code files by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Log in or register at [www.packtpub.com](http://www.packtpub.com/support).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the SUPPORT tab.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on Code Downloads & Errata.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter the name of the book in the Search box and follow the onscreen instructions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once the file is downloaded, please make sure that you unzip or extract the
    folder using the latest version of:'
  prefs: []
  type: TYPE_NORMAL
- en: WinRAR/7-Zip for Windows
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zipeg/iZip/UnRarX for Mac
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 7-Zip/PeaZip for Linux
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code bundle for the book is also hosted on GitHub at [https://github.com/PacktPublishing/Hands-On-Intelligent-Agents-with-OpenAI-Gym](https://github.com/PacktPublishing/Hands-On-Intelligent-Agents-with-OpenAI-Gym). In
    case there's an update to the code, it will be updated on the existing GitHub
    repository.
  prefs: []
  type: TYPE_NORMAL
- en: We also have other code bundles from our rich catalog of books and videos available
    at **[https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)**.
    Check them out!
  prefs: []
  type: TYPE_NORMAL
- en: Download the color images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We also provide a PDF file that has color images of the screenshots/diagrams
    used in this book. You can download it here: [http://www.packtpub.com/sites/default/files/downloads/HandsOnIntelligentAgentswithOpenAIGym_ColorImages.pdf](http://www.packtpub.com/sites/default/files/downloads/HandsOnIntelligentAgentswithOpenAIGym_ColorImages.pdf).'
  prefs: []
  type: TYPE_NORMAL
- en: Conventions used
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a number of text conventions used throughout this book.
  prefs: []
  type: TYPE_NORMAL
- en: '`CodeInText`: Indicates code words in text, database table names, folder names,
    filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles.
    Here is an example: "Mount the downloaded `WebStorm-10*.dmg` disk image file as
    another disk in your system."'
  prefs: []
  type: TYPE_NORMAL
- en: 'A block of code is set as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'When we wish to draw your attention to a particular part of a code block, the
    relevant lines or items are set in bold:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Any command-line input or output is written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**Bold**: Indicates a new term, an important word, or words that you see onscreen.
    For example, words in menus or dialog boxes appear in the text like this. Here
    is an example: "Select System info from the Administration panel."'
  prefs: []
  type: TYPE_NORMAL
- en: Warnings or important notes appear like this.
  prefs: []
  type: TYPE_NORMAL
- en: Tips and tricks appear like this.
  prefs: []
  type: TYPE_NORMAL
- en: Get in touch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Feedback from our readers is always welcome.
  prefs: []
  type: TYPE_NORMAL
- en: '**General feedback**: Email `feedback@packtpub.com` and mention the book title
    in the subject of your message. If you have questions about any aspect of this
    book, please email us at `questions@packtpub.com`.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Errata**: Although we have taken every care to ensure the accuracy of our
    content, mistakes do happen. If you have found a mistake in this book, we would
    be grateful if you would report this to us. Please visit [www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata),
    selecting your book, clicking on the Errata Submission Form link, and entering
    the details.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Piracy**: If you come across any illegal copies of our works in any form
    on the Internet, we would be grateful if you would provide us with the location
    address or website name. Please contact us at `copyright@packtpub.com` with a
    link to the material.'
  prefs: []
  type: TYPE_NORMAL
- en: '**If you are interested in becoming an author**: If there is a topic that you
    have expertise in and you are interested in either writing or contributing to
    a book, please visit [authors.packtpub.com](http://authors.packtpub.com/).'
  prefs: []
  type: TYPE_NORMAL
- en: Reviews
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Please leave a review. Once you have read and used this book, why not leave
    a review on the site that you purchased it from? Potential readers can then see
    and use your unbiased opinion to make purchase decisions, we at Packt can understand
    what you think about our products, and our authors can see your feedback on their
    book. Thank you!
  prefs: []
  type: TYPE_NORMAL
- en: For more information about Packt, please visit [packtpub.com](https://www.packtpub.com/).
  prefs: []
  type: TYPE_NORMAL
