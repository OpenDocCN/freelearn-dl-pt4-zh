["```py\n    from keras.callbacks import TensorBoard\n    model_name = 'bitcoin_lstm_v0_run_0'\n    tensorboard = TensorBoard(log_dir='./logs/{}'.format(model_name))\n    model.fit(x=X_train, y=Y_validate,\n    batch_size=1, epochs=100,\n    verbose=0, callbacks=[tensorboard])\n```", "```py\n    model.fit(x=X_train, y=Y_train,\n    batch_size=1, epochs=100,\n    verbose=0, callbacks=[tensorboard],\n    validation_split=0.1,\n    validation_data=(X_validation, Y_validation))\n```", "```py\n     model.evaluate(x=X_test, y=Y_test)\n```", "```py\n    combined_set = np.concatenate((train_data, test_data), axis=1)\n        evaluated_weeks = []\n        for i in range(0, validation_data.shape[1]):\n        input_series = combined_set[0:,i:i+77]\n\n       X_test = input_series[0:,:-1].reshape(1, input_series.shape[1] - 1,)\n       Y_test = input_series[0:,-1:][0]\n\n       result = B.model.evaluate(x=X_test, y=Y_test, verbose=0)\n       evaluated_weeks.append(result)\n```", "```py\n    combined_set = np.concatenate((train_data, test_data), axis=1)\n\n        predicted_weeks = []\n        for i in range(0, validation_data.shape[1] + 1):\n        input_series = combined_set[0:,i:i+76]\n        predicted_weeks.append(B.predict(input_series))\n```", "```py\n    def denormalize(reference, series,\n\n    normalized_variable='close_point_relative_normalization',\n    denormalized_variable='close'):\n    week_values = observed[reference['iso_week']==series['iso_week'].\n    values[0]]\n    last_value = week_values[denormalized_variable].values[0]\n    series[denormalized_variable] = \n    last_value*(series[normalized_variable]+1)\n\n    return series\n\n    predicted_close = predicted.groupby('iso_week').apply\n    (lambda x: denormalize(observed, x))\n```", "```py\n    def mape(A, B):\n    return np.mean(np.abs((A - B) / A)) * 100\n\n    def rmse(A, B):\n    return np.sqrt(np.square(np.subtract(A, B)).mean())\n\n```", "```py\n      $ jupyter notebook\n```", "```py\n      $ cd ./chapter_3/activity_6/\n      $ tensorboard --logdir=logs/\n```", "```py\n      $ train = pd.read_csv('data/train_dataset.csv')\n      $ test = pd.read_csv('data/test_dataset.csv') \n```", "```py\n      $ model = load_model('bitcoin_lstm_v0.h5')\n```", "```py\n       $ result = model.evaluate(x=X_test, y=Y_test, verbose=0) \n```", "```py\n      predicted_weeks = []\n      for i in range(0, test_data.shape[1]):\n      input_series = combined_set[0:,i:i+76]\n      predicted_weeks.append(model.predict(input_series)) \n```", "```py\n      predicted_close = predicted.groupby('iso_week').apply(\n         lambda x: denormalize(observed, x))\n```", "```py\n      from scripts.utilities import rmse, mape \n```", "```py\n      def mape(A, B):\n      return np.mean(np.abs((A - B) / A)) * 100\n\n      def rmse(A, B):\n      return np.sqrt(np.square(np.subtract(A, B)).mean())\n```", "```py\n      model = load_model('bitcoin_lstm_v0.h5') \n```", "```py\n      train_model(X=X_train, Y=Y_validate, version=0, run_number=0)\n```", "```py\n    period_length = 7\n    number_of_periods = 76\n    batch_size = 1\n\n    model = Sequential()\n    model.add(LSTM(\n        units=period_length,\n        batch_input_shape=(batch_size, number_of_periods, period_length),\n        input_shape=(number_of_periods, period_length),\n        return_sequences=True, stateful=False))\n\n    model.add(LSTM(\n        units=period_length,\n        batch_input_shape=(batch_size, number_of_periods, period_length),\n        input_shape=(number_of_periods, period_length),\n        return_sequences=False, stateful=False))\n\n    model.add(Dense(units=period_length))\n    model.add(Activation(\"linear\"))\n\n    model.compile(loss=\"mse\", optimizer=\"rmsprop\") \n```", "```py\n    number_of_epochs = 10**3\n    model.fit(x=X, y=Y, batch_size=1,\n        epochs=number_of_epochs,\n        verbose=0,\n    callbacks=[tensorboard]) \n```", "```py\n    model = Sequential()\n\n    model.add(LSTM(\n        units=period_length,\n        batch_input_shape=(batch_size, number_of_periods, period_length),\n        input_shape=(number_of_periods, period_length),\n        return_sequences=True, stateful=False))\n\n    model.add(LSTM(\n        units=period_length,\n        batch_input_shape=(batch_size, number_of_periods, period_length),\n        input_shape=(number_of_periods, period_length),\n        return_sequences=False, stateful=False))\n\n    model.add(Dense(units=period_length))\n    model.add(Activation(\"tanh\"))\n\n    model.compile(loss=\"mse\", optimizer=\"rmsprop\") \n```", "```py\n    model = Sequential()\n    model.add(LSTM(\n        units=period_length,\n        batch_input_shape=(batch_size, number_of_periods, period_length),\n        input_shape=(number_of_periods, period_length),\n        return_sequences=True, stateful=False))\n\n    model.add(Dropout(0.2))\n    model.add(LSTM(\n        units=period_length,\n        batch_input_shape=(batch_size, number_of_periods, period_length),\n        input_shape=(number_of_periods, period_length),\n        return_sequences=False, stateful=False))\n\n    model.add(Dropout(0.2))\n\n    model.add(Dense(units=period_length))\n    model.add(Activation(\"tanh\"))\n\n    model.compile(loss=\"mse\", optimizer=\"rmsprop\") \n```", "```py\n      $ cd ./chapter_3/activity_7/\n      $ tensorboard --logdir=logs/ \n```", "```py\n       $ jupyter notebook\n```", "```py\n      train_model(model=model_v0, X=X_train, Y=Y_validate, epochs=100,\n      version=0, run_number=0) \n```", "```py\n      activation_function = \"tanh\" \n```"]