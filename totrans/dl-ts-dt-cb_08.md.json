["```py\nimport pandas as pd\ndata_directory = 'assets/datasets/Car'\ntrain = pd.read_table(f'{data_directory}/Car_TRAIN.tsv', header=None)\ntest = pd.read_table(f'{data_directory}/Car_TEST.tsv', header=None)\n```", "```py\n    y_train = train.iloc[:, 0]\n    y_test = test.iloc[:, 0]\n    X_train = train.iloc[:, 1:]\n    X_test = test.iloc[:, 1:]\n    ```", "```py\n    from sklearn.preprocessing import MinMaxScaler\n    scaler = MinMaxScaler()\n    X_train = scaler.fit_transform(X_train)\n    X_test = scaler.transform(X_test)\n    ```", "```py\n    classifier = KNeighborsTimeSeriesClassifier()\n    classifier.fit(X_train, y_train)\n    predictions = classifier.predict(X_test)\n    ```", "```py\nimport pandas as pd\ndata_directory = 'assets/datasets/Car'\ntrain = pd.read_table(f'{data_directory}/Car_TRAIN.tsv', header=None)\ntest = pd.read_table(f'{data_directory}/Car_TEST.tsv', header=None)\n```", "```py\n    from torch.utils.data import Dataset\n    class TSCDataset(Dataset):\n        def __init__(self, X_data, y_data):\n            self.X_data = X_data\n            self.y_data = y_data\n        def __getitem__(self, index):\n            return self.X_data[index], self.y_data[index]\n        def __len__(self):\n            return len(self.X_data)\n    ```", "```py\n    from torch.utils.data import Dataset, DataLoader\n    import lightning.pytorch as pl\n    from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n    class TSCDataModule(pl.LightningDataModule):\n        def __init__(self, train_df, test_df, batch_size=1):\n            super().__init__()\n            self.train_df = train_df\n            self.test_df = test_df\n            self.batch_size = batch_size\n            self.scaler = MinMaxScaler()\n            self.encoder = OneHotEncoder(categories='auto',\n                sparse_output=False)\n            self.train = None\n            self.validation = None\n            self.test = None\n    ```", "```py\n    def setup(self, stage=None):\n        y_train = self.encoder.fit_transform(\n            self.train_df.iloc[:, 0].values.reshape(-1, 1)\n        )\n        y_test = self.encoder.transform(\n            self.test_df.iloc[:,0].values.reshape(-1, 1))\n        X_train = train.iloc[:, 1:]\n        X_test = test.iloc[:, 1:]\n        X_train = self.scaler.fit_transform(X_train)\n        X_test = self.scaler.transform(X_test)\n        X_train, X_val, y_train, y_val = train_test_split(\n            X_train, y_train, test_size=0.2, stratify=y_train\n        )\n        X_train, X_val, X_test = [\n            torch.tensor(arr, dtype=torch.float).unsqueeze(1)\n            for arr in [X_train, X_val, X_test]\n        ]\n        y_train, y_val, y_test = [\n            torch.tensor(arr, dtype=torch.long)\n            for arr in [y_train, y_val, y_test]\n        ]\n        self.train = TSCDataset(X_train, y_train)\n        self.validation = TSCDataset(X_val, y_val)\n        self.test = TSCDataset(X_test, y_test)\n    ```", "```py\n        def train_dataloader(self):\n            return DataLoader(self.train, \n                batch_size=self.batch_size)\n        def val_dataloader(self):\n            return DataLoader(self.validation, \n                batch_size=self.batch_size)\n        def test_dataloader(self):\n            return DataLoader(self.test, batch_size=self.batch_size)\n    ```", "```py\n    datamodule = TSCDataModule(train_df=train, test_df=test)\n    datamodule.setup()\n    x, y = next(iter(datamodule.train_dataloader()))\n    ```", "```py\nimport pandas as pd\ndata_directory = 'assets/datasets/Car'\ntrain = pd.read_table(f'{data_directory}/Car_TRAIN.tsv', header=None)\ntest = pd.read_table(f'{data_directory}/Car_TEST.tsv', header=None)\ndatamodule = TSCDataModule(train_df=train,\n                           test_df=test,\n                           batch_size=8)\n```", "```py\n    from torch import nn\n    class ConvolutionalTSC(nn.Module):\n        def __init__(self, input_dim, output_dim=1):\n            super(ConvolutionalTSC, self).__init__()\n            self.conv1 = nn.Conv1d(in_channels=input_dim,\n                                   out_channels=64,\n                                   kernel_size=3,\n                                   stride=1,\n                                   padding=1)\n            self.conv2 = nn.Conv1d(in_channels=64,\n                                   out_channels=32,\n                                   kernel_size=3,\n                                   stride=1,\n                                   padding=1)\n            self.conv3 = nn.Conv1d(in_channels=32,\n                                   out_channels=16,\n                                   kernel_size=3,\n                                   stride=1,\n                                   padding=1)\n            self.maxp = nn.MaxPool1d(kernel_size=3)\n            self.fc1 = nn.Linear(in_features=336, out_features=32)\n            self.fc2 = nn.Linear(in_features=32, \n                out_features=output_dim)\n        def forward(self, x):\n            x = F.relu(self.conv1(x))\n            x = self.maxp(x)\n            x = F.relu(self.conv2(x))\n            x = self.maxp(x)\n            x = F.relu(self.conv3(x))\n            x = self.maxp(x)\n            x = x.view(x.size(0), -1)\n            x = self.fc1(x)\n            x = self.fc2(x)\n            return x\n    ```", "```py\n    import torch.nn.functional as F\n    import lightning.pytorch as pl\n    class TSCCnnModel(pl.LightningModule):\n        def __init__(self, output_dim):\n            super().__init__()\n            self.network = ConvolutionalTSC(\n                input_dim=1,\n                output_dim=output_dim,\n            )\n        def forward(self, x):\n            x = x.type(torch.FloatTensor)\n            return self.network(x)\n    ```", "```py\n        def training_step(self, batch, batch_idx):\n            x, y = batch\n            y_pred = self.forward(x)\n            loss = F.cross_entropy(y_pred, \n                y.type(torch.FloatTensor))\n            self.log('train_loss', loss)\n            return loss\n        def validation_step(self, batch, batch_idx):\n            x, y = batch\n            y_pred = self(x)\n            loss = F.cross_entropy(y_pred, \n                y.type(torch.FloatTensor))\n            self.log('val_loss', loss)\n            return loss\n        def test_step(self, batch, batch_idx):\n            x, y = batch\n            y_pred = self(x)\n            loss = F.cross_entropy(y_pred, \n                y.type(torch.FloatTensor))\n            self.log('test_loss', loss)\n        def configure_optimizers(self):\n            return torch.optim.Adam(self.parameters(), lr=0.01)\n    ```", "```py\n    import lightning.pytorch as pl\n    from lightning.pytorch.callbacks import EarlyStopping\n    model = TSCCnnModel(output_dim=4)\n    early_stop_callback = EarlyStopping(monitor=\"val_loss\",\n        min_delta=1e-4,\n        patience=10,\n        verbose=False,\n        mode=\"min\")\n    trainer = pl.Trainer(\n        max_epochs=30,\n        accelerator='cpu',\n        log_every_n_steps=2,\n        enable_model_summary=True,\n        callbacks=[early_stop_callback],\n    )\n    trainer.fit(model, datamodule)\n    ```", "```py\nimport pandas as pd\ndata_directory = 'assets/datasets/Car'\ntrain = pd.read_table(f'{data_directory}/Car_TRAIN.tsv', header=None)\ntest = pd.read_table(f'{data_directory}/Car_TEST.tsv', header=None)\ndatamodule = TSCDataModule(train_df=train,\n    test_df=test,\n    batch_size=8)\n```", "```py\n    class ResidualNeuralNetworkModel(nn.Module):\n        def __init__(self,\n                     in_channels: int,\n                     out_channels: int = 64,\n                     num_classes: int = 1):\n            super().__init__()\n            self.input_args = {\n                'in_channels': in_channels,\n                'num_classes': num_classes\n            }\n            self.layers = nn.Sequential(*[\n                ResNNBlock(in_channels=in_channels,\n                    out_channels=out_channels),\n                ResNNBlock(in_channels=out_channels,\n                    out_channels=out_channels * 2),\n                ResNNBlock(in_channels=out_channels * 2,\n                    out_channels=out_channels * 2),\n            ])\n            self.fc = nn.Linear(mid_channels * 2, num_classes)\n        def forward(self, x):\n            x = self.layers(x)\n            return self.fc(x.mean(dim=-1))\n    ```", "```py\n    class TSCResNet(pl.LightningModule):\n        def __init__(self, output_dim):\n            super().__init__()\n            self.resnet = \\\n                ResidualNeuralNetworkModel(in_channels=1,\n                    num_pred_classes=output_dim)\n        def forward(self, x):\n            out = self.resnet.forward(x)\n            return out\n    ```", "```py\n        def training_step(self, batch, batch_idx):\n            x, y = batch\n            x = x.type(torch.FloatTensor)\n            y = y.type(torch.FloatTensor)\n            y_pred = self.forward(x)\n            loss = F.cross_entropy(y_pred, y)\n            self.log('train_loss', loss)\n            return loss\n        def validation_step(self, batch, batch_idx):\n            x, y = batch\n            x = x.type(torch.FloatTensor)\n            y = y.type(torch.FloatTensor)\n            y_pred = self(x)\n            loss = F.cross_entropy(y_pred, y)\n            self.log('val_loss', loss)\n            return loss\n        def test_step(self, batch, batch_idx):\n            x, y = batch\n            x = x.type(torch.FloatTensor)\n            y = y.type(torch.FloatTensor)\n            y_pred = self(x)\n            loss = F.cross_entropy(y_pred, y)\n            acc = Accuracy(task='multiclass', num_classes=4)\n            acc_score = acc(y_pred, y)\n            self.log('acc_score', acc_score)\n            self.log('test_loss', loss)\n        def configure_optimizers(self):\n            return torch.optim.Adam(self.parameters(), lr=0.01)\n    ```", "```py\n    model = TSCResNet(output_dim=4)\n    datamodule = TSCDataModule(train_df=train, test_df=test, \n        batch_size=8)\n    early_stop_callback = EarlyStopping(monitor=\"val_loss\",\n        min_delta=1e-4,\n        patience=20,\n        verbose=False,\n        mode=\"min\")\n    trainer = pl.Trainer(\n        max_epochs=100,\n        accelerator='cpu',\n        log_every_n_steps=2,\n        enable_model_summary=True,\n        callbacks=[early_stop_callback],\n    )\n    trainer.fit(model, datamodule)\n    trainer.test(model, datamodule)\n    ```", "```py\npip install 'sktime[dl]'\npip install keras-self-attention\n```", "```py\nfrom sktime.datasets import load_italy_power_demand\nX_train, y_train = \\\n    load_italy_power_demand(split=\"train\", return_type=\"numpy3D\")\nX_test, y_test = load_italy_power_demand(split=\"test\",\n    return_type=\"numpy3D\")\n```", "```py\nfrom sktime.classification.deep_learning.fcn import FCNClassifier\nfcn = FCNClassifier(n_epochs=200,\n    loss='categorical_crossentropy',\n    activation='sigmoid',\n    batch_size=4)\nfcn.fit(X_train, y_train)\nfcn_pred = fcn.predict(X_test)\n```", "```py\nfrom sktime.classification.deep_learning.cnn import CNNClassifier\ncnn = CNNClassifier(n_epochs=200,\n    loss='categorical_crossentropy',\n    activation='sigmoid',\n    kernel_size=7,\n    batch_size=4)\ncnn.fit(X_train, y_train)\ncnn_pred = cnn.predict(X_test)\n```", "```py\nfrom sktime.classification.deep_learning.lstmfcn import( \n    LSTMFCNClassifier)\nlstmfcn = LSTMFCNClassifier(n_epochs=200,\n                            attention=True,\n                            batch_size=4)\nlstmfcn.fit(X_train, y_train)\nlstmfcn_pred = lstmfcn.predict(X_test)\n```", "```py\nfrom sktime.classification.deep_learning.tapnet import(\n    TapNetClassifier)\ntapnet = TapNetClassifier(n_epochs=200,\n                          loss='categorical_crossentropy',\n                          batch_size=4)\ntapnet.fit(X_train, y_train)\ntapnet_pred = tapnet.predict(X_test)\n```", "```py\nfrom sktime.classification.deep_learning import( \n    InceptionTimeClassifier)\ninception = InceptionTimeClassifier(n_epochs=200,\n        loss='categorical_crossentropy',\n        use_residual=True,\n        batch_size=4)\ninception.fit(X_train, y_train)\ninception_pred = inception.predict(X_test)\n```", "```py\nfrom sklearn.metrics import accuracy_score\nperf = {\n    'FCN': accuracy_score(y_test, fcn_pred),\n    'CNN': accuracy_score(y_test, cnn_pred),\n    'InceptionTime': accuracy_score(y_test, inception_pred),\n    'TapNet': accuracy_score(y_test, tapnet_pred),\n    'LSTMFCN': accuracy_score(y_test, lstmfcn_pred),\n}\n```"]