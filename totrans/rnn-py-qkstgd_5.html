<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Building Your Personal Assistant</h1>
                </header>
            
            <article>
                
<p class="mce-root">In this chapter, we will focus our full attention on the practical side of recurrent neural networks when building a conversational chatbot. Using your most recent knowledge on sequence models, you will create an end-to-end model that aims to yield meaningful results. You will make use of a high-level TensorFlow-based library, called TensorLayer. This library makes it easier to create simple prototypes of complicated systems such as that of a chatbot. The main topics that will be covered are the following:</p>
<ul>
<li><strong>What are we building?</strong>:This is a more detailed introduction to the exact problem and its solution</li>
<li><strong>Preparing the data</strong><span>: </span>As always, any deep learning model requires this step, so it is crucial to mention it here</li>
<li><strong>Creating the chatbot network</strong>: You will learn how to use TensorLayer to build the graph for the sequence-to-sequence model used for the chatbot</li>
<li><strong>Training the chatbot</strong>: This step combines the data and the network graph in order to find the best possible combination of weights and biases</li>
<li><strong>Building a conversation</strong>: This last step uses the already trained model, together with sample sentences, to produce a meaningful conversation</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">What are we building?</h1>
                </header>
            
            <article>
                
<p>The focus of this chapter is to walk you through building a simple conversational chatbot that is able to give answers to a set of different questions. Recently, chatbots have become more and more popular, and we can see them in numerous practical applications.</p>
<p>Some areas where you can see the use of this software include the following:</p>
<ul>
<li><strong>Communication between clients and businesses</strong>, where the chatbot assists users in finding what they need, or provides support if something does not work properly. For example, Facebook offers a really handy way of implementing a chatbot for your business</li>
<li><strong>The personal assistant behind voice control systems such as Amazon Alexa, Apple Siri, and more</strong>: You have a full end-to-end human-like conversation where you can set reminders, order products, and more</li>
</ul>
<p>Our simple example will present a slightly augmented version of the TensorLayer chatbot code example (<a href="https://github.com/tensorlayer/seq2seq-chatbot" target="_blank">https://github.com/tensorlayer/seq2seq-chatbot</a>). We will be using a dataset formed of pre-collected tweets and will utilize the sequence-to-sequence model. Recall from previous chapters that this kind of model uses two recurrent neural networks, where the first one is an encoder and the second one a decoder. Later, we will give more detail on how this architecture is used for building the chatbot. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Preparing the data</h1>
                </header>
            
            <article>
                
<p>In this section, we will focus on how our data (tweets, in this case) is transformed to fit the model's requirements. We will first see how, using the files in the <kbd>data/</kbd> folder from the GitHub repo for this task, the model can help us extract the needed tweets. Then, we will look at how, with the help of a simple set of functions, we can split and transform the data to achieve the needed results. </p>
<p>An important file to examine is <kbd>data.py</kbd>, inside the <kbd>data/twitter</kbd> folder. It transforms plain text into a numeric format so it is easy for us to train the network. We won't go deep into the implementation, since you can examine it by yourself. After running the code, we produce three important files:</p>
<ul>
<li><span><kbd>idx_q.npy</kbd>: This is an array of arrays containing index representation of all the words in different sentences forming the chatbot questions</span></li>
<li><kbd>idx_a.npy</kbd>: This is an array of arrays containing index representation of all the words in different sentences forming the chatbot answers</li>
<li><kbd>metadata.pkl</kbd>: This contains both the <em>index to word</em> (<kbd>idx2w</kbd>) and <em>word to index</em> (<kbd>w2idx</kbd>) dictionaries used for this dataset</li>
</ul>
<p>Now, let's focus on the actual usage of this data. You can review it in the first 20 lines of <kbd>ch5_task.py</kbd> from the GitHub repository for this chapter. </p>
<p>First, we import several Python libraries that will be used throughout the whole program:</p>
<pre><span>import </span>time<br/><span>import </span>tensorflow <span>as </span>tflow<br/><span>import </span>tensorlayer <span>as </span>tlayer<br/><span>from </span>sklearn.utils <span>import </span>shuffle<br/><span>from </span>tensorlayer.layers <span>import </span>EmbeddingInputlayer, Seq2Seq, DenseLayer, retrieve_seq_length_op2</pre>
<p class="mce-root">Here is a breakdown of these libraries, accompanied with descriptions:</p>
<ul>
<li><kbd>time</kbd>: This is used for keeping track of how long our operations take. You will see its usage in the following section, where we train the network</li>
<li><kbd>tensorflow</kbd>: This is used only for a handful of operations (initializing variables, optimizing the network using adam optimizer, and initializing the TensorFlow session: <kbd>tf.Session()</kbd>)</li>
<li><kbd>tensorlayer</kbd>: As you already know, TensorLayer (<a href="https://tensorlayer.readthedocs.io/en/stable/" target="_blank">https://tensorlayer.readthedocs.io/en/stable/</a>) is a deep learning library on top of TensorFlow. It offers a wide range of methods and classes that make it easy for any developer to simply build solutions for complicated tasks. This library will help us construct and train our sequence-to-sequence model easily</li>
<li><kbd>shuffle</kbd>: We use this to shuffle all arrays, which represent different sentences, inside <kbd>trainX</kbd> and <kbd>trainY</kbd>. You will see how we obtain <kbd>trainX</kbd> and <kbd>trainY</kbd> in the following section</li>
<li><kbd>EmbeddingInputlayer</kbd>: A TensorLayer class that represents the input layer of a sequence-to-sequence model. As you know, every <kbd>Seq2Seq</kbd> model has two input layers, the encoder and the decoder</li>
<li><kbd>Seq2Seq</kbd>: A TensorLayer class that builds a sequence-to-sequence model similar to the one in the following diagram:</li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img src="assets/3c97d0f9-8a48-4ceb-951a-953bc79f5f8e.png"/></p>
<ul>
<li><kbd>DenseLayer</kbd>: A TensorLayer representation of a fully connected (dense) layer. There are different types of layers that perform different transformations and are used in specific scenarios. For example, we have already used a recurrent layer, which is used for time series data. There is also a convolutional layer used for images, and so on. You can learn more about them in this video (<a href="https://www.youtube.com/watch?v=FK77zZxaBoI" target="_blank">https://www.youtube.com/watch?v=FK77zZxaBoI</a>)</li>
<li><kbd>retrieve_seq_length_op2</kbd>: A TensorLayer function used for calculating the sequence length, excluding any paddings of zeros. We will use this function for both the encoding and decoding sequences</li>
</ul>
<p>After importing the libraries, we need to access the data as follows:</p>
<pre><span>from </span>data.twitter <span>import </span>data<br/>metadata, idx_q, idx_a = data.load_data(<span>PATH</span>=<span>'data/twitter/'</span>)<br/>(trainX, trainY), (testX, testY), (validX, validY) = data.split_dataset(idx_q, idx_a)</pre>
<p>First, we load the <kbd>metadata</kbd>, <kbd>idx_q</kbd>, and <kbd>idx_a</kbd> from the <kbd>data/twitter/</kbd> folder found in the GitHub repository. Second, we use the <kbd>split_dataset</kbd> method to separate the encoder (<kbd>idx_q</kbd>) and decoder (<kbd>idx_a</kbd>) data into training (70%), testing (15%), and validation (15%).</p>
<p>Finally, we convert <kbd>trainX, trainY, testX, testY, validX, validY</kbd> into Python lists, and then remove the padding (zero elements) from the end of every list using a TensorLayer function, <kbd>tlayer.prepro.remove_pad_sequences()</kbd>. </p>
<p>Combining the preceding operations leads to well-defined training, testing, and validation data. You will see how we make use of them during training and prediction later in this chapter. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating the chatbot network</h1>
                </header>
            
            <article>
                
<p>This section is one of the most important, so you need to make sure you understand it quite well in order to grasp the full concept of our application. We will be introducing the network graph that will be used for training and prediction. </p>
<p>But first, let's define the hyperparameters of the model. These are predefined constants that play a significant role in determining how well the model performs. As you will learn in the next chapter, our main task is to tweak the hyperparameters' values until we're satisfied with the model's prediction. In this case, an initial set of hyperparameters is selected. Of course, for better performance, one needs to do some optimization on them. This chapter won't focus on this part but I highly recommend doing it using techniques from the last chapter of this book (<a href="85ffa70b-f86d-4432-9c53-9f3e2ab0e007.xhtml" target="_blank"/><a href="85ffa70b-f86d-4432-9c53-9f3e2ab0e007.xhtml" target="_blank">Chapter 6</a>, <em>Improving Your RNN Performance</em>). The current hyperparameter selection is as follows:</p>
<pre>batch_size = <span>34<br/></span>embedding_dimension = <span>1024<br/></span>learning_rate = <span>0.0001<br/></span>number_epochs = <span>1000</span></pre>
<p>Here is a brief explanation of these hyperparameters:</p>
<ul>
<li><kbd>batch_size</kbd>: This determines how many elements each batch should have. Normally, training is done on batches where data is separated into subarrays, each with the size of <kbd>batch_size</kbd></li>
<li><kbd>embedding_dimension</kbd>: This determines the size of the word embedding vector. A single word from the input is encoded into a vector with the size of <kbd>embedding_dimension</kbd></li>
<li><kbd>learning_rate</kbd>: Its value determines how fast a network learns. It is typically a really small value (<kbd>0.001, 0.0001</kbd>). If the loss function does not decrease during training, it is good practice to reduce the learning rate</li>
<li><kbd>number_epochs</kbd>: This determines the number of training iterations (epochs). In the beginning of each iteration, we shuffle the data and, since an epoch is <span>too big to feed to the computer at once, we divide it into several smaller batches. Then we train the network using these batches. After every iteration, we shuffle again and run the second epoch. This operation is done for the number of epochs we have set.</span></li>
</ul>
<p>After determining the set of hyperparameters, the time comes for additional values that help us in building our model:</p>
<pre>xseq_len = <span>len</span>(trainX)<br/>yseq_len = <span>len</span>(trainY)<br/><span>assert </span>xseq_len == yseq_len<br/><br/>n_step = <span>int</span>(xseq_len/batch_size)<br/><br/>w2idx = metadata[<span>'w2idx'</span>]<br/>idx2w = metadata[<span>'idx2w'</span>]<span><br/></span><span><br/></span>xvocab_size = <span>len</span>(metadata[<span>'idx2w'</span>])<span><br/></span>start_id = xvocab_size<span><br/></span>end_id = xvocab_size+<span>1</span><span><br/></span><span><br/></span>w2idx.update({<span>'start_id'</span>: start_id})<br/>w2idx.update({<span>'end_id'</span>: end_id})<br/>idx2w = idx2w + [<span>'start_id'</span>, <span>'end_id'</span>]<br/><br/>xvocab_size = yvocab_size = xvocab_size + <span>2</span></pre>
<p>Let's examine each line, one by one:</p>
<pre>xseq_len = <span>len</span>(trainX)<br/>yseq_len = <span>len</span>(trainY)<br/>assert xseq_len == yseq_len</pre>
<p>We use <kbd>xseq_len</kbd> and <kbd>yseq_len</kbd> to store the length of the encoder's and decoder's input sequence. Then, we make sure both values are equal, otherwise, the program will break. </p>
<p><kbd>n_step = <span>int</span>(xseq_len/batch_size)</kbd>: with this, we store the number of steps that our training is about to perform. This value is only used when printing the state of training and we will see its usage later in the chapter.</p>
<p>We use<span> </span><kbd>w2idx</kbd><span> </span>and<span> </span><kbd>idx2w</kbd><span> </span>to store the word dictionary in both formats (the word as the dictionary key, and the ID as the dictionary key). These dictionaries are used when predicting the chatbot responses:</p>
<pre>w2idx = metadata['w2idx']<br/>idx2w = metadata['idx2w']</pre>
<p>We make <kbd>start_id = xvocab_size</kbd> and <kbd>end_id = xvocab_size + 1</kbd> to assure uniqueness of these two indices. They are used for indicating the start and end of a single sentence:</p>
<pre>xvocab_size = <span>len</span>(metadata[<span>'idx2w'</span>])<span><br/></span>start_id = xvocab_size<span><br/></span>end_id = xvocab_size+<span>1</span></pre>
<p><span>Finally, we extend these dictionaries to include starting and ending elements. An example set of our data is the following:</span></p>
<ul>
<li><kbd>encode_seqs</kbd> (the input encoder sentence): <kbd>['how', 'are', 'you', '&lt;PAD_ID&gt;']</kbd></li>
<li><kbd>decode_seqs</kbd> (the input decoder sentence): <kbd>['&lt;START_ID&gt;', 'I', 'am', 'fine', '&lt;PAD_ID&gt;']</kbd></li>
</ul>
<ul>
<li><kbd>target_seqs</kbd> (the predicted decoder sentence): <kbd>['I', 'am', 'fine', '&lt;END_ID&gt;', '&lt;PAD_ID&gt;']</kbd></li>
<li><kbd>target_mask</kbd> (a mask applied at each sequence): <kbd>[1, 1, 1, 1, 0]</kbd>. This is an array the same size as <kbd>target_seqs</kbd>, but has <kbd>0</kbd> at the places where padding is applied, and <kbd>1</kbd> everywhere else. You can learn more about masking in recurrent neural networks by reading this great Quora answer (<a href="https://www.quora.com/What-is-masking-in-a-recurrent-neural-network-RNN" target="_blank">https://www.quora.com/What-is-masking-in-a-recurrent-neural-network-RNN</a>)</li>
</ul>
<p class="mce-root">The next step is to define our model structure. We start by introducing the model's placeholders:</p>
<pre>encode_seqs = tf.placeholder(<span>dtype</span>=tf.int64, <span>shape</span>=[batch_size, <span>None</span>], <span>name</span>=<span>"encode_seqs"</span>)<br/>decode_seqs = tf.placeholder(<span>dtype</span>=tf.int64, <span>shape</span>=[batch_size, <span>None</span>], <span>name</span>=<span>"decode_seqs"</span>)<br/>target_seqs = tf.placeholder(<span>dtype</span>=tf.int64, <span>shape</span>=[batch_size, <span>None</span>], <span>name</span>=<span>"target_seqs"</span>)<br/>target_mask = tf.placeholder(<span>dtype</span>=tf.int64, <span>shape</span>=[batch_size, <span>None</span>], <span>name</span>=<span>"target_mask"</span>)</pre>
<p>As you can see, this is the same set of variables shown previously. Each one has a <kbd>batch_size</kbd> dimension and <kbd>tf.int64</kbd> type. Then, we calculate the model output as follows:</p>
<pre>net_out, _ = model(encode_seqs, decode_seqs, <span>is_train</span>=<span>True</span>, <span>reuse</span>=<span>False</span>)</pre>
<p>The purpose of the preceding line is to find the network's output using the input encoder and decoder sequences. We will define and explain the <kbd>model</kbd> <span>method in the following section.</span></p>
<p>Finally, we define the loss function and optimizer:</p>
<pre>loss = tl.cost.cross_entropy_seq_with_mask(<span>logits</span>=net_out.outputs, <span>target_seqs</span>=target_seqs, <span>input_mask</span>=target_mask, <span>name</span>=<span>'cost'</span>)<span><br/></span><span><br/></span>optimizer = tf.train.AdamOptimizer(<span>learning_rate</span>=learning_rate).minimize(loss)</pre>
<p>As you can see, the loss function is a cross entropy with applied mask to make sure each input sequence has the same length. The <kbd>logits</kbd> (predicted outputs) are taken from the preceding model output and are accessed using <kbd>net_out.outputs</kbd>. The <kbd>target_seqs</kbd> are the expected results for every input. </p>
<p>The model's optimizer is <kbd>AdamOptimizer</kbd> and is defined using the built-in function from TensorFlow, <kbd>tf.train.AdamOptimizer</kbd>. As usual, we pass the <kbd>learning_rate</kbd> to decide the rate of the <kbd>loss</kbd> function <span>minimization</span>.</p>
<p>The last step is defining and explaining the <kbd>model</kbd> function:</p>
<pre><span>def </span>model(encode_seqs, decode_seqs, is_train=<span>True</span>, reuse=<span>False</span>):<br/>   <span>with </span>tf.variable_scope(<span>"model"</span>, <span>reuse</span>=reuse):<br/>        <span>with </span>tf.variable_scope(<span>"embedding"</span>) <span>as </span>vs:<br/>            net_encode = EmbeddingInputlayer(<br/>                <span>inputs </span>= encode_seqs,<br/>                <span>vocabulary_size </span>= xvocab_size,<br/>                <span>embedding_size </span>= embedding_dimension,<br/>                <span>name </span>= <span>'seq_embedding'</span>)<br/>                vs.reuse_variables()<br/>            net_decode = EmbeddingInputlayer(<br/>                <span>inputs </span>= decode_seqs,<br/>                <span>vocabulary_size </span>= xvocab_size,<br/>                <span>embedding_size </span>= embedding_dimension,<br/>                <span>name </span>= <span>'seq_embedding'</span>)<br/>           net_rnn = Seq2Seq(net_encode, net_decode,<br/>                <span>cell_fn </span>= tf.contrib.rnn.BasicLSTMCell,<br/>                <span>n_hidden </span>= embedding_dimension,<br/>                <span>initializer </span>= tf.random_uniform_initializer(-<span>0.1</span>, <span>0.1</span>),<br/>                <span>encode_sequence_length </span>= <br/>                retrieve_seq_length_op2(encode_seqs),<br/>                <span>decode_sequence_length </span>= <br/>                retrieve_seq_length_op2(decode_seqs),<br/>                <span>initial_state_encode </span>= <span>None</span>,<br/>                <span>n_layer </span>= <span>3</span>,<br/>                <span>return_seq_2d </span>= <span>True</span>,<br/>                <span>name </span>= <span>'seq2seq'</span>)<br/>                net_out = DenseLayer(net_rnn, <span>n_units</span>=xvocab_size, <br/><span>                act</span>=tf.identity, <span>name</span>=<span>'output'</span>)<br/>      <span>return </span>net_out, net_rnn</pre>
<p>TensorLayer makes it as simple as possible to build the sequence-to-sequence model. It uses four main components:</p>
<ul>
<li><kbd>net_encode</kbd>: An encoder network using the <kbd>EmbeddingInputlayer</kbd> class.</li>
<li><kbd>net_decode</kbd>: A decoder network using the <kbd>EmbeddingInputlayer</kbd> class.</li>
<li><kbd>net_rnn</kbd>: A sequence-to-sequence model that combines the two aforementioned networks. It is implemented using the <kbd>Seq2Seq</kbd> class.</li>
<li><kbd>net_out</kbd>: The final, fully connected (dense) layer producing the end result. This layer is built on top of the sequence-to-sequence network.</li>
</ul>
<p><kbd>net_encode</kbd> and <kbd>net_decode</kbd> are similarly initialized using <kbd>EmbeddingInputlayer</kbd> (<a href="https://tensorlayer.readthedocs.io/en/stable/modules/layers.html#tensorlayer.layers.EmbeddingInputlayer" target="_blank">https://tensorlayer.readthedocs.io/en/stable/modules/layers.html#tensorlayer.layers.EmbeddingInputlayer</a>). Three important parameters are used: <kbd>inputs</kbd>, <kbd>vocabulary_size</kbd>, and <kbd>embedding_size</kbd>. The <kbd>inputs</kbd> are <kbd>encode_seqs</kbd> or <kbd>decode_seqs</kbd>, which we defined in the preceding section. In both cases, <kbd>vocabulary_size</kbd> is equal to <kbd>xvocab_size</kbd>, and the <kbd>embedding_size</kbd> is equal to <kbd>embedding_dimension</kbd>. This embedding layer transforms the input vector into one of the <kbd>embedding_dimension</kbd> <span>size.</span></p>
<p><kbd>net_rnn</kbd> combines both the encoder and decoder layers into a full sequence-to-sequence model. The parameters are the following:</p>
<ul>
<li><kbd>cell_fn</kbd>: The RNN cell used throughout the whole network. In our case, this is <kbd>BasicLSTMCell</kbd>.</li>
<li><kbd>n_hidden</kbd>: The number of hidden units in each of the two layers.</li>
<li><kbd>initializer</kbd>: The distribution used for defining the parameters (weights, biases).</li>
<li><kbd>encode_sequence_length</kbd>: This specifies the length of the encoder input sequence. It uses the <span><kbd>retrieve_seq_length_op2</kbd> (<a href="https://tensorlayer.readthedocs.io/en/stable/modules/layers.html#tensorlayer.layers.retrieve_seq_length_op2" target="_blank">https://tensorlayer.readthedocs.io/en/stable/modules/layers.html#tensorlayer.layers.retrieve_seq_length_op2</a>) method on the <kbd>encode_seqs</kbd>.</span></li>
<li><kbd>decode_sequence_length</kbd>: This specifies the length of the decoder input sequence. It uses the <kbd>retrive_seq_length_op2</kbd> method on the <kbd>decode_seqs</kbd>.</li>
<li><kbd>initial_state_encode</kbd>: If <kbd>None</kbd>, the initial state of the encoder networks is zero state and can be set automatically by the placeholder or another RNN.</li>
<li><kbd>n_layer</kbd>: The number of RNN layers stacked together in each of the two networks (encoder and decoder).</li>
<li><kbd>return_seq_2d</kbd>: If the value is <kbd>True</kbd>, <span>return <kbd>2D Tensor [n_example, 2 * n_hidden]</kbd>, for stacking DenseLayer after it. </span></li>
</ul>
<p>In the end, we use a fully connected (dense) layer <kbd>net_out</kbd> to calculate the final output of the network. It uses the <kbd>Seq2Seq</kbd> network as a previous layer, the vocabulary size (<kbd>xvocab_size</kbd>) as the number of units, and <kbd>tf.identity</kbd> as the activation function. It is normally used for <span>explicit transport of a tensor between devices (for example, from a GPU to a CPU). In our case, we use it to build dummy nodes that copy the values from the previous layer. </span></p>
<p>One last thing to point out is the use of the <kbd>reuse</kbd> parameter and the <kbd>vs.reuse_variables()</kbd> method call. During training, we are not reusing the model's parameters (weights and biases), so <kbd>reuse = False</kbd>, but when predicting the chatbot response, we make use of the pre-trained parameters, and so have <kbd>reuse = True.</kbd> The method call triggers a reuse for the next set of calculations. </p>
<p>And with this, we have finished defining the model. There are only two parts left from now: training and predicting.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Training the chatbot</h1>
                </header>
            
            <article>
                
<p>Once we have defined the model graph, we want to train it using our input data. Then, we will have a well-tuned set of parameters that can be used for accurate predictions. </p>
<p>First, we specify the TensorFlow's Session object that encapsulates the environment in which Operation (summation, subtraction, and so on) objects are executed and Tensor (placeholders, variables, and so on) objects are evaluated:</p>
<pre>sess = tf.Session(<span>config</span>=tf.ConfigProto(<span>allow_soft_placement</span>=<span>True</span>, <span>log_device_placement</span>=<span>False</span>))<br/>sess.run(tf.global_variables_initializer())</pre>
<p>A good explanation of the <kbd>config</kbd> parameter can be found at <a href="https://stackoverflow.com/questions/44873273/what-do-the-options-in-configproto-like-allow-soft-placement-and-log-device-plac" target="_blank">https://stackoverflow.com/questions/44873273/what-do-the-options-in-configproto-like-allow-soft-placement-and-log-device-plac</a>. In summary, once we specify <kbd>allow_soft_placement</kbd>, the operations will be executed on the CPU only if there is no GPU registered. If this value is false, we are not allowed to execute any operation on a GPU. </p>
<p>Only after running the second line (<kbd>sess.run(tf.global_variables_initializer())</kbd>) will all variables actually hold their values. Initially, they only store a persistent Tensor. </p>
<p>Now, we will train the network using the <kbd>train()</kbd> <span>function, </span>defined as follows:</p>
<pre><span>def </span>train():<br/>    <span>print</span>(<span>"Start training"</span>)<br/>    <span>for </span>epoch <span>in </span><span>range</span>(number_epochs):<br/>        epoch_time = time.time()<br/>        trainX_shuffled, trainY_shuffled = shuffle(trainX, trainY, <br/><span>        random_state</span>=<span>0</span>)<br/>        total_err, n_iter = <span>0</span>, <span>0<br/><br/></span><span>        </span><span>for </span>X, Y <span>in </span>tl.iterate.minibatches(<span>inputs</span>=trainX_shuffled, <br/><span>        targets</span>=trainY_shuffled, <span>batch_size</span>=batch_size, <span>shuffle</span>=<span>False</span>):<br/><br/>            X = tl.prepro.pad_sequences(X)<br/><br/>            _decode_seqs = tl.prepro.sequences_add_start_id(Y, <br/><span>             start_id</span>=start_id, <span>remove_last</span>=<span>False</span>)<br/>            _decode_seqs = tl.prepro.pad_sequences(_decode_seqs)   <br/> <br/>            _target_seqs = tl.prepro.sequences_add_end_id(Y, <br/><span>             end_id</span>=end_id)<br/>            _target_seqs = tl.prepro.pad_sequences(_target_seqs)<br/>            _target_mask = tl.prepro.sequences_get_mask(_target_seqs)<br/><br/>            _, err = sess.run([optimizer, loss],<br/>                                {encode_seqs: X,<br/>                                decode_seqs: _decode_seqs,<br/>                                target_seqs: _target_seqs,<br/>                                target_mask: _target_mask})<br/><br/>            <span>if </span>n_iter % <span>200 </span>== <span>0</span>:<br/><span>                print</span>(<span>"Epoch[%d/%d] step:[%d/%d] loss:%f took:%.5fs" </span>% <br/>                (epoch, number_epochs, n_iter, n_step, err, time.time() <br/>                 - epoch_time))<br/><br/>                total_err += err; n_iter += <span>1</span></pre>
<p>Let's explain what the preceding code does<span> line by line</span>. </p>
<p>The implementation has two nested loops, where the outer one decides how many times the training should go through the whole set of data. This is often done using epochs, and aims to strengthen the model accuracy. It is rarely the case that weights and biases have learned enough from a certain example when it is propagated just once. This is the reason why we should go over every example multiple times—in our case, this will be 1,000 times (the number of epochs). </p>
<p>After we enter an epoch iteration, we shuffle the data using <span>the</span> <kbd>shuffle</kbd> function in <kbd>sklearn</kbd>, which prepares it for entering the inner loop. Then, we use <kbd>tl.iterate.minibatches</kbd> to split the data into sub-arrays each with the <kbd>batch_size</kbd> size. Each iteration inside the inner loop trains the network using the current batch of data. </p>
<p>Before calculating the optimizer, we do some small modification on X (encoder batch data) and Y (decoder batch data). As you remember, the model has an encoder input (<kbd>encoder_seqs</kbd>), a decoder input (<kbd>decoder_seqs</kbd>), and a target output (<kbd>target_seqs</kbd>) incorporated into two RNNs. </p>
<p>The first recurrent neural network is the encoder, which accepts <kbd>encoder_seqs</kbd> as an input. In the preceding code block, this is marked with <em>X</em>. We only need to add padding to this sequence before applying it to the network. Padding is the operation of adding zeros to the end of a sequence in order for it to match a fixed length, determined by the longest sequence in the training set. This network produces a single vector which is then used in the second RNN.</p>
<p>The second recurrent neural network accepts the encoded vector from the first RNN and a decoder input sequence (<kbd>decoder_seqs</kbd>), and returns a predicted result. During training, we compare the predicted result to a target sequence (<kbd>target_seqs</kbd>), which happens to be the exact same sequence.</p>
<p>Let's clarify the preceding statement. Say you have the sentence <em>Hello, how are you?</em> as an input, and its response, <em>I am fine.</em>, as the output. The first sentence goes into the encoder network. The second sentence is the expected output of the second decoder network. We need to compare this expected output with the actual output that our decoder produces. We get the first word <strong>I</strong> and try to predict the following word <strong>am</strong>, then we get <strong>am</strong> and try to predict <strong>fine</strong>, and so on. In the beginning, our prediction will be way off, but with time, the weights and biases should be adjusted to produce accurate results. The following diagram can accompany the explanation: </p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/6a698f1d-cc35-4910-9cdd-ec42863c98b2.png" style="width:18.00em;height:9.67em;"/></p>
<p>As you can see, we need to add a starting symbol to <kbd>decoder_seqs</kbd> and an ending symbol to <kbd>target_seqs</kbd>. This is what <kbd>_decode_seqs = tl.prepro.sequences_add_start_id(Y, <span>start_id</span>=start_id, <span>remove_last</span>=<span>False</span>)</kbd> and <kbd>_target_seqs = tl.prepro.sequences_add_end_id(Y, <span>end_id</span>=end_id)</kbd> do, where <kbd>start_id = xvocab_size</kbd> and <kbd>end_id = xvocab_size+1</kbd>. Finally, we add padding to both sequences, equalizing the lengths. </p>
<p>Just before the actual training, we extract <kbd>_target_mask</kbd> from <kbd>_target_seqs</kbd>. Recall from earlier that if <kbd>_target_seqs = ["I", "am", "fine", "&lt;END_ID&gt;", "&lt;PAD_ID&gt;"]</kbd>, then <kbd>_target_mask = [1, 1, 1, 1, 0]</kbd>.</p>
<p>In the end, we use the sequence arrays defined previously to train our network. It might take some time, so we have added a printing statement every 200 iterations. I would recommend leaving your computer running overnight for this training so you extract the maximum potential from your data. </p>
<p>The next step is to use our model in predicting an actual output. Let's see how well it can handle this task. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Building a conversation</h1>
                </header>
            
            <article>
                
<p>This step is really similar to the training one. The first difference is that we don't make any evaluation of our predictions, but instead use the input to generate the results. The second difference is that we use the already trained set of variables to yield this result. You will see how it is done later in this chapter. </p>
<p>To make things clearer, we first initialize a new sequence-to-sequence model. Its purpose is to use the already trained weights and biases and make predictions based on different sets of inputs. We only have an encoder and decoder sequence, where the encoder one is an input sentence and the decoder sequence is fed one word at a time. We define the new model as follows:</p>
<pre>encode_seqs2 = tf.placeholder(<span>dtype</span>=tf.int64, <span>shape</span>=[<span>1</span>, <span>None</span>], <span>name</span>=<span>"encode_seqs"</span>)<br/>decode_seqs2 = tf.placeholder(<span>dtype</span>=tf.int64, <span>shape</span>=[<span>1</span>, <span>None</span>], <span>name</span>=<span>"decode_seqs"</span>)<br/>net, net_rnn = model(encode_seqs2, decode_seqs2, <span>is_train</span>=<span>False</span>, <span>reuse</span>=<span>True</span>)<br/>y = tf.nn.softmax(net.outputs)</pre>
<p>As you can see, it follows exactly the same pattern as the training architecture, with the difference that our sequence matrices are of shape <kbd>1</kbd>, instead of <kbd>batch_size</kbd>. </p>
<div class="mce-root packt_tip">An important thing to note is that when calculating the network's results, we must <strong>reuse</strong> the same parameters used during training. This step is essential because it makes sure our prediction is a result of the recent training we have done. </div>
<p><span>Finally, we calculate the final output, </span><kbd>y</kbd><span>, using the softmax function. This is usually done at the final layer to make sure that our vector values sum up to 1, and is a necessary step during classification.</span></p>
<p>After defining our new model, the time comes for the actual prediction. We follow this pattern:</p>
<ol>
<li>Generate an initial sentence that will start the conversation.</li>
<li>Convert the sentence into a list of word indices using the <kbd>word2idx</kbd> dictionary.</li>
<li>Decide how many replies<span> back and forth</span> we want the conversation to have (in our case, this would be five).</li>
<li>Calculate the final state of the encoder by feeding the <kbd>net_rnn</kbd> (as defined previously) with the initial sentence.</li>
<li>Finally, we iteratively predict the next word using the previously predicted word and the network. At the first time step, we use <kbd>start_id</kbd>, as defined previously, as the first word from the decoder.</li>
</ol>
<p>These steps are executed in the following code snippet:</p>
<pre><span>def </span>predict():<br/>    seeds = [<span>"happy birthday have a nice day"</span>,<br/>            <span>"the presidential debate held last night was spectacular"</span>]<br/>    <span>for </span>seed <span>in </span>seeds:<br/>        seed_id = [w2idx[w] <span>for </span>w <span>in </span>seed.split(<span>" "</span>)]<br/>        <span>for </span>_ <span>in </span><span>range</span>(<span>5</span>):  <span># 5 Replies<br/></span><span>            # 1. encode, get state<br/></span><span>            </span>state = sess.run(net_rnn.final_state_encode,<br/>                            {encode_seqs2: [seed_id]})<br/><br/>            <span># 2. decode, feed start_id, get first word<br/></span><span>            </span>o, state = sess.run([y, net_rnn.final_state_decode],<br/>                            {net_rnn.initial_state_decode: state,<br/>                            decode_seqs2: [[start_id]]})<br/><br/>            w_id = tl.nlp.sample_top(o[<span>0</span>], <span>top_k</span>=<span>3</span>)<br/>            w = idx2w[w_id]<br/><br/>            <span># 3. decode, feed state iteratively<br/></span><span>            </span>sentence = [w]<br/>            <span>for </span>_ <span>in </span><span>range</span>(<span>30</span>): <span># max sentence length<br/></span><span>                </span>o, state = sess.run([y, net_rnn.final_state_decode],<br/>                                {net_rnn.initial_state_decode: state,<br/>                                decode_seqs2: [[w_id]]})<br/>                w_id = tl.nlp.sample_top(o[<span>0</span>], <span>top_k</span>=<span>2</span>)<br/>                w = idx2w[w_id]<br/>                <span>if </span>w_id == end_id:<br/>                    <span>break<br/></span><span>                </span>sentence = sentence + [w]<br/><br/>            <span>print</span>(<span>" &gt;"</span>, <span>' '</span>.join(sentence))</pre>
<p>An interesting thing to note is how <kbd># 2. decode, feed start_id, get first word</kbd> and <kbd># 3. decode, feed state iteratively</kbd> perform exactly the same action, but step #2 is a special case, focused on predicting only the first word. Step #3 uses this first word to iteratively predict all the others.</p>
<p><kbd>tl.nlp.sample_top(o[0], top_k=3)</kbd> might also be confusing to you. This line samples an index from the probability array o[0], where you consider only three candidates. The same functionality goes for <kbd>w_id = tl.nlp.sample_top(o[0], top_k = 2)</kbd>. You can learn more on the TensorLayer documentation (<a href="https://tensorlayer.readthedocs.io/en/stable/modules/nlp.html#sampling-functions">https://tensorlayer.readthedocs.io/en/stable/modules/nlp.html#sampling-functions</a>).</p>
<p>Finally, we print the formed sentence of 30 words (we cap the number of words per sentence). If you trained the network long enough, you should see some decent results. If they don't satisfy you, then extensive work is needed. You will learn more about this in the upcoming <a href="85ffa70b-f86d-4432-9c53-9f3e2ab0e007.xhtml" target="_blank"/><a href="85ffa70b-f86d-4432-9c53-9f3e2ab0e007.xhtml" target="_blank">Chapter 6</a>, <em>Improving Your RNN Performance</em>. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>This chapter reveals a full implementation of a chatbot system that manages to construct a short conversation. The prototype shows, in detail, each stage of building the intelligent chatbot. This includes collecting data, training the network, and making predictions (generating conversation). </p>
<p>For the network's architecture, we use the powerful encoder-decoder sequence-to-sequence model that utilizes two recurrent neural networks, while connecting them using an encoder vector. For the actual implementation, we make use of a deep learning library built on top of TensorFlow, called TensorLayer. It simplifies most of the work by introducing simple one-line implementations of standard models such as <em>sequence-to sequence</em>. In addition, this library is useful for preprocessing your data before using it for training.</p>
<p>The next chapter shifts focus to, probably, the most important part of building a recurrent neural network (and any deep learning model), which is how to improve your performance and actually make your program return satisfying results. As you have already seen, building a neural network follows a similar pattern in most basic/medium examples. The hard part is to make sure the implementations are actually useful and produce meaningful results. This will be the focus of our next chapter—I hope you enjoy it.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">External links</h1>
                </header>
            
            <article>
                
<ul>
<li>TensorLayer chatbot code example: <a href="https://github.com/tensorlayer/seq2seq-chatbot">https://github.com/tensorlayer/seq2seq-chatbot</a></li>
<li>TensorLayer library: <a href="https://tensorlayer.readthedocs.io/en/stable/">https://tensorlayer.readthedocs.io/en/stable/</a></li>
<li>Layers in neural network:<a href="https://www.youtube.com/watch?v=FK77zZxaBoI"> https://www.youtube.com/watch?v=FK77zZxaBoI</a></li>
<li>What is masking in a recurrent neural network (RNN)?: <a href="https://www.quora.com/What-is-masking-in-a-recurrent-neural-network-RNN">https://www.quora.com/What-is-masking-in-a-recurrent-neural-network-RNN</a></li>
<li>TensorLayer's embeddingInputlayer class: <a href="https://tensorlayer.readthedocs.io/en/stable/modules/layers.html#tensorlayer.layers.EmbeddingInputlayer">https://tensorlayer.readthedocs.io/en/stable/modules/layers.html#tensorlayer.layers.EmbeddingInputlayer</a></li>
<li>TensorLayer's <kbd>retrieve_seq_length_op2</kbd> method: <a href="https://tensorlayer.readthedocs.io/en/stable/modules/layers.html#tensorlayer.layers.retrieve_seq_length_op2">https://tensorlayer.readthedocs.io/en/stable/modules/layers.html#tensorlayer.layers.retrieve_seq_length_op2</a></li>
<li>TensorFlow session's config parameter: <a href="https://stackoverflow.com/questions/44873273/what-do-the-options-in-configproto-like-allow-soft-placement-and-log-device-plac">https://stackoverflow.com/questions/44873273/what-do-the-options-in-configproto-like-allow-soft-placement-and-log-device-plac</a></li>
<li>TensorLayer Sampling Functions: <a href="https://tensorlayer.readthedocs.io/en/stable/modules/nlp.html#sampling-functions">https://tensorlayer.readthedocs.io/en/stable/modules/nlp.html#sampling-functions</a></li>
</ul>


            </article>

            
        </section>
    </body></html>