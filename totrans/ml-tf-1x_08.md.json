["```py\ngit clone https://github.com/tensorflow/models/\n```", "```py\npython download_and_convert_data.py --dataset_name diabetic --dataset_dir D:\\\\datasets\\\\diabetic\n```", "```py\nfrom datasets import download_and_convert_diabetic \nand a new else-if clause to process the dataset_name \"diabetic\" at line 69: \n  elif FLAGS.dataset_name == 'diabetic': \n      download_and_convert_diabetic.run(FLAGS.dataset_dir)\n```", "```py\n  def run(dataset_dir): \n    \"\"\"Runs the download and conversion operation. \n\n    Args: \n      dataset_dir: The dataset directory where the dataset is stored. \n    \"\"\" \n    if not tf.gfile.Exists(dataset_dir): \n        tf.gfile.MakeDirs(dataset_dir) \n\n    if _dataset_exists(dataset_dir): \n        print('Dataset files already exist. Exiting without re-creating   \n        them.') \n        return \n\n    # Pre-processing the images. \n    data_utils.prepare_dr_dataset(dataset_dir) \n    training_filenames, validation_filenames, class_names =   \n    _get_filenames_and_classes(dataset_dir) \n    class_names_to_ids = dict(zip(class_names,    \n    range(len(class_names)))) \n\n    # Convert the training and validation sets. \n    _convert_dataset('train', training_filenames, class_names_to_ids,   \n    dataset_dir) \n    _convert_dataset('validation', validation_filenames,    \n    class_names_to_ids, dataset_dir) \n\n    # Finally, write the labels file: \n    labels_to_class_names = dict(zip(range(len(class_names)),    \n    class_names)) \n    dataset_utils.write_label_file(labels_to_class_names, dataset_dir) \n\n    print('\\nFinished converting the Diabetic dataset!')\n```", "```py\n  def _get_filenames_and_classes(dataset_dir): \n    train_root = os.path.join(dataset_dir, 'processed_images', 'train') \n    validation_root = os.path.join(dataset_dir, 'processed_images',   \n    'validation') \n    class_names = [] \n    for filename in os.listdir(train_root): \n        path = os.path.join(train_root, filename) \n        if os.path.isdir(path): \n            class_names.append(filename) \n\n    train_filenames = [] \n    directories = [os.path.join(train_root, name) for name in    \n    class_names] \n    for directory in directories: \n        for filename in os.listdir(directory): \n            path = os.path.join(directory, filename) \n            train_filenames.append(path) \n\n    validation_filenames = [] \n    directories = [os.path.join(validation_root, name) for name in    \n    class_names] \n    for directory in directories: \n        for filename in os.listdir(directory): \n            path = os.path.join(directory, filename) \n            validation_filenames.append(path) \n    return train_filenames, validation_filenames, sorted(class_names) \n```", "```py\nnum_of_processing_threads = 16 \ndr_dataset_base_path = os.path.realpath(dataset_dir) \nunique_labels_file_path = os.path.join(dr_dataset_base_path, \"unique_labels_file.txt\") \nprocessed_images_folder = os.path.join(dr_dataset_base_path, \"processed_images\") \nnum_of_processed_images = 35126 \ntrain_processed_images_folder = os.path.join(processed_images_folder, \"train\") \nvalidation_processed_images_folder = os.path.join(processed_images_folder, \"validation\") \nnum_of_training_images = 30000 \nraw_images_folder = os.path.join(dr_dataset_base_path, \"train\") \ntrain_labels_csv_path = os.path.join(dr_dataset_base_path, \"trainLabels.csv\")\n```", "```py\n  def crop_black_borders(image, threshold=0):\n     \"\"\"Crops any edges below or equal to threshold\n\n     Crops blank image to 1x1.\n\n     Returns cropped image.\n\n     \"\"\"\n     if len(image.shape) == 3:\n         flatImage = np.max(image, 2)\n     else:\n         flatImage = image\n     assert len(flatImage.shape) == 2\n\n     rows = np.where(np.max(flatImage, 0) > threshold)[0]\n     if rows.size:\n         cols = np.where(np.max(flatImage, 1) > threshold)[0]\n         image = image[cols[0]: cols[-1] + 1, rows[0]: rows[-1] + 1]\n     else:\n         image = image[:1, :1]\n\n     return image \n```", "```py\n  def process_images_batch(thread_index, files, labels, subset):\n\n     num_of_files = len(files)\n\n     for index, file_and_label in enumerate(zip(files, labels)):\n         file = file_and_label[0] + '.jpeg'\n         label = file_and_label[1]\n\n         input_file = os.path.join(raw_images_folder, file)\n         output_file = os.path.join(processed_images_folder, subset,   \n         str(label), file)\n\n         image = ndimage.imread(input_file)\n         cropped_image = crop_black_borders(image, 10)\n         resized_cropped_image = imresize(cropped_image, (299, 299, 3),   \n         interp=\"bicubic\")\n         imsave(output_file, resized_cropped_image)\n\n         if index % 10 == 0:\n             print(\"(Thread {}): Files processed {} out of  \n             {}\".format(thread_index, index, num_of_files)) \n```", "```py\n   def process_images(files, labels, subset):\n\n     # Break all images into batches with a [ranges[i][0], ranges[i] \n     [1]].\n     spacing = np.linspace(0, len(files), num_of_processing_threads +  \n     1).astype(np.int)\n     ranges = []\n     for i in xrange(len(spacing) - 1):\n         ranges.append([spacing[i], spacing[i + 1]])\n\n     # Create a mechanism for monitoring when all threads are finished.\n     coord = tf.train.Coordinator()\n\n     threads = []\n     for thread_index in xrange(len(ranges)):\n         args = (thread_index, files[ranges[thread_index] \n         [0]:ranges[thread_index][1]],\n                 labels[ranges[thread_index][0]:ranges[thread_index] \n                 [1]],\n                 subset)\n         t = threading.Thread(target=process_images_batch, args=args)\n         t.start()\n         threads.append(t)\n\n     # Wait for all the threads to terminate.\n     coord.join(threads) \n```", "```py\ndef process_training_and_validation_images():\n     train_files = []\n     train_labels = []\n\n     validation_files = []\n     validation_labels = []\n\n     with open(train_labels_csv_path) as csvfile:\n         reader = csv.DictReader(csvfile)\n         for index, row in enumerate(reader):\n             if index < num_of_training_images:\n                 train_files.extend([row['image'].strip()])\n                 train_labels.extend([int(row['level'].strip())])\n             else:\n                 validation_files.extend([row['image'].strip()])\n\n   validation_labels.extend([int(row['level'].strip())])\n\n     if not os.path.isdir(processed_images_folder):\n         os.mkdir(processed_images_folder)\n\n     if not os.path.isdir(train_processed_images_folder):\n         os.mkdir(train_processed_images_folder)\n\n     if not os.path.isdir(validation_processed_images_folder):\n         os.mkdir(validation_processed_images_folder)\n\n     for directory_index in range(5):\n         train_directory_path =   \n    os.path.join(train_processed_images_folder,   \n    str(directory_index))\n         valid_directory_path =   \n   os.path.join(validation_processed_images_folder,  \n   str(directory_index))\n\n         if not os.path.isdir(train_directory_path):\n             os.mkdir(train_directory_path)\n\n         if not os.path.isdir(valid_directory_path):\n             os.mkdir(valid_directory_path)\n\n     print(\"Processing training files...\")\n     process_images(train_files, train_labels, \"train\")\n     print(\"Done!\")\n\n     print(\"Processing validation files...\")\n     process_images(validation_files, validation_labels,  \n     \"validation\")\n     print(\"Done!\")\n\n     print(\"Making unique labels file...\")\n     with open(unique_labels_file_path, 'w') as unique_labels_file:\n         unique_labels = \"\"\n         for index in range(5):\n             unique_labels += \"{}\\n\".format(index)\n         unique_labels_file.write(unique_labels)\n\n     status = check_folder_status(processed_images_folder, \n     num_of_processed_images,\n     \"All processed images are present in place\",\n     \"Couldn't complete the image processing of training and  \n     validation files.\")\n\n     return status \n```", "```py\ndef _get_dataset_filename(dataset_dir, split_name, shard_id): \n    output_filename = 'diabetic_%s_%05d-of-%05d.tfrecord' % ( \n        split_name, shard_id, _NUM_SHARDS) \n    return os.path.join(dataset_dir, output_filename) \ndef _convert_dataset(split_name, filenames, class_names_to_ids, dataset_dir): \n    \"\"\"Converts the given filenames to a TFRecord dataset. \n\n    Args: \n      split_name: The name of the dataset, either 'train' or  \n     'validation'. \n      filenames: A list of absolute paths to png or jpg images. \n      class_names_to_ids: A dictionary from class names (strings) to  \n      ids \n        (integers). \n      dataset_dir: The directory where the converted datasets are  \n     stored. \n    \"\"\" \n    assert split_name in ['train', 'validation'] \n\n    num_per_shard = int(math.ceil(len(filenames) /  \n    float(_NUM_SHARDS))) \n\n    with tf.Graph().as_default(): \n        image_reader = ImageReader() \n\n        with tf.Session('') as sess: \n\n            for shard_id in range(_NUM_SHARDS): \n                output_filename = _get_dataset_filename( \n                    dataset_dir, split_name, shard_id) \n\n                with tf.python_io.TFRecordWriter(output_filename)\n                as   \n                tfrecord_writer: \n                    start_ndx = shard_id * num_per_shard \n                    end_ndx = min((shard_id + 1) * num_per_shard,  \n                    len(filenames)) \n                    for i in range(start_ndx, end_ndx): \n                        sys.stdout.write('\\r>> Converting image  \n                         %d/%d shard %d' % ( \n                            i + 1, len(filenames), shard_id)) \n                        sys.stdout.flush() \n\n                        # Read the filename: \n                        image_data =  \n                    tf.gfile.FastGFile(filenames[i], 'rb').read() \n                        height, width =          \n                    image_reader.read_image_dims(sess, image_data) \n\n                        class_name =  \n                     os.path.basename(os.path.dirname(filenames[i])) \n                        class_id = class_names_to_ids[class_name] \n\n                        example = dataset_utils.image_to_tfexample( \n                            image_data, b'jpg', height, width,   \n                             class_id) \n\n                 tfrecord_writer.write(example.SerializeToString()) \n\n                  sys.stdout.write('\\n') \n                  sys.stdout.flush() \n```", "```py\n_FILE_PATTERN = 'diabetic_%s_*.tfrecord' \nSPLITS_TO_SIZES = {'train': 30000, 'validation': 5126} \n_NUM_CLASSES = 5 \n_ITEMS_TO_DESCRIPTIONS = { \n    'image': 'A color image of varying size.', \n    'label': 'A single integer between 0 and 4', \n} \ndef get_split(split_name, dataset_dir, file_pattern=None, reader=None): \n  \"\"\"Gets a dataset tuple with instructions for reading flowers. \n  Args: \n    split_name: A train/validation split name. \n    dataset_dir: The base directory of the dataset sources. \n    file_pattern: The file pattern to use when matching the dataset sources. \n      It is assumed that the pattern contains a '%s' string so that the split \n      name can be inserted. \n    reader: The TensorFlow reader type. \n  Returns: \n    A `Dataset` namedtuple. \n  Raises: \n    ValueError: if `split_name` is not a valid train/validation split. \n  \"\"\" \n  if split_name not in SPLITS_TO_SIZES: \n    raise ValueError('split name %s was not recognized.' % split_name) \n\n  if not file_pattern: \n    file_pattern = _FILE_PATTERN \n  file_pattern = os.path.join(dataset_dir, file_pattern % split_name) \n\n  # Allowing None in the signature so that dataset_factory can use the default. \n  if reader is None: \n    reader = tf.TFRecordReader \n\n  keys_to_features = { \n      'image/encoded': tf.FixedLenFeature((), tf.string, default_value=''), \n      'image/format': tf.FixedLenFeature((), tf.string, default_value='png'), \n      'image/class/label': tf.FixedLenFeature( \n          [], tf.int64, default_value=tf.zeros([], dtype=tf.int64)), \n  } \n  items_to_handlers = { \n      'image': slim.tfexample_decoder.Image(), \n      'label': slim.tfexample_decoder.Tensor('image/class/label'), \n  } \n  decoder = slim.tfexample_decoder.TFExampleDecoder( \n      keys_to_features, items_to_handlers) \n\n  labels_to_names = None \n  if dataset_utils.has_labels(dataset_dir): \n    labels_to_names = dataset_utils.read_label_file(dataset_dir) \n\n  return slim.dataset.Dataset( \n      data_sources=file_pattern, \n      reader=reader, \n      decoder=decoder, \n      num_samples=SPLITS_TO_SIZES[split_name], \n      items_to_descriptions=_ITEMS_TO_DESCRIPTIONS, \n      num_classes=_NUM_CLASSES, \n      labels_to_names=labels_to_names) \n```", "```py\npython train_image_classifier.py --train_dir=D:\\datasets\\diabetic\\checkpoints --dataset_name=diabetic --dataset_split_name=train --dataset_dir=D:\\datasets\\diabetic\\tfrecords --model_name=inception_v3 --checkpoint_path=D:\\datasets\\diabetic\\checkpoints\\inception_v3\\inception_v3.ckpt --checkpoint_exclude_scopes=InceptionV3/Logits,InceptionV3/AuxLogits --trainable_scopes=InceptionV3/Logits,InceptionV3/AuxLogits --learning_rate=0.000001 --learning_rate_decay_type=exponential \n```", "```py\npython eval_image_classifier.py --alsologtostderr --checkpoint_path=D:\\datasets\\diabetic\\checkpoints\\model.ckpt-92462 --dataset_name=diabetic --dataset_split_name=validation --dataset_dir=D:\\datasets\\diabetic\\tfrecords --model_name=inception_v3\n\n```", "```py\ntensorboard -logdir .\n```", "```py\n>>> import dicom \n>>> plan = dicom.read_file(\"rtplan.dcm\") \n>>> plan.PatientName \n'Last^First^mid^pre' \n>>> plan.dir(\"setup\")    # get a list of tags with \"setup\" somewhere in the name \n['PatientSetupSequence'] \n>>> plan.PatientSetupSequence[0] \n(0018, 5100) Patient Position                    CS: 'HFS' \n(300a, 0182) Patient Setup Number                IS: '1' \n(300a, 01b2) Setup Technique Description         ST: '' \n```", "```py\n>>> ds \n(0008, 0012) Instance Creation Date              DA: '20030903' \n(0008, 0013) Instance Creation Time              TM: '150031' \n(0008, 0016) SOP Class UID                       UI: RT Plan Storage \n(0008, 0018) Diagnosis                        UI: Positive  \n(0008, 0020) Study Date                          DA: '20030716' \n(0008, 0030) Study Time                          TM: '153557' \n(0008, 0050) Accession Number                    SH: '' \n(0008, 0060) Modality                            CS: 'RTPLAN'\n```", "```py\n>>> import dicom, glob, os \n>>> os.chdir(\"/some/medical/data/dir\") \n>>> domains={} \n>>> for file in glob.glob(\"*.dcm\"): \n>>>    aMedFile = dicom.read_file(file) \n>>>    theVal=aMedFile.ds[0x10,0x10].value \n>>>    if domains[theVal]>0: \n>>>       domains[theVal]= domains[theVal]+1 \n>>>    else: \n>>>       domains[theVal]=1 \n```", "```py\n>>> import dicom \n>>> ds=dicom.read_file(\"MR_small.dcm\") \n>>> ds.pixel_array \narray([[ 905, 1019, 1227, ...,  302,  304,  328], \n       [ 628,  770,  907, ...,  298,  331,  355], \n       [ 498,  566,  706, ...,  280,  285,  320], \n       ..., \n       [ 334,  400,  431, ..., 1094, 1068, 1083], \n       [ 339,  377,  413, ..., 1318, 1346, 1336], \n       [ 378,  374,  422, ..., 1369, 1129,  862]], dtype=int16) \n>>> ds.pixel_array.shape \n(64, 64)\n```", "```py\nimport os \nfrom pydicom import dicomio \nimport png \nimport errno \nimport fnmatch\n```"]