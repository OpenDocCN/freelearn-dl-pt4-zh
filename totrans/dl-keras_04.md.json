["```py\ndef generator_model():\n    model = Sequential()\n    model.add(Dense(input_dim=100, output_dim=1024))\n    model.add(Activation('tanh'))\n    model.add(Dense(128*7*7))\n    model.add(BatchNormalization())\n    model.add(Activation('tanh'))\n    model.add(Reshape((128, 7, 7), input_shape=(128*7*7,)))\n    model.add(UpSampling2D(size=(2, 2)))\n    model.add(Convolution2D(64, 5, 5, border_mode='same'))\n    model.add(Activation('tanh'))\n    model.add(UpSampling2D(size=(2, 2)))\n    model.add(Convolution2D(1, 5, 5, border_mode='same'))\n    model.add(Activation('tanh'))\n    return model\n\n```", "```py\ndef discriminator_model():\n    model = Sequential()\n    model.add(Convolution2D(64, 5, 5, border_mode='same',\n    input_shape=(1, 28, 28)))\n    model.add(Activation('tanh'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Convolution2D(128, 5, 5))\n    model.add(Activation('tanh'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Flatten())\n    model.add(Dense(1024))\n    model.add(Activation('tanh'))\n    model.add(Dense(1))\n    model.add(Activation('sigmoid'))\n    return model\n\n```", "```py\ngit clone --depth=50 --branch=master https://github.com/bstriner/keras-adversarial.git\n\n```", "```py\npython setup.py install\n\n```", "```py\nadversarial_model = AdversarialModel(base_model=M,\n    player_params=[generator.trainable_weights, discriminator.trainable_weights],\n    player_names=[\"generator\", \"discriminator\"])\n\n```", "```py\nadversarial_model = AdversarialModel(player_models=[gan_g, gan_d],\n    player_params=[generator.trainable_weights, discriminator.trainable_weights],\n    player_names=[\"generator\", \"discriminator\"])\n\n```", "```py\nimport matplotlib as mpl\n# This line allows mpl to run with no DISPLAY defined\nmpl.use('Agg')\n\n```", "```py\nfrom keras.layers import Dense, Reshape, Flatten, Dropout, LeakyReLU,\n    Input, Activation, BatchNormalization\nfrom keras.models import Sequential, Model\nfrom keras.layers.convolutional import Convolution2D, UpSampling2D\nfrom keras.optimizers import Adam\nfrom keras.regularizers import l1, l1l2\nfrom keras.datasets import mnist\n\nimport pandas as pd\nimport numpy as np\n\n```", "```py\nfrom keras_adversarial import AdversarialModel, ImageGridCallback,\n    simple_gan, gan_targets\nfrom keras_adversarial import AdversarialOptimizerSimultaneous,\n    normal_latent_sampling, AdversarialOptimizerAlternating\nfrom image_utils import dim_ordering_fix, dim_ordering_input,\n    dim_ordering_reshape, dim_ordering_unfix\n\n```", "```py\ndef gan_targets(n):\n    \"\"\"\n    Standard training targets [generator_fake, generator_real, discriminator_fake,     \n    discriminator_real] = [1, 0, 0, 1]\n    :param n: number of samples\n    :return: array of targets\n    \"\"\"\n    generator_fake = np.ones((n, 1))\n    generator_real = np.zeros((n, 1))\n    discriminator_fake = np.zeros((n, 1))\n    discriminator_real = np.ones((n, 1))\n    return [generator_fake, generator_real, discriminator_fake, discriminator_real]\n\n```", "```py\ndef model_generator():\n    nch = 256\n    g_input = Input(shape=[100])\n    H = Dense(nch * 14 * 14, init='glorot_normal')(g_input)\n    H = BatchNormalization(mode=2)(H)\n    H = Activation('relu')(H)\n    H = dim_ordering_reshape(nch, 14)(H)\n    H = UpSampling2D(size=(2, 2))(H)\n    H = Convolution2D(int(nch / 2), 3, 3, border_mode='same', \n        init='glorot_uniform')(H)\n    H = BatchNormalization(mode=2, axis=1)(H)\n    H = Activation('relu')(H)\n    H = Convolution2D(int(nch / 4), 3, 3, border_mode='same', \n        init='glorot_uniform')(H)\n    H = BatchNormalization(mode=2, axis=1)(H)\n    H = Activation('relu')(H)\n    H = Convolution2D(1, 1, 1, border_mode='same', init='glorot_uniform')(H)\n    g_V = Activation('sigmoid')(H)\n    return Model(g_input, g_V)\n\n```", "```py\ndef model_discriminator(input_shape=(1, 28, 28), dropout_rate=0.5):\n    d_input = dim_ordering_input(input_shape, name=\"input_x\")\n    nch = 512\n    H = Convolution2D(int(nch / 2), 5, 5, subsample=(2, 2),\n        border_mode='same', activation='relu')(d_input)\n    H = LeakyReLU(0.2)(H)\n    H = Dropout(dropout_rate)(H)\n    H = Convolution2D(nch, 5, 5, subsample=(2, 2),\n        border_mode='same', activation='relu')(H)\n    H = LeakyReLU(0.2)(H)\n    H = Dropout(dropout_rate)(H)\n    H = Flatten()(H)\n    H = Dense(int(nch / 2))(H)\n    H = LeakyReLU(0.2)(H)\n    H = Dropout(dropout_rate)(H)\n    d_V = Dense(1, activation='sigmoid')(H)\n    return Model(d_input, d_V)\n\n```", "```py\ndef mnist_process(x):\n    x = x.astype(np.float32) / 255.0\n    return x\n\ndef mnist_data():\n    (xtrain, ytrain), (xtest, ytest) = mnist.load_data()\n    return mnist_process(xtrain), mnist_process(xtest)\n\n```", "```py\nif __name__ == \"__main__\":\n    # z in R^100\n    latent_dim = 100\n    # x in R^{28x28}\n    input_shape = (1, 28, 28)\n    # generator (z -> x)\n    generator = model_generator()\n    # discriminator (x -> y)\n    discriminator = model_discriminator(input_shape=input_shape)\n    # gan (x - > yfake, yreal), z generated on GPU\n    gan = simple_gan(generator, discriminator, normal_latent_sampling((latent_dim,)))\n    # print summary of models\n    generator.summary()\n    discriminator.summary()\n    gan.summary()\n\n```", "```py\n# build adversarial model\nmodel = AdversarialModel(base_model=gan,\n    player_params=[generator.trainable_weights, discriminator.trainable_weights],\n    player_names=[\"generator\", \"discriminator\"])\nmodel.adversarial_compile(adversarial_optimizer=AdversarialOptimizerSimultaneous(),\n    player_optimizers=[Adam(1e-4, decay=1e-4), Adam(1e-3, decay=1e-4)],\n    loss='binary_crossentropy')\n\n```", "```py\ndef generator_sampler():\n    zsamples = np.random.normal(size=(10 * 10, latent_dim))\n    gen = dim_ordering_unfix(generator.predict(zsamples))\n    return gen.reshape((10, 10, 28, 28))\n\ngenerator_cb = ImageGridCallback(\n    \"output/gan_convolutional/epoch-{:03d}.png\",generator_sampler)\nxtrain, xtest = mnist_data()\nxtrain = dim_ordering_fix(xtrain.reshape((-1, 1, 28, 28)))\nxtest = dim_ordering_fix(xtest.reshape((-1, 1, 28, 28)))\ny = gan_targets(xtrain.shape[0])\nytest = gan_targets(xtest.shape[0])\nhistory = model.fit(x=xtrain, y=y,\nvalidation_data=(xtest, ytest), callbacks=[generator_cb], nb_epoch=100,\n    batch_size=32)\ndf = pd.DataFrame(history.history)\ndf.to_csv(\"output/gan_convolutional/history.csv\")\ngenerator.save(\"output/gan_convolutional/generator.h5\")\ndiscriminator.save(\"output/gan_convolutional/discriminator.h5\")\n\n```", "```py\ndef dim_ordering_fix(x):\n    if K.image_dim_ordering() == 'th':\n        return x\n    else:\n        return np.transpose(x, (0, 2, 3, 1))\n\n```", "```py\nimport matplotlib as mpl\n# This line allows mpl to run with no DISPLAY defined\nmpl.use('Agg')\nimport pandas as pd\nimport numpy as np\nimport os\nfrom keras.layers import Dense, Reshape, Flatten, Dropout, LeakyReLU, \n    Activation, BatchNormalization, SpatialDropout2D\nfrom keras.layers.convolutional import Convolution2D, UpSampling2D, \n    MaxPooling2D, AveragePooling2D\nfrom keras.models import Sequential, Model\nfrom keras.optimizers import Adam\nfrom keras.callbacks import TensorBoard\nfrom keras.regularizers import l1l2\nfrom keras_adversarial import AdversarialModel, ImageGridCallback, \n    simple_gan, gan_targets\nfrom keras_adversarial import AdversarialOptimizerSimultaneous, \n    normal_latent_sampling, fix_names\nimport keras.backend as K\nfrom cifar10_utils import cifar10_data\nfrom image_utils import dim_ordering_fix, dim_ordering_unfix, \n    dim_ordering_shape\n\n```", "```py\ndef model_generator():\n    model = Sequential()\n    nch = 256\n    reg = lambda: l1l2(l1=1e-7, l2=1e-7)\n    h = 5\n    model.add(Dense(input_dim=100, output_dim=nch * 4 * 4, W_regularizer=reg()))\n    model.add(BatchNormalization(mode=0))\n    model.add(Reshape(dim_ordering_shape((nch, 4, 4))))\n    model.add(Convolution2D(nch/2, h, h, border_mode='same', W_regularizer=reg()))\n    model.add(BatchNormalization(mode=0, axis=1))\n    model.add(LeakyReLU(0.2))\n    model.add(UpSampling2D(size=(2, 2)))\n    model.add(Convolution2D(nch / 2, h, h, border_mode='same', W_regularizer=reg()))\n    model.add(BatchNormalization(mode=0, axis=1))\n    model.add(LeakyReLU(0.2))\n    model.add(UpSampling2D(size=(2, 2)))\n    model.add(Convolution2D(nch / 4, h, h, border_mode='same', W_regularizer=reg()))\n    model.add(BatchNormalization(mode=0, axis=1))\n    model.add(LeakyReLU(0.2))\n    model.add(UpSampling2D(size=(2, 2)))\n    model.add(Convolution2D(3, h, h, border_mode='same', W_regularizer=reg()))\n    model.add(Activation('sigmoid'))\n    return model\n\n```", "```py\ndef model_discriminator():\n    nch = 256\n    h = 5\n    reg = lambda: l1l2(l1=1e-7, l2=1e-7)\n    c1 = Convolution2D(nch / 4, h, h, border_mode='same', W_regularizer=reg(),\n    input_shape=dim_ordering_shape((3, 32, 32)))\n    c2 = Convolution2D(nch / 2, h, h, border_mode='same', W_regularizer=reg())\n    c3 = Convolution2D(nch, h, h, border_mode='same', W_regularizer=reg())\n    c4 = Convolution2D(1, h, h, border_mode='same', W_regularizer=reg())\n    def m(dropout):\n        model = Sequential()\n        model.add(c1)\n        model.add(SpatialDropout2D(dropout))\n        model.add(MaxPooling2D(pool_size=(2, 2)))\n        model.add(LeakyReLU(0.2))\n        model.add(c2)\n        model.add(SpatialDropout2D(dropout))\n        model.add(MaxPooling2D(pool_size=(2, 2)))\n        model.add(LeakyReLU(0.2))\n        model.add(c3)\n        model.add(SpatialDropout2D(dropout))\n        model.add(MaxPooling2D(pool_size=(2, 2)))\n        model.add(LeakyReLU(0.2))\n        model.add(c4)\n        model.add(AveragePooling2D(pool_size=(4, 4), border_mode='valid'))\n        model.add(Flatten())\n        model.add(Activation('sigmoid'))\n        return model\n    return m\n\n```", "```py\ndef example_gan(adversarial_optimizer, path, opt_g, opt_d, nb_epoch, generator,\n        discriminator, latent_dim, targets=gan_targets, loss='binary_crossentropy'):\n    csvpath = os.path.join(path, \"history.csv\")\n    if os.path.exists(csvpath):\n        print(\"Already exists: {}\".format(csvpath))\n    return\n\n```", "```py\nprint(\"Training: {}\".format(csvpath))\n# gan (x - > yfake, yreal), z is gaussian generated on GPU\n# can also experiment with uniform_latent_sampling\nd_g = discriminator(0)\nd_d = discriminator(0.5)\ngenerator.summary()\nd_d.summary()\ngan_g = simple_gan(generator, d_g, None)\ngan_d = simple_gan(generator, d_d, None)\nx = gan_g.inputs[1]\nz = normal_latent_sampling((latent_dim,))(x)\n# eliminate z from inputs\ngan_g = Model([x], fix_names(gan_g([z, x]), gan_g.output_names))\ngan_d = Model([x], fix_names(gan_d([z, x]), gan_d.output_names))\n\n```", "```py\n# build adversarial model\nmodel = AdversarialModel(player_models=[gan_g, gan_d],\n    player_params=[generator.trainable_weights, d_d.trainable_weights],\n    player_names=[\"generator\", \"discriminator\"])\nmodel.adversarial_compile(adversarial_optimizer=adversarial_optimizer,\n    player_optimizers=[opt_g, opt_d], loss=loss)\n\n```", "```py\n# create callback to generate images\nzsamples = np.random.normal(size=(10 * 10, latent_dim))\ndef generator_sampler():\n    xpred = dim_ordering_unfix(generator.predict(zsamples)).transpose((0, 2, 3, 1))\n    return xpred.reshape((10, 10) + xpred.shape[1:])\ngenerator_cb =\n    ImageGridCallback(os.path.join(path, \"epoch-{:03d}.png\"),\n    generator_sampler, cmap=None)\n\n```", "```py\n# train model\nxtrain, xtest = cifar10_data()\ny = targets(xtrain.shape[0])\nytest = targets(xtest.shape[0])\ncallbacks = [generator_cb]\nif K.backend() == \"tensorflow\":\n    callbacks.append(TensorBoard(log_dir=os.path.join(path, 'logs'),\n        histogram_freq=0, write_graph=True, write_images=True))\nhistory = model.fit(x=dim_ordering_fix(xtrain),y=y,\n    validation_data=(dim_ordering_fix(xtest), ytest),\n    callbacks=callbacks, nb_epoch=nb_epoch,\n    batch_size=32)\n# save history to CSV\ndf = pd.DataFrame(history.history)\ndf.to_csv(csvpath)\n# save models\ngenerator.save(os.path.join(path, \"generator.h5\"))\nd_d.save(os.path.join(path, \"discriminator.h5\"))\n\n```", "```py\ndef main():\n    # z in R^100\n    latent_dim = 100\n    # x in R^{28x28}\n    # generator (z -> x)\n    generator = model_generator()\n    # discriminator (x -> y)\n    discriminator = model_discriminator()\n    example_gan(AdversarialOptimizerSimultaneous(), \"output/gan-cifar10\",\n        opt_g=Adam(1e-4, decay=1e-5),\n        opt_d=Adam(1e-3, decay=1e-5),\n        nb_epoch=100, generator=generator, discriminator=discriminator,\n        latent_dim=latent_dim)\nif __name__ == \"__main__\":\nmain()\n\n```", "```py\nfrom matplotlib import pyplot as plt, gridspec\nimport os\n\ndef write_image_grid(filepath, imgs, figsize=None, cmap='gray'):\n    directory = os.path.dirname(filepath)\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n    fig = create_image_grid(imgs, figsize, cmap=cmap)\n    fig.savefig(filepath)\n    plt.close(fig)\n\ndef create_image_grid(imgs, figsize=None, cmap='gray'):\n    n = imgs.shape[0]\n    m = imgs.shape[1]\n    if figsize is None:\n        figsize=(n,m)\n    fig = plt.figure(figsize=figsize)\n    gs1 = gridspec.GridSpec(n, m)\n    gs1.update(wspace=0.025, hspace=0.025) # set the spacing between axes.\n    for i in range(n):\n        for j in range(m):\n            ax = plt.subplot(gs1[i, j])\n            img = imgs[i, j, :]\n    ax.imshow(img, cmap=cmap)\n    ax.axis('off')\n    return fig\n\n```", "```py\nimport keras.backend as K\nimport numpy as np\nfrom keras.layers import Input, Reshape\n\ndef dim_ordering_fix(x):\n    if K.image_dim_ordering() == 'th':\n        return x\n    else:\n        return np.transpose(x, (0, 2, 3, 1))\n\ndef dim_ordering_unfix(x):\n    if K.image_dim_ordering() == 'th':\n        return x\n    else:\n        return np.transpose(x, (0, 3, 1, 2))\n\ndef dim_ordering_shape(input_shape):\n    if K.image_dim_ordering() == 'th':\n        return input_shape\n    else:\n        return (input_shape[1], input_shape[2], input_shape[0])\n\ndef dim_ordering_input(input_shape, name):\n    if K.image_dim_ordering() == 'th':\n        return Input(input_shape, name=name)\n    else:\n        return Input((input_shape[1], input_shape[2], input_shape[0]), name=name)\n\ndef dim_ordering_reshape(k, w, **kwargs):\n    if K.image_dim_ordering() == 'th':\n        return Reshape((k, w, w), **kwargs)\n    else:\n        return Reshape((w, w, k), **kwargs)\n\n# One more utility function is used to fix names\ndef fix_names(outputs, names):\n    if not isinstance(outputs, list):\n        outputs = [outputs]\n    if not isinstance(names, list):\n        names = [names]\n    return [Activation('linear', name=name)(output) \n        for output, name in zip(outputs, names)]\n\n```", "```py\npip install virtualenv\nmkdir ~/virtualenvs && cd ~/virtualenvs\nvirtualenv wavenet\nsource wavenet/bin/activate\ncd ~\ngit clone https://github.com/basveeling/wavenet.git\ncd wavenet\npip install -r requirements.txt\n\n```", "```py\n$ python wavenet.py with 'data_dir=your_data_dir_name'\n\n```", "```py\npython wavenet.py predict with 'models/[run_folder]/config.json predict_seconds=1'\n\n```", "```py\ndef residual_block(x):\n    original_x = x\n    tanh_out = CausalAtrousConvolution1D(nb_filters, 2, atrous_rate=2 ** i,\n        border_mode='valid', causal=True, bias=use_bias,\n        name='dilated_conv_%d_tanh_s%d' % (2 ** i, s), activation='tanh',\n        W_regularizer=l2(res_l2))(x)\n    sigm_out = CausalAtrousConvolution1D(nb_filters, 2, atrous_rate=2 ** i,\n        border_mode='valid', causal=True, bias=use_bias,\n        name='dilated_conv_%d_sigm_s%d' % (2 ** i, s), activation='sigmoid',\n        W_regularizer=l2(res_l2))(x)\n    x = layers.Merge(mode='mul',\n        name='gated_activation_%d_s%d' % (i, s))([tanh_out, sigm_out])\n        res_x = layers.Convolution1D(nb_filters, 1, border_mode='same', bias=use_bias,\n        W_regularizer=l2(res_l2))(x)\n    skip_x = layers.Convolution1D(nb_filters, 1, border_mode='same', bias=use_bias,\n        W_regularizer=l2(res_l2))(x)\n    res_x = layers.Merge(mode='sum')([original_x, res_x])\n    return res_x, skip_x\n\n```", "```py\nLayer (type) Output Shape Param # Connected to\n====================================================================================================\ninput_part (InputLayer) (None, 1152, 256) 0\n____________________________________________________________________________________________________\ninitial_causal_conv (CausalAtrou (None, 1152, 256) 131328 input_part[0][0]\n____________________________________________________________________________________________________\ndilated_conv_1_tanh_s0 (CausalAt (None, 1152, 256) 131072 initial_causal_conv[0][0]\n____________________________________________________________________________________________________\ndilated_conv_1_sigm_s0 (CausalAt (None, 1152, 256) 131072 initial_causal_conv[0][0]\n____________________________________________________________________________________________________\ngated_activation_0_s0 (Merge) (None, 1152, 256) 0 dilated_conv_1_tanh_s0[0][0]\ndilated_conv_1_sigm_s0[0][0]\n______________________________________________________________________\n_____________________________\nconvolution1d_1 (Convolution1D) (None, 1152, 256) 65536 gated_activation_0_s0[0][0]\n____________________________________________________________________________________________________\nmerge_1 (Merge) (None, 1152, 256) 0 initial_causal_conv[0][0]\nconvolution1d_1[0][0]\n____________________________________________________________________________________________________\ndilated_conv_2_tanh_s0 (CausalAt (None, 1152, 256) 131072 merge_1[0][0]\n____________________________________________________________________________________________________\ndilated_conv_2_sigm_s0 (CausalAt (None, 1152, 256) 131072 merge_1[0][0]\n____________________________________________________________________________________________________\ngated_activation_1_s0 (Merge) (None, 1152, 256) 0 dilated_conv_2_tanh_s0[0][0]\ndilated_conv_2_sigm_s0[0][0]\n____________________________________________________________________________________________________\nconvolution1d_3 (Convolution1D) (None, 1152, 256) 65536 gated_activation_1_s0[0][0]\n____________________________________________________________________________________________________\nmerge_2 (Merge) (None, 1152, 256) 0 merge_1[0][0]\nconvolution1d_3[0][0]\n____________________________________________________________________________________________________\ndilated_conv_4_tanh_s0 (CausalAt (None, 1152, 256) 131072 merge_2[0][0]\n____________________________________________________________________________________________________\ndilated_conv_4_sigm_s0 (CausalAt (None, 1152, 256) 131072 merge_2[0][0]\n____________________________________________________________________________________________________\ngated_activation_2_s0 (Merge) (None, 1152, 256) 0 dilated_conv_4_tanh_s0[0][0]\ndilated_conv_4_sigm_s0[0][0]\n____________________________________________________________________________________________________\nconvolution1d_5 (Convolution1D) (None, 1152, 256) 65536 gated_activation_2_s0[0][0]\n____________________________________________________________________________________________________\nmerge_3 (Merge) (None, 1152, 256) 0 merge_2[0][0]\nconvolution1d_5[0][0]\n____________________________________________________________________________________________________\ndilated_conv_8_tanh_s0 (CausalAt (None, 1152, 256) 131072 merge_3[0][0]\n____________________________________________________________________________________________________\ndilated_conv_8_sigm_s0 (CausalAt (None, 1152, 256) 131072 merge_3[0][0]\n____________________________________________________________________________________________________\ngated_activation_3_s0 (Merge) (None, 1152, 256) 0 dilated_conv_8_tanh_s0[0][0]\ndilated_conv_8_sigm_s0[0][0]\n____________________________________________________________________________________________________\nconvolution1d_7 (Convolution1D) (None, 1152, 256) 65536 gated_activation_3_s0[0][0]\n____________________________________________________________________________________________________\nmerge_4 (Merge) (None, 1152, 256) 0 merge_3[0][0]\nconvolution1d_7[0][0]\n____________________________________________________________________________________________________\ndilated_conv_16_tanh_s0 (CausalA (None, 1152, 256) 131072 merge_4[0][0]\n____________________________________________________________________________________________________\ndilated_conv_16_sigm_s0 (CausalA (None, 1152, 256) 131072 merge_4[0][0]\n____________________________________________________________________________________________________\ngated_activation_4_s0 (Merge) (None, 1152, 256) 0 dilated_conv_16_tanh_s0[0][0]\ndilated_conv_16_sigm_s0[0][0]\n____________________________________________________________________________________________________\nconvolution1d_9 (Convolution1D) (None, 1152, 256) 65536 gated_activation_4_s0[0][0]\n____________________________________________________________________________________________________\nmerge_5 (Merge) (None, 1152, 256) 0 merge_4[0][0]\nconvolution1d_9[0][0]\n____________________________________________________________________________________________________\ndilated_conv_32_tanh_s0 (CausalA (None, 1152, 256) 131072 merge_5[0][0]\n____________________________________________________________________________________________________\ndilated_conv_32_sigm_s0 (CausalA (None, 1152, 256) 131072 merge_5[0][0]\n____________________________________________________________________________________________________\ngated_activation_5_s0 (Merge) (None, 1152, 256) 0 dilated_conv_32_tanh_s0[0][0]\ndilated_conv_32_sigm_s0[0][0]\n____________________________________________________________________________________________________\nconvolution1d_11 (Convolution1D) (None, 1152, 256) 65536 gated_activation_5_s0[0][0]\n____________________________________________________________________________________________________\nmerge_6 (Merge) (None, 1152, 256) 0 merge_5[0][0]\nconvolution1d_11[0][0]\n____________________________________________________________________________________________________\ndilated_conv_64_tanh_s0 (CausalA (None, 1152, 256) 131072 merge_6[0][0]\n____________________________________________________________________________________________________\ndilated_conv_64_sigm_s0 (CausalA (None, 1152, 256) 131072 merge_6[0][0]\n____________________________________________________________________________________________________\ngated_activation_6_s0 (Merge) (None, 1152, 256) 0 dilated_conv_64_tanh_s0[0][0]\ndilated_conv_64_sigm_s0[0][0]\n____________________________________________________________________________________________________\nconvolution1d_13 (Convolution1D) (None, 1152, 256) 65536 gated_activation_6_s0[0][0]\n____________________________________________________________________________________________________\nmerge_7 (Merge) (None, 1152, 256) 0 merge_6[0][0]\nconvolution1d_13[0][0]\n____________________________________________________________________________________________________\ndilated_conv_128_tanh_s0 (Causal (None, 1152, 256) 131072 merge_7[0][0]\n____________________________________________________________________________________________________\ndilated_conv_128_sigm_s0 (Causal (None, 1152, 256) 131072 merge_7[0][0]\n____________________________________________________________________________________________________\ngated_activation_7_s0 (Merge) (None, 1152, 256) 0 dilated_conv_128_tanh_s0[0][0]\ndilated_conv_128_sigm_s0[0][0]\n____________________________________________________________________________________________________\nconvolution1d_15 (Convolution1D) (None, 1152, 256) 65536 gated_activation_7_s0[0][0]\n____________________________________________________________________________________________________\nmerge_8 (Merge) (None, 1152, 256) 0 merge_7[0][0]\nconvolution1d_15[0][0]\n____________________________________________________________________________________________________\ndilated_conv_256_tanh_s0 (Causal (None, 1152, 256) 131072 merge_8[0][0]\n____________________________________________________________________________________________________\ndilated_conv_256_sigm_s0 (Causal (None, 1152, 256) 131072 merge_8[0][0]\n____________________________________________________________________________________________________\ngated_activation_8_s0 (Merge) (None, 1152, 256) 0 dilated_conv_256_tanh_s0[0][0]\ndilated_conv_256_sigm_s0[0][0]\n____________________________________________________________________________________________________\nconvolution1d_17 (Convolution1D) (None, 1152, 256) 65536 gated_activation_8_s0[0][0]\n____________________________________________________________________________________________________\nmerge_9 (Merge) (None, 1152, 256) 0 merge_8[0][0]\nconvolution1d_17[0][0]\n____________________________________________________________________________________________________\ndilated_conv_512_tanh_s0 (Causal (None, 1152, 256) 131072 merge_9[0][0]\n____________________________________________________________________________________________________\ndilated_conv_512_sigm_s0 (Causal (None, 1152, 256) 131072 merge_9[0][0]\n____________________________________________________________________________________________________\ngated_activation_9_s0 (Merge) (None, 1152, 256) 0 dilated_conv_512_tanh_s0[0][0]\ndilated_conv_512_sigm_s0[0][0]\n____________________________________________________________________________________________________\nconvolution1d_2 (Convolution1D) (None, 1152, 256) 65536 gated_activation_0_s0[0][0]\n____________________________________________________________________________________________________\nconvolution1d_4 (Convolution1D) (None, 1152, 256) 65536 gated_activation_1_s0[0][0]\n____________________________________________________________________________________________________\nconvolution1d_6 (Convolution1D) (None, 1152, 256) 65536 gated_activation_2_s0[0][0]\n____________________________________________________________________________________________________\nconvolution1d_8 (Convolution1D) (None, 1152, 256) 65536 gated_activation_3_s0[0][0]\n____________________________________________________________________________________________________\nconvolution1d_10 (Convolution1D) (None, 1152, 256) 65536 gated_activation_4_s0[0][0]\n____________________________________________________________________________________________________\nconvolution1d_12 (Convolution1D) (None, 1152, 256) 65536 gated_activation_5_s0[0][0]\n____________________________________________________________________________________________________\nconvolution1d_14 (Convolution1D) (None, 1152, 256) 65536 gated_activation_6_s0[0][0]\n____________________________________________________________________________________________________\nconvolution1d_16 (Convolution1D) (None, 1152, 256) 65536 gated_activation_7_s0[0][0]\n____________________________________________________________________________________________________\nconvolution1d_18 (Convolution1D) (None, 1152, 256) 65536 gated_activation_8_s0[0][0]\n____________________________________________________________________________________________________\nconvolution1d_20 (Convolution1D) (None, 1152, 256) 65536 gated_activation_9_s0[0][0]\n____________________________________________________________________________________________________\nmerge_11 (Merge) (None, 1152, 256) 0 convolution1d_2[0][0]\nconvolution1d_4[0][0]\nconvolution1d_6[0][0]\nconvolution1d_8[0][0]\nconvolution1d_10[0][0]\nconvolution1d_12[0][0]\nconvolution1d_14[0][0]\nconvolution1d_16[0][0]\nconvolution1d_18[0][0]\nconvolution1d_20[0][0]\n____________________________________________________________________________________________________\nactivation_1 (Activation) (None, 1152, 256) 0 merge_11[0][0]\n____________________________________________________________________________________________________\nconvolution1d_21 (Convolution1D) (None, 1152, 256) 65792 activation_1[0][0]\n____________________________________________________________________________________________________\nactivation_2 (Activation) (None, 1152, 256) 0 convolution1d_21[0][0]\n____________________________________________________________________________________________________\nconvolution1d_22 (Convolution1D) (None, 1152, 256) 65792 activation_2[0][0]\n____________________________________________________________________________________________________\noutput_softmax (Activation) (None, 1152, 256) 0 convolution1d_22[0][0]\n====================================================================================================\nTotal params: 4,129,536\nTrainable params: 4,129,536\nNon-trainable params: 0\n\n```"]