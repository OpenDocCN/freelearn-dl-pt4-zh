<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Deep Learning Models Using TensorFlow in R</h1>
                </header>
            
            <article>
                
<p class="mce-root">This chapter is about using TensorFlow in R. We have already used TensorFlow quite a lot, as Keras is a high-level neural network API that uses either TensorFlow, CNTK, or Theano. In R, Keras uses TensorFlow in the background. TensorFlow is more difficult to develop deep learning models in. However, there are two interesting packages <span>in TensorFlow that </span><span>could be overlooked:</span> TensorFlow estimators and TensorFlow runs. We will cover both of these packages in this chapter.</p>
<p class="mce-root">In this chapter, we will cover the following topics:</p>
<ul>
<li class="mce-root">Introduction to TensorFlow</li>
<li>Building models using TensorFlow</li>
<li>TensorFlow estimators</li>
<li>TensorFlow runs packages</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introduction to the TensorFlow library</h1>
                </header>
            
            <article>
                
<p><span><strong>TensorFlow</strong> is not just a deep learning library, but an expressive programming language that can implement various optimization and mathematical transformations on data. While it is mainly used to implement deep learning algorithms, it can perform much more. In </span>TensorFlow, programs are represented as computational graphs, and data in TensorFlow is stored in <kbd>tensors</kbd>. A <strong>tensor</strong> is an array of data that has the same data type, and the rank of a tensor is the number of dimensions. Because all the data in a tensor must have the same type, they are more similar to R matrices than data frames.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Here is an example of tensors of various ranks:</p>
<pre>library(tensorflow)<br/> <br/>&gt; # tensor of rank-0<br/>&gt; var1 &lt;- tf$constant(0.1)<br/>&gt; print(var1)<br/>Tensor("Const:0", shape=(), dtype=float32)<br/> <br/>&gt; sess &lt;- tf$InteractiveSession()<br/>T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3019 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)<br/><br/>&gt; sess$run(tf$global_variables_initializer())<br/>&gt; var2 &lt;- tf$constant(2.3)<br/>&gt; var3 = var1 + var2<br/>&gt; print(var1)<br/>Tensor("Const:0", shape=(), dtype=float32)<br/> num 0.1<br/> <br/>&gt; print(var2)<br/>Tensor("Const_1:0", shape=(), dtype=float32)<br/> num 2.3<br/> <br/>&gt; print(var3)<br/>Tensor("Add:0", shape=(), dtype=float32)<br/> num 2.4<br/> <br/>&gt; # tensor of rank-1<br/>&gt; var4 &lt;- tf$constant(4.5,shape=shape(5L))<br/>&gt; print(var4)<br/>Tensor("Const_2:0", shape=(5,), dtype=float32)<br/> num [1:5(1d)] 4.5 4.5 4.5 4.5 4.5<br/> <br/>&gt; # tensor of rank-2<br/>&gt; var5 &lt;- tf$constant(6.7,shape=shape(3L,3L))<br/>&gt; print(var5)<br/>Tensor("Const_3:0", shape=(3, 3), dtype=float32)<br/> num [1:3, 1:3] 6.7 6.7 6.7 6.7 6.7 ...</pre>
<p class="mce-root">A TensorFlow program has two parts. First, you have to build the computational graph, which contains the tensors and the operations on those tensors. <span>When they have defined the graph, the second part is to create a TensorFlow session to run the graph. </span>In the previous example, the first time we print out the value for the tensor, <kbd>a</kbd>, we only get the tensor definition and not the value. All we have done is define part of the computation graph. It is only when we call <kbd>tf$InteractiveSession</kbd> that we tell TensorFlow to run the operations on the tensors. A session is responsible for running the computational graph.</p>
<p class="mce-root">The TensorFlow program is referred to as a graph because the code can be structured as a graph. This might not be obvious to us as most of the deep learning models that we have built in this book have consisted of sequential operations on layers. In TensorFlow (and Keras and MXNet), it is possible to use the output of an operation multiple times and to combine inputs in one operation.</p>
<p class="mce-root">As deep learning models get larger, it is increasingly difficult to visualize and debug them. In some code blocks, we have printed a summary of the model showing the layers, or we have plotted the network. However, neither of these tools would be helpful for debugging problems in a model with 10 million+ parameters! Fortunately, there is a <span>visualization tool included with TensorFlow </span>to help summarize, debug, and fix TensorFlow programs. This is called TensorBoard, and we will cover this next.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using TensorBoard to visualize deep learning networks</h1>
                </header>
            
            <article>
                
<p>Computation graphs in TensorFlow can be very complex, so there is a visualization tool called <strong>TensorBoard</strong> to visualize these graphs and assist in debugging. TensorBoard can plot a computation graph, display metrics from training, and so on. Since Keras uses TensorFlow in the backend, it too can use TensorBoard. Here is the MNIST example from Keras with TensorBoard logging enabled. This code can be found in the <kbd>Chapter8/mnist_keras.R</kbd> folder. The first part of the code loads the data, pre-processes it, and defines the model architecture. Hopefully, this should be familiar to you at this stage:</p>
<pre>library(keras)<br/><br/>mnist_data &lt;- dataset_mnist()<br/>xtrain &lt;- array_reshape(mnist_data$train$x,c(nrow(mnist_data$train$x),28,28,1))<br/>ytrain &lt;- to_categorical(mnist_data$train$y,10)<br/>xtrain &lt;- xtrain / 255.0<br/><br/>model &lt;- keras_model_sequential()<br/>model %&gt;%<br/>  layer_conv_2d(filters=32,kernel_size=c(5,5),activation='relu',<br/>                input_shape=c(28,28,1)) %&gt;% <br/>  layer_max_pooling_2d(pool_size=c(2,2)) %&gt;% <br/>  layer_dropout(rate=0.25) %&gt;% <br/>  layer_conv_2d(filters=32,kernel_size=c(5,5),activation='relu') %&gt;% <br/>  layer_max_pooling_2d(pool_size=c(2,2)) %&gt;% <br/>  layer_dropout(rate=0.25) %&gt;% <br/>  layer_flatten() %&gt;% <br/>  layer_dense(units=256,activation='relu') %&gt;% <br/>  layer_dropout(rate=0.4) %&gt;% <br/>  layer_dense(units=10,activation='softmax')<br/><br/>model %&gt;% compile(<br/>  loss=loss_categorical_crossentropy,<br/>  optimizer="rmsprop",metrics="accuracy"<br/>)</pre>
<p><span>To enable logging, add a </span><kbd>callbacks</kbd><span> parameter to the </span><kbd>model.fit</kbd><span> function to tell Keras/TensorFlow to log events to a directory.</span> <span>The following code will output log data to the <kbd>/tensorflow_logs</kbd> directory:</span></p>
<pre>model %&gt;% fit(<br/>  xtrain,ytrain,<br/>  batch_size=128,epochs=10,<br/><strong>  callbacks=callback_tensorboard("/tensorflow_logs",</strong><br/><strong>                                 histogram_freq=1,write_images=0),</strong><br/>  validation_split=0.2<br/>)<br/># from cmd line,run 'tensorboard --logdir /tensorflow_logs'</pre>
<div class="packt_infobox"><span><strong>Warning</strong>: The event logs can take up a lot of space. For 5 epochs on the <kbd>MNIST</kbd> dataset, 1.75 GB of information was created. Most of this was because of the image data that was included, so you may consider setting <kbd>write_images=0</kbd> to reduce the size of the logs.</span></div>
<div>
<p><span>TensorBoard is a web application, and you must start the TensorBoard program for it to run. When the model has finished training, follow these steps to start the TensorBoard web application:</span></p>
</div>
<ol>
<li><span>Open up Command Prompt and enter the following:</span></li>
</ol>
<pre style="padding-left: 60px"><strong>$ tensorboard --logdir /tensorflow_logs</strong></pre>
<ol start="2"/>
<ol start="2">
<li class="mce-root">If TensorBoard starts successfully, you should get a message similar to the following at Command Prompt:</li>
</ol>
<pre style="padding-left: 60px">TensorBoard 0.4.0rc2 at http://xxxxxx:6006 (Press CTRL+C to quit)</pre>
<ol start="3">
<li>Open a web browser to the link that was provided. The web page should be similar to the following:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-705 image-border" src="assets/2c775aa3-5ea3-40d4-9bdd-b2dfaf3e5786.png" style="width:104.50em;height:64.00em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 8.1: TensorBoard <span>–</span> model metrics</div>
<ol start="4">
<li>The preceding screenshot shows us the model metrics on the training and validation test sets <span>– </span>these are similar to the metrics shown in RStudio during training:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/c4be3ad7-5e78-4f42-9ef6-3fc0645d3843.png" style="width:57.75em;height:38.75em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 8.2: RStudio <span>– </span>model metrics</div>
<ol start="5">
<li>If you click on the <strong>Images</strong> option, you will be able to visualize the layers in the model and see how they change over epochs:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-706 image-border" src="assets/c9a63540-797c-45c4-bb53-bccdd90bb7ed.png" style="width:111.92em;height:60.17em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref"><span><span>Figure 8.3: TensorBoard – visualizing the model layers</span></span></div>
<ol start="6">
<li>If you click on the <strong>Graphs</strong> option, it will show the computation graph for the model. You can also download it as an image file. Here is the <span>computation graph for this model:</span></li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-707 image-border" src="assets/85274738-c4f0-4804-9588-550900583db8.png" style="width:142.42em;height:98.17em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref"><span><span>Figure 8.4: TensorBoard – computation graph</span></span></div>
<p style="padding-left: 60px">Some of this will seem familiar. We can see our convolutional, max pooling, flatten, dense, and dropout layers. The rest are not as obvious. As a higher-level abstraction, Keras takes care of a lot of the complexities in creating the <span>computation graph.</span></p>
<ol start="7">
<li>By clicking on the<span> <strong>Histogram</strong> option, you can see </span>how the distribution of tensors changes over time:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/7d0685a1-da65-43e7-b00c-6afaa95f4abc.png"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref"><span>Figure 8.5: TensorBoard – histograms</span></div>
<p>It is possible to use TensorBoard to debug a model. For example, it would be possible to investigate a vanishing gradient or an exploding <span>gradient </span>problem to see where the weights of the model were either vanishing to zero or exploding to infinity. There is a lot more to TensorBoard, so if you are curious you can follow the online documentation on it.</p>
<p><span>In the next section, we will use TensorFlow to build a regression model and a convolutional neural network.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">TensorFlow models</h1>
                </header>
            
            <article>
                
<p>In this section, we will use TensorFlow to build some machine learning models. First, we will build a simple linear regression model and then a convolutional neural network model, similar to what we have seen in <a href="1c0b9897-b0cc-4a8f-9ce8-e6409c347f4f.xhtml">Chapter 5</a>, <em>Image Classification Using Convolutional Neural Networks</em>.</p>
<p>The following code loads the TensorFlow library. We can confirm it loaded successfully by setting and accessing a constant string value:</p>
<pre>&gt; library(tensorflow)<br/><br/># confirm that TensorFlow library has loaded<br/>&gt; sess=tf$Session()<br/>&gt; hello_world &lt;- tf$constant('Hello world from TensorFlow')<br/>&gt; sess$run(hello_world)<br/>b'Hello world from TensorFlow'</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Linear regression using TensorFlow</h1>
                </header>
            
            <article>
                
<p>In this first Tensorflow example, we will look at regression. The code for this section is in the <kbd>Chapter8/regression_tf.R</kbd> folder:</p>
<ol>
<li>First, we create some fake data for an an input value, <em>x</em>, and an output value, <em>y</em>. We set <em>y</em> to be approximately equal to <kbd>0.8 + x * 1.3</kbd>. We want the application to discover the <kbd>beta0</kbd> and <kbd>beta1</kbd> values, which are <kbd>0.8</kbd> and <kbd>1.3</kbd>, respectively:</li>
</ol>
<pre style="padding-left: 60px">library(tensorflow)<br/><br/>set.seed(42)<br/># create 50000 x variable between 0 and 100<br/>x_var &lt;- runif(50000,min=0,max=1)<br/>#y = approx(1.3x + 0.8)<br/>y_var &lt;- rnorm(50000,0.8,0.04) + x_var * rnorm(50000,1.3,0.05)<br/><br/># y_pred = beta0 + beta1 * x<br/>beta0 &lt;- tf$Variable(tf$zeros(shape(1L)))<br/>beta1 &lt;- tf$Variable(tf$random_uniform(shape(1L), -1.0, 1.0))<br/>y_pred &lt;- beta0 + beta1*x_var</pre>
<ol start="2">
<li>Now, we set up our <kbd>loss</kbd> function so that the gradient descent algorithm can work:</li>
</ol>
<pre style="padding-left: 60px"># create our loss value which we want to minimize<br/>loss &lt;- tf$reduce_mean((y_pred-y_var)^2)<br/># create optimizer<br/>optimizer &lt;- tf$train$GradientDescentOptimizer(0.6)<br/>train &lt;- optimizer$minimize(loss)</pre>
<ol start="3">
<li>We then set up a TensorFlow session and initialize the variables. Finally, we can run the graph:</li>
</ol>
<pre style="padding-left: 60px"># create TensorFlow session and initialize variables<br/>sess = tf$Session()<br/>sess$run(tf$global_variables_initializer())<br/><br/># solve the regression<br/>for (step in 0:80) {<br/>  if (step %% 10 == 0)<br/>    print(sprintf("Step %1.0f:beta0=%1.4f, beta1=%1.4f",step,sess$run(beta0), sess$run(beta1)))<br/>  sess$run(train)<br/>}<br/>[1] "Step 0:beta0=0.0000, beta1=-0.3244"<br/>[1] "Step 10:beta0=1.0146, beta1=0.8944"<br/>[1] "Step 20:beta0=0.8942, beta1=1.1236"<br/>[1] "Step 30:beta0=0.8410, beta1=1.2229"<br/>[1] "Step 40:beta0=0.8178, beta1=1.2662"<br/>[1] "Step 50:beta0=0.8077, beta1=1.2850"<br/>[1] "Step 60:beta0=0.8033, beta1=1.2932"<br/>[1] "Step 70:beta0=0.8014, beta1=1.2967"<br/>[1] "Step 80:beta0=0.8006, beta1=1.2983"</pre>
<p>We can see that the model manages to find the values for <kbd>beta0</kbd> and <kbd>beta1</kbd> that solve the function <kbd>y=beta0 + beta1*x</kbd>. The next section is a more more complex example, where we will build a TensorFlow model for image classification.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Convolutional neural networks using TensorFlow</h1>
                </header>
            
            <article>
                
<p>In this section, we will <span>build a TensorFlow model on the </span>MNIST dataset. The code has similar layers and parameters to the Lenet model that we saw in <a href="1c0b9897-b0cc-4a8f-9ce8-e6409c347f4f.xhtml">Chapter 5</a>, <em>Image Classification Using Convolutional Neural Networks</em>. However, the code to build the model in TensorFlow is more complicated than the <span>code to build the model in </span>Keras or in MXNet. One reason for this is that it is the programmer's job to ensure that the sizes of the layers are correctly aligned. In the <span>Keras/MXNet models</span>, we can just change the number of nodes in a layer in one statement. In TensorFlow, if we change the number of nodes in a layer, we must ensure that we also change the inputs in the next layer.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>In some ways, programming in TensorFlow is closer to the hand-written neural network code we wrote in <a href="6e6dd858-9f00-454a-8434-a95c59e85b25.xhtml">Chapter 3</a>, <em>Deep Learning Fundamentals</em>. Another difference from Keras/MXNet in the training loop is that we <span>need to manage the batches </span>rather than just call, asking to iterate over all the data <em>x</em> times (where <em>x</em> is an epoch). The code for this example is in the <kbd>Chapter8/mnist_tf.R</kbd> folder. First, we load the Keras package to get the MNIST data, but we train the model using TensorFlow. Here is the first part of the code:</p>
<pre>library(RSNNS) # for decodeClassLabels<br/>library(tensorflow)<br/>library(keras)<br/><br/>mnist &lt;- dataset_mnist()<br/>set.seed(42)<br/><br/>xtrain &lt;- array_reshape(mnist$train$x,c(nrow(mnist$train$x),28*28))<br/>ytrain &lt;- decodeClassLabels(mnist$train$y)<br/>xtest &lt;- array_reshape(mnist$test$x,c(nrow(mnist$test$x),28*28))<br/>ytest &lt;- decodeClassLabels(mnist$test$y)<br/>xtrain &lt;- xtrain / 255.0<br/>xtest &lt;- xtest / 255.0<br/>head(ytrain)<br/>     0 1 2 3 4 5 6 7 8 9<br/>[1,] 0 0 0 0 0 1 0 0 0 0<br/>[2,] 1 0 0 0 0 0 0 0 0 0<br/>[3,] 0 0 0 0 1 0 0 0 0 0<br/>[4,] 0 1 0 0 0 0 0 0 0 0<br/>[5,] 0 0 0 0 0 0 0 0 0 1<br/>[6,] 0 0 1 0 0 0 0 0 0 0</pre>
<p>We use the <kbd>decodeClassLabels</kbd> function from the RSNNS library because TensorFlow requires a dummy coded matrix, so each possible class is represented as a column coded as 0/1, as shown in the preceding code output.</p>
<p>In the next code block, we create some placeholders for our input and output values in the model. <span>We also reshape the input data into a rank-4 tensor, that is, a 4 dimensional data structure. The first dimension (-1L) is for the records that will be processed in a batch. The next two dimensions are the dimensions of the image files, and the final dimension is the channels, which is the number of colors. Since our images are greyscale, there is only 1 channel. If the images were color images, there would be 3 channels. The following code block creates the placeholders and reshapes the data:</span></p>
<pre># placeholders<br/>x &lt;- tf$placeholder(tf$float32, shape(NULL,28L*28L))<br/>y &lt;- tf$placeholder(tf$float32, shape(NULL,10L))<br/>x_image &lt;- tf$reshape(x, shape(-1L,28L,28L,1L))</pre>
<p class="mce-root"/>
<p><span>Next, we will define the model architecture. We will create convolution blocks, just like we did previously. However, there are a lot more values that need to be set. For example, in the first convolutional layer, we must define the shape, initialize the weights, and take care of the bias variable. Here is the code for the TensorFlow model:</span></p>
<pre># first convolution layer<br/>conv_weights1 &lt;- tf$Variable(tf$random_uniform(shape(5L,5L,1L,16L), -0.4, 0.4))<br/>conv_bias1 &lt;- tf$constant(0.0, shape=shape(16L))<br/>conv_activ1 &lt;- tf$nn$tanh(tf$nn$conv2d(x_image, conv_weights1, strides=c(1L,1L,1L,1L), padding='SAME') + conv_bias1)<br/>pool1 &lt;- tf$nn$max_pool(conv_activ1, ksize=c(1L,2L,2L,1L),strides=c(1L,2L,2L,1L), padding='SAME')<br/><br/># second convolution layer<br/>conv_weights2 &lt;- tf$Variable(tf$random_uniform(shape(5L,5L,16L,32L), -0.4, 0.4))<br/>conv_bias2 &lt;- tf$constant(0.0, shape=shape(32L))<br/>conv_activ2 &lt;- tf$nn$relu(tf$nn$conv2d(pool1, conv_weights2, strides=c(1L,1L,1L,1L), padding='SAME') + conv_bias2)<br/>pool2 &lt;- tf$nn$max_pool(conv_activ2, ksize=c(1L,2L,2L,1L),strides=c(1L,2L,2L,1L), padding='SAME')<br/><br/># densely connected layer<br/>dense_weights1 &lt;- tf$Variable(tf$truncated_normal(shape(7L*7L*32L,512L), stddev=0.1))<br/>dense_bias1 &lt;- tf$constant(0.0, shape=shape(512L))<br/>pool2_flat &lt;- tf$reshape(pool2, shape(-1L,7L*7L*32L))<br/>dense1 &lt;- tf$nn$relu(tf$matmul(pool2_flat, dense_weights1) + dense_bias1)<br/><br/># dropout<br/>keep_prob &lt;- tf$placeholder(tf$float32)<br/>dense1_drop &lt;- tf$nn$dropout(dense1, keep_prob)<br/><br/># softmax layer<br/>dense_weights2 &lt;- tf$Variable(tf$truncated_normal(shape(512L,10L), stddev=0.1))<br/>dense_bias2 &lt;- tf$constant(0.0, shape=shape(10L))<br/><br/>yconv &lt;- tf$nn$softmax(tf$matmul(dense1_drop, dense_weights2) + dense_bias2)</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>
<p>Now, we have to define the loss equation, define the optimizer to use (Adam), and define the accuracy metric:</p>
<pre>cross_entropy &lt;- tf$reduce_mean(-tf$reduce_sum(y * tf$log(yconv), reduction_indices=1L))<br/>train_step &lt;- tf$train$AdamOptimizer(0.0001)$minimize(cross_entropy)<br/>correct_prediction &lt;- tf$equal(tf$argmax(yconv, 1L), tf$argmax(y, 1L))<br/>accuracy &lt;- tf$reduce_mean(tf$cast(correct_prediction, tf$float32))</pre>
<p>Finally, we can train the model over 10 epochs. However, one complication still exists, so we must manually manage the batches. We get the number of batches to train for and load them in turn. If we have 60,000 images in our train dataset, we have 469 batches (60,000/128 = 468.75 and round up to 469) per epoch. We feed in every batch and output metrics every 100 batches:</p>
<pre>sess &lt;- tf$InteractiveSession()<br/>sess$run(tf$global_variables_initializer())<br/><br/># if you get out of memory errors when running on gpu<br/># then lower the batch_size<br/>batch_size &lt;- 128<br/>batches_per_epoch &lt;- 1+nrow(xtrain) %/% batch_size<br/>for (epoch in 1:10)<br/>{<br/>  for (batch_no in 0:(-1+batches_per_epoch))<br/>  {<br/>    nStartIndex &lt;- 1 + batch_no*batch_size<br/>    nEndIndex &lt;- nStartIndex + batch_size-1<br/>    if (nEndIndex &gt; nrow(xtrain))<br/>      nEndIndex &lt;- nrow(xtrain)<br/>    xvalues &lt;- xtrain[nStartIndex:nEndIndex,]<br/>    yvalues &lt;- ytrain[nStartIndex:nEndIndex,]<br/>    if (batch_no %% 100 == 0) {<br/>      batch_acc &lt;- accuracy$eval(feed_dict=dict(x=xvalues,y=yvalues,keep_prob=1.0))<br/>      print(sprintf("Epoch %1.0f, step %1.0f: training accuracy=%1.4f",epoch, batch_no, batch_acc))<br/>    }<br/>    sess$run(train_step,feed_dict=dict(x=xvalues,y=yvalues,keep_prob=0.5))<br/>  }<br/>  cat("\n")<br/>}</pre>
<p>Here is the output for the first epoch:</p>
<pre>[1] "Epoch 1, step 0: training accuracy=0.0625"<br/>[1] "Epoch 1, step 100: training accuracy=0.8438"<br/>[1] "Epoch 1, step 200: training accuracy=0.8984"<br/>[1] "Epoch 1, step 300: training accuracy=0.9531"<br/>[1] "Epoch 1, step 400: training accuracy=0.8750"</pre>
<p>When training is complete, we can evaluate the model by calculating the accuracy on the test set. Again, we have to do this in batches to prevent out-of-memory errors:</p>
<pre># calculate test accuracy<br/># have to run in batches to prevent out of memory errors<br/>batches_per_epoch &lt;- 1+nrow(xtest) %/% batch_size<br/>test_acc &lt;- vector(mode="numeric", length=batches_per_epoch)<br/>for (batch_no in 0:(-1+batches_per_epoch))<br/>{<br/>  nStartIndex &lt;- 1 + batch_no*batch_size<br/>  nEndIndex &lt;- nStartIndex + batch_size-1<br/>  if (nEndIndex &gt; nrow(xtest))<br/>    nEndIndex &lt;- nrow(xtest)<br/>  xvalues &lt;- xtest[nStartIndex:nEndIndex,]<br/>  yvalues &lt;- ytest[nStartIndex:nEndIndex,]<br/>  batch_acc &lt;- accuracy$eval(feed_dict=dict(x=xvalues,y=yvalues,keep_prob=1.0))<br/>  test_acc[batch_no+1] &lt;- batch_acc<br/>}<br/># using the mean is not totally accurate as last batch is not a complete batch<br/>print(sprintf("Test accuracy=%1.4f",mean(test_acc)))<br/>[1] "Test accuracy=0.9802"</pre>
<p>We get a final accuracy of <kbd>0.9802</kbd>. If we compare this code to the MNIST example in <a href="1c0b9897-b0cc-4a8f-9ce8-e6409c347f4f.xhtml">Chapter 5</a>,<em> Image Classification Using Convolutional Neural Networks</em><span>, t</span>he TensorFlow code is more verbose and it is easier to make mistakes. We can really see the benefit of using a higher, level abstraction, such as MXNet or Keras (which can use TensorFlow as a backend). For most deep learning use cases, especially for building deep learning models using existing layers as building blocks, there is little to be gained in developing code in TensorFlow. For these use cases, it is simpler and more efficient to use Keras or MXNet.</p>
<p>After seeing this code, you may want to go back to something more familiar in Keras and MXNet. However, the next section looks at TensorFlow estimators and TensorFlow runs, which are <span>two useful packages that you should be aware of.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">TensorFlow estimators and TensorFlow runs packages</h1>
                </header>
            
            <article>
                
<p class="mce-root">TensorFlow estimators and the TensorFlow runs packages are great packages to use for deep learning. In this section, we will use both to train a model based on our churn prediction data from <a href="28315a07-2bf0-45c8-8e6f-0e4f01616ca3.xhtml">Chapter 4</a>, <em>Training Deep Prediction Models</em>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">TensorFlow estimators</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span><strong>TensorFlow estimators</strong> </span>allow you to build TensorFlow models using a simpler <span>API </span>interface. In R, the <kbd>tfestimators</kbd> package allows you to call this API. There are different model types, including linear models and neural networks. The following estimators are available:</p>
<ul>
<li class="mce-root"><kbd>linear_regressor()</kbd> for linear regression</li>
<li class="mce-root"><kbd>linear_classifier()</kbd> for linear classification</li>
<li class="mce-root"><kbd>dnn_regressor()</kbd> for deep neural network regression</li>
<li class="mce-root"><kbd>dnn_classifier()</kbd> for deep neural network classification</li>
<li class="mce-root"><kbd>dnn_linear_combined_regressor()</kbd> for deep neural network linear combined regression</li>
<li class="mce-root"><kbd>dnn_linear_combined_classifier()</kbd> for deep neural network linear combined classification</li>
</ul>
<p>Estimators hide a lot of the detail in creating a deep learning model, including building the graph, initializing variables and layers, and they can also integrate with TensorBoard. More details are available at <a href="https://tensorflow.rstudio.com/tfestimators/">https://tensorflow.rstudio.com/tfestimators/</a>. We will use <kbd>dnn_classifier</kbd> with the data from the binary classification task from <a href="28315a07-2bf0-45c8-8e6f-0e4f01616ca3.xhtml">Chapter 4</a>,<em><span> </span>Training Deep Prediction Models</em>. The following code in the <kbd>Chapter8/tf_estimators.R</kbd> folder demonstrates <span>TensorFlow estimators.</span></p>
<ol>
<li>We only include the code that is specific to TensorFlow estimators and omit the code at the start of the file that loads the data and splits it into train and test data:</li>
</ol>
<pre style="padding-left: 60px">response &lt;- function() "Y_categ"<br/>features &lt;- function() predictorCols<br/> <br/>FLAGS &lt;- flags(<br/>  flag_numeric("layer1", 256),<br/>  flag_numeric("layer2", 128),<br/>  flag_numeric("layer3", 64),<br/>  flag_numeric("layer4", 32),<br/>  flag_numeric("dropout", 0.2)<br/>)<br/>num_hidden &lt;- c(FLAGS$layer1,FLAGS$layer2,FLAGS$layer3,FLAGS$layer4)<br/><br/>classifier &lt;- dnn_classifier(<br/>  feature_columns = feature_columns(column_numeric(predictorCols)),<br/>  hidden_units = num_hidden,<br/>  activation_fn = "relu",<br/>  dropout = FLAGS$dropout,<br/>  n_classes = 2<br/>)<br/> <br/>bin_input_fn &lt;- function(data)<br/>{<br/> input_fn(data, features = features(), response = response())<br/>}<br/>tr &lt;- train(classifier, input_fn = bin_input_fn(trainData))<br/>[\] Training -- loss: 22.96, step: 2742 <br/><br/>tr<br/>Trained for 2,740 steps. <br/>Final step (plot to see history):<br/> mean_losses: 61.91<br/>total_losses: 61.91</pre>
<ol start="2">
<li>Once the model is trained, the following code plots the training and validation metrics:</li>
</ol>
<pre style="padding-left: 60px">plot(tr)</pre>
<ol start="3">
<li>This produces the following plot:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/9b2eefd3-08c8-40d2-ad7d-4ee4b0250033.png" style="width:56.58em;height:38.00em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref"><span><span>Figure 8.6: Training a loss plot for a TensorFlow estimator model</span></span></div>
<ol start="4">
<li>The next part of the code calls the <kbd>evaluate</kbd> function to produce metrics for the model:</li>
</ol>
<pre style="padding-left: 60px"># predictions &lt;- predict(classifier, input_fn = bin_input_fn(testData))<br/>evaluation &lt;- evaluate(classifier, input_fn = bin_input_fn(testData))<br/>[-] Evaluating -- loss: 37.77, step: 305<br/><br/>for (c in 1:ncol(evaluation))<br/> print(paste(colnames(evaluation)[c]," = ",evaluation[c],sep=""))<br/>[1] "accuracy = 0.77573162317276"<br/>[1] "accuracy_baseline = 0.603221416473389"<br/>[1] "auc = 0.842994153499603"<br/>[1] "auc_precision_recall = 0.887594640254974"<br/>[1] "average_loss = 0.501933991909027"<br/>[1] "label/mean = 0.603221416473389"<br/>[1] "loss = 64.1636199951172"<br/>[1] "precision = 0.803375601768494"<br/>[1] "prediction/mean = 0.562777876853943"<br/>[1] "recall = 0.831795573234558"<br/>[1] "global_step = 2742"</pre>
<p>We can see that we got an accuracy of <kbd>77.57%</kbd>, which is actually almost identical to the accuracy we got on the MXNet model in <a href="28315a07-2bf0-45c8-8e6f-0e4f01616ca3.xhtml">Chapter 4</a>, <em>Training Deep Prediction Models</em>, which had a similar architecture. The <span><kbd>dnn_classifier()</kbd> function hides a lot of the detail, so </span>Tensorflow estimators are a good way to use the power of TensorFlow for tasks with structured data.</p>
<p>Models created using TensorFlow estimators can be saved onto disk and loaded later. The <span><kbd>model_dir()</kbd> function </span>shows the location of where the model artifacts were saved (usually in a <kbd>temp</kbd> directory, but it can be copied elsewhere):</p>
<pre>model_dir(classifier)<br/>"C:\\Users\\xxxxxx\\AppData\\Local\\Temp\\tmpv1e_ri23"<br/># dnn_classifier has a model_dir parameter to load an existing model<br/>?dnn_classifier</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Included in the model <span>artifacts are the event logs that can be used by TensorBoard. For example, when I load TensorBoard up and point it to the logs directory in the <kbd>temp</kbd> directory, I can see the TensorFlow graph that was created:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-708 image-border" src="assets/b3037cf0-3e7e-4247-8606-2b0b4c550baf.png" style="width:162.50em;height:135.67em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref"><span><span>Figure 8.7: Graph using TensorBoard for a TensorFlow estimator model</span></span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">TensorFlow runs package</h1>
                </header>
            
            <article>
                
<p class="mce-root">The <kbd>tfruns</kbd> package is a set of utilities for managing different training runs for deep learning models. It can be used as a framework to build multiple deep learning models using different hyper-parameters. It can track the hyper-parameters, metrics, output, and source code for every training run and allows you to compare the best models so that you can see the differences between the training runs. This makes hyper-parameter tuning much easier and can be used with any <kbd>tfestimator</kbd> model or <kbd>Keras</kbd> model. For more details, go to <a href="https://tensorflow.rstudio.com/tools/tfruns/articles/overview.html">https://tensorflow.rstudio.com/tools/tfruns/articles/overview.html</a>.</p>
<p class="mce-root">The following code is in the <kbd>Chapter8/hyperparams.R</kbd> folder and also uses the script we used in the <em>TensorFlow estimators</em> section (<kbd><span>Chapter8/tf_estimators.R</span></kbd>):</p>
<pre>library(tfruns)<br/># FLAGS &lt;- flags(<br/># flag_numeric("layer1", 256),<br/># flag_numeric("layer2", 128),<br/># flag_numeric("layer3", 64),<br/># flag_numeric("layer4", 32),<br/># flag_numeric("dropout", 0.2),<br/># flag_string("activ","relu")<br/># )<br/><br/>training_run('tf_estimators.R')<br/>training_run('tf_estimators.R', flags = list(layer1=128,layer2=64,layer3=32,layer4=16))<br/>training_run('tf_estimators.R', flags = list(dropout=0.1,activ="tanh"))</pre>
<p>This will run the <kbd><span>Chapter8/tf_estimators.R</span></kbd> script with different hyper-parameters. The first time, we don't change any hyper-parameters, so it uses the defaults included in <kbd>Chapter8/tf_estimators.R</kbd>. Each time a new model is trained using the classification script, it is called a <strong><span>training r</span></strong><strong>un</strong>, and the details of the <span>training </span>run is stored in the <kbd>runs</kbd> folder in the current working directory.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>For each <span>training </span>run, a new website will pop up with details on the run, as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-709 image-border" src="assets/320da535-5b81-4e24-9072-6c2c4ee07181.png" style="width:46.17em;height:27.58em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 8.8: TensorFlow training run <span>–</span> Summary screen</div>
<p>We can see the progress of the training in the plots, along with the details of when the <span>training</span> run occurred and the evaluation metrics. We can also see in the bottom right that the <strong>flags</strong> (that is, <span>hyper-parameters) used in the training run are also shown. There is another tab for the R code output, which includes all of the output from the R code in the inner file (<kbd>Chapter8/tf_estimators.R</kbd>), including plots.</span></p>
<p><span>Once all of the training runs are complete, the following code shows a summary of all the training runs:</span></p>
<pre>ls_runs(order=eval_accuracy)<br/>ls_runs(order=eval_accuracy)[,1:5]<br/>Data frame: 3 x 5 <br/>                    run_dir eval_accuracy eval_accuracy_baseline eval_auc eval_auc_precision_recall<br/>3 runs/2018-08-02T19-50-17Z        0.7746                 0.6032   0.8431                    0.8874<br/>2 runs/2018-08-02T19-52-04Z        0.7724                 0.6032   0.8425                    0.8873<br/>1 runs/2018-08-02T19-53-39Z        0.7711                 0.6032   0.8360                    0.8878</pre>
<p>Here, we have ordered the results by the column <kbd>eval_accuracy</kbd>. If you close the window showing the summary for the <span>training run, you can display it again by calling the <kbd>view_run</kbd> function and passing in the folder name. For example, to show the summary for the best training run, use the following code:</span></p>
<pre>dir1 &lt;- ls_runs(order=eval_accuracy)[1,1]<br/>view_run(dir1)</pre>
<p>Finally, you can also compare two runs. Here, we are comparing the two best models:</p>
<pre>dir1 &lt;- ls_runs(order=eval_accuracy)[1,1]<br/>dir2 &lt;- ls_runs(order=eval_accuracy)[2,1]<br/>compare_runs(runs=c(dir1,dir2))</pre>
<p>This brings up a page similar to the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-710 image-border" src="assets/e006024e-8f31-4080-8a20-b5e7f81e6949.png" style="width:44.00em;height:29.75em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref"><span>Figure 8.9: Comparing two TensorFlow runs</span></div>
<p><span>This page shows the evaluation metrics for both training runs and also displays the hyper-parameters that were used. As we can see, this makes managing the process of tuning deep learning models much easier. This approach to hyper-parameter tuning has automatic logging, traceability, and it is easy to compare different sets of hyper-parameters. </span>You can see the metrics and the different hyper-parameters used for the training runs. There's no more comparing configuration files to try and match hyper-parameter settings to output logs! In comparison, the code I wrote for hyper-parameter selection for the NLP example in <a href="03f666ab-60ce-485a-8090-c158b29ef306.xhtml">Chapter 7</a>, <em>Natural Language Processing Using Deep Learning</em>, seems crude in comparison</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we developed some TensorFlow models. We looked at TensorBoard, which is a great tool for visualizing and debugging deep learning models. We built a couple of models using TensorFlow, including a basic regression model and a <span>Lenet model for </span><span>computer vision models. From these examples, we saw that programming in TensorFlow was more complicated and error-prone than using the higher-level APIs (MXNet and Keras) that we used elsewhere in this book.</span></p>
<p><span>We then moved onto using TensorFlow estimators, which is a much easier interface than using TensorFlow. We then used that script in another package called <strong>tfruns</strong>, which stands for TensorFlow runs. This package allows us to call a TensorFlow estimators or Keras script with different flags each time. We used this for hyper-parameter selection, running, and evaluating multiple models. The TensorFlow runs have excellent integration with RStudio and we were able to view summaries for each run and compare runs to see the difference in the metrics and hyper-parameters that were used.</span></p>
<p>In the next chapter, we we will look at embeddings and auto-encoders. We have already seen embeddings in <a href="03f666ab-60ce-485a-8090-c158b29ef306.xhtml">Chapter 7</a>, <em>Natural Language Processing Using Deep Learning</em>, so in the next chapter we will see how embeddings can create a lower level encoding of data. We will also use train auto-encoders, which create these embeddings. We will use <span>auto-encoders for anomaly detection and also for collaborative filtering (recommender system).</span></p>


            </article>

            
        </section>
    </body></html>