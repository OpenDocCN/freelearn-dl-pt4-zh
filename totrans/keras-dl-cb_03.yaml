- en: Optimization for Neural Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A number of applications in deep learning require optimization problems to be
    solved. Optimization refers to bringing whatever we are dealing with towards its
    ultimate state. The problem solved through the use of an optimization process
    must be supplied with data, providing model constants and parameters in functions,
    describing the overall objective function along with some constraints.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will look at the TensorFlow pipeline and various optimization
    models provided by the TensorFlow library. The list of topics covered are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Optimization basics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Types of optimizers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gradient descent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choosing the correct optimizer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is optimization?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The process to find maxima or minima is based on constraints. The choice of
    optimization algorithm for your deep learning model can mean the difference between
    good results in minutes, hours, and days.
  prefs: []
  type: TYPE_NORMAL
- en: Optimization sits at the center of deep learning. Most learning problems reduce
    to optimization problems. Let's imagine we are solving a problem for some set
    of data. Using this pre-processed data, we train a model by solving an optimization
    problem, which optimizes the weights of the model with regards to the chosen loss
    function and some regularization function.
  prefs: []
  type: TYPE_NORMAL
- en: Hyper parameters of a model play a significant role in the efficient training
    of a model. Therefore, it is essential to use the different optimization strategies
    and algorithms to measure appropriate and optimum values of model's hyper parameters,
    which affect our Model's learning process, and finally the output of a model.
  prefs: []
  type: TYPE_NORMAL
- en: Types of optimizers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First, we look at the high-level categories of optimization algorithms and then
    dive deep into the individual optimizers.
  prefs: []
  type: TYPE_NORMAL
- en: '**First order optimization** algorithms minimize or maximize a loss function
    using its gradient values concerning the parameters. The popularly used First
    order optimization algorithm is gradient descent. Here, the first order derivative
    tells us whether the function is decreasing or increasing at a particular point.
    The first order derivative gives us a line which is tangential to a point on its
    error surface.'
  prefs: []
  type: TYPE_NORMAL
- en: The derivative for a function depends on single variables, whereas a gradient
    for a function depends on multiple variables.
  prefs: []
  type: TYPE_NORMAL
- en: '**Second order optimization** algorithms use the second order derivative, which
    is also known as **Hessian**, to minimize or maximize the given loss function.
    Here, the Hessian is a matrix of second order partial derivatives. The second
    derivative is costly to compute. Hence, it''s not used much. The second order
    derivative indicates to us whether the first derivative is increasing or decreasing,
    giving an idea of functions curvature. The second order derivative gives us with
    a quadratic surface which touches the shape of the error surface.'
  prefs: []
  type: TYPE_NORMAL
- en: The second order derivative is costly to compute, but the advantage of a second
    order optimization method is that it does not neglect or ignore the curvature
    of a surface. Also, the stepwise performance is better. The key thing to note
    while choosing the optimization method is, first-order optimization methods are
    simple to compute and less time consuming, converging rather fast on large data
    sets. Second order methods are faster only when the second order derivative is
    known, and these methods are slower and expensive to compute in terms of both
    time and memory.
  prefs: []
  type: TYPE_NORMAL
- en: The second order optimization method can, at times, work better than first-order
    gradient descent methods because second-order methods will never get stuck around
    paths of slow convergence, that is, around saddle points, whereas gradient descent
    at times gets stuck and does not converge.
  prefs: []
  type: TYPE_NORMAL
- en: Gradient descent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Gradient descent is an algorithm which minimizes functions. A set of parameters
    defines a function, and the gradient descent algorithm starts with the initial
    set of param values and iteratively moves toward a set of param values that minimizes
    the function.
  prefs: []
  type: TYPE_NORMAL
- en: 'This iterative minimization is achieved using calculus, taking steps in the
    negative direction of the function gradient, as can be seen in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e3e8215c-9a54-438f-926c-e840fb8dd465.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Gradient descent is the most successful optimization algorithm. As mentioned
    earlier, it is used to do weights updates in a neural network so that we minimize
    the loss function. Let's now talk about an important neural network method called
    backpropagation, in which we firstly propagate forward and calculate the dot product
    of inputs with their corresponding weights, and then apply an activation function
    to the sum of products which transforms the input to an output and adds non linearities
    to the model, which enables the model to learn almost any arbitrary functional
    mappings.
  prefs: []
  type: TYPE_NORMAL
- en: 'Later, we back propagate in the neural network, carrying error terms and updating
    weights values using gradient descent, as shown in the following graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6408090e-36de-4968-8d52-5868895befb7.png)'
  prefs: []
  type: TYPE_IMG
- en: Different variants of gradient descent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Standard gradient descent**, also known as **batch gradient descent**, will
    calculate the gradient of the whole dataset but will perform only one update.
    Therefore, it can be quite slow and tough to control for datasets which are extremely
    large and don''t fit in the memory. Let''s now look at algorithms that can solve
    this problem.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Stochastic gradient descent** (**SGD**) performs parameter updates on each
    training example, whereas mini batch performs an update with *n* number of training
    examples in each batch. The issue with SGD is that, due to the frequent updates
    and fluctuations, it eventually complicates the convergence to the accurate minimum
    and will keep exceeding due to regular fluctuations. Mini-batch gradient descent
    comes to the rescue here, which reduces the variance in the parameter update,
    leading to a much better and stable convergence. SGD and mini-batch are used interchangeably.'
  prefs: []
  type: TYPE_NORMAL
- en: Overall problems with gradient descent include choosing a proper learning rate
    so that we avoid slow convergence at small values, or divergence at larger values and
    applying the same learning rate to all parameter updates wherein if the data is
    sparse we might not want to update all of them to the same extent. Lastly, is
    dealing with saddle points.
  prefs: []
  type: TYPE_NORMAL
- en: Algorithms to optimize gradient descent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will now be looking at various methods for optimizing gradient descent in
    order to calculate different learning rates for each parameter, calculate momentum,
    and prevent decaying learning rates.
  prefs: []
  type: TYPE_NORMAL
- en: To solve the problem of high variance oscillation of the SGD, a method called
    **momentum** was discovered; this accelerates the SGD by navigating along the
    appropriate direction and softening the oscillations in irrelevant directions.
    Basically, it adds a fraction of the update vector of the past step to the current
    update vector. Momentum value is usually set to .9\. Momentum leads to a faster
    and stable convergence with reduced oscillations.
  prefs: []
  type: TYPE_NORMAL
- en: '**Nesterov accelerated gradient** explains that as we reach the minima, that
    is, the lowest point on the curve, momentum is quite high and it doesn''t know
    to slow down at that point due to the large momentum which could cause it to miss
    the minima entirely and continue moving up. Nesterov proposed that we first make
    a long jump based on the previous momentum, then calculate the gradient and then
    make a correction which results in a parameter update. Now, this update prevents
    us to go too fast and not miss the minima, and makes it more responsive to changes.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Adagrad** allows the learning rate to adapt based on the parameters. Therefore,
    it performs large updates for infrequent parameters and small updates for frequent
    parameters. Therefore, it is very well-suited for dealing with sparse data. The
    main flaw is that its learning rate is always decreasing and decaying. Problems
    with decaying learning rates are solved using AdaDelta.'
  prefs: []
  type: TYPE_NORMAL
- en: '**AdaDelta** solves the problem of decreasing learning rate in AdaGrad. In
    AdaGrad, the learning rate is computed as one divided by the sum of square roots.
    At each stage, we add another square root to the sum, which causes the denominator
    to decrease constantly. Now, instead of summing all prior square roots, it uses
    a sliding window which allows the sum to decrease.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Adaptive Moment Estimation** (**Adam**) computes adaptive learning rates
    for each parameter. Like AdaDelta, Adam not only stores the decaying average of
    past squared gradients but additionally stores the momentum change for each parameter.
    Adam works well in practice and is one of the most used optimization methods today.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following two images (image credit: Alec Radford) show the optimization
    behavior of optimization algorithms described earlier. We see their behavior on
    the contours of a loss surface over time. Adagrad, RMsprop, and Adadelta almost
    quickly head off in the right direction and converge fast, whereas momentum and
    NAG are headed off-track. NAG is soon able to correct its course due to its improved
    responsiveness by looking ahead and going to the minimum.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/21078e47-ab9b-4dbd-95a9-aaf1f8dfa1eb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The second image displays the behavior of the algorithms at a saddle point.
    **SGD**, **Momentum**, and **NAG** find it challenging to break symmetry, but
    slowly they manage to escape the saddle point, whereas **Adagrad**, **Adadelta**,
    and **RMsprop** head down the negative slope, as can seen from the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/04660bd2-3f81-4c3a-b5bf-94447cf0b8c5.png)'
  prefs: []
  type: TYPE_IMG
- en: Which optimizer to choose
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the case that the input data is sparse or if we want fast convergence while
    training complex neural networks, we get the best results using adaptive learning
    rate methods. We also don't need to tune the learning rate. For most cases, Adam
    is usually a good choice.
  prefs: []
  type: TYPE_NORMAL
- en: Optimization with an example
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's take an example of linear regression, where we try to find the best fit
    for a straight line through a number of data points by minimizing the squares
    of the distance from the line to each data point. This is why we call it least
    squares regression. Essentially, we are formulating the problem as an optimization
    problem, where we are trying to minimize a loss function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s set up input data and look at the scatter plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/c03f289d-0fed-49f7-b77b-519f3e7ed240.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Define the data size and batch size:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We will need to resize the data to meet the TensorFlow input format, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The following scope initializes the `weights` and `bias`, and describes the
    linear model and loss function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We then set optimizers for minimizing the loss:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e5d26fc6-cbfa-4d72-bbb5-a894c7135c0f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We also get a sliding curve, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ba681a85-288f-4c46-90ba-092a214c96f1.png)'
  prefs: []
  type: TYPE_IMG
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned the fundamentals of optimization techniques and
    various types. Optimization is a complicated subject and a lot depends on the
    nature and size of our data. Also, optimization depends on weight matrices. A
    lot of these optimizers are trained and tuned for tasks like image classification
    or predictions. However, for custom or new use cases, we need to perform trial
    and error to determine the best solution.
  prefs: []
  type: TYPE_NORMAL
