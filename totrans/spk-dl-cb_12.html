<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Creating a Movie Recommendation Engine with Keras</h1>
                </header>
            
            <article>
                
<p class="mce-root">The following recipes will be covered in this chapter:</p>
<ul>
<li>Downloading MovieLens datasets</li>
<li>Manipulating and merging the MovieLens datasets</li>
<li>Exploring the MovieLens datasets</li>
<li>Preparing dataset for the deep learning pipeline</li>
<li>Applying the deep learning pipeline with Keras</li>
<li>Evaluating the recommendation engine's accuracy</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introduction</h1>
                </header>
            
            <article>
                
<p>In 2006, a small DVD rental company set out to make their recommendation engine 10% better. That company was Netflix and The Netflix Prize was worth $1M. This competition attracted many engineers and scientists from some of the largest tech companies around the world. The recommendation engine for the winning participant was built with machine learning. Netflix is now one of the leading tech giants when it comes to streaming data and recommending to its customers what they should watch next. </p>
<p>Ratings are everywhere these days, no matter<span> </span>what you are doing. If you are looking for a recommendation to go out to eat at a new restaurant, to order some clothing online, to watch a new movie at your local theater, or to watch a new series on television or online, there is most likely a website or a mobile application that will give you some type of rating along with feedback on the product or<span> </span>service you are looking to purchase. It is because of this immediate increase in feedback that recommendation algorithms have become more in demand over the last couple of years. This chapter will focus on building a movie recommendation engine for users, using the deep learning library Keras.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Downloading MovieLens datasets</h1>
                </header>
            
            <article>
                
<p>There is a great research lab center that began in 1992 in Minneapolis, MN called <strong>GroupLens</strong>, which<em> </em>focuses on recommendation engines and has graciously put together millions of rows of data over several years from the MovieLens website. We will use its dataset as our data source for training our recommendation engine model.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>The MovieLens dataset is housed and maintained by GroupLens on the following website:</p>
<p><a href="https://grouplens.org/datasets/movielens/">https://grouplens.org/datasets/movielens/</a>.</p>
<p>It is important to note that the dataset we will use will come directly from their website and not from a third-party intermediary or repository. Additionally, there are two different datasets that are available for us to query:</p>
<ul>
<li>Recommended for new research</li>
<li>Recommended for education and development</li>
</ul>
<p>The purpose of using this dataset is purely for educational purposes, so we will download the data from the <span class="packt_screen">education and development</span> section of the website. The educational data still contains a significant number of rows for our model, as it contains 100,000 ratings, as seen in the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/fab49ebd-7fe9-4090-9a3b-8156637c0290.png" style="width:45.58em;height:22.42em;"/></div>
<p>Additionally, this dataset has information regarding over 600 anonymous users collected over a period of several years between 1/9/1995 and 3/31/2015. The dataset was last updated in October 2017.</p>
<div class="packt_infobox"><span>F Maxwell Harper and Joseph A Konstan, 2015. <em>The MovieLens Datasets: History and Context</em>. ACM <strong>Transactions on Interactive Intelligent Systems</strong> (<strong>TiiS</strong>) 5, 4, Article 19 (December 2015), 19 pages. DOI:</span> <a href="http://dx.doi.org/10.1145/2827872">http://dx.doi.org/10.1145/2827872</a></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>This section will cover downloading and unzipping the MovieLens dataset:</p>
<ol>
<li>Download the research version of the smaller MovieLens dataset, which is available for public download at the following website: <a href="https://grouplens.org/datasets/movielens/latest/">https://grouplens.org/datasets/movielens/latest/</a>.</li>
</ol>
<p> </p>
<ol start="2">
<li>Download the <kbd>ZIP</kbd> file called <kbd>ml-latest-small.zip</kbd> to one of our local folders, as seen in in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/96e7ba85-7262-4431-bcb2-1efb3b9a4332.png" style="width:47.00em;height:30.33em;"/></div>
<ol start="3">
<li>When <kbd>ml-latest-small.zip</kbd> is downloaded and unzipped, the following four files should be extracted:<br/>
<ol>
<li><kbd><span>links.csv</span></kbd></li>
<li><kbd><span>movies.csv</span></kbd></li>
<li><kbd><span>ratings.csv</span></kbd></li>
<li><kbd><kbd><span>tags.csv</span></kbd></kbd></li>
</ol>
</li>
<li>Execute the following script to begin our <kbd>SparkSession</kbd>:</li>
</ol>
<pre style="padding-left: 60px">spark = SparkSession.builder \<br/>         .master("local") \<br/>         .appName("RecommendationEngine") \<br/>         .config("spark.executor.memory", "6gb") \<br/>         .getOrCreate()</pre>
<ol start="5">
<li>Confirm the following six files are available for access by executing the following script:</li>
</ol>
<pre style="padding-left: 60px">import os<br/>os.listdir('ml-latest-small/')</pre>
<ol start="6">
<li>Load each dataset into a Spark dataframe using the following script:</li>
</ol>
<pre style="padding-left: 60px">movies = spark.read.format('com.databricks.spark.csv')\<br/>            .options(header='true', inferschema='true')\<br/>            .load('ml-latest-small/movies.csv')<br/>tags = spark.read.format('com.databricks.spark.csv')\<br/>            .options(header='true', inferschema='true')\<br/>            .load('ml-latest-small/tags.csv')<br/>links = spark.read.format('com.databricks.spark.csv')\<br/>            .options(header='true', inferschema='true')\<br/>            .load('ml-latest-small/links.csv')<br/>ratings = spark.read.format('com.databricks.spark.csv')\<br/>            .options(header='true', inferschema='true')\<br/>            .load('ml-latest-small/ratings.csv')</pre>
<ol start="7">
<li>Confirm the row counts for each dataset by executing the following script:</li>
</ol>
<pre style="padding-left: 60px">print('The number of rows in movies dataset is {}'.format(movies.toPandas().shape[0]))<br/>print('The number of rows in ratings dataset is {}'.format(ratings.toPandas().shape[0]))<br/>print('The number of rows in tags dataset is {}'.format(tags.toPandas().shape[0]))<br/>print('The number of rows in links dataset is {}'.format(links.toPandas().shape[0]))</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>This section will focus on explaining the fields in each of the datasets available in the MovieLens 100K dataset. Take a look at these steps:</p>
<ol>
<li>The datasets are all available in the zipped file, <kbd>ml-latest-small.zip</kbd>, where the <kbd>ratings.csv</kbd> dataset will serve as the pseudo-fact table of our data, since it has transactions for each movie that is rated. The dataset, <kbd>ratings</kbd>, has the four column names shown in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1365 image-border" src="assets/0694eb08-d2d3-4314-b351-c58bf888f100.png" style="width:39.42em;height:27.83em;"/></div>
<ol start="2">
<li>The dataset shows the <span class="packt_screen">rating</span> selected by each <span class="packt_screen">userId</span> over the course of their time, from the earliest rating to the latest rating. The range of a <span class="packt_screen">rating</span> can vary from 0.5 to 5.0 stars, as seen by <kbd>userId = 1</kbd> in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1366 image-border" src="assets/46bff071-431b-47ef-bdd6-f6d0696be41a.png" style="width:24.00em;height:28.67em;"/></div>
<ol start="3">
<li>The <kbd>tags</kbd> dataset contains a <span class="packt_screen">tag</span> column that contains a specific word or phrase used by that user to describe a specific <span class="packt_screen">movieId</span> at a specific <span class="packt_screen">timestamp</span>. As can be seen in the following screenshot, <span class="packt_screen">userId</span> <span class="packt_screen">15</span> was not particularly fond of <span class="packt_screen">Sandra Bulluck</span> in one of her movies:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1367 image-border" src="assets/7ae51ecd-e9ce-4675-bbec-503239ddd17a.png" style="width:32.75em;height:27.92em;"/></div>
<ol start="4">
<li>The <kbd>movies</kbd> dataset is primarily a lookup table for the genre of films that have ratings. There are 19 unique <span class="packt_screen">genres</span> that can be associated with a film; however, it is important to note that a film can be affiliated with more than one genre at a time, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1368 image-border" src="assets/1d6b42d9-ac4b-43d2-80bc-a98199959546.png" style="width:34.00em;height:27.42em;"/></div>
<ol start="5">
<li> The final dataset is the <kbd>links</kbd> dataset, which also functions as a lookup table. It connects movies from MovieLens to data available for those same movies on popular film database sites such as <a href="http://www.imdb.com">http://www.imdb.com</a>, as well as <a href="https://www.themoviedb.org">https://www.themoviedb.org</a>. Links to IMDB are under the column called <span class="packt_screen">imdbId,</span> and links to the MovieDB are under the column called <span class="packt_screen">tmdbId</span>, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1369 image-border" src="assets/0b327b48-7367-4dbe-a908-f1af5c8d6a3f.png" style="width:16.50em;height:25.33em;"/></div>
<ol start="6">
<li>Before we finish, it is always a good idea to confirm that we are truly experiencing the expected row counts from all of the datasets. This helps to ensure that we did not encounter any issues with uploading the files to the notebook. We should expect to see around 100k rows for the <span class="packt_screen">ratings</span> dataset, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1370 image-border" src="assets/2984e7d6-e073-4bd9-ae06-2c20c2518f64.png" style="width:41.83em;height:8.17em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>While we are not going to use the 20 million-row dataset version of MovieLens for this chapter, you could elect to use it for this recommendation engine. You will still have the same four datasets, but with much more data, especially for the <kbd>ratings</kbd> dataset. If you choose to go with this approach, the full zipped dataset can be downloaded from the following website:</p>
<div class="CDPAlignLeft CDPAlign"><a href="http://files.grouplens.org/datasets/movielens/ml-latest.zip">http://files.grouplens.org/datasets/movielens/ml-latest.zip</a></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p>To learn more about the metadata behind the MovieLens dataset used in this chapter, visit the following website:</p>
<p><a href="http://files.grouplens.org/datasets/movielens/ml-latest-small-README.html">http://files.grouplens.org/datasets/movielens/ml-latest-small-README.html</a></p>
<p>To learn more about the history and context of the MovieLens dataset used in this chapter, visit the following website:</p>
<p><a href="https://www.slideshare.net/maxharp3r/the-movielens-datasets-history-and-context">https://www.slideshare.net/maxharp3r/the-movielens-datasets-history-and-context</a></p>
<p>To learn more about <em>The Netflix Prize</em>, visit the following website:</p>
<p><a href="https://www.netflixprize.com/">https://www.netflixprize.com/</a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Manipulating and merging the MovieLens datasets</h1>
                </header>
            
            <article>
                
<p>We currently have four separate datasets that we are working with, but ultimately we would like to get it down to a single dataset. This chapter will focus on pairing down our datasets to one.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>This section will not require any import of PySpark libraries but a background in SQL joins will come in handy, as we will explore multiple approaches to joining dataframes.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>This section will walk through the following steps for joining dataframes in PySpark:</p>
<ol>
<li>Execute the following script to rename all field names in <kbd>ratings</kbd>, by appending a <kbd>_1</kbd> to the end of the name:</li>
</ol>
<pre style="padding-left: 60px">for i in ratings.columns:<br/>     ratings = ratings.withColumnRenamed(i, i+'_1') </pre>
<ol start="2">
<li>Execute the following script to <kbd>inner join</kbd> the <kbd>movies</kbd> dataset to the <kbd>ratings</kbd> dataset, creating a new table called <kbd>temp1</kbd>:</li>
</ol>
<pre style="padding-left: 60px">temp1 = ratings.join(movies, ratings.movieId_1 == movies.movieId, how = 'inner')</pre>
<ol start="3">
<li>Execute the following script to inner join the <kbd>temp1</kbd> dataset to the <kbd>links</kbd> dataset, creating a new table called <kbd>temp2</kbd>:</li>
</ol>
<pre style="padding-left: 60px">temp2 = temp1.join(links, temp1.movieId_1 == links.movieId, how = 'inner')</pre>
<ol start="4">
<li>Create our final combined dataset, <kbd>mainDF</kbd>, by left-joining <kbd>temp2</kbd> to <kbd>tags</kbd> using the following script:</li>
</ol>
<pre style="padding-left: 60px">mainDF = temp2.join(tags, (temp2.userId_1 == tags.userId) &amp; (temp2.movieId_1 == tags.movieId), how = 'left')</pre>
<ol start="5">
<li>Select only the columns needed for our final <kbd>mainDF</kbd> dataset by executing the following script:</li>
</ol>
<pre style="padding-left: 60px">mainDF = mainDF.select('userId_1',<br/>                       'movieId_1',<br/>                       'rating_1',<br/>                       'title', <br/>                       'genres', <br/>                       'imdbId',<br/>                       'tmdbId', <br/>                       'timestamp_1').distinct()</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>This section will walk through our design process for joining tables together as well as which final columns will be kept:</p>
<ol>
<li>As was mentioned in the previous section, the <span class="packt_screen">ratings</span> dataframe will serve as our fact table, since it contains all the main transactions of ratings for each user over time. The columns in <span class="packt_screen">ratings</span> will be used in each subsequent join with the other three tables, and to maintain a uniqueness of the columns, we will attach a _1 to the end of each column name, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1371 image-border" src="assets/4b7f411f-5d3c-4e7d-b168-31fff520c535.png" style="width:31.25em;height:30.50em;"/></div>
<ol start="2">
<li>We can now join the three lookup tables to the <span class="packt_screen">ratings</span> table. The first two joins to <span class="packt_screen">ratings</span> are <span class="packt_screen">inner</span> joins, as the row counts for <span class="packt_screen">temp1</span> and <span class="packt_screen">temp2</span> are still <span class="packt_screen">100,004</span> rows. The third join to <span class="packt_screen">ratings</span> from <span class="packt_screen">tags</span> needs to be an <span class="packt_screen">outer</span> join to avoid dropping rows. Additionally, the join needs to be applied to both <span class="packt_screen">movieId</span> as well as <span class="packt_screen">userId,</span> as a tag is unique to both a specific user and a specific movie at any given time. The row counts for the three tables <span class="packt_screen">temp1</span>, <span class="packt_screen">temp2</span>, and <span class="packt_screen">mainDF</span> can be seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1372 image-border" src="assets/a4d62f47-77b8-4443-ac41-4c9dcbe4a47b.png" style="width:43.83em;height:15.08em;"/></div>
<div class="packt_tip">Often times when working with joins between datasets, we encounter three types of joins: inner, left, and right. An inner join will only produce a result set when both join keys are available from dataset 1 and dataset 2. A left join will produce all of the rows from dataset 1 and only the rows with matching keys from dataset 2. A right join will produce all of the rows from dataset 2 and only the rows from the matching keys from dataset 1. Later on in this section, we will explore SQL joins within Spark.</div>
<ol start="3">
<li>It is interesting to note that our newly created dataset, <span class="packt_screen">mainDF</span>, has <span class="packt_screen">100,441</span> rows, instead of the <span class="packt_screen">100,004</span> rows that are in the original dataset for <span class="packt_screen">ratings,</span> as well as <span class="packt_screen">temp1</span> and <span class="packt_screen">temp2</span>. There are 437 ratings that have more than one tag associated with them. Additionally, we can see that the majority of <span class="packt_screen">ratings_1</span> have a <span class="packt_screen">null</span> <span class="packt_screen">tag</span> value affiliated with them, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1373 image-border" src="assets/8a98e621-ab31-4307-ad13-356e3ce4a70e.png" style="width:63.17em;height:31.25em;"/></div>
<ol start="4">
<li>We have accumulated additional duplicative columns that will no longer be needed. There are 14 columns in total, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1375 image-border" src="assets/02801672-6ad8-41ee-a068-550a76eb103b.png" style="width:15.08em;height:18.00em;"/></div>
<ol start="5">
<li>Additionally, we have determined that the <span class="packt_screen">tags</span> field is relatively useless as it has over 99k null values. Therefore, we will use the <kbd>select()</kbd> function on the dataframe to pull in only the eight columns that we will use for our recommendation engine. We can then confirm that our final new dataframe, <span class="packt_screen">mainDF</span>, has the correct amount of rows, <span class="packt_screen">100,004</span>, as seen in the following screenshot:</li>
</ol>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/46d3d417-ff51-4850-8611-2d86851293a9.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>While we did do our joins using functions within a Spark dataframe using PySpark, we could have also done it by registering the dataframes as temporary tables and then joining them using <kbd>sqlContext.sql()</kbd>:</p>
<ol>
<li>First, we would register each of our datasets as temporary views using <kbd>creatorReplaceTempView()</kbd>, as seen in the following script:</li>
</ol>
<pre style="padding-left: 60px">movies.createOrReplaceTempView('movies_')<br/>links.createOrReplaceTempView('links_')<br/>ratings.createOrReplaceTempView('ratings_')</pre>
<ol start="2">
<li>Next, we would write our SQL script just as we would do with any other relational database using the <kbd>sqlContext.sql()</kbd> function, as seen in the following script:</li>
</ol>
<pre style="padding-left: 60px">mainDF_SQL = \<br/>sqlContext.sql(<br/>"""<br/>    select<br/>    r.userId_1<br/>    ,r.movieId_1<br/>    ,r.rating_1<br/>    ,m.title<br/>    ,m.genres<br/>    ,l.imdbId<br/>    ,l.tmdbId<br/>    ,r.timestamp_1<br/>    from ratings_ r<br/><br/>    inner join movies_ m on <br/>    r.movieId_1 = m.movieId<br/>    inner join links_ l on <br/>    r.movieId_1 = l.movieId<br/>"""<br/>)</pre>
<ol start="3">
<li>Finally, we can profile the new dataframe, <span class="packt_screen">mainDF_SQL</span>, and observe that it looks the same as our other dataframe, <span class="packt_screen">mainDF</span>, while also keeping the exact same row count, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1376 image-border" src="assets/bf1bd64c-b1d0-40d1-b786-ed4c8b99ca41.png" style="width:39.00em;height:29.08em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p>To learn more about SQL programming within Spark, visit the following website:</p>
<p><a href="https://spark.apache.org/docs/latest/sql-programming-guide.html">https://spark.apache.org/docs/latest/sql-programming-guide.html</a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Exploring the MovieLens datasets</h1>
                </header>
            
            <article>
                
<p>Before any modeling takes place, it is important to get familiar with the source dataset and perform some exploratory data analysis.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>We will import the following library to assist with visualizing and exploring the MovieLens dataset: <kbd>matplotlib</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>This section will walk through the steps to analyze the movie ratings in the MovieLens database:</p>
<ol>
<li>Retrieve some summary statistics on the <kbd>rating_1</kbd> column by executing the following script:</li>
</ol>
<pre style="padding-left: 60px">mainDF.describe('rating_1').show</pre>
<ol start="2">
<li>Build a histogram of the distribution of ratings by executing the following script:</li>
</ol>
<pre style="padding-left: 60px">import matplotlib.pyplot as plt<br/>%matplotlib inline<br/><br/>mainDF.select('rating_1').toPandas().hist(figsize=(16, 6), grid=True)<br/>plt.title('Histogram of Ratings')<br/>plt.show()</pre>
<ol start="3">
<li>Execute the following script to view the values of the histogram in a spreadsheet dataframe:</li>
</ol>
<pre style="padding-left: 60px">mainDF.groupBy(['rating_1']).agg({'rating_1':'count'})\<br/> .withColumnRenamed('count(rating_1)', 'Row Count').orderBy(["Row Count"],ascending=False)\<br/> .show()</pre>
<ol start="4">
<li>A unique count of user selections of ratings can be stored as a dataframe, <kbd>userId_frequency</kbd>, by executing the following script:</li>
</ol>
<pre style="padding-left: 60px">userId_frequency = mainDF.groupBy(['userId_1']).agg({'rating_1':'count'})\<br/>         .withColumnRenamed('count(rating_1)', '# of Reviews').orderBy(["# of             Reviews"],ascending=False)</pre>
<ol start="5">
<li>Plot a histogram of <kbd>userID_frequency</kbd> using the following script:</li>
</ol>
<pre style="padding-left: 60px">userId_frequency.select('# of Reviews').toPandas().hist(figsize=(16, 6), grid=True)<br/>plt.title('Histogram of User Ratings')<br/>plt.show()</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>This section will discuss how the ratings and user activities are distributed in the MovieLens database. Take a look at these steps:</p>
<ol>
<li>We can see that the average movie rating made by a user is approximately 3.5, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1377 image-border" src="assets/9bf2ee64-20b9-49c6-ac0d-7099c4beed8d.png" style="width:22.92em;height:11.42em;"/></div>
<ol start="2">
<li>Even though the average rating is 3.54, we can see that the histogram shows that the median rating is 4, which indicates that the user ratings are heavily skewed towards higher ratings, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1378 image-border" src="assets/01032540-4b8b-4b6e-8038-830800a2aa5a.png" style="width:66.67em;height:32.42em;"/></div>
<ol start="3">
<li>Another look at the data behind the histogram shows that users select <span class="packt_screen">4.0</span> most frequently, followed by <span class="packt_screen">3.0,</span> and then <span class="packt_screen">5.0</span>. Additionally, it is interesting to note that users are more likely to give ratings that are at the 0.0 level and not at the 0.5 level, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1380 image-border" src="assets/0e0481f0-b6f5-442c-90a4-a08c40ff4629.png" style="width:150.75em;height:47.50em;"/></div>
<ol start="4">
<li>We can look at the distribution of user selection of ratings and see that some users are very active in expressing their opinions on the films they've seen. This is the case with anonymous user <span class="packt_screen">547</span> who has posted <span class="packt_screen">2391</span> ratings, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1381 image-border" src="assets/f646edec-36fa-4edc-b64e-005cbf035ca5.png" style="width:42.08em;height:30.08em;"/></div>
<ol start="5">
<li>However, when we look at the distribution of users making rating selections, we do see that while there are some instances of users making over a thousand selections on their own, the overwhelming majority of users have made less than 250 selections, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1382 image-border" src="assets/32fd3b17-ec38-4450-83b8-fc1746b3b68b.png" style="width:154.75em;height:67.33em;"/></div>
<ol start="6">
<li>The distribution of the histogram is the previous screenshot is in a long-tail format which indicates that the majority of the occurrences are away from the center of the histogram. This is an indication that the overwhelming majority of ratings are defined by a few users.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>There are features that the <kbd>pyspark</kbd> dataframe that are similar to those of the <kbd>pandas</kbd> dataframe and can perform some summary statistics on specific columns.</p>
<p>In <kbd>pandas</kbd>, we perform summary statistics using the following script: <kbd>dataframe['column'].describe()</kbd>.</p>
<p>In <kbd>pyspark</kbd>, we perform summary statistics using the following script: <kbd>dataframe.describe('column').show()</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p>To learn more about the <kbd>describe()</kbd> function in PySpark, visit the following website:<br/>
<a href="http://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html#pyspark.sql.DataFrame.describe">http://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html#pyspark.sql.DataFrame.describe</a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Preparing dataset for the deep learning pipeline</h1>
                </header>
            
            <article>
                
<p>We are now ready to prepare our dataset to be fed into the deep learning model that we will build in Keras.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>While preparing the dataset for <kbd>Keras</kbd> we will import the following libraries into our notebook:</p>
<ul>
<li><kbd>import pyspark.sql.functions as F</kbd></li>
<li><kbd>import numpy as np</kbd></li>
<li><kbd>from pyspark.ml.feature import StringIndexer</kbd></li>
<li><kbd>import keras.utils</kbd></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>This section walks through the following steps to prepare the dataset for the deep learning pipeline:</p>
<ol>
<li>Execute the following script to clean up the column names:</li>
</ol>
<pre style="padding-left: 60px">mainDF = mainDF.withColumnRenamed('userId_1', 'userid')<br/>mainDF = mainDF.withColumnRenamed('movieId_1', 'movieid')<br/>mainDF = mainDF.withColumnRenamed('rating_1', 'rating')<br/>mainDF = mainDF.withColumnRenamed('timestamp_1', 'timestamp')<br/>mainDF = mainDF.withColumnRenamed('imdbId', 'imdbid')<br/>mainDF = mainDF.withColumnRenamed('tmdbId', 'tmdbid')</pre>
<ol start="2">
<li>The <kbd>rating</kbd> column is currently divided into 0.5 increments. Tweak the ratings to be rounded to a whole integer using the following script:</li>
</ol>
<pre style="padding-left: 60px">import pyspark.sql.functions as F<br/>mainDF = mainDF.withColumn("rating", F.round(mainDF["rating"], 0))</pre>
<ol start="3">
<li>Convert the <kbd>genres</kbd> column from a string to an index with a name of <kbd>genreCount</kbd> based on the frequency of the <kbd>genres</kbd> labels as seen in the following script:</li>
</ol>
<pre style="padding-left: 60px">from pyspark.ml.feature import StringIndexer<br/>string_indexer = StringIndexer(inputCol="genres", outputCol="genreCount")<br/>mainDF = string_indexer.fit(mainDF).transform(mainDF)</pre>
<ol start="4">
<li>Pair down our dataframe using the following script:</li>
</ol>
<pre style="padding-left: 60px"><span>mainDF = mainDF.select('rating', '</span>userid<span>', '</span>movieid<span>', '</span>imdbid<span>', '</span>tmdbid<span>', 'timestamp', 'genreCount')</span></pre>
<ol start="5">
<li>Split <kbd>mainDF</kbd> into a training and testing set for model-training purposes, using the following script:</li>
</ol>
<pre style="padding-left: 60px">trainDF, testDF = mainDF.randomSplit([0.8, 0.2], seed=1234)</pre>
<ol start="6">
<li>Convert our two Spark dataframes, <kbd>trainDF</kbd> and <kbd>testDF</kbd>, into four <kbd>numpy</kbd> arrays for consumption within our deep learning model using the following script:</li>
</ol>
<pre style="padding-left: 60px">import numpy as np<br/><br/>xtrain_array = np.array(trainDF.select('userid','movieid', 'genreCount').collect())<br/>xtest_array = np.array(testDF.select('userid','movieid', 'genreCount').collect())<br/><br/>ytrain_array = np.array(trainDF.select('rating').collect())<br/>ytest_array = np.array(testDF.select('rating').collect()</pre>
<ol start="7">
<li>Convert both <kbd>ytrain_array</kbd> and <kbd>ytest_array</kbd> into one-hot encoded labels, <kbd>ytrain_OHE</kbd> and <kbd>ytest_OHE</kbd>, using the following script:</li>
</ol>
<pre style="padding-left: 60px">import keras.utils as u<br/>ytrain_OHE = u.to_categorical(ytrain_array)<br/>ytest_OHE = u.to_categorical(ytest_array)</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p><span>This section explains how we prepare the dataset for the deep learning pipeline:</span></p>
<ol>
<li>For ease of use inside the deep learning pipeline, it is best to clean up the column names and the order of the columns before the pipeline receives the data. After renaming the column headers, we can view the updated columns, as seen in the following script:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1383 image-border" src="assets/48d6fbb2-a88d-4f5d-8cc3-63d6d7c0a4e5.png" style="width:37.25em;height:17.83em;"/></div>
<ol start="2">
<li>A bit of manipulation is performed on the <kbd>ratings</kbd> column to round up values of 0.5 increments to the next-highest whole number. This will assist when we are doing our multi-class classification within Keras to group <kbd>ratings</kbd> into six categories, instead of 11 categories.</li>
</ol>
<p> </p>
<ol start="3">
<li>To consume the movie genre types into the deep learning model within, we need to convert the string values of <kbd>genres</kbd> into a numeric label. The most frequent genres type will get a value of 0, and the values increase for the next most frequent- type. In the following screenshot, we can see that <span class="packt_screen">Good Will Hunting</span> has two <span class="packt_screen">genres</span> associated with it (<span class="packt_screen">Drama | Romance</span>), and that is the fourth most-frequent <span class="packt_screen">genreCount,</span> with a value of <span class="packt_screen">3.0</span>:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1384 image-border" src="assets/b2052136-259d-4c20-904f-0680d8578a04.png" style="width:153.00em;height:77.17em;"/></div>
<ol start="4">
<li>The <span class="packt_screen">genres</span> column is no longer needed for the deep model, as it will be replaced by the <span class="packt_screen">genreCount</span> column, as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1385 image-border" src="assets/1f9e53cc-18c8-41fe-a5a3-84038f749771.png" style="width:64.08em;height:33.00em;"/></div>
<ol start="5">
<li>Our main dataframe, <span class="packt_screen">mainDF</span>, is split into a <span class="packt_screen">trainDF</span> and <span class="packt_screen">testDF</span> for modeling, training, and evaluation purposes, using an 80/20 split. The row count for all three dataframes can be seen in the following screenshot:</li>
</ol>
<div class="mce-root CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1386 image-border" src="assets/b24c2d12-6e5e-48a8-8908-9bde8ebf6140.png" style="width:39.75em;height:9.17em;"/></div>
<ol start="6">
<li>Data is passed into a Keras deep learning model, using matrices instead of dataframes. Therefore, our training and testing dataframes are converted into numpy arrays and split out into <em>x</em> and <em>y</em>. The features selected for <kbd>xtrain_array</kbd> and <kbd>xtest_array</kbd> are <span class="packt_screen">userid</span>, <span class="packt_screen">movieid</span>, and <span class="packt_screen">genreCount</span>. These are the only features that will we will use to determine what a potential rating will be for a user. We are dropping <kbd>imdbid</kbd> and <kbd>tmdbid</kbd>, as they are directly tied to the <kbd>movieid</kbd> and therefore will not provide any additional value. <kbd>timestamp</kbd> will be removed to filter out any bias associated with frequency of voting. Finally, <kbd>ytest_array</kbd> and <kbd>ytrain_array</kbd> will contain the label value for rating. The <kbd>shape</kbd> of all four arrays can be seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1388 image-border" src="assets/9de44283-57bc-48f3-9746-89d0c2f7e6b6.png" style="width:46.92em;height:17.08em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>While<span> </span><kbd>ytrain_array</kbd><span> </span>and<span> </span><kbd>ytest_array</kbd><span> </span>are both labels in a matrix format, they are not ideally encoded for deep learning. Since this is technically a classification model that we are building we need to encode our labels in a manner for them to be understood by the model. This means that our ratings of 0 through 5 should be encoded as 0 or 1 values, based on their value elements. Therefore, if a rating received the highest value of 5, it should be encoded as [0,0,0,0,0,1]. The first position is reserved for 0, and the sixth position is reserved for 1, indicating a value of 5. We can make this conversion using<span> </span><kbd>keras.utils</kbd><span> </span>and convert our categorical variables to one-hot encoded variables. In doing this, the shape of our training label is converted from<span> </span><span class="packt_screen">(80146,1)</span><span> </span>to<span> </span><span class="packt_screen">(80146,6)</span><span> </span>as seen in the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1389 image-border" src="assets/021a737b-3d8e-4bad-a1ff-7e33f7ea4bfa.png" style="width:30.33em;height:20.33em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p>To learn more about <kbd>keras.utils</kbd> visit the following website: <a href="https://keras.io/utils/">https://keras.io/utils/</a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Applying the deep learning model with Keras</h1>
                </header>
            
            <article>
                
<p>At this point, we are ready to apply Keras to our data.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>We will be using the following from Keras:</p>
<ul>
<li><kbd>from keras.models import Sequential</kbd></li>
<li><kbd>from keras.layers import Dense, Activation</kbd></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p><span>This section walks through the following steps to apply a deep learning model, using Keras on our dataset:</span></p>
<ol>
<li>Import the following libraries to build a <kbd>Sequential</kbd> model from <kbd>keras</kbd>, using the following script:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px">from keras.models import Sequential<br/>from keras.layers import Dense, Activation</pre>
<ol start="2">
<li>Configure the <kbd>Sequential</kbd> model from <kbd>keras</kbd>, using the following script:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px">model = Sequential()<br/>model.add(Dense(32, activation='relu', input_dim=xtrain_array.shape[1]))<br/>model.add(Dense(10, activation='relu'))<br/>model.add(Dense(ytrain_OHE.shape[1], activation='softmax'))<br/>model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])</pre>
<ol start="3">
<li>We <kbd>fit</kbd> and train the model and store the results to a variable called <kbd>accuracy_history</kbd>, using the following script:</li>
</ol>
<pre style="padding-left: 60px">accuracy_history = model.fit(xtrain_array, ytrain_OHE, epochs=20, batch_size=32)</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p><span>This section explains the configuration of the Keras model that is applied to the dataset to predict a rating based on the features selected.</span></p>
<ol>
<li>In Keras, a <kbd>Sequential</kbd> model is simply a linear combination of layers, which are the following: <kbd>Dense</kbd> is used to define the layer types to a fully-connected layer within a deep neural network. Finally, <kbd>Activation</kbd> is used to convert the inputs from the features into an output that can be used as a prediction. There are many types of activation functions that can be used in a neural network; however, for this chapter, we will go with <kbd>relu</kbd> and <kbd>softmax</kbd>.</li>
</ol>
<p> </p>
<ol start="2">
<li>The <kbd>Sequential</kbd> model is configured to include three <kbd>Dense</kbd> layers:
<ol>
<li>The first layer has <kbd>input_dim</kbd> set to the number of features from <kbd>xtrain_array</kbd>. The <kbd>shape</kbd> feature pulls in the value of 3, using <kbd>xtrain_array.shape[1]</kbd>. Additionally, the first layer is set to have <kbd>32</kbd> neurons in the first layer of the neural network. Finally, the three input parameters are activated using the <kbd>relu</kbd> activation function. Only the first layer requires an explicit definition of the input dimensions. This is not required in subsequent layers, as they will be able to infer the number of dimensions from the previous layer.</li>
<li>The second layer in the <kbd>Sequential</kbd> model has <kbd>10</kbd> neurons in the neural network along with an activation function set to <kbd>relu</kbd>. Rectified linear units are used early on in the neural network process because they are effective during the training process. This is due to the simplicity of the equation as any value less than 0 is thrown out, which is not the case with other activation functions.</li>
<li>The third and final layer of the <kbd>Sequential</kbd> model requires six outputs based on every possible scenario of a rating from 0 to 5. This requires setting the output to the value of <kbd>ytrain_OHE.shape[1]</kbd>. The output is generated using a <kbd>softmax</kbd> function which is often the case at the end of a neural network, as it is very useful for classification purposes. At this point, we are looking to classify a value between 0 and 5.</li>
<li>Once the layers are specified, we must <kbd>compile</kbd> the model.</li>
<li>We optimize the model using <kbd>adam</kbd>, which stands for <strong>Adaptive Moment Estimation</strong>. Optimizers are great for configuring the learning rate of the gradient descent that the model uses to tweak and update the weights of the neural network. <kbd>adam</kbd> is a popular optimizer, as it is said to combine some of the best features from other common optimizers.</li>
<li>Our loss function is set to <kbd>categorical_crossentroy</kbd>, which is often used when looking to predict a multi-class classification. The loss function evaluates the performance of the model as it is being trained.</li>
</ol>
</li>
<li>We train the model using the training features, <kbd>xtrain_array</kbd>, and the training labels <kbd>ytrain_OHE</kbd>. The model is trained over 20 <span class="packt_screen">epochs,</span> each time with a <span class="packt_screen">batch_size</span> set to <span class="packt_screen">32</span>. The model output for <kbd>accuracy</kbd> and <kbd>loss</kbd> over each epoch are captured in a variable called <kbd>accuracy_history</kbd> and can be viewed as seen in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1390 image-border" src="assets/6c24e056-9301-4c7d-b800-9d5a954ed55e.png" style="width:37.75em;height:31.58em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>While we can print out the <span class="packt_screen">loss</span> and <span class="packt_screen">accuracy</span> scores over each epoch, it is always better to visualize both outputs over each of the 20 epochs. We can plot both by using the following script:</p>
<pre>plt.plot(accuracy_history.history['acc'])<br/>plt.title('Accuracy vs. Epoch')<br/>plt.xlabel('Epoch')<br/>plt.ylabel('Accuracy')<br/>plt.show()<br/><br/>plt.plot(accuracy_history.history['loss'])<br/>plt.title('Loss vs. Epoch')<br/>plt.xlabel('Epoch')<br/>plt.ylabel('Loss')<br/>plt.show()</pre>
<p>The output of the script can be seen in the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1391 image-border" src="assets/d20c1722-00a2-4606-86cc-f3e7b74e6436.png" style="width:30.00em;height:41.92em;"/></div>
<p>It appears that after the second epoch, both the loss and accuracy are stabilized in the model.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p>To learn more about getting started with the <kbd>Sequential</kbd> model from <kbd>keras</kbd>, visit the following website: <a href="https://keras.io/getting-started/sequential-model-guide/">https://keras.io/getting-started/sequential-model-guide/</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Evaluating the recommendation engine's accuracy</h1>
                </header>
            
            <article>
                
<p>We can now calculate the accuracy rate of our deep learning model built on Keras.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>Evaluating a <kbd>Sequential</kbd> model for accuracy requires using the <kbd>model.evaluate()</kbd> function within Keras.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>We can simply calculate the accuracy score, <kbd>accuracy_rate</kbd>, by executing the following script:</p>
<pre>score = model.evaluate(xtest_array, ytest_OHE, batch_size=128)<br/>accuracy_rate = score[1]*100<br/>print('accuracy is {}%'.format(round(accuracy_rate,2)))</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>Our model performance is based on evaluating our test features, <kbd>xtest_array</kbd>, with our test labels, <kbd>ytest_OHE</kbd>. We can use <kbd>model.evaluate()</kbd> and set the <kbd>batch_size</kbd> for evaluation at <kbd>128</kbd> elements. We can see that our accuracy is around 39%, as seen in the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1392 image-border" src="assets/c18890b0-ca4a-4eaa-89f2-db7bfef8e4d5.png" style="width:36.92em;height:5.83em;"/></div>
<p class="CDPAlignCenter CDPAlign CDPAlignLeft">This means that we are able to determine the rating by a user between 0 and 5 and at nearly a 39% accuracy rate.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p>To learn more about model performance with Keras metrics, visit the following website:</p>
<p><a href="https://keras.io/metrics/">https://keras.io/metrics/</a></p>


            </article>

            
        </section>
    </body></html>