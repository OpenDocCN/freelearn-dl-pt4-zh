["```py\n# Function to download the binary file\ndownload.cifar.data <- function(data_dir) {\ndir.create(data_dir, showWarnings = FALSE)\nsetwd(data_dir)\nif (!file.exists('cifar-10-binary.tar.gz')){\ndownload.file(url='http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz', destfile='cifar-10-binary.tar.gz', method='wget')\nuntar(\"cifar-10-binary.tar.gz\") # Unzip files\nfile.remove(\"cifar-10-binary.tar.gz\") # remove zip file\n}\nsetwd(\"..\")\n}\n# Download the data\ndownload.cifar.data(data_dir=\"Cifar_10/\")\n\n```", "```py\n# Function to read cifar data\nread.cifar.data <- function(filenames,num.images){\nimages.rgb <- list()\nimages.lab <- list()\nfor (f in 1:length(filenames)) {\nto.read <- file(paste(\"Cifar_10/\",filenames[f], sep=\"\"), \"rb\")\nfor(i in 1:num.images) {\nl <- readBin(to.read, integer(), size=1, n=1, endian=\"big\")\nr <- as.integer(readBin(to.read, raw(), size=1, n=1024, endian=\"big\"))\ng <- as.integer(readBin(to.read, raw(), size=1, n=1024, endian=\"big\"))\nb <- as.integer(readBin(to.read, raw(), size=1, n=1024, endian=\"big\"))\nindex <- num.images * (f-1) + i\nimages.rgb[[index]] = data.frame(r, g, b)\nimages.lab[[index]] = l+1\n}\nclose(to.read)\ncat(\"completed :\", filenames[f], \"\\n\")\nremove(l,r,g,b,f,i,index, to.read)\n}\nreturn(list(\"images.rgb\"=images.rgb,\"images.lab\"=images.lab))\n}\n# Train dataset\ncifar_train <- read.cifar.data(filenames = c(\"data_batch_1.bin\",\"data_batch_2.bin\",\"data_batch_3.bin\",\"data_batch_4.bin\", \"data_batch_5.bin\"))\nimages.rgb.train <- cifar_train$images.rgb\nimages.lab.train <- cifar_train$images.lab\nrm(cifar_train)\n# Test dataset\ncifar_test <- read.cifar.data(filenames = c(\"test_batch.bin\"))\nimages.rgb.test <- cifar_test$images.rgb\nimages.lab.test <- cifar_test$images.lab\nrm(cifar_test)\n\n```", "```py\n# Function to flatten the data\nflat_data <- function(x_listdata,y_listdata){\n# Flatten input x variables\nx_listdata <- lapply(x_listdata,function(x){unlist(x)})\nx_listdata <- do.call(rbind,x_listdata)\n# Flatten outcome y variables\ny_listdata <- lapply(y_listdata,function(x){a=c(rep(0,10)); a[x]=1; return(a)})\ny_listdata <- do.call(rbind,y_listdata)\n# Return flattened x and y variables\nreturn(list(\"images\"=x_listdata, \"labels\"=y_listdata))\n}\n# Generate flattened train and test datasets\ntrain_data <- flat_data(x_listdata = images.rgb.train, y_listdata = images.lab.train)\ntest_data <- flat_data(x_listdata = images.rgb.test, y_listdata = images.lab.test)\n\n```", "```py\nlabels <- read.table(\"Cifar_10/batches.meta.txt\")\n# function to run sanity check on photos & labels import\ndrawImage <- function(index, images.rgb, images.lab=NULL) {\nrequire(imager)\n# Testing the parsing: Convert each color layer into a matrix,\n# combine into an rgb object, and display as a plot\nimg <- images.rgb[[index]]\nimg.r.mat <- as.cimg(matrix(img$r, ncol=32, byrow = FALSE))\nimg.g.mat <- as.cimg(matrix(img$g, ncol=32, byrow = FALSE)\nimg.b.mat <- as.cimg(matrix(img$b, ncol=32, byrow = FALSE))\nimg.col.mat <- imappend(list(img.r.mat,img.g.mat,img.b.mat),\"c\") #Bind the three channels into one image\n# Extract the label\nif(!is.null(images.lab)){\nlab = labels[[1]][images.lab[[index]]]\n}\n# Plot and output label\nplot(img.col.mat,main=paste0(lab,\":32x32 size\",sep=\" \"),xaxt=\"n\")\naxis(side=1, xaxp=c(10, 50, 4), las=1)\nreturn(list(\"Image label\" =lab,\"Image description\" =img.col.mat))\n}\n# Draw a random image along with its label and description from train dataset\ndrawImage(sample(1:50000, size=1), images.rgb.train, images.lab.train)\n\n```", "```py\n# Function to normalize data\nRequire(caret) \nnormalizeObj<-preProcess(train_data$images, method=\"range\") \ntrain_data$images<-predict(normalizeObj, train_data$images) \ntest_data$images <- predict(normalizeObj, test_data$images) \n\n```", "```py\n# CIFAR images are 32 x 32 pixels.\nimg_width  = 32L\nimg_height = 32L\n\n# Tuple with height and width of images used to reshape arrays.\nimg_shape = c(img_width, img_height)\n# Number of classes, one class for each of 10 images\nnum_classes = 10L\n\n```", "```py\n# Number of color channels for the images: 3 channel for red, blue, green scales.\nnum_channels = 3L\n\n```", "```py\n# Images are stored in one-dimensional arrays of length.\nimg_size_flat = img_width * img_height * num_channels\n\n```", "```py\n# Convolutional Layer 1.\nfilter_size1 = 5L\nnum_filters1 = 64L\n\n```", "```py\n# Convolutional Layer 2.\nfilter_size2 = 5L\nnum_filters2 = 64L\n\n```", "```py\n# Fully-connected layer.\nfc_size = 1024L\n\n```", "```py\n# Weight Initialization\nweight_variable <- function(shape) {\ninitial <- tf$truncated_normal(shape, stddev=0.1)\ntf$Variable(initial)\n}\n\n```", "```py\nbias_variable <- function(shape) {\ninitial <- tf$constant(0.1, shape=shape)\ntf$Variable(initial)\n}\n\n```", "```py\n# Create a new convolution layer\ncreate_conv_layer <- function(input,\nnum_input_channels,\nfilter_size,\nnum_filters,\nuse_pooling=True)\n{\n# Shape of the filter-weights for the convolution.\nshape1 = shape(filter_size, filter_size, num_input_channels, num_filters)\n# Create new weights\nweights = weight_variable(shape=shape1)\n# Create new biases\nbiases = bias_variable(shape=shape(num_filters))\n# Create the TensorFlow operation for convolution.\nlayer = tf$nn$conv2d(input=input,\nfilter=weights,\nstrides=shape(1L, 1L, 1L ,1L),\npadding=\"SAME\")\n# Add the biases to the results of the convolution.\nlayer = layer + biases\n# Use pooling (binary flag) to reduce the image resolution\nif(use_pooling){\nlayer = tf$nn$max_pool(value=layer,\nksize=shape(1L, 2L, 2L, 1L),\nstrides=shape(1L, 2L, 2L, 1L),\npadding='SAME')\n}\n# Add non-linearity using Rectified Linear Unit (ReLU).\nlayer = tf$nn$relu(layer)\n# Retrun resulting layer and updated weights\nreturn(list(\"layer\" = layer, \"weights\" = weights))\n}\n\n```", "```py\ndrawImage_conv <- function(index, images.bw, images.lab=NULL,par_imgs=8) {\nrequire(imager)\nimg <- images.bw[index,,,]\nn_images <- dim(img)[3]\npar(mfrow=c(par_imgs,par_imgs), oma=c(0,0,0,0),\nmai=c(0.05,0.05,0.05,0.05),ann=FALSE,ask=FALSE)\nfor(i in 1:n_images){\nimg.bwmat <- as.cimg(img[,,i])\n# Extract the label\nif(!is.null(images.lab)){\nlab = labels[[1]][images.lab[[index]]]\n}\n# Plot and output label\nplot(img.bwmat,axes=FALSE,ann=FALSE)\n}\npar(mfrow=c(1,1))\n}\n\n```", "```py\ndrawImage_conv_weights <- function(weights_conv, par_imgs=8) {\nrequire(imager)\nn_images <- dim(weights_conv)[4]\npar(mfrow=c(par_imgs,par_imgs), oma=c(0,0,0,0),\nmai=c(0.05,0.05,0.05,0.05),ann=FALSE,ask=FALSE)\nfor(i in 1:n_images){\nimg.r.mat <- as.cimg(weights_conv[,,1,i])\nimg.g.mat <- as.cimg(weights_conv[,,2,i])\nimg.b.mat <- as.cimg(weights_conv[,,3,i])\nimg.col.mat <- imappend(list(img.r.mat,img.g.mat,img.b.mat),\"c\") \n#Bind the three channels into one image\n# Plot and output label\nplot(img.col.mat,axes=FALSE,ann=FALSE)\n}\npar(mfrow=c(1,1))\n}\n\n```", "```py\nflatten_conv_layer <- function(layer){\n# Extract the shape of the input layer\nlayer_shape = layer$get_shape()\n# Calculate the number of features as img_height * img_width * num_channels\nnum_features = prod(c(layer_shape$as_list()[[2]],layer_shape$as_list()[[3]],layer_shape$as_list()[[4]]))\n# Reshape the layer to [num_images, num_features].\nlayer_flat = tf$reshape(layer, shape(-1, num_features))\n# Return both the flattened layer and the number of features.\nreturn(list(\"layer_flat\"=layer_flat, \"num_features\"=num_features))\n}\n\n```", "```py\n# Create a new fully connected layer\ncreate_fc_layer <- function(input,\nnum_inputs,\nnum_outputs,\nuse_relu=True)\n{\n# Create new weights and biases.\nweights = weight_variable(shape=shape(num_inputs, num_outputs))\nbiases = bias_variable(shape=shape(num_outputs))\n# Perform matrix multiplication of input layer with weights and then add biases\nlayer = tf$matmul(input, weights) + biases\n# Use ReLU?\nif(use_relu){\nlayer = tf$nn$relu(layer)\n}\nreturn(layer)\n}\n\n```", "```py\nx = tf$placeholder(tf$float32, shape=shape(NULL, img_size_flat), name='x')\n\n```", "```py\nx_image = tf$reshape(x, shape(-1L, img_size, img_size, num_channels))\n\n```", "```py\ny_true = tf$placeholder(tf$float32, shape=shape(NULL, num_classes), name='y_true')\n\n```", "```py\ny_true_cls = tf$argmax(y_true, dimension=1L)\n\n```", "```py\n# Convolutional Layer 1\nconv1 <- create_conv_layer(input=x_image,\nnum_input_channels=num_channels,\nfilter_size=filter_size1,\nnum_filters=num_filters1,\nuse_pooling=TRUE)\n\n```", "```py\nlayer_conv1 <- conv1$layer\nconv1_images <- conv1$layer$eval(feed_dict = dict(x = train_data$images, y_true = train_data$labels))\n\n```", "```py\nweights_conv1 <- conv1$weights\nweights_conv1 <- weights_conv1$eval(session=sess)\n\n```", "```py\ndrawImage_conv(sample(1:50000, size=1), images.bw = conv1_images, images.lab=images.lab.train)\n\n```", "```py\ndrawImage_conv_weights(weights_conv1)\n\n```", "```py\n# Convolutional Layer 2\nconv2 <- create_conv_layer(input=layer_conv1,\nnum_input_channels=num_filters1,\nfilter_size=filter_size2,\nnum_filters=num_filters2,\nuse_pooling=TRUE)\n\n```", "```py\nlayer_conv2 <- conv2$layer\nconv2_images <- conv2$layer$eval(feed_dict = dict(x = train_data$images, y_true = train_data$labels))\n\n```", "```py\nweights_conv2 <- conv2$weights\nweights_conv2 <- weights_conv2$eval(session=sess)\n\n```", "```py\ndrawImage_conv(sample(1:50000, size=1), images.bw = conv2_images, images.lab=images.lab.train)\n\n```", "```py\ndrawImage_conv_weights(weights_conv2)\n\n```", "```py\nflatten_lay <- flatten_conv_layer(layer_conv2)\n\n```", "```py\nlayer_flat <- flatten_lay$layer_flat\n\n```", "```py\nnum_features <- flatten_lay$num_features\n\n```", "```py\nlayer_fc1 = create_fc_layer(input=layer_flat,\nnum_inputs=num_features,\nnum_outputs=fc_size,\nuse_relu=TRUE)\n\n```", "```py\nkeep_prob <- tf$placeholder(tf$float32)\n\n```", "```py\nlayer_fc1_drop <- tf$nn$dropout(layer_fc1, keep_prob)\n\n```", "```py\nlayer_fc2 = create_fc_layer(input=layer_fc1_drop,\nnum_inputs=fc_size,\nnum_outputs=num_classes,\nuse_relu=FALSE)\n\n```", "```py\nlayer_fc2_drop <- tf$nn$dropout(layer_fc2, keep_prob)\n\n```", "```py\ny_pred = tf$nn$softmax(layer_fc2_drop)\n\n```", "```py\ny_pred_cls = tf$argmax(y_pred, dimension=1L)\n\n```", "```py\ncross_entropy = tf$nn$softmax_cross_entropy_with_logits(logits=layer_fc2_drop, labels=y_true)\n\n```", "```py\ncost = tf$reduce_mean(cross_entropy)\n\n```", "```py\noptimizer = tf$train$AdamOptimizer(learning_rate=1e-4)$minimize(cost)\n\n```", "```py\ncorrect_prediction = tf$equal(y_pred_cls, y_true_cls)\naccuracy = tf$reduce_mean(tf$cast(correct_prediction, tf$float32))\n\n```", "```py\nlibrary(tensorflow)\nnp <- import(\"numpy\")\n\n```", "```py\ntf$reset_default_graph()\n\n```", "```py\nsess <- tf$InteractiveSession()\n\n```", "```py\nsess$run(tf$global_variables_initializer())\n\n```", "```py\n# Train the model\ntrain_batch_size = 128L\nfor (i in 1:100) {\nspls <- sample(1:dim(train_data$images)[1],train_batch_size)\nif (i %% 10 == 0) {\ntrain_accuracy <- accuracy$eval(feed_dict = dict(\nx = train_data$images[spls,], y_true = train_data$labels[spls,], keep_prob = 1.0))\ncat(sprintf(\"step %d, training accuracy %g\\n\", i, train_accuracy))\n}\noptimizer$run(feed_dict = dict(\nx = train_data$images[spls,], y_true = train_data$labels[spls,], keep_prob = 0.5))\n}\n\n```", "```py\n# Test the model\ntest_accuracy <- accuracy$eval(feed_dict = dict(\nx = test_data$images, y_true = test_data$labels, keep_prob = 1.0))\ncat(sprintf(\"test accuracy %g\", test_accuracy))\n\n```", "```py\ntest_true_class <- c(unlist(images.lab.test))\n\n```", "```py\ntest_pred_class <- y_pred_cls$eval(feed_dict = dict(\nx = test_data$images, y_true = test_data$labels, keep_prob = 1.0))\ntest_pred_class <- test_pred_class + 1\n\n```", "```py\ntable(actual = test_true_class, predicted = test_pred_class)\n\n```", "```py\nconfusion <- as.data.frame(table(actual = test_true_class, predicted = test_pred_class))\nplot <- ggplot(confusion)\nplot + geom_tile(aes(x=actual, y=predicted, fill=Freq)) + scale_x_discrete(name=\"Actual Class\") + scale_y_discrete(name=\"Predicted Class\") + scale_fill_gradient(breaks=seq(from=-.5, to=4, by=.2)) + labs(fill=\"Normalized\\nFrequency\")\n\n```", "```py\ncheck.image <- function(images.rgb,index,true_lab, pred_lab) {\nrequire(imager)\n# Testing the parsing: Convert each color layer into a matrix,\n# combine into an rgb object, and display as a plot\nimg <- images.rgb[[index]]\nimg.r.mat <- as.cimg(matrix(img$r, ncol=32, byrow = FALSE))\nimg.g.mat <- as.cimg(matrix(img$g, ncol=32, byrow = FALSE))\nimg.b.mat <- as.cimg(matrix(img$b, ncol=32, byrow = FALSE))\nimg.col.mat <- imappend(list(img.r.mat,img.g.mat,img.b.mat),\"c\")\n# Plot with actual and predicted label\nplot(img.col.mat,main=paste0(\"True: \", true_lab,\":: Pred: \",\npred_lab),xaxt=\"n\")\naxis(side=1, xaxp=c(10, 50, 4), las=1)\n}\n\n```", "```py\nlabels <- c(\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\")\n# Plot misclassified test images\nplot.misclass.images <- function(images.rgb, y_actual, y_predicted,labels){\n# Get indices of misclassified\nindices <- which(!(y_actual == y_predicted))\nid <- sample(indices,1)\n# plot the image with true and predicted class\ntrue_lab <- labels[y_actual[id]]\npred_lab <- labels[y_predicted[id]]\ncheck.image(images.rgb,index=id, true_lab=true_lab,pred_lab=pred_lab)\n}\nplot.misclass.images(images.rgb=images.rgb.test,y_actual=test_true_class,y_predicted=test_pred_class,labels=labels)\n\n```"]