<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer755">
<h1 class="chapter-number" id="_idParaDest-198"><a id="_idTextAnchor203"/>18</h1>
<h1 id="_idParaDest-199"><a id="_idTextAnchor204"/>Unlocking the Potential of Graph Neural Networks for Real-World Applications</h1>
<p>Thank you for taking the time to read <em class="italic">Hands-On Graph Neural Networks Using Python</em>. We hope that it has provided you with valuable insights into the world of graph neural networks and <span class="No-Break">their applications.</span></p>
<p>As we conclude this book, we would like to leave you with some final pieces of advice on how to effectively use GNNs. GNNs <a id="_idIndexMarker946"/>can be incredibly performant in the right conditions, but<a id="_idIndexMarker947"/> they suffer from the same pros and cons as other deep learning techniques. Knowing when and where to apply these models is a crucial skill to master, as over-engineered solutions can result in <span class="No-Break">poor performance.</span></p>
<p>First, GNNs are especially effective when a large amount of data is available for training. This is because deep learning algorithms require a lot of data to learn complex patterns and relationships effectively. With a large enough dataset, GNNs can achieve high levels of accuracy <span class="No-Break">and generalization.</span></p>
<p>For similar reasons, GNNs are most valuable when dealing with complex, high-dimensional data (node and edge features). They can automatically learn intricate patterns and relationships between features that would be difficult or impossible for humans to identify. Traditional machine learning algorithms, such as linear regression or decision trees, rely on handcrafted features that are often limited in their ability to capture the complexity of <span class="No-Break">real-world data.</span></p>
<p>Finally, when working with GNNs, it is important to ensure that the graph representation adds value to the features. This is particularly applicable when the graph is an artificially constructed representation rather than a natural one, such as social networks or protein structures. The connections between nodes should not be arbitrary but represent meaningful relationships between <span class="No-Break">the nodes.</span></p>
<p>You might notice that some examples in this book did not follow the previous rules. This is mostly due to the technical limitation of being able to run the code in Google Colab, and a general lack of high-quality datasets. However, this is also reflective of real-life datasets, which can be messy and difficult to obtain in large quantities. Most of this data also tends to be tabular, where excellent tree-based models such as XGBoost are difficult <span class="No-Break">to beat.</span></p>
<p>More generally, sound baseline solutions are crucial, as they can be challenging to outperform, even in the right conditions. A powerful strategy when working with GNNs is to implement multiple <a id="_idIndexMarker948"/>types of GNNs and compare their performance. For example, a convolutional-based GNN such as GCN (<a href="B19153_06.xhtml#_idTextAnchor074"><span class="No-Break"><em class="italic">Chapter 6</em></span></a>) might work well for certain types of graphs, while an attention-based GNN such as GAT (<a href="B19153_07.xhtml#_idTextAnchor082"><span class="No-Break"><em class="italic">Chapter 7</em></span></a>) might be better suited for others. Additionally, a message-passing GNN such as MPNN (<a href="B19153_12.xhtml#_idTextAnchor144"><span class="No-Break"><em class="italic">Chapter 12</em></span></a>) might excel in certain contexts. Note how each approach is more expressive than the previous one, and each has different strengths <span class="No-Break">and weaknesses.</span></p>
<p>If you’re working on a more specific problem, there are several GNN approaches covered in this book that may be more appropriate. For example, if you’re dealing with small graph data that lacks node and edge features, you may want to consider using Node2Vec (<a href="B19153_04.xhtml#_idTextAnchor054"><span class="No-Break"><em class="italic">Chapter 4</em></span></a>). On the contrary, if you’re dealing with large graphs, GraphSAGE and LightGCN can help manage the computational time and memory storage requirements (<em class="italic">Chapters 8</em> <span class="No-Break">and </span><span class="No-Break"><em class="italic">17</em></span><span class="No-Break">).</span></p>
<p>Additionally, GIN and global pooling layers may be suitable for graph classification tasks (<a href="B19153_09.xhtml#_idTextAnchor106"><span class="No-Break"><em class="italic">Chapter 9</em></span></a>), while Variational Graph Autoencoders and SEAL can be used for link prediction (<a href="B19153_10.xhtml#_idTextAnchor116"><span class="No-Break"><em class="italic">Chapter 10</em></span></a>). For generating new graphs, you can explore GraphRNN and MolGAN (<a href="B19153_11.xhtml#_idTextAnchor131"><span class="No-Break"><em class="italic">Chapter 11</em></span></a>). If you’re working with heterogeneous graphs, you may want to consider one of the many flavors of heterogeneous GNNs (<em class="italic">Chapters 12</em> and <em class="italic">16</em>). For spatio-temporal graphs, Graph WaveNet, STGraph, and other temporal GNNs can be useful (<em class="italic">Chapters 13</em> and <em class="italic">15</em>). Finally, if you need to explain the predictions made by your GNN, you can turn to the graph explainability techniques covered in <a href="B19153_14.xhtml#_idTextAnchor165"><span class="No-Break"><em class="italic">Chapter 14</em></span></a><span class="No-Break">.</span></p>
<p>By reading this book, you will have gained a deep understanding of GNNs and how they can be applied to solve real-world problems. As you continue to work in this field, we encourage you to put this knowledge into practice, experiment with new approaches, and continue to grow your expertise. The field of machine learning is constantly evolving, and your skills will only become more valuable as time goes on. We hope that you will apply what you have learned to tackle challenges and have a positive impact on the world. Thank you again for reading this book, and we wish you all the best in your <span class="No-Break">future endeavors.</span></p>
</div>
<div>
<div class="IMG---Figure" id="_idContainer756">
</div>
</div>
</div></body></html>