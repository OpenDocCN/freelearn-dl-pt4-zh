<html><head></head><body><div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Generative Models</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">Generative models are the family of machine learning models that are used to describe how data is generated. To train a generative model we first accumulate a vast amount of data in any domain and later train a model to create or generate data like it.</p>
<p class="calibre4">In other words, these are the models that can learn to create data that is similar to data that we give them. One such approach is using <strong class="calibre7">Generative Adversarial Networks (GANs)</strong>, which will be discussed as part of this chapter in detail.</p>
<p class="calibre4">The following topics will be covered in this chapter:</p>
<ul class="calibre20">
<li class="calibre21">Introduction to generative models</li>
<li class="calibre21">GANs</li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Generative models</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">There are two kinds of machine learning models: generative models and discriminative models. Let's examine the following list of classifiers: decision trees, neural networks, random forests, generalized boosted models, logistic regression, naive bayes, and <strong class="calibre7">Support Vector Machine</strong> (<strong class="calibre7">SVM</strong>). Most of these are classifiers and ensemble models. The odd one out here is Naive Bayes. It's the only generative model in the list. The others are examples of discriminative models.</p>
<p class="calibre4">The fundamental difference between generative and discriminative models lies in the underlying probability inference structure. In this chapter, we will study the key concepts of generative models like types and GANs, but before that, let's go through some of the key differences between generative and discriminative models.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Discriminative versus generative models</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">Discriminative models learn <em class="calibre17">P(Y|X),</em> which is the conditional relationship between the target variable <em class="calibre17">Y</em> and features <em class="calibre17">X</em>. This is how least squares regression works, and it is the kind of inference pattern that gets used. It is an approach to sort out the relationship among variables.</p>
<p class="calibre4">Generative models aim for a complete probabilistic description of the dataset. With generative models, the goal is to develop the joint probability distribution <em class="calibre17">P(X, Y)</em>, either directly or by computing <em class="calibre17">P(Y | X)</em> and <em class="calibre17">P(X)</em> and then inferring the conditional probabilities required to classify newer data. This method requires more solid probabilistic thought than regression demands, but it provides a complete model of the probabilistic structure of the data. Knowing the joint distribution enables you to generate the data; hence, Naive Bayes is a generative model.</p>
<p class="calibre4">Suppose we have a supervised learning task, where <em class="calibre17">x<sub class="calibre36">i</sub></em> is the given features of the data points and <em class="calibre17">y<sub class="calibre36">i</sub></em> is the corresponding labels. One way to predict <em class="calibre17">y</em> on future <em class="calibre17">x</em> is to learn a function <em class="calibre17">f()</em> from <em class="calibre17">(x<sub class="calibre36">i</sub>,y<sub class="calibre36">i</sub>)</em> that takes in <em class="calibre17">x</em> and outputs the most likely <em class="calibre17">y</em>. Such models fall in the category of discriminative models, as you are learning how to discriminate between <em class="calibre17">x</em>'s from different classes. Methods like SVMs and neural networks fall into this category. Even if you're able to classify the data very accurately, you have no notion of how the data might have been generated.</p>
<p class="calibre4">The second approach is to model how the data might have been generated and learn a function <em class="calibre17">f(x,y)</em> that gives a score to the configuration determined by <em class="calibre17">x</em> and <em class="calibre17">y</em> together. Then you can predict <em class="calibre17">y</em> for a new <em class="calibre17">x</em> by finding the <em class="calibre17">y</em> for which the score <em class="calibre17">f(x,y)</em> is maximum. A canonical example of this is Gaussian mixture models.</p>
<p class="calibre4">Another example of this is: you can imagine <em class="calibre17">x</em> to be an image and <em class="calibre17">y</em> to be a kind of object like a dog, namely in the image. The probability written as <em class="calibre17">p(y|x)</em> tells us how much the model believes that there is a dog, given an input image compared to all possibilities it knows about. Algorithms that try to model this probability map directly are called <strong class="calibre7">discriminative models</strong>.</p>
<p class="calibre4">Generative models, on the other hand, try to learn a function called the joint probability <em class="calibre17">p(y, x)</em>. We can read this as how much the model believes that <em class="calibre17">x</em> is an image and there is a dog <em class="calibre17">y</em> in it at the same time. These two probabilities are related and that could be written as <em class="calibre17">p(y, x) = p(x) p(y|x)</em>, with <em class="calibre17">p(x)</em> being how likely it is that the input <em class="calibre17">x</em> is an image. The <em class="calibre17">p(x)</em> probability is usually called a <strong class="calibre7">density function</strong> in literature.</p>
<p class="calibre4">The main reason to call these models generative ultimately connects to the fact that the model has access to the probability of both input and output at the same time. Using this, we can generate images of animals by sampling animal kinds <em class="calibre17">y</em> and new images <em class="calibre17">x</em> from <em class="calibre17">p(y, x)</em>.</p>
<p class="calibre4">We can mainly learn the density function <em class="calibre17">p(x)</em> which only depends on the input space.</p>
<p class="calibre4">Both models are useful; however, comparatively, generative models have an interesting advantage over discriminative models, namely, they have the potential to understand and explain the underlying structure of the input data even when there are no labels available. This is very desirable when working in the real world.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Types of generative models</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">Discriminative models have been at the forefront of the recent success in the field of machine learning. Models make predictions that depend on a given input, although they are not able to generate new samples or data.</p>
<p class="calibre4">The idea behind the recent progress of generative modeling is to convert the generation problem to a prediction one and use deep learning algorithms to learn such a problem.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Autoencoders</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">One way to convert a generative to a discriminative problem can be by learning the mapping from the input space itself. For example, we want to learn an identity map that, for each image <em class="calibre17">x</em>, would ideally predict the same image, namely, <em class="calibre17">x = f(x)</em>, where <em class="calibre17">f</em> is the predictive model.</p>
<p class="calibre4">This model may not be of use in its current form, but from this, we can create a generative model.</p>
<p class="calibre4">Here, we create a model formed of two main components: an encoder model <em class="calibre17">q(h|x)</em> that maps the input to another space, which is referred to as hidden or the latent space represented by <em class="calibre17">h</em>, and a decoder model <em class="calibre17">q(x|h)</em> that learns the opposite mapping from the hidden input space.</p>
<p class="calibre4">These components--encoder and decoder--are connected together to create an end-to-end trainable model. Both the encoder and decoder models are neural networks of different architectures, for example, RNNs and Attention Nets, to get desired outcomes.</p>
<p class="calibre4">As the model is learned, we can remove the decoder from the encoder and then use them separately. To generate a new data sample, we can first generate a sample from the latent space and then feed that to the decoder to create a new sample from the output space.</p>
<p class="calibre4">Autoencoders are covered in more detail in <a href="130cc1c9-51d3-4ba5-95d3-12bb53dee5bd.xhtml" target="_blank" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2">Chapter 8</a>, <span class="calibre14"><em class="calibre17">Autoencoders</em></span> .</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">GAN</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">As seen with autoencoders, we can think of a general concept to create networks that will work together in a relationship, and training them will help us learn the latent spaces that allow us to generate new data samples.</p>
<p class="calibre4">Another type of generative network is GAN, where we have a generator model <em class="calibre17">q(x|h)</em> to map the small dimensional latent space of <em class="calibre17">h</em> (which is usually represented as noise samples from a simple distribution) to the input space of <em class="calibre17">x</em>. This is quite similar to the role of decoders in autoencoders.</p>
<p class="calibre4">The deal is now to introduce a discriminative model <em class="calibre17">p(y| x),</em> which tries to associate an input instance <em class="calibre17">x</em> to a yes/no binary answer <em class="calibre17">y</em>, about whether the generator model generated the input or was a genuine sample from the dataset we were training on.</p>
<p class="calibre4">Let's use the image example done previously. Assume that the generator model creates a new image, and we also have the real image from our actual dataset. If the generator model was right, the discriminator model would not be able to distinguish between the two images easily. If the generator model was poor, it would be very simple to tell which one was a fake or fraud and which one was real.</p>
<p class="calibre4">When both these models are coupled, we can train them end to end by assuring that the generator model is getting better over time to fool the discriminator model, while the discriminator model is trained to work on the harder problem of detecting frauds. Finally, we desire a generator model with outputs that are indistinguishable from the real data that we used for the training.</p>
<p class="calibre4">Through the initial parts of the training, the discriminator model can easily detect the samples coming from the actual dataset versus the ones generated synthetically by the generator model, which is just beginning to learn. As the generator gets better at modeling the dataset, we begin to see more and more generated samples that look similar to the dataset. The following example depicts the generated images of a GAN model learning over time:</p>
<div class="mce-root"><img src="Images/ba581ac8-3fa3-42cc-ac63-18e7597d0d06.png" width="725" height="725" class="calibre153"/></div>
<p class="calibre4">In the upcoming sections, we will discuss GANs in detail.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Sequence models</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">If the data is temporal in nature, then we can use specialized algorithms called <strong class="calibre7">Sequence Models</strong>. These models can learn the probability of the form <em class="calibre17">p(y|x_n, x_1)</em>, where <em class="calibre17">i</em> is an index signifying the location in the sequence and <em class="calibre17">x_i</em> is the <em class="calibre17">i<sup class="calibre120">th</sup></em> input sample.</p>
<p class="calibre4">As an example, we can consider each word as a series of characters, each sentence as a series of words, and each paragraph as a series of sentences. Output <em class="calibre17">y</em> could be the sentiment of the sentence.</p>
<p class="calibre4">Using a similar trick from autoencoders, we can replace <em class="calibre17">y</em> with the next item in the series or sequence, namely <em class="calibre17">y =x_n + 1</em>, allowing the model to learn.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">GANs</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">GANs were introduced by a group of researchers at the University of Montreal led by <em class="calibre17">Ian Goodfellow</em>. The core idea behind a GAN model is to have two competing neural network models. One network takes the noise as input and generates samples (hence known as <strong class="calibre7">generator</strong>). The second model (known as <strong class="calibre7">discriminator</strong>) gets samples from both the generator and the actual training data, and should be able to differentiate between the two sources. Generative and discriminative networks are playing a continuous game, where the generator model is learning to generate more realistic samples or examples, and the discriminator is learning to get better and better at differentiating generated data from the real data. The two networks are trained simultaneously, and the goal is that the competition will make the generated samples indistinguishable from the real data:</p>
<div class="mce-root"><img src="Images/746e5e26-9573-47b6-8569-d28866ce5966.png" width="960" height="540" class="calibre154"/></div>
<p class="calibre4">The analogy used to describe GANs is that the generator is like a forger that is attempting to produce some forged material, and the discriminator model is the police trying to detect the forged items. This may seem somewhat similar to reinforcement learning where the generator is getting a reward from the discriminator, allowing it to know whether the generated data is accurate or not. The key distinction with GANs is that we can backpropagate gradient information from the discriminator network back to the generator network, such that the generator knows how to adapt its parameters in order to generate output data that can fool the discriminator.</p>
<p class="calibre4">As of today, GANs have been mainly applied to model natural images. They provide best results in image generation tasks and also in generating images that are sharper than the ones trained using other generative methods based on maximum likelihood training objectives.</p>
<p class="calibre4">Here are some examples of images generated by GANs:</p>
<div class="mce-root"><img src="Images/2a4a2461-6921-4252-ad7b-9bbc56cf8ce4.png" width="825" height="416" class="calibre155"/></div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">GAN with an example</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">For a deeper understanding of how GANs work, we'll use a GAN to solve a simple problem in TensorFlow, namely, learning to approximate a one-dimensional Gaussian distribution.</p>
<p class="calibre4">First, we will create the actual data distribution, a simple Gaussian with a mean of four and standard deviation of 0.5. It has a sample function that returns a given number of samples (sorted by value) from the distribution. The data distribution that we learn will look like the following diagram:</p>
<div class="mce-root"><img src="Images/066437dd-ffad-443b-8b62-c1429b9d428b.png" width="714" height="516" class="calibre156"/></div>
<p class="calibre4">Generator input noise distribution is also defined with a similar sample function used for actual data.</p>
<p class="calibre4">Both generator and discriminator networks are very simple. Generator is a linear transformation passed through a non linearity (<kbd class="calibre18">softplus</kbd> function), followed by another linear transformation.</p>
<p class="calibre4">We kept the discriminator stronger than the generator; otherwise, it would not have enough capacity to learn to be able to differentiate accurately between generated and real samples. Hence, we made it a deeper neural network with a higher number of dimensions. We use <em class="calibre17">tanh</em> non linearities in all layers except the final one, which is a sigmoid (the output of which can be described as a probability).</p>
<p class="calibre4">We connect these networks as part of the TensorFlow graph and define loss functions for each of the networks so that the generator network will be simply fooling the discriminator network. The Gradient Descent Optimizer from TensorFlow with exponential learning rate decay is used as an optimizer.</p>
<p class="calibre4">To train the model, we draw samples from the data distribution and the noise distribution, and alternate between optimizing the parameters of the discriminator and the generator.</p>
<p class="calibre4">We will see that, at the start of the training method, the generator was generating a very different distribution to the real data. The network slowly learns to approximate it quite closely before converging to a narrower distribution focused on the mean of the input distribution. After training the networks, the two distributions look something like this:</p>
<div class="mce-root"><img src="Images/fdf1eb31-e0b5-4821-ab33-1801f9c0fd20.png" width="720" height="525" class="calibre157"/></div>
<p class="calibre4">The problem of the generator network falling to a param setting where it generates a very narrow distribution or pattern of points is one of the major failures of GANs. The solution will be to allow the discriminator to look at multiple samples at once, a technique that we call minibatch discrimination. Minibatch discrimination is a method wherein the discriminator can glance at an entire batch of samples to determine whether they come from the generator network or from the actual data.</p>
<p class="calibre4">A summary of the method is as follows:</p>
<ul class="calibre20">
<li class="calibre21">Take the output of any intermediate layer of the discriminator network</li>
<li class="calibre21">Multiply this output by a 3D tensor to generate a matrix of size <em class="calibre29">numOfKernels *</em> <em class="calibre29">kernelDim</em></li>
<li class="calibre21">Calculate the L1-distance between rows in this matrix across all samples in a batch, and then apply a negative exponential</li>
<li class="calibre21">Minibatch features or properties for a sample are then the sum of these exponentiated distances</li>
<li class="calibre21">Concatenate the actual input to the mini batch layer, that is, output of the previous or former discriminator layer with the created minibatch features, and then pass this as input to the next layer of the discriminator network</li>
</ul>
<p class="calibre4">Minibatch discrimination makes the batch size as important as a hyperparameter:</p>
<pre class="calibre26"><span class="calibre5">import </span>argparse<br class="calibre2"/><span class="calibre5">import </span>numpy <span class="calibre5">as </span>np<br class="calibre2"/><span class="calibre5">import </span>tensorflow <span class="calibre5">as </span>tf<br class="calibre2"/><span class="calibre5">import </span>matplotlib.pyplot <span class="calibre5">as </span>plt<br class="calibre2"/><span class="calibre5">from </span>matplotlib <span class="calibre5">import </span>animation<br class="calibre2"/><span class="calibre5">import </span>seaborn <span class="calibre5">as </span>sns<br class="calibre2"/><span class="calibre5">from </span>tensorflow.python.training.gradient_descent <span class="calibre5">import </span>GradientDescentOptimizer<br class="calibre2"/><br class="calibre2"/>sns.set(<span class="calibre5">color_codes</span>=<span class="calibre5">True</span>)<br class="calibre2"/><br class="calibre2"/>seed = <span class="calibre5">42<br class="calibre2"/></span>np.random.seed(seed)<br class="calibre2"/>tf.set_random_seed(seed)<br class="calibre2"/><br class="calibre2"/><br class="calibre2"/><span class="calibre5"># gaussian data distribution<br class="calibre2"/></span><span class="calibre5">class </span>DataDist(<span class="calibre5">object</span>):<br class="calibre2"/>    <span class="calibre5">def </span><span class="calibre5">__init__</span>(<span class="calibre5">self</span>):<br class="calibre2"/>        <span class="calibre5">self</span>.mue = <span class="calibre5">4<br class="calibre2"/></span><span class="calibre5">        </span><span class="calibre5">self</span>.sigma = <span class="calibre5">0.5<br class="calibre2"/></span><span class="calibre5"><br class="calibre2"/></span><span class="calibre5">    </span><span class="calibre5">def </span>sample(<span class="calibre5">self</span>, N):<br class="calibre2"/>        samples = np.random.normal(<span class="calibre5">self</span>.mue, <span class="calibre5">self</span>.sigma, N)<br class="calibre2"/>        samples.sort()<br class="calibre2"/>        <span class="calibre5">return </span>samples<br class="calibre2"/><br class="calibre2"/><br class="calibre2"/><span class="calibre5"># data distribution with noise<br class="calibre2"/></span><span class="calibre5">class </span>GeneratorDist(<span class="calibre5">object</span>):<br class="calibre2"/>    <span class="calibre5">def </span><span class="calibre5">__init__</span>(<span class="calibre5">self</span>, rnge):<br class="calibre2"/>        <span class="calibre5">self</span>.rnge = rnge<br class="calibre2"/><br class="calibre2"/>    <span class="calibre5">def </span>sample(<span class="calibre5">self</span>, N):<br class="calibre2"/>        <span class="calibre5">return </span>np.linspace(-<span class="calibre5">self</span>.rnge, <span class="calibre5">self</span>.rnge, N) + \<br class="calibre2"/>               np.random.random(N) * <span class="calibre5">0.01<br class="calibre2"/></span><span class="calibre5"><br class="calibre2"/></span><span class="calibre5"><br class="calibre2"/></span><span class="calibre5"># linear method<br class="calibre2"/></span><span class="calibre5">def </span>linearUnit(input, output_dim, scope=<span class="calibre5">None</span>, stddev=<span class="calibre5">1.0</span>):<br class="calibre2"/>    <span class="calibre5">with </span>tf.variable_scope(scope <span class="calibre5">or </span><span class="calibre5">'linearUnit'</span>):<br class="calibre2"/>        weight = tf.get_variable(<br class="calibre2"/>            <span class="calibre5">'weight'</span>,<br class="calibre2"/>            [input.get_shape()[<span class="calibre5">1</span>], output_dim],<br class="calibre2"/>            <span class="calibre5">initializer</span>=tf.random_normal_initializer(<span class="calibre5">stddev</span>=stddev)<br class="calibre2"/>        )<br class="calibre2"/>        bias = tf.get_variable(<br class="calibre2"/>            <span class="calibre5">'bias'</span>,<br class="calibre2"/>            [output_dim],<br class="calibre2"/>            <span class="calibre5">initializer</span>=tf.constant_initializer(<span class="calibre5">0.0</span>)<br class="calibre2"/>        )<br class="calibre2"/>        <span class="calibre5">return </span>tf.matmul(input, weight) + bias<br class="calibre2"/><br class="calibre2"/><br class="calibre2"/><span class="calibre5"># generator network<br class="calibre2"/></span><span class="calibre5">def </span>generatorNetwork(input, hidden_size):<br class="calibre2"/>    hidd0 = tf.nn.softplus(linearUnit(input, hidden_size, <span class="calibre5">'g0'</span>))<br class="calibre2"/>    hidd1 = linearUnit(hidd0, <span class="calibre5">1</span>, <span class="calibre5">'g1'</span>)<br class="calibre2"/>    <span class="calibre5">return </span>hidd1<br class="calibre2"/><br class="calibre2"/><br class="calibre2"/><span class="calibre5"># discriminator network<br class="calibre2"/></span><span class="calibre5">def </span>discriminatorNetwork(input, h_dim, minibatch_layer=<span class="calibre5">True</span>):<br class="calibre2"/>    hidd0 = tf.nn.relu(linearUnit(input, h_dim * <span class="calibre5">2</span>, <span class="calibre5">'d0'</span>))<br class="calibre2"/>    hidd1 = tf.nn.relu(linearUnit(hidd0, h_dim * <span class="calibre5">2</span>, <span class="calibre5">'d1'</span>))<br class="calibre2"/><br class="calibre2"/>    <span class="calibre5">if </span>minibatch_layer:<br class="calibre2"/>        hidd2 = miniBatch(hidd1)<br class="calibre2"/>    <span class="calibre5">else</span>:<br class="calibre2"/>        hidd2 = tf.nn.relu(linearUnit(hidd1, h_dim * <span class="calibre5">2</span>, <span class="calibre5">scope</span>=<span class="calibre5">'d2'</span>))<br class="calibre2"/><br class="calibre2"/>    hidd3 = tf.sigmoid(linearUnit(hidd2, <span class="calibre5">1</span>, <span class="calibre5">scope</span>=<span class="calibre5">'d3'</span>))<br class="calibre2"/>    <span class="calibre5">return </span>hidd3<br class="calibre2"/><br class="calibre2"/><br class="calibre2"/><span class="calibre5"># minibatch<br class="calibre2"/></span><span class="calibre5">def </span>miniBatch(input, numKernels=<span class="calibre5">5</span>, kernelDim=<span class="calibre5">3</span>):<br class="calibre2"/>    x = linearUnit(input, numKernels * kernelDim, <span class="calibre5">scope</span>=<span class="calibre5">'minibatch'</span>, <span class="calibre5">stddev</span>=<span class="calibre5">0.02</span>)<br class="calibre2"/>    act = tf.reshape(x, (-<span class="calibre5">1</span>, numKernels, kernelDim))<br class="calibre2"/>    differences = tf.expand_dims(act, <span class="calibre5">3</span>) - \<br class="calibre2"/>            tf.expand_dims(tf.transpose(act, [<span class="calibre5">1</span>, <span class="calibre5">2</span>, <span class="calibre5">0</span>]), <span class="calibre5">0</span>)<br class="calibre2"/>    absDiffs = tf.reduce_sum(tf.abs(differences), <span class="calibre5">2</span>)<br class="calibre2"/>    minibatchFeatures = tf.reduce_sum(tf.exp(-absDiffs), <span class="calibre5">2</span>)<br class="calibre2"/>    <span class="calibre5">return </span>tf.concat([input, minibatchFeatures], <span class="calibre5">1</span>)<br class="calibre2"/><br class="calibre2"/><br class="calibre2"/><span class="calibre5"># optimizer<br class="calibre2"/></span><span class="calibre5">def </span>optimizer(loss, var_list):<br class="calibre2"/>    learning_rate = <span class="calibre5">0.001<br class="calibre2"/></span><span class="calibre5">    </span>step = tf.Variable(<span class="calibre5">0</span>, <span class="calibre5">trainable</span>=<span class="calibre5">False</span>)<br class="calibre2"/>    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(<br class="calibre2"/>        loss,<br class="calibre2"/>        <span class="calibre5">global_step</span>=step,<br class="calibre2"/>        <span class="calibre5">var_list</span>=var_list<br class="calibre2"/>    )<br class="calibre2"/>    <span class="calibre5">return </span>optimizer<br class="calibre2"/><br class="calibre2"/><br class="calibre2"/><span class="calibre5"># log<br class="calibre2"/></span><span class="calibre5">def </span>log(x):<br class="calibre2"/>    <span class="calibre5">return </span>tf.log(tf.maximum(x, <span class="calibre5">1e-5</span>))<br class="calibre2"/><br class="calibre2"/><br class="calibre2"/><span class="calibre5">class </span>GAN(<span class="calibre5">object</span>):<br class="calibre2"/>    <span class="calibre5">def </span><span class="calibre5">__init__</span>(<span class="calibre5">self</span>, params):<br class="calibre2"/>        <span class="calibre5">with </span>tf.variable_scope(<span class="calibre5">'Generator'</span>):<br class="calibre2"/>            <span class="calibre5">self</span>.zee = tf.placeholder(tf.float32, <span class="calibre5">shape</span>=(params.batchSize, <span class="calibre5">1</span>))<br class="calibre2"/>            <span class="calibre5">self</span>.Gee = generatorNetwork(<span class="calibre5">self</span>.zee, params.hidden_size)<br class="calibre2"/><br class="calibre2"/>        <span class="calibre5">self</span>.xVal = tf.placeholder(tf.float32, <span class="calibre5">shape</span>=(params.batchSize, <span class="calibre5">1</span>))<br class="calibre2"/>        <span class="calibre5">with </span>tf.variable_scope(<span class="calibre5">'Discriminator'</span>):<br class="calibre2"/>            <span class="calibre5">self</span>.Dis1 = discriminatorNetwork(<br class="calibre2"/>                <span class="calibre5">self</span>.xVal,<br class="calibre2"/>                params.hidden_size,<br class="calibre2"/>                params.minibatch<br class="calibre2"/>            )<br class="calibre2"/>        <span class="calibre5">with </span>tf.variable_scope(<span class="calibre5">'D'</span>, <span class="calibre5">reuse</span>=<span class="calibre5">True</span>):<br class="calibre2"/>            <span class="calibre5">self</span>.Dis2 = discriminatorNetwork(<br class="calibre2"/>                <span class="calibre5">self</span>.Gee,<br class="calibre2"/>                params.hidden_size,<br class="calibre2"/>                params.minibatch<br class="calibre2"/>            )<br class="calibre2"/><br class="calibre2"/>        <span class="calibre5">self</span>.lossD = tf.reduce_mean(-log(<span class="calibre5">self</span>.Dis1) - log(<span class="calibre5">1 </span>- <span class="calibre5">self</span>.Dis2))<br class="calibre2"/>        <span class="calibre5">self</span>.lossG = tf.reduce_mean(-log(<span class="calibre5">self</span>.Dis2))<br class="calibre2"/><br class="calibre2"/>        vars = tf.trainable_variables()<br class="calibre2"/>        <span class="calibre5">self</span>.dParams = [v <span class="calibre5">for </span>v <span class="calibre5">in </span>vars <span class="calibre5">if </span>v.name.startswith(<span class="calibre5">'D/'</span>)]<br class="calibre2"/>        <span class="calibre5">self</span>.gParams = [v <span class="calibre5">for </span>v <span class="calibre5">in </span>vars <span class="calibre5">if </span>v.name.startswith(<span class="calibre5">'G/'</span>)]<br class="calibre2"/><br class="calibre2"/>        <span class="calibre5">self</span>.optD = optimizer(<span class="calibre5">self</span>.lossD, <span class="calibre5">self</span>.dParams)<br class="calibre2"/>        <span class="calibre5">self</span>.optG = optimizer(<span class="calibre5">self</span>.lossG, <span class="calibre5">self</span>.gParams)<br class="calibre2"/><br class="calibre2"/><br class="calibre2"/><span class="calibre5">'''<br class="calibre2"/></span><span class="calibre5">Train GAN model<br class="calibre2"/></span><span class="calibre5">'''<br class="calibre2"/></span><span class="calibre5">def </span>trainGan(model, data, gen, params):<br class="calibre2"/>    animFrames = []<br class="calibre2"/><br class="calibre2"/>    <span class="calibre5">with </span>tf.Session() <span class="calibre5">as </span>session:<br class="calibre2"/>        tf.local_variables_initializer().run()<br class="calibre2"/>        tf.global_variables_initializer().run()<br class="calibre2"/><br class="calibre2"/>        <span class="calibre5">for </span>step <span class="calibre5">in </span><span class="calibre5">range</span>(params.numSteps + <span class="calibre5">1</span>):<br class="calibre2"/>            x = data.sample(params.batchSize)<br class="calibre2"/>            z = gen.sample(params.batchSize)<br class="calibre2"/>            lossD, _, = session.run([model.lossD, model.optD], {<br class="calibre2"/>                model.x: np.reshape(x, (params.batchSize, <span class="calibre5">1</span>)),<br class="calibre2"/>                model.z: np.reshape(z, (params.batchSize, <span class="calibre5">1</span>))<br class="calibre2"/>            })<br class="calibre2"/><br class="calibre2"/>            z = gen.sample(params.batchSize)<br class="calibre2"/>            lossG, _ = session.run([model.lossG, model.optG], {<br class="calibre2"/>                model.z: np.reshape(z, (params.batchSize, <span class="calibre5">1</span>))<br class="calibre2"/>            })<br class="calibre2"/><br class="calibre2"/>            <span class="calibre5">if </span>step % params.log_every == <span class="calibre5">0</span>:<br class="calibre2"/>                <span class="calibre5">print</span>(<span class="calibre5">'{}: {:.4f}</span><span class="calibre5">\t</span><span class="calibre5">{:.4f}'</span>.format(step, lossD, lossG))<br class="calibre2"/><br class="calibre2"/>            <span class="calibre5">if </span>params.animPath <span class="calibre5">and </span>(step % params.animEvery == <span class="calibre5">0</span>):<br class="calibre2"/>                animFrames.append(<br class="calibre2"/>                    getSamples(model, session, data, gen.range, params.batchSize)<br class="calibre2"/>                )<br class="calibre2"/><br class="calibre2"/>        <span class="calibre5">if </span>params.animPath:<br class="calibre2"/>            saveAnimation(animFrames, params.animPath, gen.range)<br class="calibre2"/>        <span class="calibre5">else</span>:<br class="calibre2"/>            samps = getSamples(model, session, data, gen.range, params.batchSize)<br class="calibre2"/>            plotDistributions(samps, gen.range)<br class="calibre2"/><br class="calibre2"/><br class="calibre2"/><span class="calibre5">def </span>getSamples(<br class="calibre2"/>        model,<br class="calibre2"/>        session,<br class="calibre2"/>        data,<br class="calibre2"/>        sampleRange,<br class="calibre2"/>        batchSize,<br class="calibre2"/>        numPoints=<span class="calibre5">10000</span>,<br class="calibre2"/>        numBins=<span class="calibre5">100<br class="calibre2"/></span>):<br class="calibre2"/>    xs = np.linspace(-sampleRange, sampleRange, numPoints)<br class="calibre2"/>    binss = np.linspace(-sampleRange, sampleRange, numBins)<br class="calibre2"/><br class="calibre2"/>    <span class="calibre5"># decision boundary<br class="calibre2"/></span><span class="calibre5">    </span>db = np.zeros((numPoints, <span class="calibre5">1</span>))<br class="calibre2"/>    <span class="calibre5">for </span>i <span class="calibre5">in </span><span class="calibre5">range</span>(numPoints // batchSize):<br class="calibre2"/>        db[batchSize * i:batchSize * (i + <span class="calibre5">1</span>)] = session.run(<br class="calibre2"/>            model.D1,<br class="calibre2"/>            {<br class="calibre2"/>                model.x: np.reshape(<br class="calibre2"/>                    xs[batchSize * i:batchSize * (i + <span class="calibre5">1</span>)],<br class="calibre2"/>                    (batchSize, <span class="calibre5">1</span>)<br class="calibre2"/>                )<br class="calibre2"/>            }<br class="calibre2"/>        )<br class="calibre2"/><br class="calibre2"/>    <span class="calibre5"># data distribution<br class="calibre2"/></span><span class="calibre5">    </span>d = data.sample(numPoints)<br class="calibre2"/>    pds, _ = np.histogram(d, <span class="calibre5">bins</span>=binss, <span class="calibre5">density</span>=<span class="calibre5">True</span>)<br class="calibre2"/><br class="calibre2"/>    zs = np.linspace(-sampleRange, sampleRange, numPoints)<br class="calibre2"/>    g = np.zeros((numPoints, <span class="calibre5">1</span>))<br class="calibre2"/>    <span class="calibre5">for </span>i <span class="calibre5">in </span><span class="calibre5">range</span>(numPoints // batchSize):<br class="calibre2"/>        g[batchSize * i:batchSize * (i + <span class="calibre5">1</span>)] = session.run(<br class="calibre2"/>            model.G,<br class="calibre2"/>            {<br class="calibre2"/>                model.z: np.reshape(<br class="calibre2"/>                    zs[batchSize * i:batchSize * (i + <span class="calibre5">1</span>)],<br class="calibre2"/>                    (batchSize, <span class="calibre5">1</span>)<br class="calibre2"/>                )<br class="calibre2"/>            }<br class="calibre2"/>        )<br class="calibre2"/>    pgs, _ = np.histogram(g, <span class="calibre5">bins</span>=binss, <span class="calibre5">density</span>=<span class="calibre5">True</span>)<br class="calibre2"/><br class="calibre2"/>    <span class="calibre5">return </span>db, pds, pgs<br class="calibre2"/><br class="calibre2"/><br class="calibre2"/><span class="calibre5">def </span>plotDistributions(samps, sampleRange):<br class="calibre2"/>    db, pd, pg = samps<br class="calibre2"/>    dbX = np.linspace(-sampleRange, sampleRange, <span class="calibre5">len</span>(db))<br class="calibre2"/>    pX = np.linspace(-sampleRange, sampleRange, <span class="calibre5">len</span>(pd))<br class="calibre2"/>    f, ax = plt.subplots(<span class="calibre5">1</span>)<br class="calibre2"/>    ax.plot(dbX, db, <span class="calibre5">label</span>=<span class="calibre5">'Decision Boundary'</span>)<br class="calibre2"/>    ax.set_ylim(<span class="calibre5">0</span>, <span class="calibre5">1</span>)<br class="calibre2"/>    plt.plot(pX, pd, <span class="calibre5">label</span>=<span class="calibre5">'Real Data'</span>)<br class="calibre2"/>    plt.plot(pX, pg, <span class="calibre5">label</span>=<span class="calibre5">'Generated Data'</span>)<br class="calibre2"/>    plt.title(<span class="calibre5">'1D Generative Adversarial Network'</span>)<br class="calibre2"/>    plt.xlabel(<span class="calibre5">'Data Values'</span>)<br class="calibre2"/>    plt.ylabel(<span class="calibre5">'Probability Density'</span>)<br class="calibre2"/>    plt.legend()<br class="calibre2"/>    plt.show()<br class="calibre2"/><br class="calibre2"/><br class="calibre2"/><span class="calibre5">def </span>saveAnimation(animFrames, animPath, sampleRange):<br class="calibre2"/>    f, ax = plt.subplots(<span class="calibre5">figsize</span>=(<span class="calibre5">6</span>, <span class="calibre5">4</span>))<br class="calibre2"/>    f.suptitle(<span class="calibre5">'1D GAN'</span>, <span class="calibre5">fontsize</span>=<span class="calibre5">15</span>)<br class="calibre2"/>    plt.xlabel(<span class="calibre5">'dataValues'</span>)<br class="calibre2"/>    plt.ylabel(<span class="calibre5">'probabilityDensity'</span>)<br class="calibre2"/>    ax.set_xlim(-<span class="calibre5">6</span>, <span class="calibre5">6</span>)<br class="calibre2"/>    ax.set_ylim(<span class="calibre5">0</span>, <span class="calibre5">1.4</span>)<br class="calibre2"/>    lineDb, = ax.plot([], [], <span class="calibre5">label</span>=<span class="calibre5">'decision boundary'</span>)<br class="calibre2"/>    linePd, = ax.plot([], [], <span class="calibre5">label</span>=<span class="calibre5">'real data'</span>)<br class="calibre2"/>    linePg, = ax.plot([], [], <span class="calibre5">label</span>=<span class="calibre5">'generated data'</span>)<br class="calibre2"/>    frameNumber = ax.text(<br class="calibre2"/>        <span class="calibre5">0.02</span>,<br class="calibre2"/>        <span class="calibre5">0.95</span>,<br class="calibre2"/>        <span class="calibre5">''</span>,<br class="calibre2"/>        <span class="calibre5">horizontalalignment</span>=<span class="calibre5">'left'</span>,<br class="calibre2"/>        <span class="calibre5">verticalalignment</span>=<span class="calibre5">'top'</span>,<br class="calibre2"/>        <span class="calibre5">transform</span>=ax.transAxes<br class="calibre2"/>    )<br class="calibre2"/>    ax.legend()<br class="calibre2"/><br class="calibre2"/>    db, pd, _ = animFrames[<span class="calibre5">0</span>]<br class="calibre2"/>    dbX = np.linspace(-sampleRange, sampleRange, <span class="calibre5">len</span>(db))<br class="calibre2"/>    pX = np.linspace(-sampleRange, sampleRange, <span class="calibre5">len</span>(pd))<br class="calibre2"/><br class="calibre2"/>    <span class="calibre5">def </span>init():<br class="calibre2"/>        lineDb.set_data([], [])<br class="calibre2"/>        linePd.set_data([], [])<br class="calibre2"/>        linePg.set_data([], [])<br class="calibre2"/>        frameNumber.set_text(<span class="calibre5">''</span>)<br class="calibre2"/>        <span class="calibre5">return </span>(lineDb, linePd, linePg, frameNumber)<br class="calibre2"/><br class="calibre2"/>    <span class="calibre5">def </span>animate(i):<br class="calibre2"/>        frameNumber.set_text(<br class="calibre2"/>            <span class="calibre5">'Frame: {}/{}'</span>.format(i, <span class="calibre5">len</span>(animFrames))<br class="calibre2"/>        )<br class="calibre2"/>        db, pd, pg = animFrames[i]<br class="calibre2"/>        lineDb.set_data(dbX, db)<br class="calibre2"/>        linePd.set_data(pX, pd)<br class="calibre2"/>        linePg.set_data(pX, pg)<br class="calibre2"/>        <span class="calibre5">return </span>(lineDb, linePd, linePg, frameNumber)<br class="calibre2"/><br class="calibre2"/>    anim = animation.FuncAnimation(<br class="calibre2"/>        f,<br class="calibre2"/>        animate,<br class="calibre2"/>        <span class="calibre5">init_func</span>=init,<br class="calibre2"/>        <span class="calibre5">frames</span>=<span class="calibre5">len</span>(animFrames),<br class="calibre2"/>        <span class="calibre5">blit</span>=<span class="calibre5">True<br class="calibre2"/></span><span class="calibre5">    </span>)<br class="calibre2"/>    anim.save(animPath, <span class="calibre5">fps</span>=<span class="calibre5">30</span>, <span class="calibre5">extra_args</span>=[<span class="calibre5">'-vcodec'</span>, <span class="calibre5">'libx264'</span>])<br class="calibre2"/><br class="calibre2"/><br class="calibre2"/><span class="calibre5"># start gan modeling<br class="calibre2"/></span><span class="calibre5">def </span>gan(args):<br class="calibre2"/>    model = GAN(args)<br class="calibre2"/>    trainGan(model, DataDist(), GeneratorDist(<span class="calibre5">range</span>=<span class="calibre5">8</span>), args)<br class="calibre2"/><br class="calibre2"/><br class="calibre2"/><span class="calibre5"># input arguments<br class="calibre2"/></span><span class="calibre5">def </span>parseArguments():<br class="calibre2"/>    argParser = argparse.ArgumentParser()<br class="calibre2"/>    argParser.add_argument(<span class="calibre5">'--num-steps'</span>, <span class="calibre5">type</span>=<span class="calibre5">int</span>, <span class="calibre5">default</span>=<span class="calibre5">5000</span>,<br class="calibre2"/>                           <span class="calibre5">help</span>=<span class="calibre5">'the number of training steps to take'</span>)<br class="calibre2"/>    argParser.add_argument(<span class="calibre5">'--hidden-size'</span>, <span class="calibre5">type</span>=<span class="calibre5">int</span>, <span class="calibre5">default</span>=<span class="calibre5">4</span>,<br class="calibre2"/>                           <span class="calibre5">help</span>=<span class="calibre5">'MLP hidden size'</span>)<br class="calibre2"/>    argParser.add_argument(<span class="calibre5">'--batch-size'</span>, <span class="calibre5">type</span>=<span class="calibre5">int</span>, <span class="calibre5">default</span>=<span class="calibre5">8</span>,<br class="calibre2"/>                           <span class="calibre5">help</span>=<span class="calibre5">'the batch size'</span>)<br class="calibre2"/>    argParser.add_argument(<span class="calibre5">'--minibatch'</span>, <span class="calibre5">action</span>=<span class="calibre5">'store_true'</span>,<br class="calibre2"/>                           <span class="calibre5">help</span>=<span class="calibre5">'use minibatch discrimination'</span>)<br class="calibre2"/>    argParser.add_argument(<span class="calibre5">'--log-every'</span>, <span class="calibre5">type</span>=<span class="calibre5">int</span>, <span class="calibre5">default</span>=<span class="calibre5">10</span>,<br class="calibre2"/>                           <span class="calibre5">help</span>=<span class="calibre5">'print loss after this many steps'</span>)<br class="calibre2"/>    argParser.add_argument(<span class="calibre5">'--anim-path'</span>, <span class="calibre5">type</span>=<span class="calibre5">str</span>, <span class="calibre5">default</span>=<span class="calibre5">None</span>,<br class="calibre2"/>                           <span class="calibre5">help</span>=<span class="calibre5">'path to the output animation file'</span>)<br class="calibre2"/>    argParser.add_argument(<span class="calibre5">'--anim-every'</span>, <span class="calibre5">type</span>=<span class="calibre5">int</span>, <span class="calibre5">default</span>=<span class="calibre5">1</span>,<br class="calibre2"/>                           <span class="calibre5">help</span>=<span class="calibre5">'save every Nth frame for animation'</span>)<br class="calibre2"/>    <span class="calibre5">return </span>argParser.parse_args()<br class="calibre2"/><br class="calibre2"/><br class="calibre2"/><span class="calibre5"># start the gan app<br class="calibre2"/></span><span class="calibre5">if </span>__name__ == <span class="calibre5">'__main__'</span>:<br class="calibre2"/>    gan(parseArguments())</pre>
<p class="calibre4">Output Listing:</p>
<pre class="calibre26">0: 6.6300 0.1449<br class="calibre2"/> 10: 6.5390 0.1655<br class="calibre2"/> 20: 6.4552 0.1866<br class="calibre2"/> 30: 6.3789 0.2106<br class="calibre2"/> 40: 6.3190 0.2372<br class="calibre2"/> 50: 6.2814 0.2645<br class="calibre2"/> 60: 6.2614 0.2884<br class="calibre2"/> 70: 6.2556 0.3036<br class="calibre2"/> 80: 6.2814 0.3104<br class="calibre2"/> 90: 6.2796 0.3113<br class="calibre2"/> 100: 6.3008 0.3106<br class="calibre2"/> 110: 6.2923 0.3112<br class="calibre2"/> 120: 6.2792 0.3153<br class="calibre2"/> 130: 6.3299 0.3196<br class="calibre2"/> 140: 6.3512 0.3205<br class="calibre2"/> 150: 6.2999 0.3197<br class="calibre2"/> 160: 6.3513 0.3236<br class="calibre2"/> 170: 6.3521 0.3291<br class="calibre2"/> 180: 6.3377 0.3292</pre>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Types of GANs</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">The following section shows different types of GANs, for example, Vanilla GAN, Conditional GAN etc. Refer to <a href="https://arxiv.org" target="_blank" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2">https://arxiv.org</a> for further information on the papers. The following description about each GAN network is taken from the respective paper on <a href="https://arxiv.org" target="_blank" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2">https://arxiv.org</a>.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Vanilla GAN</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">Vanilla GANs has two networks called generator network and a discriminator network. Both the networks are trained at the same time and compete or battle against each other in a minimax play. Generator network is trained or prepared such that it can fool the discriminator network by creating the real images as per the input, and the discriminator is trained not to be fooled by the generator network.</p>
<div class="packt_infobox">For further reading on Vanilla GAN refer to<span class="calibre5"> </span><a href="https://arxiv.org/abs/1406.2661" target="_blank" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre31">https://arxiv.org/abs/1406.2661</a><span class="calibre5">.</span></div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Conditional GAN</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">GANs was started as a novel way of generative training models. These are GAN networks that utilize extra label data. It results in excellent quality images and being able to control to an extent how generated images will look. This model can be used to learn a multi-modal model.</p>
<div class="packt_infobox"><span class="calibre5">For further reading on </span>Conditional<span class="calibre5"> GAN refer to</span><span class="calibre5"> </span><a href="https://arxiv.org/abs/1411.1784." class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre31">https://arxiv.org/abs/1411.1784<span class="calibre5">.</span></a></div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Info GAN</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">GANs that can encode or learn important image features or disentangled representations in an unsupervised manner. An example is to encode the rotation of a digit. Info GANs also maximizes the mutual information between a small subset of the latent variables and the observation.</p>
<div class="packt_infobox"><span class="calibre5">For further reading on </span><span class="calibre5">Info</span><span class="calibre5"> GAN refer to <a href="https://arxiv.org/abs/1606.03657" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre31">https://arxiv.org/abs/1606.03657</a></span></div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Wasserstein GAN</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">WGAN is an option to regular GAN training. WGANs have loss functions that correlate with image quality. Additionally, the stability of the training improves and is not as dependent on the architecture and provide significant learning curves useful for debugging.</p>
<div class="packt_infobox"><span class="calibre5">For further reading on </span><span class="calibre5">Wasserstein</span><span class="calibre5"> GAN refer to <a href="https://arxiv.org/abs/1701.07875" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre31">https://arxiv.org/abs/1701.07875</a></span></div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Coupled GAN</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">Coupled GANs is used for generating sets of like images in two separate domains. It consists of set of GANs each accountable for generating images in the single domain. The Coupled GANs learns a joint distribution from images in the two domains which are drawn separately from the marginal distributions of the unique domains.</p>
<div class="packt_infobox"><span class="calibre5">For further reading on Coupled</span><span class="calibre5"> GAN refer to <a href="https://arxiv.org/abs/1606.07536" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre31">https://arxiv.org/abs/1606.07536</a></span></div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">Generative models are a fast advancing area of study and research. As we proceed to advance these models and grow the training and datasets, we can expect to generate data examples that depict completely believable images, finally. This can be used in several applications such as image denoising, painting, structured prediction, and exploration in reinforcement learning.</p>
<p class="calibre4">The deeper promise of this effort is that, in the process of building generative models, we will enrich the computer with an understanding of the world and what elements it is made up of.</p>
<p class="calibre4"/>
<p class="calibre4"/>
<p class="calibre4"/>


            </article>

            
        </section>
    </div>



  </body></html>