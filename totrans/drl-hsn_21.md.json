["```py\nclass Action(enum.Enum): \n    R = 0 \n    L = 1 \n    T = 2 \n    D = 3 \n    F = 4 \n    B = 5 \n    r = 6 \n    l = 7 \n    t = 8 \n    d = 9 \n    f = 10 \n    b = 11\n```", "```py\n_inverse_action = { \n    Action.R: Action.r,   Action.r: Action.R, \n    Action.L: Action.l,   Action.l: Action.L, \n    Action.T: Action.t,   Action.t: Action.T, \n    Action.D: Action.d,   Action.d: Action.D, \n    Action.F: Action.f,   Action.f: Action.F, \n    Action.B: Action.b,   Action.b: Action.B, \n}\n```", "```py\nState = collections.namedtuple(\"State\", field_names=[ \n    ’corner_pos’, ’side_pos’, ’corner_ort’, ’side_ort’]) \n\ninitial_state = State(corner_pos=tuple(range(8)), side_pos=tuple(range(12)), \n                      corner_ort=tuple([0]*8), side_ort=tuple([0]*12))\n```", "```py\nclass Net(nn.Module): \n    def __init__(self, input_shape, actions_count): \n        super(Net, self).__init__() \n\n        self.input_size = int(np.prod(input_shape)) \n        self.body = nn.Sequential( \n            nn.Linear(self.input_size, 4096), \n            nn.ELU(), \n            nn.Linear(4096, 2048), \n            nn.ELU() \n        ) \n        self.policy = nn.Sequential( \n            nn.Linear(2048, 512), \n            nn.ELU(), \n            nn.Linear(512, actions_count) \n        ) \n        self.value = nn.Sequential( \n            nn.Linear(2048, 512), \n            nn.ELU(), \n            nn.Linear(512, 1) \n        ) \n\n    def forward(self, batch, value_only=False): \n        x = batch.view((-1, self.input_size)) \n        body_out = self.body(x) \n        value_out = self.value(body_out) \n        if value_only: \n            return value_out \n        policy_out = self.policy(body_out) \n        return policy_out, value_out\n```", "```py\nclass CubeEnv: \n    def __init__(self, name, state_type, initial_state, is_goal_pred, \n                 action_enum, transform_func, inverse_action_func, \n                 render_func, encoded_shape, encode_func): \n        self.name = name \n        self._state_type = state_type \n        self.initial_state = initial_state \n        self._is_goal_pred = is_goal_pred \n        self.action_enum = action_enum \n        self._transform_func = transform_func \n        self._inverse_action_func = inverse_action_func \n        self._render_func = render_func \n        self.encoded_shape = encoded_shape \n        self._encode_func = encode_func\n```", "```py\n def __repr__(self): \n        return \"CubeEnv(%r)\" % self.name \n\n    def is_goal(self, state): \n        assert isinstance(state, self._state_type) \n        return self._is_goal_pred(state) \n\n    def transform(self, state, action): \n        assert isinstance(state, self._state_type) \n        assert isinstance(action, self.action_enum) \n        return self._transform_func(state, action) \n\n    def inverse_action(self, action): \n        return self._inverse_action_func(action) \n\n    def render(self, state): \n        assert isinstance(state, self._state_type) \n        return self._render_func(state) \n\n    def encode_inplace(self, target, state): \n        assert isinstance(state, self._state_type) \n        return self._encode_func(target, state)\n```", "```py\n def sample_action(self, prev_action=None): \n        while True: \n            res = self.action_enum(random.randrange(len(self.action_enum))) \n            if prev_action is None or self.inverse_action(res) != prev_action: \n                return res\n```", "```py\n def scramble(self, actions): \n        s = self.initial_state \n        for action in actions: \n            s = self.transform(s, action) \n        return s\n```", "```py\n def scramble_cube(self, scrambles_count, return_inverse=False, include_initial=False): \n        assert isinstance(scrambles_count, int) \n        assert scrambles_count > 0 \n\n        state = self.initial_state \n        result = [] \n        if include_initial: \n            assert not return_inverse \n            result.append((1, state)) \n        prev_action = None \n        for depth in range(scrambles_count): \n            action = self.sample_action(prev_action=prev_action) \n            state = self.transform(state, action) \n            prev_action = action \n            if return_inverse: \n                inv_action = self.inverse_action(action) \n                res = (depth+1, state, inv_action) \n            else: \n                res = (depth+1, state) \n            result.append(res) \n        return result\n```", "```py\n def explore_state(self, state): \n        res_states, res_flags = [], [] \n        for action in self.action_enum: \n            new_state = self.transform(state, action) \n            is_init = self.is_goal(new_state) \n            res_states.append(new_state) \n            res_flags.append(is_init) \n        return res_states, res_flags\n```", "```py\n_env.register(_env.CubeEnv(name=\"cube2x2\", state_type=State, initial_state=initial_state, \n                           is_goal_pred=is_initial, action_enum=Action, \n                           transform_func=transform, inverse_action_func=inverse_action, \n                           render_func=render, encoded_shape=encoded_shape, \n                           encode_func=encode_inplace))\n```", "```py\n[general] \ncube_type=cube2x2 \nrun_name=paper \n\n[train] \ncuda=True \nlr=1e-5 \nbatch_size=10000 \nscramble_depth=200 \nreport_batches=10 \ncheckpoint_batches=100 \nlr_decay=True \nlr_decay_gamma=0.95 \nlr_decay_batches=1000\n```", "```py\n$ ./train.py -i ini/cube2x2-paper-d200.ini -n t1\n```"]