["```py\nrequire(h2o)\n\n```", "```py\nlocalH2O = h2o.init(ip = \"localhost\", port = 54321, startH2O = TRUE,min_mem_size = \"20G\",nthreads = 8)\n\n```", "```py\n# Load the occupancy data \noccupancy_train <-read.csv(\"C:/occupation_detection/datatraining.txt\",stringsAsFactors = T)\noccupancy_test <- read.csv(\"C:/occupation_detection/datatest.txt\",stringsAsFactors = T)\n\n```", "```py\n# Define input (x) and output (y) variables\"\nx = c(\"Temperature\", \"Humidity\", \"Light\", \"CO2\", \"HumidityRatio\")\ny = \"Occupancy\"\n\n```", "```py\n# Convert the outcome variable into factor\noccupancy_train$Occupancy <- as.factor(occupancy_train$Occupancy)\noccupancy_test$Occupancy <- as.factor(occupancy_test$Occupancy)\n\n```", "```py\noccupancy_train.hex <- as.h2o(x = occupancy_train, destination_frame = \"occupancy_train.hex\")\noccupancy_test.hex <- as.h2o(x = occupancy_test, destination_frame = \"occupancy_test.hex\")\n\n```", "```py\n# Train the model\noccupancy_train.glm <- h2o.glm(x = x, # Vector of predictor variable names\n                               y = y, # Name of response/dependent variable\n                               training_frame = occupancy_train.hex, # Training data\n                               seed = 1234567,        # Seed for random numbers\n                               family = \"binomial\",   # Outcome variable\n                               lambda_search = TRUE,  # Optimum regularisation lambda\n                               alpha = 0.5,           # Elastic net regularisation\n                               nfolds = 5             # N-fold cross validation\n                               )\n\n```", "```py\n# Training accuracy (AUC)\n> occupancy_train.glm@model$training_metrics@metrics$AUC\n[1] 0.994583\n\n# Cross validation accuracy (AUC)\n> occupancy_train.glm@model$cross_validation_metrics@metrics$AUC\n[1] 0.9945057\n\n```", "```py\n# Predict on test data\nyhat <- h2o.predict(occupancy_train.glm, occupancy_test.hex)\n\n```", "```py\n# Test accuracy (AUC)\n> yhat$pmax <- pmax(yhat$p0, yhat$p1, na.rm = TRUE) \n> roc_obj <- pROC::roc(c(as.matrix(occupancy_test.hex$Occupancy)),\n                       c(as.matrix(yhat$pmax)))\n> auc(roc_obj)\nArea under the curve: 0.9915\n\n```", "```py\n#compute variable importance and performance\nh2o.varimp_plot(occupancy_train.glm, num_of_features = 5)\n\n```", "```py\nlibrary(\"tensorflow\") # Load TensorFlow \nnp <- import(\"numpy\") # Load numpy library\n\n```", "```py\n# Loading input and test data\nxFeatures = c(\"Temperature\", \"Humidity\", \"Light\", \"CO2\", \"HumidityRatio\")\nyFeatures = \"Occupancy\"\noccupancy_train <-as.matrix(read.csv(\"datatraining.txt\",stringsAsFactors = T))\noccupancy_test <- as.matrix(read.csv(\"datatest.txt\",stringsAsFactors = T))\n\n# subset features for modeling and transform to numeric values\noccupancy_train<-apply(occupancy_train[, c(xFeatures, yFeatures)], 2, FUN=as.numeric) \noccupancy_test<-apply(occupancy_test[, c(xFeatures, yFeatures)], 2, FUN=as.numeric)\n\n# Data dimensions\nnFeatures<-length(xFeatures)\nnRow<-nrow(occupancy_train)\n\n```", "```py\n# Reset the graph\ntf$reset_default_graph()\n\n```", "```py\n# Starting session as interactive session\nsess<-tf$InteractiveSession()\n\n```", "```py\n# Setting-up Logistic regression graph\nx <- tf$constant(unlist(occupancy_train[, xFeatures]), shape=c(nRow, nFeatures), dtype=np$float32) # \nW <- tf$Variable(tf$random_uniform(shape(nFeatures, 1L)))\nb <- tf$Variable(tf$zeros(shape(1L)))\ny <- tf$matmul(x, W) + b\n\n```", "```py\n# Setting-up cost function and optimizer\ny_ <- tf$constant(unlist(occupancy_train[, yFeatures]), dtype=\"float32\", shape=c(nRow, 1L))\ncross_entropy<-tf$reduce_mean(tf$nn$sigmoid_cross_entropy_with_logits(labels=y_, logits=y, name=\"cross_entropy\"))\noptimizer <- tf$train$GradientDescentOptimizer(0.15)$minimize(cross_entropy)\n\n```", "```py\n# Start a session\ninit <- tf$global_variables_initializer()\nsess$run(init)\n\n```", "```py\n# Running optimization \nfor (step in 1:5000) {\n  sess$run(optimizer)\n  if (step %% 20== 0)\n    cat(step, \"-\", sess$run(W), sess$run(b), \"==>\", sess$run(cross_entropy), \"n\")\n}\n\n```", "```py\n# Performance on Train\nlibrary(pROC) \nypred <- sess$run(tf$nn$sigmoid(tf$matmul(x, W) + b))\nroc_obj <- roc(occupancy_train[, yFeatures], as.numeric(ypred))\n\n# Performance on test\nnRowt<-nrow(occupancy_test)\nxt <- tf$constant(unlist(occupancy_test[, xFeatures]), shape=c(nRowt, nFeatures), dtype=np$float32)\nypredt <- sess$run(tf$nn$sigmoid(tf$matmul(xt, W) + b))\nroc_objt <- roc(occupancy_test[, yFeatures], as.numeric(ypredt)).\n\n```", "```py\nplot.roc(roc_obj, col = \"green\", lty=2, lwd=2)\nplot.roc(roc_objt, add=T, col=\"red\", lty=4, lwd=2)\n\n```", "```py\n$ tensorboard --logdir home/log --port 6006 \n\n```", "```py\n# Create Writer Obj for log\nlog_writer = tf$summary$FileWriter('c:/log', sess$graph)\n\n```", "```py\n# Adding histogram summary to weight and bias variable\nw_hist = tf$histogram_summary(\"weights\", W)\nb_hist = tf$histogram_summary(\"biases\", b)\n\n```", "```py\n# Set-up cross entropy for test\nnRowt<-nrow(occupancy_test)\nxt <- tf$constant(unlist(occupancy_test[, xFeatures]), shape=c(nRowt, nFeatures), dtype=np$float32)\nypredt <- tf$nn$sigmoid(tf$matmul(xt, W) + b)\nyt_ <- tf$constant(unlist(occupancy_test[, yFeatures]), dtype=\"float32\", shape=c(nRowt, 1L))\ncross_entropy_tst<-tf$reduce_mean(tf$nn$sigmoid_cross_entropy_with_logits(labels=yt_, logits=ypredt, name=\"cross_entropy_tst\"))\n\n```", "```py\n# Add summary ops to collect data\nw_hist = tf$summary$histogram(\"weights\", W)\nb_hist = tf$summary$histogram(\"biases\", b)\ncrossEntropySummary<-tf$summary$scalar(\"costFunction\", cross_entropy)\ncrossEntropyTstSummary<-tf$summary$scalar(\"costFunction_test\", cross_entropy_tst)\n\n```", "```py\n# Create Writer Obj for log\nlog_writer = tf$summary$FileWriter('c:/log', sess$graph)\n\n```", "```py\nfor (step in 1:2500) {\n  sess$run(optimizer)\n\n  # Evaluate performance on training and test data after 50 Iteration\n  if (step %% 50== 0){\n   ### Performance on Train\n   ypred <- sess$run(tf$nn$sigmoid(tf$matmul(x, W) + b))\n   roc_obj <- roc(occupancy_train[, yFeatures], as.numeric(ypred))\n\n   ### Performance on Test\n   ypredt <- sess$run(tf$nn$sigmoid(tf$matmul(xt, W) + b))\n   roc_objt <- roc(occupancy_test[, yFeatures], as.numeric(ypredt))\n   cat(\"train AUC: \", auc(roc_obj), \" Test AUC: \", auc(roc_objt), \"n\")\n\n   # Save summary of Bias and weights\n   log_writer$add_summary(sess$run(b_hist), global_step=step)\n   log_writer$add_summary(sess$run(w_hist), global_step=step)\n   log_writer$add_summary(sess$run(crossEntropySummary), global_step=step)\n   log_writer$add_summary(sess$run(crossEntropyTstSummary), global_step=step)\n} }\n\n```", "```py\nsummary = tf$summary$merge_all() \n\n```", "```py\nlog_writer = tf$summary$FileWriter('c:/log', sess$graph)\nsummary_str = sess$run(summary)\nlog_writer$add_summary(summary_str, step)\nlog_writer$close()\n\n```", "```py\n# Load the required packages\nrequire(h2o)\n\n```", "```py\n# Initialize H2O instance (single node)\nlocalH2O = h2o.init(ip = \"localhost\", port = 54321, startH2O = TRUE,min_mem_size = \"20G\",nthreads = 8)\n\n```", "```py\n# Load the occupancy data \noccupancy_train <-read.csv(\"C:/occupation_detection/datatraining.txt\",stringsAsFactors = T)\noccupancy_test <- read.csv(\"C:/occupation_detection/datatest.txt\",stringsAsFactors = T)\n\n```", "```py\n# Define input (x) and output (y) variables\nx = c(\"Temperature\", \"Humidity\", \"Light\", \"CO2\", \"HumidityRatio\")\ny = \"Occupancy\"\n\n```", "```py\n# Convert the outcome variable into factor\noccupancy_train$Occupancy <- as.factor(occupancy_train$Occupancy)\noccupancy_test$Occupancy <- as.factor(occupancy_test$Occupancy)\n\n```", "```py\n# Convert Train and Test datasets into H2O objects\noccupancy_train.hex <- as.h2o(x = occupancy_train, destination_frame = \"occupancy_train.hex\")\noccupancy_test.hex <- as.h2o(x = occupancy_test, destination_frame = \"occupancy_test.hex\")\n\n```", "```py\n# H2O based neural network to Train the model \noccupancy.deepmodel <- h2o.deeplearning(x = x, \n                                        y = y, \n                                        training_frame = occupancy_train.hex, \n                                        validation_frame = occupancy_test.hex, \n                                        standardize = F, \n                                        activation = \"Rectifier\", \n                                        epochs = 50, \n                                        seed = 1234567, \n                                        hidden = 5, \n                                        variable_importances = T,\n                                        nfolds = 5,\n                                        adpative_rate = TRUE)\n\n```", "```py\n# Get the training accuracy (AUC)\n> train_performance <- h2o.performance(occupancy.deepmodel,train = T)\n> train_performance@metrics$AUC\n[1] 0.9848667\n\n# Get the cross-validation accuracy (AUC)\n> xval_performance <- h2o.performance(occupancy.deepmodel,xval = T)\n> xval_performance@metrics$AUC\n[1] 0.9821723\n\n```", "```py\n# Get the testing accuracy(AUC)\n> test_performance <- h2o.performance(occupancy.deepmodel,valid = T)\n> test_performance@metrics$AUC\n[1] 0.9905056\n\n```", "```py\n# Load the required packages\nrequire(h2o)\n\n# Initialize H2O instance (single node)\nlocalH2O = h2o.init(ip = \"localhost\", port = 54321, startH2O = TRUE,min_mem_size = \"20G\",nthreads = 8)\n\n```", "```py\n# Perform hyper parameter tuning\nactivation_opt <- c(\"Rectifier\",\"RectifierWithDropout\", \"Maxout\",\"MaxoutWithDropout\")\nhidden_opt <- list(5, c(5,5))\nepoch_opt <- c(10,50,100)\nl1_opt <- c(0,1e-3,1e-4)\nl2_opt <- c(0,1e-3,1e-4)\n\nhyper_params <- list(activation = activation_opt,\n                     hidden = hidden_opt,\n                     epochs = epoch_opt,\n                     l1 = l1_opt,\n                     l2 = l2_opt)\n\n```", "```py\n#set search criteria\nsearch_criteria <- list(strategy = \"RandomDiscrete\", max_models=300)\n\n```", "```py\n# Perform grid search on training data\ndl_grid <- h2o.grid(x = x,\n                    y = y,\n                    algorithm = \"deeplearning\",\n                    grid_id = \"deep_learn\",\n                    hyper_params = hyper_params,\n                    search_criteria = search_criteria,\n                    training_frame = occupancy_train.hex,\n                    nfolds = 5)\n\n```", "```py\n#Select best model based on auc\nd_grid <- h2o.getGrid(\"deep_learn\",sort_by = \"auc\", decreasing = T)\nbest_dl_model <- h2o.getModel(d_grid@model_ids[[1]])\n\n```", "```py\n# Performance on Training data after grid search\n> train_performance.grid <- h2o.performance(best_dl_model,train = T)\n> train_performance.grid@metrics$AUC\n[1] 0.9965881\n\n# Performance on Cross validation data after grid search\n> xval_performance.grid <- h2o.performance(best_dl_model,xval = T)\n> xval_performance.grid@metrics$AUC\n[1] 0.9979131\n\n```", "```py\n# Predict the outcome on test dataset\nyhat <- h2o.predict(best_dl_model, occupancy_test.hex) \n\n# Performance of the best grid-searched model on the Test dataset\n> yhat$pmax <- pmax(yhat$p0, yhat$p1, na.rm = TRUE) \n> roc_obj <- pROC::roc(c(as.matrix(occupancy_test.hex$Occupancy)), c(as.matrix(yhat$pmax)))\n> pROC::auc(roc_obj)\nArea under the curve: 0.9932\n\n```", "```py\n# Load the required packages\nrequire(mxnet)\n\n```", "```py\n# Load the occupancy data \noccupancy_train <-read.csv(\"C:/occupation_detection/datatraining.txt\",stringsAsFactors = T)\noccupancy_test <- read.csv(\"C:/occupation_detection/datatest.txt\",stringsAsFactors = T)\n\n```", "```py\n# Define input (x) and output (y) variables\nx = c(\"Temperature\", \"Humidity\", \"Light\", \"CO2\", \"HumidityRatio\")\ny = \"Occupancy\"\n\n```", "```py\n# convert the train data into matrix\noccupancy_train.x <- data.matrix(occupancy_train[,x])\noccupancy_train.y <- occupancy_train$Occupancy\n\n# convert the test data into matrix\noccupancy_test.x <- data.matrix(occupancy_test[,x])\noccupancy_test.y <- occupancy_test$Occupancy\n\n```", "```py\n# Configure Neural Network structure \nsmb.data <- mx.symbol.Variable(\"data\")\nsmb.fc <- mx.symbol.FullyConnected(smb.data, num_hidden=5) \nsmb.soft <- mx.symbol.SoftmaxOutput(smb.fc)\n\n```", "```py\n# Train the network\nmodel.nn <- mx.model.FeedForward.create(symbol = smb.soft,\n                                        X = occupancy_train.x,\n                                        y = occupancy_train.y,\n                                        ctx = mx.cpu(),\n                                        num.round = 100,\n                                        eval.metric = mx.metric.accuracy,\n                                        array.batch.size = 100,\n                                        learning.rate = 0.01)\n\n```", "```py\n# Train accuracy (AUC)\n> train_pred <- predict(model.nn,occupancy_train.x)\n> train_yhat <- max.col(t(train_pred))-1\n> roc_obj <- pROC::roc(c(occupancy_train.y), c(train_yhat))\n> pROC::auc(roc_obj)\nArea under the curve: 0.9786\n\n#Test accuracy (AUC)\n> test_pred <- predict(nnmodel,occupancy_test.x)\n> test_yhat <- max.col(t(test_pred))-1\n> roc_obj <- pROC::roc(c(occupancy_test.y), c(test_yhat))\n> pROC::auc(roc_obj)\nArea under the curve: 0.9824\n\n```", "```py\nlibrary(\"tensorflow\") # Load Tensorflow \nnp <- import(\"numpy\") # Load numpy library\n\n```", "```py\n# Loading input and test data\nxFeatures = c(\"Temperature\", \"Humidity\", \"Light\", \"CO2\", \"HumidityRatio\")\nyFeatures = \"Occupancy\"\noccupancy_train <-as.matrix(read.csv(\"datatraining.txt\",stringsAsFactors = T))\noccupancy_test <- as.matrix(read.csv(\"datatest.txt\",stringsAsFactors = T))\n\n# subset features for modeling and transform to numeric values\noccupancy_train<-apply(occupancy_train[, c(xFeatures, yFeatures)], 2, FUN=as.numeric) \noccupancy_test<-apply(occupancy_test[, c(xFeatures, yFeatures)], 2, FUN=as.numeric)\n\n# Data dimensions\nnFeatures<-length(xFeatures)\nnRow<-nrow(occupancy_train)\n\n```", "```py\n# Network Parameters\nn_hidden_1 = 5L # 1st layer number of features\nn_hidden_2 = 5L # 2nd layer number of features\nn_input = 5L    # 5 attributes\nn_classes = 1L  # Binary class\n\n# Model Parameters\nlearning_rate = 0.001\ntraining_epochs = 10000\n\n```", "```py\n# Reset the graph\ntf$reset_default_graph()\n\n```", "```py\n# Starting session as interactive session\nsess<-tf$InteractiveSession()\n\n```", "```py\n# Graph input\nx = tf$constant(unlist(occupancy_train[,xFeatures]), shape=c(nRow, n_input), dtype=np$float32)\ny = tf$constant(unlist(occupancy_train[,yFeatures]), dtype=\"float32\", shape=c(nRow, 1L))\n\n```", "```py\n# Initializes and store hidden layer's weight & bias\nweights = list(\n \"h1\" = tf$Variable(tf$random_normal(c(n_input, n_hidden_1))),\n \"h2\" = tf$Variable(tf$random_normal(c(n_hidden_1, n_hidden_2))),\n \"out\" = tf$Variable(tf$random_normal(c(n_hidden_2, n_classes)))\n)\nbiases = list(\n \"b1\" = tf$Variable(tf$random_normal(c(1L,n_hidden_1))),\n \"b2\" = tf$Variable(tf$random_normal(c(1L,n_hidden_2))),\n \"out\" = tf$Variable(tf$random_normal(c(1L,n_classes)))\n)\n\n# Create model\nmultilayer_perceptron <- function(x, weights, biases){\n # Hidden layer with RELU activation\n layer_1 = tf$add(tf$matmul(x, weights[[\"h1\"]]), biases[[\"b1\"]])\n layer_1 = tf$nn$relu(layer_1)\n # Hidden layer with RELU activation\n layer_2 = tf$add(tf$matmul(layer_1, weights[[\"h2\"]]), biases[[\"b2\"]])\n layer_2 = tf$nn$relu(layer_2)\n # Output layer with linear activation\n out_layer = tf$matmul(layer_2, weights[[\"out\"]]) + biases[[\"out\"]]\n return(out_layer)\n}\n\n```", "```py\npred = multilayer_perceptron(x, weights, biases)\n\n```", "```py\n# Define cost and optimizer\ncost = tf$reduce_mean(tf$nn$sigmoid_cross_entropy_with_logits(logits=pred, labels=y))\noptimizer = tf$train$AdamOptimizer(learning_rate=learning_rate)$minimize(cost)\n\n```", "```py\n# Initializing the global variables\ninit = tf$global_variables_initializer()\nsess$run(init)\n\n```", "```py\n# Training cycle\nfor(epoch in 1:training_epochs){\n    sess$run(optimizer)\n   if (epoch %% 20== 0)\n    cat(epoch, \"-\", sess$run(cost), \"n\") \n}\n\n```", "```py\n# Performance on Train\nlibrary(pROC) \nypred <- sess$run(tf$nn$sigmoid(multilayer_perceptron(x, weights, biases)))\nroc_obj <- roc(occupancy_train[, yFeatures], as.numeric(ypred))\n\n# Performance on Test\nnRowt<-nrow(occupancy_test)\nxt <- tf$constant(unlist(occupancy_test[, xFeatures]), shape=c(nRowt, nFeatures), dtype=np$float32) #\nypredt <- sess$run(tf$nn$sigmoid(multilayer_perceptron(xt, weights, biases)))\nroc_objt <- roc(occupancy_test[, yFeatures], as.numeric(ypredt))\n\n```", "```py\nplot.roc(roc_obj, col = \"green\", lty=2, lwd=2)\nplot.roc(roc_objt, add=T, col=\"red\", lty=4, lwd=2)\n\n```"]