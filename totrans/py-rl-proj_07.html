<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Creating a Chatbot</h1>
                </header>
            
            <article>
                
<p><span class="s2">Dialogue agents and chatbots have been on the rise in recent years. Many businesses have resorted to chatbots to answer customer inquiries, and this has been largely successful. Chatbots have been growing quickly, <span class="s3">at 5.6x in the last year (<a href="https://chatbotsmagazine.com/chatbot-report-2018-global-trends-and-analysis-4d8bbe4d924b">https://chatbotsmagazine.com/chatbot-report-2018-global-trends-and-analysis-4d8bbe4d924b</a>). </span>Chatbots can help organizations to communicate and interact with customers without any human intervention, at a very minimal cost. Over <span class="s3">51% of customers</span> have stated that they want businesses to be available 24/7, and they expect replies in less than one hour. For businesses to achieve this kind of success in an affordable manner, especially with a large customer base, they must resort to chatbots.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The background problem</h1>
                </header>
            
            <article>
                
<p class="p5"><span class="s2">Many chatbots are created with regular machine learning natural language processing algorithms, and these focus on immediate responses. A new concept is to create chatbots with the use of deep reinforcement learning.</span> This would mea<span class="s2">n that the future implications of our immediate responses would be considered to maintain coherence.</span></p>
<p class="p6"><span class="s2">In this chapter, you will learn how to apply deep reinforcement learning to natural language processing. Our reward function will be a future-looking function, and you will learn how to think probabilistically through the creation of this function.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Dataset</h1>
                </header>
            
            <article>
                
<p class="p6"><span class="s2">The dataset that we will use mainly consists of conversations from selected movies. This dataset will help to stimulate and understand conversational methods in the chatbot. Also, there are movie lines, which are essentially the same as the movie conversations, albeit shorter exchanges between people. Other data sets that will be used include some containing movie titles, movie characters, and raw scripts.</span></p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step-by-step guide</h1>
                </header>
            
            <article>
                
<p class="p6"><span class="s2">Our solution will use modeling and will focus on the future direction of a dialogue agent, so as to generate coherent and interesting dialogue. The model will simulate the dialogue between two virtual agents, with the use of policy gradient methods. These methods are designed to reward the sequences of interaction that display three important properties of conversation: informativeness (non-repeating turns), high coherence, and simplicity in answering (this is related to the forward-looking function). </span><span class="s2">In our solution, an action will be defined as the dialogue or communication utterance that the chatbot generates. </span><span class="s2">Also, a state will be defined as the two previous interaction turns. </span><span class="s2">In order to achieve all of this, we will use the scripts in the following sections.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Data parser</h1>
                </header>
            
            <article>
                
<p><span class="s2">The data parser script is designed to help with the cleaning and preprocessing of our datasets. There are a number of dependencies in this script, such as <kbd>pickle</kbd>, <kbd>codecs</kbd>, <kbd>re</kbd>, <kbd>OS</kbd>, <kbd>time</kbd>, and <kbd>numpy</kbd>. This script contains three functions. The first function helps to filter words, by preprocessing word counts and creating vocabulary based on word count thresholds. The second function helps to parse all words into this script, and the third function helps to extract only the defined vocabulary from the data:</span></p>
<pre><span>import </span>pickle<br/><span>import </span>codecs<br/><span>import </span>re<br/><span>import </span>os<br/><span>import </span>time<br/><span>import </span>numpy <span>as </span>np</pre>
<p><span>The following module cleans and preprocesses the text in the training dataset:</span><span><br/></span></p>
<pre><span>def </span><span>preProBuildWordVocab</span>(word_count_threshold=<span>5</span><span>, </span>all_words_path=<span>'data/all_words.txt'</span>):<br/>    <span># borrowed this function from NeuralTalk<br/></span><span><br/></span><span>    </span><span>if not </span>os.path.exists(all_words_path):<br/>        parse_all_words(all_words_path)<br/><br/>    corpus = <span>open</span>(all_words_path<span>, </span><span>'r'</span>).read().split(<span>'</span><span>\n</span><span>'</span>)[:-<span>1</span>]<br/>    captions = np.asarray(corpus<span>, </span><span>dtype</span>=np.object)<br/><br/>    captions = <span>map</span>(<span>lambda </span>x: x.replace(<span>'.'</span><span>, </span><span>''</span>)<span>, </span>captions)<br/>    captions = <span>map</span>(<span>lambda </span>x: x.replace(<span>','</span><span>, </span><span>''</span>)<span>, </span>captions)<br/>    captions = <span>map</span>(<span>lambda </span>x: x.replace(<span>'"'</span><span>, </span><span>''</span>)<span>, </span>captions)<br/>    captions = <span>map</span>(<span>lambda </span>x: x.replace(<span>'</span><span>\n</span><span>'</span><span>, </span><span>''</span>)<span>, </span>captions)<br/>    captions = <span>map</span>(<span>lambda </span>x: x.replace(<span>'?'</span><span>, </span><span>''</span>)<span>, </span>captions)<br/>    captions = <span>map</span>(<span>lambda </span>x: x.replace(<span>'!'</span><span>, </span><span>''</span>)<span>, </span>captions)<br/>    captions = <span>map</span>(<span>lambda </span>x: x.replace(<span>'</span><span>\\</span><span>'</span><span>, </span><span>''</span>)<span>, </span>captions)<br/>    captions = <span>map</span>(<span>lambda </span>x: x.replace(<span>'/'</span><span>, </span><span>''</span>)<span>, </span>captions)</pre>
<p>Next, iterate through the captions and create the vocabulary. </p>
<pre><br/>    <span>print</span>(<span>'preprocessing word counts and creating vocab based on word count threshold %d' </span>% (word_count_threshold))<br/>    word_counts = {}<br/>    nsents = <span>0<br/></span><span>    </span><span>for </span>sent <span>in </span>captions:<br/>        nsents += <span>1<br/></span><span>        </span><span>for </span>w <span>in </span>sent.lower().split(<span>' '</span>):<br/>            <br/>            word_counts[w] = word_counts.get(w<span>, </span><span>0</span>) + <span>1<br/></span><span>    </span>vocab = [w <span>for </span>w <span>in </span>word_counts <span>if </span>word_counts[w] &gt;= word_count_threshold]<br/>    <span>print</span>(<span>'filtered words from %d to %d' </span>% (len(word_counts)<span>, </span>len(vocab)))<br/><br/>    ixtoword = {}<br/>    ixtoword[<span>0</span>] = <span>'&lt;pad&gt;'<br/></span><span>    </span>ixtoword[<span>1</span>] = <span>'&lt;bos&gt;'<br/></span><span>    </span>ixtoword[<span>2</span>] = <span>'&lt;eos&gt;'<br/></span><span>    </span>ixtoword[<span>3</span>] = <span>'&lt;unk&gt;'<br/></span><span><br/></span><span>    </span>wordtoix = {}<br/>    wordtoix[<span>'&lt;pad&gt;'</span>] = <span>0<br/></span><span>    </span>wordtoix[<span>'&lt;bos&gt;'</span>] = <span>1<br/></span><span>    </span>wordtoix[<span>'&lt;eos&gt;'</span>] = <span>2<br/></span><span>    </span>wordtoix[<span>'&lt;unk&gt;'</span>] = <span>3<br/></span><span><br/></span><span>    </span><span>for </span>idx<span>, </span>w <span>in </span>enumerate(vocab):<br/>        wordtoix[w] = idx+<span>4<br/></span><span>        </span>ixtoword[idx+<span>4</span>] = w<br/><br/>    word_counts[<span>'&lt;pad&gt;'</span>] = nsents<br/>    word_counts[<span>'&lt;bos&gt;'</span>] = nsents<br/>    word_counts[<span>'&lt;eos&gt;'</span>] = nsents<br/>    word_counts[<span>'&lt;unk&gt;'</span>] = nsents<br/><br/>    bias_init_vector = np.array([<span>1.0 </span>* word_counts[ixtoword[i]] <span>for </span>i <span>in </span>ixtoword])<br/>    bias_init_vector /= np.sum(bias_init_vector) <span># normalize to frequencies<br/></span><span>    </span>bias_init_vector = np.log(bias_init_vector)<br/>    bias_init_vector -= np.max(bias_init_vector) <span># shift to nice numeric range<br/></span><span><br/></span><span>    </span><span>return </span>wordtoix<span>, </span>ixtoword<span>, </span>bias_init_vector</pre>
<p>Next, parse all the words from the movie lines.</p>
<pre><br/><span>def </span><span>parse_all_words</span>(all_words_path):<br/>    raw_movie_lines = open(<span>'data/movie_lines.txt'</span><span>, </span><span>'r'</span><span>, </span><span>encoding</span>=<span>'utf-8'</span><span>, </span><span>errors</span>=<span>'ignore'</span>).read().split(<span>'</span><span>\n</span><span>'</span>)[:-<span>1</span>]<br/><br/>    <span>with </span>codecs.open(all_words_path<span>, </span><span>"w"</span><span>, </span><span>encoding</span>=<span>'utf-8'</span><span>, </span><span>errors</span>=<span>'ignore'</span>) <span>as </span>f:<br/>        <span>for </span>line <span>in </span>raw_movie_lines:<br/>            line = line.split(<span>' +++$+++ '</span>)<br/>            utterance = line[-<span>1</span>]<br/>            f.write(utterance + <span>'</span><span>\n</span><span>'</span>)</pre>
<p><span>Extract only the vocabulary part of the data, as follows:</span></p>
<pre><span><br/></span><span>def </span><span>refine</span>(data):<br/>    words = re.findall(<span>"[a-zA-Z'-]+"</span><span>, </span>data)<br/>    words = [<span>""</span>.join(word.split(<span>"'"</span>)) <span>for </span>word <span>in </span>words]<br/>    <span># words = ["".join(word.split("-")) for word in words]<br/></span><span>    </span>data = <span>' '</span>.join(words)<br/>    <span>return </span>data</pre>
<p>Next, the utterance dictionary is created and stored. </p>
<pre><br/><span>if </span>__name__ == <span>'__main__'</span>:<br/>    parse_all_words(<span>'data/all_words.txt'</span>)<br/><br/>    raw_movie_lines = open(<span>'data/movie_lines.txt'</span><span>, </span><span>'r'</span><span>, </span><span>encoding</span>=<span>'utf-8'</span><span>, </span><span>errors</span>=<span>'ignore'</span>).read().split(<span>'</span><span>\n</span><span>'</span>)[:-<span>1</span>]<br/>    <br/>    utterance_dict = {}<br/>    <span>with </span>codecs.open(<span>'data/tokenized_all_words.txt'</span><span>, </span><span>"w"</span><span>, </span><span>encoding</span>=<span>'utf-8'</span><span>, </span><span>errors</span>=<span>'ignore'</span>) <span>as </span>f:<br/>        <span>for </span>line <span>in </span>raw_movie_lines:<br/>            line = line.split(<span>' +++$+++ '</span>)<br/>            line_ID = line[<span>0</span>]<br/>            utterance = line[-<span>1</span>]<br/>            utterance_dict[line_ID] = utterance<br/>            utterance = <span>" "</span>.join([refine(w) <span>for </span>w <span>in </span>utterance.lower().split()])<br/>            f.write(utterance + <span>'</span><span>\n</span><span>'</span>)<br/>    pickle.dump(utterance_dict<span>, </span>open(<span>'data/utterance_dict'</span><span>, </span><span>'wb'</span>)<span>, </span><span>True</span>)</pre>
<p>The data is parsed and can be utilized in further steps. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Data reader</h1>
                </header>
            
            <article>
                
<p><span class="s2">The data reader script helps to generate trainable batches from the preprocessed training text from the data parser script. Let's start by importing the required methods:</span></p>
<pre><span>import </span>pickle<br/><span>import </span>random</pre>
<p>This helper module helps generate trainable batches from the preprocessed training text.</p>
<pre><span>class </span>Data_Reader:<br/>    <span>def </span><span>__init__</span>(<span>self</span><span>, </span>cur_train_index=<span>0</span><span>, </span>load_list=<span>False</span>):<br/>        <span>self</span>.training_data = pickle.load(open(<span>'data/conversations_lenmax22_formersents2_with_former'</span><span>, </span><span>'rb'</span>))<br/>        <span>self</span>.data_size = len(<span>self</span>.training_data)<br/>        <span>if </span>load_list:<br/>            <span>self</span>.shuffle_list = pickle.load(open(<span>'data/shuffle_index_list'</span><span>, </span><span>'rb'</span>))<br/>        <span>else</span>:    <br/>            <span>self</span>.shuffle_list = <span>self</span>.shuffle_index()<br/>        <span>self</span>.train_index = cur_train_index</pre>
<p><span class="s2">The following code gets the batch number from the data:</span></p>
<pre>    <span>def </span><span>get_batch_num</span>(<span>self</span><span>, </span>batch_size):<br/>        <span>return </span><span>self</span>.data_size // batch_size</pre>
<p><span class="s2">The following code shuffles the index from the data:</span></p>
<pre>    <span>def </span><span>shuffle_index</span>(<span>self</span>):<br/>        shuffle_index_list = random.sample(range(<span>self</span>.data_size)<span>, </span><span>self</span>.data_size)<br/>        pickle.dump(shuffle_index_list<span>, </span>open(<span>'data/shuffle_index_list'</span><span>, </span><span>'wb'</span>)<span>, </span><span>True</span>)<br/>        <span>return </span>shuffle_index_list</pre>
<p><span class="s2">The following code generates the batch indices, based on the batch number that was obtained earlier:</span></p>
<pre>    <span>def </span><span>generate_batch_index</span>(<span>self</span><span>, </span>batch_size):<br/>        <span>if </span><span>self</span>.train_index + batch_size &gt; <span>self</span>.data_size:<br/>            batch_index = <span>self</span>.shuffle_list[<span>self</span>.train_index:<span>self</span>.data_size]<br/>            <span>self</span>.shuffle_list = <span>self</span>.shuffle_index()<br/>            remain_size = batch_size - (<span>self</span>.data_size - <span>self</span>.train_index)<br/>            batch_index += <span>self</span>.shuffle_list[:remain_size]<br/>            <span>self</span>.train_index = remain_size<br/>        <span>else</span>:<br/>            batch_index = <span>self</span>.shuffle_list[<span>self</span>.train_index:<span>self</span>.train_index+batch_size]<br/>            <span>self</span>.train_index += batch_size<br/><br/>        <span>return </span>batch_index</pre>
<p><span class="s2">The following code generates the training batch:</span></p>
<pre><br/>    <span>def </span><span>generate_training_batch</span>(<span>self</span><span>, </span>batch_size):<br/>        batch_index = <span>self</span>.generate_batch_index(batch_size)<br/>        batch_X = [<span>self</span>.training_data[i][<span>0</span>] <span>for </span>i <span>in </span>batch_index]   <span># batch_size of conv_a<br/></span><span>        </span>batch_Y = [<span>self</span>.training_data[i][<span>1</span>] <span>for </span>i <span>in </span>batch_index]   <span># batch_size of conv_b<br/></span><span><br/></span><span>        </span><span>return </span>batch_X<span>, </span>batch_Y</pre>
<p>The following function generates training batch with the former. </p>
<pre><br/>    <span>def </span><span>generate_training_batch_with_former</span>(<span>self</span><span>, </span>batch_size):<br/>        batch_index = <span>self</span>.generate_batch_index(batch_size)<br/>        batch_X = [<span>self</span>.training_data[i][<span>0</span>] <span>for </span>i <span>in </span>batch_index]   <span># batch_size of conv_a<br/></span><span>        </span>batch_Y = [<span>self</span>.training_data[i][<span>1</span>] <span>for </span>i <span>in </span>batch_index]   <span># batch_size of conv_b<br/></span><span>        </span>former = [<span>self</span>.training_data[i][<span>2</span>] <span>for </span>i <span>in </span>batch_index]    <span># batch_size of former utterance<br/></span><span><br/></span><span>        </span><span>return </span>batch_X<span>, </span>batch_Y<span>, </span>former</pre>
<p><span class="s2">The following code generates the testing batch:</span></p>
<pre><br/>    <span>def </span><span>generate_testing_batch</span>(<span>self</span><span>, </span>batch_size):<br/>        batch_index = <span>self</span>.generate_batch_index(batch_size)<br/>        batch_X = [<span>self</span>.training_data[i][<span>0</span>] <span>for </span>i <span>in </span>batch_index]   <span># batch_size of conv_a<br/></span><span><br/></span><span>        </span><span>return </span>batch_X</pre>
<p>This concludes the data reading part. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Helper methods</h1>
                </header>
            
            <article>
                
<p>This script consists of a<span> </span><kbd>Seq2seq</kbd><span> </span>dialogue generator model, which is used for the reverse model of the backward entropy loss. This will determine the semantic coherence reward for the policy gradients dialogue. Essentially, this script will help us to represent our future reward function. The script will achieve this via the followin<span class="s2">g actions:</span></p>
<ul>
<li class="li6"><span class="s2">Encoding</span></li>
<li class="li6"><span class="s2">Decoding</span></li>
<li class="li6"><span class="s2">Generating builds</span></li>
</ul>
<p class="p7"><span class="s2">All of the preceding actions are based on<span> </span><strong>long short-term memory</strong><span> </span>(<strong>LSTM</strong>) units.</span></p>
<p>The feature extractor script helps with the extraction of features and characteristics from the data, in order to help us train it better. Let us start by importing the required modules. </p>
<pre>import tensorflow as tf
import numpy as np
import re</pre>
<p> Next, define the model inputs. If reinforcement learning is set to True, a scalar is computed based on semantic coherence and ease of answering loss caption. </p>
<pre>def model_inputs(embed_dim, reinforcement= False):    
    word_vectors = tf.placeholder(tf.float32, [None, None, embed_dim], name = "word_vectors")
    reward = tf.placeholder(tf.float32, shape = (), name = "rewards")
    caption = tf.placeholder(tf.int32, [None, None], name = "captions")
    caption_mask = tf.placeholder(tf.float32, [None, None], name = "caption_masks")
    if reinforcement: #Normal training returns only the word_vectors, caption and caption_mask placeholders, 
        #With reinforcement learning, there is an extra placeholder for rewards
        return word_vectors, caption, caption_mask, reward
    else:
        return word_vectors, caption, caption_mask</pre>
<p>Next, define the encoding layers which perform encoding for the sequence to sequence network. The input sequence is passed into the encoder and returns the output of RNN output and the state. </p>
<pre>       
def encoding_layer(word_vectors, lstm_size, num_layers, keep_prob, 
                   vocab_size):
    
    cells = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.LSTMCell(lstm_size), keep_prob) for _ in range(num_layers)])
    
    outputs, state = tf.nn.dynamic_rnn(cells, 
                                       word_vectors, 
                                       dtype=tf.float32)
    return outputs, state</pre>
<p>Next, define the training process for decoder using LSTMS cells with the encoder state together with the decoder inputs.</p>
<pre>def decode_train(enc_state, dec_cell, dec_input, 
                         target_sequence_length,output_sequence_length,
                         output_layer, keep_prob):
    dec_cell = tf.contrib.rnn.DropoutWrapper(dec_cell,                #Apply dropout to the LSTM cell
                                             output_keep_prob=keep_prob)
    
    
    helper = tf.contrib.seq2seq.TrainingHelper(dec_input,             #Training helper for decoder 
                                               target_sequence_length)
    
    decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell, 
                                              helper, 
                                              enc_state, 
                                              output_layer)

    # unrolling the decoder layer
    outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder, 
                                                      impute_finished=True,
                                                     maximum_iterations=output_sequence_length)
    return outputs</pre>
<p>Next, define an inference decoder similar to the one used for the training. Makes use of a greedy helper which feeds the last output of the decoder as the next decoder input. The output returned contains the training logits and the sample id.</p>
<pre>def decode_generate(encoder_state, dec_cell, dec_embeddings,
                         target_sequence_length,output_sequence_length,
                         vocab_size, output_layer, batch_size, keep_prob):
    dec_cell = tf.contrib.rnn.DropoutWrapper(dec_cell, 
                                             output_keep_prob=keep_prob)
    
    helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(dec_embeddings, 
                                                      tf.fill([batch_size], 1),  #Decoder helper for inference
                                                      2)
    
    decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell, 
                                              helper, 
                                              encoder_state, 
                                              output_layer)
    
    outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder, 
                                                      impute_finished=True,
                                                     maximum_iterations=output_sequence_length)
    return outputs</pre>
<p>Next, create a decoding layer.</p>
<pre>def decoding_layer(dec_input, enc_state,
                   target_sequence_length,output_sequence_length,
                   lstm_size,
                   num_layers,n_words,
                   batch_size, keep_prob,embedding_size, Train = True):
    target_vocab_size = n_words
    with tf.device("/cpu:0"):
        dec_embeddings = tf.Variable(tf.random_uniform([target_vocab_size,embedding_size], -0.1, 0.1), name='Wemb')
    dec_embed_input = tf.nn.embedding_lookup(dec_embeddings, dec_input)
    
    cells = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.LSTMCell(lstm_size) for _ in range(num_layers)])
    
    with tf.variable_scope("decode"):
        output_layer = tf.layers.Dense(target_vocab_size)
    
    if Train:
        with tf.variable_scope("decode"):
            train_output = decode_train(enc_state, 
                                                cells, 
                                                dec_embed_input, 
                                                target_sequence_length, output_sequence_length,
                                                output_layer, 
                                                keep_prob)

    with tf.variable_scope("decode", reuse=tf.AUTO_REUSE):
        infer_output = decode_generate(enc_state, 
                                            cells, 
                                            dec_embeddings, target_sequence_length,
                                           output_sequence_length,
                                            target_vocab_size, 
                                            output_layer,
                                            batch_size,
                                            keep_prob)
    if Train:
        return train_output, infer_output
    return infer_output</pre>
<p>Next, create the bos inclusion which appends the index corresponding to &lt;bos&gt; referring to the beginning of a sentence to the first index of the caption tensor for every batch.</p>
<pre>def bos_inclusion(caption,batch_size):
 
    sliced_target = tf.strided_slice(caption, [0,0], [batch_size, -1], [1,1])
    concat = tf.concat([tf.fill([batch_size, 1],1), sliced_target],1)
    return concat</pre>
<p>Next, define pad sequences which creates an array of size maxlen from every question by padding with zeros or truncating where necessary.</p>
<pre>def pad_sequences(questions, sequence_length =22):
    lengths = [len(x) for x in questions]
    num_samples = len(questions)
    x = np.zeros((num_samples, sequence_length)).astype(int)
    for idx, sequence in enumerate(questions):
        if not len(sequence):
            continue  # empty list/array was found
        truncated  = sequence[-sequence_length:]

        truncated = np.asarray(truncated, dtype=int)

        x[idx, :len(truncated)] = truncated
        
    return x</pre>
<p>Ignore non-vocabulary parts if the data and take only all alphabets.</p>
<pre>def refine(data):
    words = re.findall("[a-zA-Z'-]+", data)
    words = ["".join(word.split("'")) for word in words]
    data = ' '.join(words)
    return data</pre>
<p>Next, create batches to be fed into the network from in word vector representation.</p>
<pre>def make_batch_input(batch_input, input_sequence_length, embed_dims, word2vec):
    
    for i in range(len(batch_input)):
        
        batch_input[i] = [word2vec[w] if w in word2vec else np.zeros(embed_dims) for w in batch_input[i]]
        if len(batch_input[i]) &gt;input_sequence_length:
            batch_input[i] = batch_input[i][:input_sequence_length]
        else:
            for _ in range(input_sequence_length - len(batch_input[i])):
                batch_input[i].append(np.zeros(embed_dims))

    
    return np.array(batch_input)<br/><br/>def replace(target,symbols):  #Remove symbols from sequence
    for symbol in symbols:
        target = list(map(lambda x: x.replace(symbol,''),target))
    return target
                      <br/>def make_batch_target(batch_target, word_to_index, target_sequence_length):
    target = batch_target
    target = list(map(lambda x: '&lt;bos&gt; ' + x, target))
    symbols = ['.', ',', '"', '\n','?','!','\\','/']
    target = replace(target, symbols)

    for idx, each_cap in enumerate(target):
        word = each_cap.lower().split(' ')
        if len(word) &lt; target_sequence_length:
            target[idx] = target[idx] + ' &lt;eos&gt;'  #Append the end of symbol symbol 
        else:
            new_word = ''
            for i in range(target_sequence_length-1):
                new_word = new_word + word[i] + ' '
            target[idx] = new_word + '&lt;eos&gt;'
            
    target_index = [[word_to_index[word] if word in word_to_index else word_to_index['&lt;unk&gt;'] for word in 
                          sequence.lower().split(' ')] for sequence in target]
    #print(target_index[0])
    
    
    caption_matrix = pad_sequences(target_index,target_sequence_length)
    caption_matrix = np.hstack([caption_matrix, np.zeros([len(caption_matrix), 1])]).astype(int)
    caption_masks = np.zeros((caption_matrix.shape[0], caption_matrix.shape[1]))
    nonzeros = np.array(list(map(lambda x: (x != 0).sum(), caption_matrix)))
    #print(nonzeros)
    #print(caption_matrix[1])
    
    
    for ind, row in enumerate(caption_masks): #Set the masks as an array of ones where actual words exist and zeros otherwise
        row[:nonzeros[ind]] = 1                 
        #print(row)
    print(caption_masks[0])
    print(caption_matrix[0])
    return caption_matrix,caption_masks   <br/><br/>def generic_batch(generic_responses, batch_size, word_to_index, target_sequence_length):
    size = len(generic_responses) 
    if size &gt; batch_size:
        generic_responses = generic_responses[:batch_size]
            
    else:
        for j in range(batch_size - size):
            generic_responses.append('')
                
    return make_batch_Y(generic_responses, word_to_index, target_sequence_length)
             </pre>
<p class="mce-root">Next, generate sentences from the predicted indices. Replace &lt;unk&gt;, &lt;pad&gt; with the word with the next highest probability whenever predicted.</p>
<pre>def index2sentence(generated_word_index, prob_logit, ixtoword):
    generated_word_index = list(generated_word_index)
    for i in range(len(generated_word_index)):
        if generated_word_index[i] == 3 or generated_word_index[i] == 0:
            sort_prob_logit = sorted(prob_logit[i])
            curindex = np.where(prob_logit[i] == sort_prob_logit[-2])[0][0]
            count = 1
            while curindex &lt;= 3:
                curindex = np.where(prob_logit[i] == sort_prob_logit[(-2)-count])[0][0]
                count += 1

            generated_word_index[i] = curindex

    generated_words = []
    for ind in generated_word_index:
        generated_words.append(ixtoword[ind])    
    generated_sentence = ' '.join(generated_words)
    generated_sentence = generated_sentence.replace('&lt;bos&gt; ', '')  #Replace the beginning of sentence tag
    generated_sentence = generated_sentence.replace('&lt;eos&gt;', '')   #Replace the end of sentence tag
    generated_sentence = generated_sentence.replace('--', '')      #Replace the other symbols predicted
    generated_sentence = generated_sentence.split('  ')
    for i in range(len(generated_sentence)):       #Begin sentences with Upper case 
        generated_sentence[i] = generated_sentence[i].strip()
        if len(generated_sentence[i]) &gt; 1:
            generated_sentence[i] = generated_sentence[i][0].upper() + generated_sentence[i][1:] + '.'
        else:
            generated_sentence[i] = generated_sentence[i].upper()
    generated_sentence = ' '.join(generated_sentence)
    generated_sentence = generated_sentence.replace(' i ', ' I ')
    generated_sentence = generated_sentence.replace("i'm", "I'm")
    generated_sentence = generated_sentence.replace("i'd", "I'd")

    return generated_sentence</pre>
<p>This concludes all the helper functions. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chatbot model</h1>
                </header>
            
            <article>
                
<p>The following script contains the policy gradient model, which will be used where it combines reinforcement learning rewards with the cross-entropy loss. The dependencies include <kbd>numpy</kbd> and <kbd>tensorflow</kbd>. Our policy gradient is based on an LSTM encoder-decoder. We will use a stochastic demonstration of our policy gradient, which will be a probability distribution of actions over specified states. The script represents all of these, and specifies the policy gradient loss to be minimized.</p>
<p><span>R</span><span>un the output of the first cell through the second cell; the input is concatenated with zeros. The final state for the responses mostly consists of two components—the latent representation of the input by the encoder, and the state of the decoder, based on the selected words. </span><span>The return includes placeholder tensors and other tensors, such as losses and training optimization operation. Let's start by importing the required libraries. <br/></span></p>
<pre>import tensorflow as tf
import numpy as np
import helper as h</pre>
<p>We will create a chatbot class to create the model. </p>
<pre>class Chatbot():
    def __init__(self, embed_dim, vocab_size, lstm_size, batch_size, input_sequence_length, target_sequence_length, learning_rate =0.0001, keep_prob = 0.5, num_layers = 1, policy_gradients = False, Training = True):
        self.embed_dim = embed_dim
        self.lstm_size = lstm_size
        self.batch_size = batch_size
        self.vocab_size = vocab_size
        self.input_sequence_length = tf.fill([self.batch_size],input_sequence_length+1)
        self.target_sequence_length = tf.fill([self.batch_size],target_sequence_length+1)
        self.output_sequence_length = target_sequence_length +1
        self.learning_rate = learning_rate
        self.keep_prob = keep_prob
        self.num_layers = num_layers
        self.policy_gradients = policy_gradients
        self.Training = Training
        </pre>
<p>Next, create a method that builds the model. If policy gradients are requested, then get the input accordingly. </p>
<pre>    def build_model(self):
        if self.policy_gradients:
            word_vectors, caption, caption_mask, rewards = h.model_inputs(self.embed_dim, True)
            place_holders = {'word_vectors': word_vectors,
                'caption': caption,
                'caption_mask': caption_mask, "rewards": rewards
                             }
        else:
            word_vectors, caption, caption_mask = h.model_inputs(self.embed_dim)
            
            place_holders = {'word_vectors': word_vectors,
                'caption': caption,
                'caption_mask': caption_mask}
        enc_output, enc_state = h.encoding_layer(word_vectors, self.lstm_size, self.num_layers,
                                         self.keep_prob, self.vocab_size)
        #dec_inp = h.bos_inclusion(caption, self.batch_size)
        dec_inp = caption
        </pre>
<p>Next, get the inference layer. </p>
<pre>        if not self.Training:
            print("Test mode")
            inference_out = h.decoding_layer(dec_inp, enc_state,self.target_sequence_length, 
                                                    self.output_sequence_length,
                                                    self.lstm_size, self.num_layers,
                                                    self.vocab_size, self.batch_size,
                                                  self.keep_prob, self.embed_dim, False)
            logits = tf.identity(inference_out.rnn_output, name = "train_logits")
            predictions = tf.identity(inference_out.sample_id, name = "predictions")
            return place_holders, predictions, logits
        </pre>
<p>Next, get the loss layers. </p>
<pre>        train_out, inference_out = h.decoding_layer(dec_inp, enc_state,self.target_sequence_length, 
                                                    self.output_sequence_length,
                                                    self.lstm_size, self.num_layers,
                                                    self.vocab_size, self.batch_size,
                                                  self.keep_prob, self.embed_dim)
        
        
        
        
        training_logits = tf.identity(train_out.rnn_output, name = "train_logits")
        prediction_logits = tf.identity(inference_out.sample_id, name = "predictions")
        cross_entropy = tf.contrib.seq2seq.sequence_loss(training_logits, caption, caption_mask)
        losses = {"entropy": cross_entropy}
        
        </pre>
<p>Depending on the state of the policy gradient, either minimize cross entropy loss or policy gradient loss. </p>
<pre>        if self.policy_gradients:
            pg_loss = tf.contrib.seq2seq.sequence_loss(training_logits, caption, caption_mask*rewards)
            with tf.variable_scope(tf.get_variable_scope(), reuse=False):
                optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(pg_loss)
            losses.update({"pg":pg_loss}) 
        else:
            with tf.variable_scope(tf.get_variable_scope(), reuse=False):
                optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(cross_entropy)
                
        return optimizer, place_holders,prediction_logits,training_logits, losses</pre>
<p>Now we have all the methods that are required for training. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Training the data</h1>
                </header>
            
            <article>
                
<p class="p6"><span class="s2">The scripts that were written previously were combined with training the dataset. </span>Let's start the training by importing all the modules that are developed in the previous sections as shown here:</p>
<pre><span>from </span>data_reader <span>import </span>Data_Reader<br/><span>import </span>data_parser<br/><span>from </span>gensim.models <span>import </span>KeyedVectors<br/><span>import </span>helper <span>as </span>h<br/><span>from </span>seq_model <span>import </span>Chatbot<br/><span>import </span>tensorflow <span>as </span>tf<br/><span>import </span>numpy <span>as </span>np</pre>
<p>Next, let's create a set of generic responses <span>observed in the original</span><span> </span><kbd>seq2seq</kbd><span> </span><span>model which the policy gradients are trained to avoid:</span></p>
<pre>generic_responses = [<br/>    <span>"I don't know what you're talking about."</span><span>, <br/></span><span>    </span><span>"I don't know."</span><span>, <br/></span><span>    </span><span>"You don't know."</span><span>,<br/></span><span>    </span><span>"You know what I mean."</span><span>, <br/></span><span>    </span><span>"I know what you mean."</span><span>, <br/></span><span>    </span><span>"You know what I'm saying."</span><span>,<br/></span><span>    </span><span>"You don't know anything."<br/></span>]</pre>
<p>Next, we will define all the constants that are required for the training. Tha </p>
<pre>checkpoint = <span>True<br/></span>forward_model_path = <span>'model/forward'<br/></span>reversed_model_path = <span>'model/reversed'<br/></span>rl_model_path = <span>"model/rl"<br/></span>model_name = <span>'seq2seq'<br/></span>word_count_threshold = <span>20<br/></span>reversed_word_count_threshold = <span>6<br/></span>dim_wordvec = <span>300<br/></span>dim_hidden = <span>1000<br/></span>input_sequence_length = <span>22<br/></span>output_sequence_length = <span>22<br/></span>learning_rate = <span>0.0001<br/></span>epochs = <span>1<br/></span>batch_size = <span>200<br/></span>forward_ = <span>"forward"<br/></span>reverse_ = <span>"reverse"<br/></span>forward_epochs = <span>50<br/></span>reverse_epochs = <span>50<br/></span>display_interval = <span>100<br/></span></pre>
<p>Next, define the training function. Based on the type, either the forward or reverse sequence to sequence model is loaded. The data is also read in reverse model based on the model as shown here:</p>
<pre><span>def </span><span>train</span>(type_<span>, </span>epochs=epochs<span>, </span>checkpoint=<span>False</span>):<br/>    tf.reset_default_graph()<br/>    <span>if </span>type_ == <span>"forward"</span>:<br/>        path = <span>"model/forward/seq2seq"<br/></span><span>        </span>dr = Data_Reader(<span>reverse</span>=<span>False</span>)<br/>    <span>else</span>:<br/>        dr = Data_Reader(<span>reverse</span>=<span>True</span>)<br/>        path = <span>"model/reverse/seq2seq"<br/></span></pre>
<p>Next, create the vocabulary as shown here: </p>
<pre><span>    </span>word_to_index<span>, </span>index_to_word<span>, </span>_ = data_parser.preProBuildWordVocab(<span>word_count_threshold</span>=word_count_threshold)</pre>
<p>The above command print should print the following indicated the vocabulary size that is filtered.</p>
<pre>preprocessing word counts and creating vocab based on word count threshold 20<br/>filtered words from 76029 to 6847</pre>
<p>The <kbd>word_to_index</kbd> variable is filled with the map of filtered words to an integer as shown here:</p>
<pre>{'': 4,<br/>'deposition': 1769,<br/>'next': 3397,<br/>'dates': 1768,<br/>'chance': 2597,<br/>'slipped': 4340,...</pre>
<p>The <kbd>index_to_word</kbd> variable is filled with the map of integer to the filtered works which will work as a reverse lookup.</p>
<pre>5: 'tastes',<br/>6: 'shower',<br/>7: 'agent',<br/>8: 'lack',</pre>
<p>Next, load the word to vector model from <kbd>gensim</kbd> library.</p>
<pre>    word_vector = KeyedVectors.load_word2vec_format(<span>'model/word_vector.bin'</span><span>, </span><span>binary</span>=<span>True</span>)</pre>
<p>Next, instantiate and build the model the Chatbot model with all the constants that were defined. Restore a checkpoint, if present from the previous run or initialize the graph. </p>
<pre>    model = Chatbot(dim_wordvec<span>, </span><span>len</span>(word_to_index)<span>, </span>dim_hidden<span>, </span>batch_size<span>,<br/></span><span>                    </span>input_sequence_length<span>, </span>output_sequence_length<span>, </span>learning_rate)<br/>    optimizer<span>, </span>place_holders<span>, </span>predictions<span>, </span>logits<span>, </span>losses = model.build_model()<br/>    saver = tf.train.Saver()<br/>    sess = tf.InteractiveSession()<br/>    <span>if </span>checkpoint:<br/>        saver.restore(sess<span>, </span>path)<br/>        <span>print</span>(<span>"checkpoint restored at path: {}"</span>.format(path))<br/>    <span>else</span>:<br/>        tf.global_variables_initializer().run()</pre>
<p>Next, start the training by iterating through the epochs and start the batches. </p>
<pre>    <span>for </span>epoch <span>in </span><span>range</span>(epochs):<br/>        n_batch = dr.get_batch_num(<span>batch_size</span>=batch_size)<br/>        <span>for </span>batch <span>in </span><span>range</span>(n_batch):<br/><br/>            batch_input<span>, </span>batch_target = dr.generate_training_batch(batch_size)</pre>
<p>The <kbd>batch_input</kbd> has the list of words from the training set.  The <kbd>batch_target</kbd> has the list of sentences for the input which will be the target. The list of words is converted to vector form using the helper functions. Make the feed dictionary for the graph using the transformed inputs, masks and targets.</p>
<pre>            inputs_ = h.make_batch_input(batch_input<span>, </span>input_sequence_length<span>, </span>dim_wordvec<span>, </span>word_vector)<br/><br/>            targets<span>, </span>masks = h.make_batch_target(batch_target<span>, </span>word_to_index<span>, </span>output_sequence_length)<br/>            feed_dict = {<br/>                place_holders[<span>'word_vectors'</span>]: inputs_<span>,<br/></span><span>                </span>place_holders[<span>'caption'</span>]: targets<span>,<br/></span><span>                </span>place_holders[<span>'caption_mask'</span>]: masks<br/>            }</pre>
<p>Next, train the model by calling the optimizer by feeding the training data. Log the loss value at certain intervals to see the progress of the training. Save the model at the end. </p>
<pre>            _<span>, </span>loss_val<span>, </span>preds = sess.run([optimizer<span>, </span>losses[<span>"entropy"</span>]<span>, </span>predictions]<span>,<br/></span><span>                                          </span><span>feed_dict</span>=feed_dict)<br/><br/>            <span>if </span>batch % display_interval == <span>0</span>:<br/>                <span>print</span>(preds.shape)<br/>                <span>print</span>(<span>"Epoch: {}, batch: {}, loss: {}"</span>.format(epoch<span>, </span>batch<span>, </span>loss_val))<br/>                <span>print</span>(<span>"==========================================================="</span>)<br/><br/>        saver.save(sess<span>, </span>path)<br/><br/>        <span>print</span>(<span>"Model saved at {}"</span>.format(path))<br/>    <span>print</span>(<span>"Training done"</span>)<br/><br/>    sess.close()</pre>
<p>The output should appear as shown here.</p>
<pre><strong>(200, 23)</strong><br/><strong>Epoch: 0, batch: 0, loss: 8.831538200378418</strong><br/><strong>===========================================================</strong></pre>
<p>The model is trained for both forward and reverse and the corresponding models are stored. In the next function, the models are restored and trained again to create the chatbot. </p>
<pre><span>def </span><span>pg_train</span>(epochs=epochs<span>, </span>checkpoint=<span>False</span>):<br/>    tf.reset_default_graph()<br/>    path = <span>"model/reinforcement/seq2seq"<br/></span><span>    </span>word_to_index<span>, </span>index_to_word<span>, </span>_ = data_parser.preProBuildWordVocab(<span>word_count_threshold</span>=word_count_threshold)<br/>    word_vector = KeyedVectors.load_word2vec_format(<span>'model/word_vector.bin'</span><span>, </span><span>binary</span>=<span>True</span>)<br/>    generic_caption<span>, </span>generic_mask = h.generic_batch(generic_responses<span>, </span>batch_size<span>, </span>word_to_index<span>,<br/></span><span>                                                    </span>output_sequence_length)<br/><br/>    <span>dr </span>= Data_Reader()<br/>    forward_graph = tf.Graph()<br/>    reverse_graph = tf.Graph()<br/>    <span>default_graph </span>= tf.get_default_graph()</pre>
<p>Two graphs are created to load the trained models. </p>
<pre>    <span>with </span>forward_graph.as_default():<br/>        pg_model = Chatbot(dim_wordvec<span>, </span><span>len</span>(word_to_index)<span>, </span>dim_hidden<span>, </span>batch_size<span>,<br/></span><span>                           </span>input_sequence_length<span>, </span>output_sequence_length<span>, </span>learning_rate<span>, </span><span>policy_gradients</span>=<span>True</span>)<br/>        optimizer<span>, </span>place_holders<span>, </span>predictions<span>, </span>logits<span>, </span>losses = pg_model.build_model()<br/><br/>        sess = tf.InteractiveSession()<br/>        saver = tf.train.Saver()<br/>        <span>if </span>checkpoint:<br/>            saver.restore(sess<span>, </span>path)<br/>            <span>print</span>(<span>"checkpoint restored at path: {}"</span>.format(path))<br/>        <span>else</span>:<br/>            tf.global_variables_initializer().run()<br/>            saver.restore(sess<span>, </span><span>'model/forward/seq2seq'</span>)<br/>    <span># tf.global_variables_initializer().run()<br/></span><span>    </span><span>with </span>reverse_graph.as_default():<br/>        model = Chatbot(dim_wordvec<span>, </span><span>len</span>(word_to_index)<span>, </span>dim_hidden<span>, </span>batch_size<span>,<br/></span><span>                        </span>input_sequence_length<span>, </span>output_sequence_length<span>, </span>learning_rate)<br/>        _<span>, </span>rev_place_holders<span>, </span>_<span>, </span>_<span>, </span>reverse_loss = model.build_model()<br/>        sess2 = tf.InteractiveSession()<br/>        saver2 = tf.train.Saver()<br/><br/>        saver2.restore(sess2<span>, </span><span>"model/reverse/seq2seq"</span>)<br/>        <span>print</span>(<span>"reverse model restored"</span>)<br/><br/>    dr = Data_Reader(<span>load_list</span>=<span>True</span>)</pre>
<p>Next, the data is loaded to train the data in batches. </p>
<pre>    <span>for </span>epoch <span>in </span><span>range</span>(epochs):<br/>        n_batch = dr.get_batch_num(<span>batch_size</span>=batch_size)<br/>        <span>for </span>batch <span>in </span><span>range</span>(n_batch):<br/><br/>            batch_input<span>, </span>batch_caption<span>, </span>prev_utterance = dr.generate_training_batch_with_former(batch_size)<br/>            targets<span>, </span>masks = h.make_batch_target(batch_caption<span>, </span>word_to_index<span>, </span>output_sequence_length)<br/>            inputs_ = h.make_batch_input(batch_input<span>, </span>input_sequence_length<span>, </span>dim_wordvec<span>, </span>word_vector)<br/><br/>            word_indices<span>, </span>probabilities = sess.run([predictions<span>, </span>logits]<span>,<br/></span><span>                                                   </span><span>feed_dict</span>={place_holders[<span>'word_vectors'</span>]: inputs_<br/><br/>                                                       <span>, </span>place_holders[<span>"caption"</span>]: targets})<br/><br/>            sentence = [h.index2sentence(generated_word<span>, </span>probability<span>, </span>index_to_word) <span>for<br/></span><span>                        </span>generated_word<span>, </span>probability <span>in </span><span>zip</span>(word_indices<span>, </span>probabilities)]<br/><br/>            word_list = [word.split() <span>for </span>word <span>in </span>sentence]<br/><br/>            generic_test_input = h.make_batch_input(word_list<span>, </span>input_sequence_length<span>, </span>dim_wordvec<span>, </span>word_vector)<br/><br/>            forward_coherence_target<span>, </span>forward_coherence_masks = h.make_batch_target(sentence<span>,<br/></span><span>                                                                                    </span>word_to_index<span>,<br/></span><span>                                                                                    </span>output_sequence_length)<br/><br/>            generic_loss = <span>0.0</span></pre>
<p class="mce-root">Also, learn when to say generic texts as shown here: </p>
<pre><span>            </span><span>for </span>response <span>in </span>generic_test_input:<br/>                sentence_input = np.array([response] * batch_size)<br/>                feed_dict = {place_holders[<span>'word_vectors'</span>]: sentence_input<span>,<br/></span><span>                             </span>place_holders[<span>'caption'</span>]: generic_caption<span>,<br/></span><span>                             </span>place_holders[<span>'caption_mask'</span>]: generic_mask<span>,<br/></span><span>                             </span>}<br/>                generic_loss_i = sess.run(losses[<span>"entropy"</span>]<span>, </span><span>feed_dict</span>=feed_dict)<br/>                generic_loss -= generic_loss_i / batch_size<br/><br/>            <span># print("generic loss work: {}".format(generic_loss))<br/></span><span><br/></span><span>            </span>feed_dict = {place_holders[<span>'word_vectors'</span>]: inputs_<span>,<br/></span><span>                         </span>place_holders[<span>'caption'</span>]: forward_coherence_target<span>,<br/></span><span>                         </span>place_holders[<span>'caption_mask'</span>]: forward_coherence_masks<span>,<br/></span><span>                         </span>}<br/><br/>            forward_entropy = sess.run(losses[<span>"entropy"</span>]<span>, </span><span>feed_dict</span>=feed_dict)<br/><br/>            previous_utterance<span>, </span>previous_mask = h.make_batch_target(prev_utterance<span>,<br/></span><span>                                                                    </span>word_to_index<span>, </span>output_sequence_length)<br/><br/>            feed_dict = {rev_place_holders[<span>'word_vectors'</span>]: generic_test_input<span>,<br/></span><span>                         </span>rev_place_holders[<span>'caption'</span>]: previous_utterance<span>,<br/></span><span>                         </span>rev_place_holders[<span>'caption_mask'</span>]: previous_mask<span>,<br/></span><span>                         </span>}<br/>            reverse_entropy = sess2.run(reverse_loss[<span>"entropy"</span>]<span>, </span><span>feed_dict</span>=feed_dict)<br/><br/>            rewards = <span>1 </span>/ (<span>1 </span>+ np.exp(-reverse_entropy - forward_entropy - generic_loss))<br/><br/>            feed_dict = {place_holders[<span>'word_vectors'</span>]: inputs_<span>,<br/></span><span>                         </span>place_holders[<span>'caption'</span>]: targets<span>,<br/></span><span>                         </span>place_holders[<span>'caption_mask'</span>]: masks<span>,<br/></span><span>                         </span>place_holders[<span>'rewards'</span>]: rewards<br/>                         }<br/><br/>            _<span>, </span>loss_pg<span>, </span>loss_ent = sess.run([optimizer<span>, </span>losses[<span>"pg"</span>]<span>, </span>losses[<span>"entropy"</span>]]<span>, </span><span>feed_dict</span>=feed_dict)<br/><br/>            <span>if </span>batch % display_interval == <span>0</span>:<br/>                <span>print</span>(<span>"Epoch: {}, batch: {}, Entropy loss: {}, Policy gradient loss: {}"</span>.format(epoch<span>, </span>batch<span>, </span>loss_ent<span>,<br/></span><span>                                                                                                </span>loss_pg))<br/><br/>                <span>print</span>(<span>"rewards: {}"</span>.format(rewards))<br/>                <span>print</span>(<span>"==========================================================="</span>)<br/>        saver.save(sess<span>, </span>path)<br/>        <span>print</span>(<span>"Model saved at {}"</span>.format(path))<br/>    <span>print</span>(<span>"Training done"</span>)<br/><br/></pre>
<p>Next, call the functions defined in sequence. First train a forward model, followed by reverse model and policy gradient at the end. </p>
<pre>train(forward_<span>, </span>forward_epochs<span>, False</span>)<br/>train(reverse_<span>, </span>reverse_epochs<span>, False</span>)<br/>pg_train(<span>100</span><span>, False</span>)</pre>
<p>This concludes the training of the chatbot. The model is trained in forward and reverse manner to </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Testing and results</h1>
                </header>
            
            <article>
                
<p class="p6"><span class="s2">After training the model, we tested it against our test dataset and obtained reasonably coherent dialogue. There is one very important issue: the context of the communication. Hence, depending on the dataset that is used, the result will be in its context. For our context, the results that were obtained were very reasonable, and they satisfied our three measures of performance—informativeness (non-repeating turns), high coherence, and simplicity in answering (this is related to the forward-looking function).</span></p>
<pre><span>import </span>data_parser<br/><span>from </span>gensim.models <span>import </span>KeyedVectors<br/><span>from </span>seq_model <span>import </span>Chatbot<br/><span>import </span>tensorflow <span>as </span>tf<br/><span>import </span>numpy <span>as </span>np<br/><span>import </span>helper <span>as </span>h</pre>
<p>Next, declare the paths to the various model that are already trained. </p>
<pre>reinforcement_model_path = <span>"model/reinforcement/seq2seq"<br/></span>forward_model_path = <span>"model/forward/seq2seq"<br/></span>reverse_model_path = <span>"model/reverse/seq2seq"</span></pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Next, declare the path of the files consisting of questions and responses. </p>
<pre>path_to_questions = <span>'results/sample_input.txt'<br/></span>responses_path = <span>'results/sample_output_RL.txt'</span></pre>
<p>Next, declare the constants required for the model. </p>
<pre>word_count_threshold = <span>20<br/></span>dim_wordvec = <span>300<br/></span>dim_hidden = <span>1000<br/></span><span><br/></span>input_sequence_length = <span>25<br/></span>target_sequence_length = <span>22<br/></span><span><br/></span>batch_size = <span>2</span><span><br/></span></pre>
<p>Next, load the data and the model as shown here:</p>
<pre><span>def </span><span>test</span>(model_path=forward_model_path):<br/>    testing_data = <span>open</span>(path_to_questions<span>, </span><span>'r'</span>).read().split(<span>'</span><span>\n</span><span>'</span>)<br/>    word_vector = KeyedVectors.load_word2vec_format(<span>'model/word_vector.bin'</span><span>, </span><span>binary</span>=<span>True</span>)<br/><br/>    _<span>, </span>index_to_word<span>, </span>_ = data_parser.preProBuildWordVocab(<span>word_count_threshold</span>=word_count_threshold)<br/><br/>    model = Chatbot(dim_wordvec<span>, </span><span>len</span>(index_to_word)<span>, </span>dim_hidden<span>, </span>batch_size<span>,<br/></span><span>                            </span>input_sequence_length<span>, </span>target_sequence_length<span>, </span><span>Training</span>=<span>False</span>)<br/><br/>    place_holders<span>, </span>predictions<span>, </span>logits = model.build_model()<br/><br/>    sess = tf.InteractiveSession()<br/><br/>    saver = tf.train.Saver()<br/><br/>    saver.restore(sess<span>, </span>model_path)</pre>
<p>Next, open the responses file and prepare the list of questions as shown here:</p>
<pre>    <span>with </span><span>open</span>(responses_path<span>, </span><span>'w'</span>) <span>as </span>out:<br/><br/>        <span>for </span>idx<span>, </span>question <span>in </span><span>enumerate</span>(testing_data):<br/>            <span>print</span>(<span>'question =&gt;'</span><span>, </span>question)<br/><br/>            question = [h.refine(w) <span>for </span>w <span>in </span>question.lower().split()]<br/>            question = [word_vector[w] <span>if </span>w <span>in </span>word_vector <span>else </span>np.zeros(dim_wordvec) <span>for </span>w <span>in </span>question]<br/>            question.insert(<span>0</span><span>, </span>np.random.normal(<span>size</span>=(dim_wordvec<span>,</span>)))  <span># insert random normal at the first step<br/></span><span><br/></span><span>            </span><span>if </span><span>len</span>(question) &gt; input_sequence_length:<br/>                question = question[:input_sequence_length]<br/>            <span>else</span>:<br/>                <span>for </span>_ <span>in </span><span>range</span>(input_sequence_length - <span>len</span>(question)):<br/>                    question.append(np.zeros(dim_wordvec))<br/><br/>            question = np.array([question])<br/><br/>            feed_dict = {place_holders[<span>"word_vectors"</span>]: np.concatenate([question] * <span>2</span><span>, </span><span>0</span>)<span>,<br/></span><span>                         </span>}<br/><br/>            word_indices<span>, </span>prob_logit = sess.run([predictions<span>, </span>logits]<span>, </span><span>feed_dict</span>=feed_dict)<br/><br/>            <span># print(word_indices[0].shape)<br/></span><span>            </span>generated_sentence = h.index2sentence(word_indices[<span>0</span>]<span>, </span>prob_logit[<span>0</span>]<span>, </span>index_to_word)<br/><br/>            <span>print</span>(<span>'generated_sentence =&gt;'</span><span>, </span>generated_sentence)<br/>            out.write(generated_sentence + <span>'</span><span>\n</span><span>'</span>)<br/><br/><br/>test(reinforcement_model_path)</pre>
<p>By passing the path to the model, we can test the chatbot for various responses. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p class="p5"><span class="s2">Chatbots<span> </span>are taking the world by storm, and are predicted to become more prevalent in the coming years. The coherence of the results obtained from dialogues with these<span> </span>chatbots<span> </span>has to constantly improve if they are to gain widespread acceptance. One way to achieve this would be via the use of reinforcement learning.</span></p>
<p class="p9"><span class="s2">In this chapter, we implemented reinforcement learning in the creation of a<span> </span>chatbot. The learning was based on a policy gradient method that focused on the future direction of a dialogue agent, in order to generate coherent and interesting interactions. The datasets that we used were from movie conversations. We proceeded to clean and preprocess the datasets, obtaining the vocabulary from them. We then formulated our policy gradient method. Our reward functions were represented by a sequence to sequence model. We then trained and tested our data and obtained very reasonable results, proving the viability of using reinforcement learning for dialogue agents.</span></p>


            </article>

            
        </section>
    </body></html>