["```py\n# input data\nxData = np.arange(100, step=.1)\nyData = xData + 20 * np.sin(xData/10)\n```", "```py\n# define the data size and batch sizenSamples = 1000\nbatchSize = 100\n```", "```py\n# resize input for tensorflowxData = np.reshape(xData, (nSamples, 1))\n yData = np.reshape(yData, (nSamples, 1)) \n```", "```py\nwith tf.variable_scope(\"linear-regression-pipeline\"):\n     W = tf.get_variable(\"weights\", (1,1), initializer=tf.random_normal_initializer())\n     b = tf.get_variable(\"bias\", (1, ), initializer=tf.constant_initializer(0.0))\n\n     *#* model\nyPred = tf.matmul(X, W) + b\n     *#* loss function\nloss = tf.reduce_sum((y - yPred)**2/nSamples)\n```", "```py\n# set the optimizer\n #optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)\n #optimizer = tf.train.AdamOptimizer(learning_rate=.001).minimize(loss)\n #optimizer = tf.train.AdadeltaOptimizer(learning_rate=.001).minimize(loss)\n #optimizer = tf.train.AdagradOptimizer(learning_rate=.001).minimize(loss)\n #optimizer = tf.train.MomentumOptimizer(learning_rate=.001, momentum=0.9).minimize(loss)\n #optimizer = tf.train.FtrlOptimizer(learning_rate=.001).minimize(loss)\n optimizer = tf.train.RMSPropOptimizer(learning_rate=.001).minimize(loss)  We then select the mini batch and run the optimizers errors = []\n with tf.Session() as sess:\n     # init variables\n     sess.run(tf.global_variables_initializer())\n\n     for _ in range(1000):\n         # select mini batchindices = np.random.choice(nSamples, batchSize)\n         xBatch, yBatch = xData[indices], yData[indices]\n         # run optimizer_, lossVal = sess.run([optimizer, loss], feed_dict={X: xBatch, y: yBatch})\n         errors.append(lossVal)\n\n plt.plot([np.mean(errors[i-50:i]) for i in range(len(errors))])\n plt.show()\n plt.savefig(\"errors.png\")\n```"]