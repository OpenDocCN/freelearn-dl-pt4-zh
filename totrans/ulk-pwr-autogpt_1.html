<html><head></head><body>
		<div id="_idContainer008">
			<h1 id="_idParaDest-14" class="chapter-number"><a id="_idTextAnchor013"/><span class="koboSpan" id="kobo.1.1">1</span></h1>
			<h1 id="_idParaDest-15"><a id="_idTextAnchor014"/><span class="koboSpan" id="kobo.2.1">Introducing Auto-GPT</span></h1>
			<p><span class="koboSpan" id="kobo.3.1">In the </span><em class="italic"><span class="koboSpan" id="kobo.4.1">Preface</span></em><span class="koboSpan" id="kobo.5.1">, I wrote about what Auto-GPT is and where it came from, but I was asking myself, “</span><em class="italic"><span class="koboSpan" id="kobo.6.1">Why would anyone read </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.7.1">this book?</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.8.1">”</span></span></p>
			<p><span class="koboSpan" id="kobo.9.1">I mean, it is what it is – an automated form of </span><strong class="bold"><span class="koboSpan" id="kobo.10.1">artificial intelligence</span></strong><span class="koboSpan" id="kobo.11.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.12.1">AI</span></strong><span class="koboSpan" id="kobo.13.1">) that may or may not help you do some tasks or be a fun toy that can be very spooky </span><span class="No-Break"><span class="koboSpan" id="kobo.14.1">sometimes, right?</span></span></p>
			<p><span class="koboSpan" id="kobo.15.1">I want you to have a clear understanding of what you can or cannot do </span><span class="No-Break"><span class="koboSpan" id="kobo.16.1">with it.</span></span></p>
			<p><span class="koboSpan" id="kobo.17.1">Of course, the more creative you get, the more it can do, but sometimes the boundaries appear to be more or less random. </span><span class="koboSpan" id="kobo.17.2">For example, let’s say you just built a house-building robot that for no apparent reason refuses to make the front door blue, even though you really want a blue door; it keeps going off-topic or even starts explaining what </span><span class="No-Break"><span class="koboSpan" id="kobo.18.1">doors are.</span></span></p>
			<p><span class="koboSpan" id="kobo.19.1">Auto-GPT can be very frustrating when it comes to these limitations as they come from a combination of OpenAI’s restrictions (which they give in their GPT model) and the humans who write and edit Auto-GPT (along with you – the user who gives it instructions). </span><span class="koboSpan" id="kobo.19.2">What first appears to be a clear instruction can result in a very different outcome just by changing one </span><span class="No-Break"><span class="koboSpan" id="kobo.20.1">single character.</span></span></p>
			<p><span class="koboSpan" id="kobo.21.1">For me, this is what makes it fascinating – you can always expect it to behave like a living being that can randomly choose to do otherwise and have its </span><span class="No-Break"><span class="koboSpan" id="kobo.22.1">own mind.</span></span></p>
			<p class="callout-heading"><span class="koboSpan" id="kobo.23.1">Note</span></p>
			<p class="callout"><span class="koboSpan" id="kobo.24.1">Always keep in mind that this is a fast-moving project, so code can and will be changed until this book is released. </span><span class="koboSpan" id="kobo.24.2">It may also be the case that you bought this book much later and Auto-GPT is completely different. </span><span class="koboSpan" id="kobo.24.3">Most of the content in this book focuses on version 0.4.1, but changes have been made and considered regarding version 0.5.0 </span><span class="No-Break"><span class="koboSpan" id="kobo.25.1">as well.</span></span></p>
			<p class="callout"><span class="koboSpan" id="kobo.26.1">For example, once I finished the draft of this book, the “Forge” (an idea we had at a team meeting) had already been implemented. </span><span class="koboSpan" id="kobo.26.2">This was an experiment that allowed other developers to build their own </span><span class="No-Break"><span class="koboSpan" id="kobo.27.1">Auto-GPT variation.</span></span></p>
			<p><span class="koboSpan" id="kobo.28.1">The Auto-GPT project is a framework that contains Auto-GPT, which we’ll be working with in this book, and can start other agents made by other developers. </span><span class="koboSpan" id="kobo.28.2">Those agents are in the repositories of the programmers who added them, so we won’t dive into </span><span class="No-Break"><span class="koboSpan" id="kobo.29.1">them here.</span></span></p>
			<p><span class="koboSpan" id="kobo.30.1">In this chapter, we aim to introduce you to Auto-GPT, including its history and development, as well as LangChain. </span><span class="koboSpan" id="kobo.30.2">This chapter will help you understand what Auto-GPT is, its significance, and how it has evolved. </span><span class="koboSpan" id="kobo.30.3">By the end of this chapter, you will have a solid foundation to build upon as we explore more advanced topics in the </span><span class="No-Break"><span class="koboSpan" id="kobo.31.1">subsequent chapters.</span></span></p>
			<p><span class="koboSpan" id="kobo.32.1">We will cover the following main topics in </span><span class="No-Break"><span class="koboSpan" id="kobo.33.1">this chapter:</span></span></p>
			<ul>
				<li><span class="koboSpan" id="kobo.34.1">Overview </span><span class="No-Break"><span class="koboSpan" id="kobo.35.1">of Auto-GPT</span></span></li>
				<li><span class="koboSpan" id="kobo.36.1">History and development </span><span class="No-Break"><span class="koboSpan" id="kobo.37.1">of Auto-GPT</span></span></li>
				<li><span class="koboSpan" id="kobo.38.1">Introduction </span><span class="No-Break"><span class="koboSpan" id="kobo.39.1">to LangChain</span></span></li>
			</ul>
			<h1 id="_idParaDest-16"><a id="_idTextAnchor015"/><span class="koboSpan" id="kobo.40.1">Overview of Auto-GPT</span></h1>
			<p><strong class="bold"><span class="koboSpan" id="kobo.41.1">Auto-GPT</span></strong><span class="koboSpan" id="kobo.42.1"> is more or less a category </span><a id="_idIndexMarker000"/><span class="koboSpan" id="kobo.43.1">of what it </span><span class="No-Break"><span class="koboSpan" id="kobo.44.1">already describes:</span></span></p>
			<p class="author-quote"><span class="koboSpan" id="kobo.45.1">“An automated generative pretrained transformer”</span></p>
			<p><span class="koboSpan" id="kobo.46.1">This means it automates GPT or ChatGPT. </span><span class="koboSpan" id="kobo.46.2">However, in this book, the main focus is on Auto-GPT by name. </span><span class="koboSpan" id="kobo.46.3">If you haven’t heard of it and just grabbed this book out of curiosity, then you’re in the </span><span class="No-Break"><span class="koboSpan" id="kobo.47.1">right place!</span></span></p>
			<p><strong class="bold"><span class="koboSpan" id="kobo.48.1">Auto-GPT</span></strong><span class="koboSpan" id="kobo.49.1"> started as an experimental self-prompting AI application that is an attempt to create an autonomous system capable of creating “agents” to perform various specialized tasks to achieve larger objectives with minimal human input. </span><span class="koboSpan" id="kobo.49.2">It is based on OpenAI’s GPT and was developed by </span><em class="italic"><span class="koboSpan" id="kobo.50.1">Toran Bruce Richards</span></em><span class="koboSpan" id="kobo.51.1">, who is better known by his GitHub handle </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.52.1">Significant Gravitas</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.53.1">.</span></span></p>
			<p><span class="koboSpan" id="kobo.54.1">Now, how does Auto-GPT think? </span><span class="koboSpan" id="kobo.54.2">Auto-GPT creates prompts that are fed to </span><strong class="bold"><span class="koboSpan" id="kobo.55.1">large language models</span></strong><span class="koboSpan" id="kobo.56.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.57.1">LLMs</span></strong><span class="koboSpan" id="kobo.58.1">) and allows AI models to generate</span><a id="_idIndexMarker001"/><span class="koboSpan" id="kobo.59.1"> original content and execute command actions such as browsing, coding, and more. </span><span class="koboSpan" id="kobo.59.2">It represents a significant step forward in the development of autonomous AI, making it the fastest-growing open source project in GitHub’s history (at the time </span><span class="No-Break"><span class="koboSpan" id="kobo.60.1">of writing).</span></span></p>
			<p><span class="koboSpan" id="kobo.61.1">Auto-GPT strings together multiple instances of OpenAI’s language model – </span><strong class="bold"><span class="koboSpan" id="kobo.62.1">GPT</span></strong><span class="koboSpan" id="kobo.63.1"> – and by doing so creates so-called “agents” that are tasked with simplified</span><a id="_idIndexMarker002"/><span class="koboSpan" id="kobo.64.1"> tasks. </span><span class="koboSpan" id="kobo.64.2">These agents work together to accomplish</span><a id="_idIndexMarker003"/><span class="koboSpan" id="kobo.65.1"> complex goals, such as writing a blog, with minimal </span><span class="No-Break"><span class="koboSpan" id="kobo.66.1">human intervention.</span></span></p>
			<p><span class="koboSpan" id="kobo.67.1">Now, let’s talk about how it rose </span><span class="No-Break"><span class="koboSpan" id="kobo.68.1">to fame.</span></span></p>
			<h2 id="_idParaDest-17"><a id="_idTextAnchor016"/><span class="koboSpan" id="kobo.69.1">From an experiment to one of the fastest-growing GitHub projects</span></h2>
			<p><span class="koboSpan" id="kobo.70.1">Auto-GPT was initially named </span><strong class="bold"><span class="koboSpan" id="kobo.71.1">Entrepreneur-GPT</span></strong><span class="koboSpan" id="kobo.72.1"> and was released on</span><a id="_idIndexMarker004"/><span class="koboSpan" id="kobo.73.1"> March 16, 2023. </span><span class="koboSpan" id="kobo.73.2">The initial goal</span><a id="_idIndexMarker005"/><span class="koboSpan" id="kobo.74.1"> of the project was to give GPT-4 autonomy to see if it could thrive in the business world and test its capability to make </span><span class="No-Break"><span class="koboSpan" id="kobo.75.1">real-world decisions.</span></span></p>
			<p><span class="koboSpan" id="kobo.76.1">For some time, the development of Auto-GPT remained mostly unnoticed until late March 2023. </span><span class="koboSpan" id="kobo.76.2">However, on March 30, 2023, Significant Gravitas tweeted about the latest demo of Auto-GPT and posted a demo video, which began to gain traction. </span><span class="koboSpan" id="kobo.76.3">The real surge in interest came on April 2, 2023, when computer scientist Andrej Karpathy quoted one of Significant Gravitas’ tweets, saying that the next frontier of prompt engineering </span><span class="No-Break"><span class="koboSpan" id="kobo.77.1">was Auto-GPT.</span></span></p>
			<p><span class="koboSpan" id="kobo.78.1">This tweet went viral, and Auto-GPT became a subject of discussion on social media. </span><span class="koboSpan" id="kobo.78.2">One of the agents</span><a id="_idIndexMarker006"/><span class="koboSpan" id="kobo.79.1"> that was created by Auto-GPT, known as </span><strong class="bold"><span class="koboSpan" id="kobo.80.1">ChaosGPT</span></strong><span class="koboSpan" id="kobo.81.1">, became particularly famous when it was humorously assigned the task of “destroying humanity,” which contributed to the viral nature of </span><span class="No-Break"><span class="koboSpan" id="kobo.82.1">Auto-GPT (</span></span><a href="https://decrypt.co/126122/meet-chaos-gpt-ai-tool-destroy-humanity"><span class="No-Break"><span class="koboSpan" id="kobo.83.1">https://decrypt.co/126122/meet-chaos-gpt-ai-tool-destroy-humanity</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.84.1">).</span></span></p>
			<p><span class="koboSpan" id="kobo.85.1">Of course, we don’t want to destroy humanity; for a reference on what Entrepreneur-GPT can do, take a look at the old logs of </span><span class="No-Break"><span class="koboSpan" id="kobo.86.1">Entrepreneur-GPT here:</span></span></p>
			<p><a href="https://github.com/Significant-Gravitas/Auto-GPT/blob/c6f61db06cde7bd766e521bf7df1dc0c2285ef73/"><span class="No-Break"><span class="koboSpan" id="kobo.87.1">https://github.com/Significant-Gravitas/Auto-GPT/blob/c6f61db06cde7bd766e521bf7df1dc0c2285ef73/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.88.1">.</span></span></p>
			<p><span class="koboSpan" id="kobo.89.1">The more creative you are with your prompts and configuration, the more creative Auto-GPT will be. </span><span class="koboSpan" id="kobo.89.2">This will be covered in </span><a href="B21128_02.xhtml#_idTextAnchor028"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.90.1">Chapter 2</span></em></span></a><span class="koboSpan" id="kobo.91.1"> when we run our first Auto-GPT </span><span class="No-Break"><span class="koboSpan" id="kobo.92.1">instance together.</span></span></p>
			<h2 id="_idParaDest-18"><a id="_idTextAnchor017"/><span class="koboSpan" id="kobo.93.1">LLMs – the core of AI</span></h2>
			<p><span class="koboSpan" id="kobo.94.1">Although Auto-GPT</span><a id="_idIndexMarker007"/><span class="koboSpan" id="kobo.95.1"> can be used with other LLMs, it best leverages the power of GPT-4, a state-of-the-art language model </span><span class="No-Break"><span class="koboSpan" id="kobo.96.1">by OpenAI.</span></span></p>
			<p><span class="koboSpan" id="kobo.97.1">It offers a huge advantage for users who don’t own a graphics card that can hold models such as GPT-4 equivalents. </span><span class="koboSpan" id="kobo.97.2">Although there are many 7-B and 13-B LLMs (</span><strong class="bold"><span class="koboSpan" id="kobo.98.1">B</span></strong><span class="koboSpan" id="kobo.99.1"> stands for </span><strong class="bold"><span class="koboSpan" id="kobo.100.1">billion parameters</span></strong><span class="koboSpan" id="kobo.101.1">) that do compete with ChatGPT, they cannot hold enough context in each prompt to be useful or are just not </span><span class="No-Break"><span class="koboSpan" id="kobo.102.1">stable enough.</span></span></p>
			<p><span class="koboSpan" id="kobo.103.1">At the time of writing, GPT-4 and GPT-3.5-turbo are both used with Auto-GPT by default. </span><span class="koboSpan" id="kobo.103.2">Depending on the complexity of the situation, Auto-GPT differs between two types </span><span class="No-Break"><span class="koboSpan" id="kobo.104.1">of models:</span></span></p>
			<ul>
				<li><span class="No-Break"><span class="koboSpan" id="kobo.105.1">Smart model</span></span></li>
				<li><span class="No-Break"><span class="koboSpan" id="kobo.106.1">Fast model</span></span></li>
			</ul>
			<h2 id="_idParaDest-19"><a id="_idTextAnchor018"/><span class="koboSpan" id="kobo.107.1">When does Auto-GPT use GPT-3.5-turbo and not GPT-4 all the time?</span></h2>
			<p><span class="koboSpan" id="kobo.108.1">When Auto-GPT goes through</span><a id="_idIndexMarker008"/><span class="koboSpan" id="kobo.109.1"> its thought process, it uses the </span><em class="italic"><span class="koboSpan" id="kobo.110.1">fast model</span></em><span class="koboSpan" id="kobo.111.1">. </span><span class="koboSpan" id="kobo.111.2">For example, as Auto-GPT loops through its thoughts, it uses the configured fast model, but when it summarizes the content of a website or writes code, it will decide to use the </span><span class="No-Break"><span class="koboSpan" id="kobo.112.1">smart model.</span></span></p>
			<p><span class="koboSpan" id="kobo.113.1">The default for the fast model is GPT-3.5-turbo. </span><span class="koboSpan" id="kobo.113.2">Although it isn’t as precise as GPT-4, its response time is much better, leading to a more fluent response time; GPT-4 can seem stuck if it thinks for </span><span class="No-Break"><span class="koboSpan" id="kobo.114.1">too long.</span></span></p>
			<p><span class="koboSpan" id="kobo.115.1">OpenAI has also added new functionalities to assist applications such as Auto-GPT. </span><span class="koboSpan" id="kobo.115.2">One of them is the </span><em class="italic"><span class="koboSpan" id="kobo.116.1">ability to call functions</span></em><span class="koboSpan" id="kobo.117.1">. </span><span class="koboSpan" id="kobo.117.2">Before this new feature, Auto-GPT had to explain to GPT what a command is and how to formulate it correctly in text. </span><span class="koboSpan" id="kobo.117.3">This resulted in many errors as GPT sometimes decides to change the syntax of the output that’s expected. </span><span class="koboSpan" id="kobo.117.4">This was a huge step forward as this feature now reduces the complexity of how commands are communicated and executed. </span><span class="koboSpan" id="kobo.117.5">This empowers GPT to better understand what the context of each </span><span class="No-Break"><span class="koboSpan" id="kobo.118.1">task is.</span></span></p>
			<p><span class="koboSpan" id="kobo.119.1">So, why don’t we use</span><a id="_idIndexMarker009"/><span class="koboSpan" id="kobo.120.1"> an LLM directly? </span><span class="koboSpan" id="kobo.120.2">Because LLMs are </span><span class="No-Break"><span class="koboSpan" id="kobo.121.1">only responsive:</span></span></p>
			<ul>
				<li><span class="koboSpan" id="kobo.122.1">They cannot fulfill </span><span class="No-Break"><span class="koboSpan" id="kobo.123.1">any tasks</span></span></li>
				<li><span class="koboSpan" id="kobo.124.1">Their knowledge is fixed, and they cannot update </span><span class="No-Break"><span class="koboSpan" id="kobo.125.1">it themselves</span></span></li>
				<li><span class="koboSpan" id="kobo.126.1">They don’t remember</span><a id="_idIndexMarker010"/><span class="koboSpan" id="kobo.127.1"> anything; only frameworks that run them can </span><span class="No-Break"><span class="koboSpan" id="kobo.128.1">do it</span></span></li>
			</ul>
			<h2 id="_idParaDest-20"><a id="_idTextAnchor019"/><span class="koboSpan" id="kobo.129.1">How does Auto-GPT make use of LLMs?</span></h2>
			<p><span class="koboSpan" id="kobo.130.1">Auto-GPT is structured in a way</span><a id="_idIndexMarker011"/><span class="koboSpan" id="kobo.131.1"> that it takes in an initial prompt from the user via </span><span class="No-Break"><span class="koboSpan" id="kobo.132.1">the terminal:</span></span></p>
			<div>
				<div id="_idContainer005" class="IMG---Figure">
					<span class="koboSpan" id="kobo.133.1"><img src="image/B21128_01_1.jpg" alt="Figure 1.1 – Letting Auto-GPT define its role"/></span>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.134.1">Figure 1.1 – Letting Auto-GPT define its role</span></p>
			<p><span class="koboSpan" id="kobo.135.1">Here, you can either define a main task or enter </span><strong class="source-inline"><span class="koboSpan" id="kobo.136.1">–-manual</span></strong><span class="koboSpan" id="kobo.137.1"> to then answer questions, as </span><span class="No-Break"><span class="koboSpan" id="kobo.138.1">shown here:</span></span></p>
			<p class="IMG---Figure"> </p>
			<div>
				<div id="_idContainer006" class="IMG---Figure">
					<span class="koboSpan" id="kobo.139.1"><img src="image/B21128_01_2.jpg" alt="Figure 1.2 – Setting Auto-GPT’s main goals"/></span>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.140.1">Figure 1.2 – Setting Auto-GPT’s main goals</span></p>
			<p><span class="koboSpan" id="kobo.141.1">The main prompt is then saved as an </span><strong class="source-inline"><span class="koboSpan" id="kobo.142.1">ai_settings.yaml</span></strong><span class="koboSpan" id="kobo.143.1"> file that may look </span><span class="No-Break"><span class="koboSpan" id="kobo.144.1">like this:</span></span></p>
			<pre class="source-code"><span class="koboSpan" id="kobo.145.1">
ai_goals:
- Conduct a thorough analysis of the current state of the book
  and identify areas for improvement.
</span><span class="koboSpan" id="kobo.145.2">- Develop a comprehensive plan for creating task lists that will help you structure research, a detailed outline per chapter and individual parts.
</span><span class="koboSpan" id="kobo.145.3">- Be sure to ask the user for feedback and improvements.
</span><span class="koboSpan" id="kobo.145.4">- Continuously assess the current state of the work and use the speak property to give the user positive affirmations.
</span><span class="koboSpan" id="kobo.145.5">ai_name: AuthorGPT
ai_role: An AI-powered author and researcher specializing in creating comprehensive, well-structured, and engaging content on Auto-GPT and its plugins, while maintaining an open line of communication with the user for feedback and guidance.
</span><span class="koboSpan" id="kobo.145.6">api_budget: 120.0</span></pre>			<p><span class="koboSpan" id="kobo.146.1">Let’s look at some of the AI components</span><a id="_idIndexMarker012"/><span class="koboSpan" id="kobo.147.1"> in the </span><span class="No-Break"><span class="koboSpan" id="kobo.148.1">preceding file:</span></span></p>
			<ul>
				<li><span class="koboSpan" id="kobo.149.1">First, we have </span><strong class="source-inline"><span class="koboSpan" id="kobo.150.1">ai_goals</span></strong><span class="koboSpan" id="kobo.151.1">, which specifies the main tasks that Auto-GPT must undertake. </span><span class="koboSpan" id="kobo.151.2">It will use those to decide which individual steps to take. </span><span class="koboSpan" id="kobo.151.3">Each iteration will decide to follow one of </span><span class="No-Break"><span class="koboSpan" id="kobo.152.1">the goals.</span></span></li>
				<li><span class="koboSpan" id="kobo.153.1">Then, we have </span><strong class="source-inline"><span class="koboSpan" id="kobo.154.1">ai_name</span></strong><span class="koboSpan" id="kobo.155.1">, which is also taken as a reference and defines parts of the behavior or character of the bot. </span><span class="koboSpan" id="kobo.155.2">This means that if you call it </span><em class="italic"><span class="koboSpan" id="kobo.156.1">AuthorGPT</span></em><span class="koboSpan" id="kobo.157.1">, it will play the role of a GPT-based author, while if you call it </span><em class="italic"><span class="koboSpan" id="kobo.158.1">Author</span></em><span class="koboSpan" id="kobo.159.1">, it will try to behave like a person. </span><span class="koboSpan" id="kobo.159.2">It is generally hard to tell how it will behave because GPT mostly decides what it puts out on </span><span class="No-Break"><span class="koboSpan" id="kobo.160.1">its own.</span></span></li>
				<li><span class="koboSpan" id="kobo.161.1">Finally, we have </span><strong class="source-inline"><span class="koboSpan" id="kobo.162.1">ai_role</span></strong><span class="koboSpan" id="kobo.163.1">, which can be viewed as a more detailed role description. </span><span class="koboSpan" id="kobo.163.2">However, in my experience, it only nudges the thoughts slightly. </span><span class="koboSpan" id="kobo.163.3">Goals are more </span><span class="No-Break"><span class="koboSpan" id="kobo.164.1">potent here.</span></span></li>
			</ul>
			<p><span class="koboSpan" id="kobo.165.1">Once this is done, it summarizes what it’s going to do and starts </span><span class="No-Break"><span class="koboSpan" id="kobo.166.1">thinking correctly:</span></span></p>
			<p class="IMG---Figure"> </p>
			<div>
				<div id="_idContainer007" class="IMG---Figure">
					<span class="koboSpan" id="kobo.167.1"><img src="image/B21128_01_3.jpg" alt="Figure 1.3 – Example of Auto-GPT’s thought process"/></span>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.168.1">Figure 1.3 – Example of Auto-GPT’s thought process</span></p>
			<p><span class="koboSpan" id="kobo.169.1">Thinking generally means that it is sending a chat completion request to </span><span class="No-Break"><span class="koboSpan" id="kobo.170.1">the LLM.</span></span></p>
			<p><span class="koboSpan" id="kobo.171.1">This process can be slow – the more tokens that are used, the more processing that’s needed. </span><span class="koboSpan" id="kobo.171.2">In the </span><em class="italic"><span class="koboSpan" id="kobo.172.1">Understanding tokens in LLMs</span></em><span class="koboSpan" id="kobo.173.1"> section, we will take a look at what </span><span class="No-Break"><span class="koboSpan" id="kobo.174.1">this means.</span></span></p>
			<p><span class="koboSpan" id="kobo.175.1">Once Auto-GPT has started “thinking,” it initiates a sequence of AI “conversations.” </span><span class="koboSpan" id="kobo.175.2">During these conversations, it forms a query, sends it to the LLM, and then processes the response. </span><span class="koboSpan" id="kobo.175.3">This process repeats until it finds a satisfactory solution or reaches the end of its </span><span class="No-Break"><span class="koboSpan" id="kobo.176.1">thinking time.</span></span></p>
			<p><span class="koboSpan" id="kobo.177.1">This entire process produces thoughts. </span><span class="koboSpan" id="kobo.177.2">These fall into the </span><span class="No-Break"><span class="koboSpan" id="kobo.178.1">following categories:</span></span></p>
			<ul>
				<li><span class="No-Break"><span class="koboSpan" id="kobo.179.1">Reasoning</span></span></li>
				<li><span class="No-Break"><span class="koboSpan" id="kobo.180.1">Planning</span></span></li>
				<li><span class="No-Break"><span class="koboSpan" id="kobo.181.1">Criticism</span></span></li>
				<li><span class="No-Break"><span class="koboSpan" id="kobo.182.1">Speak</span></span></li>
				<li><span class="No-Break"><span class="koboSpan" id="kobo.183.1">Command</span></span></li>
			</ul>
			<p><span class="koboSpan" id="kobo.184.1">These individual thoughts</span><a id="_idIndexMarker013"/><span class="koboSpan" id="kobo.185.1"> are then displayed in the terminal and the user is asked whether they want to approve the command or not – it’s </span><span class="No-Break"><span class="koboSpan" id="kobo.186.1">that simple.</span></span></p>
			<p><span class="koboSpan" id="kobo.187.1">Of course, a lot more goes on here, including a prompt being built to create </span><span class="No-Break"><span class="koboSpan" id="kobo.188.1">that response.</span></span></p>
			<p><span class="koboSpan" id="kobo.189.1">Simply put, Auto-GPT passes</span><a id="_idIndexMarker014"/><span class="koboSpan" id="kobo.190.1"> the name, role, goals, and some background information. </span><span class="koboSpan" id="kobo.190.2">You can see an example </span><span class="No-Break"><span class="koboSpan" id="kobo.191.1">here: </span></span><a href="https://github.com/PacktPublishing/Unlocking-the-Power-of-Auto-GPT-and-Its-Plugins/blob/main/Auto-GPT_thoughts_example.md"><span class="No-Break"><span class="koboSpan" id="kobo.192.1">https://github.com/PacktPublishing/Unlocking-the-Power-of-Auto-GPT-and-Its-Plugins/blob/main/Auto-GPT_thoughts_example.md</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.193.1">.</span></span></p>
			<h2 id="_idParaDest-21"><a id="_idTextAnchor020"/><span class="koboSpan" id="kobo.194.1">Auto-GPT’s thought process – understanding the one-shot action</span></h2>
			<p><span class="koboSpan" id="kobo.195.1">Let’s understand the thought process</span><a id="_idIndexMarker015"/><span class="koboSpan" id="kobo.196.1"> behind this </span><span class="No-Break"><span class="koboSpan" id="kobo.197.1">one-shot action:</span></span></p>
			<ul>
				<li><strong class="bold"><span class="koboSpan" id="kobo.198.1">Overview of the thought process</span></strong><span class="koboSpan" id="kobo.199.1">: Auto-GPT operates on a one-shot action basis. </span><span class="koboSpan" id="kobo.199.2">This approach involves processing each data block that’s sent to OpenAI as a single chat completion action. </span><span class="koboSpan" id="kobo.199.3">The outcome of this process is that a response text from GPT is generated that’s crafted based on a </span><span class="No-Break"><span class="koboSpan" id="kobo.200.1">specified structure.</span></span></li>
				<li><strong class="bold"><span class="koboSpan" id="kobo.201.1">Structure and task definition for GPT</span></strong><span class="koboSpan" id="kobo.202.1">: The structure that’s provided to GPT encompasses both the task at hand and the format for the response. </span><span class="koboSpan" id="kobo.202.2">This dual-component structure ensures that GPT’s responses are not only relevant but also adhere to the expected </span><span class="No-Break"><span class="koboSpan" id="kobo.203.1">conversational format.</span></span></li>
				<li><strong class="bold"><span class="koboSpan" id="kobo.204.1">Role assignment in Auto-GPT</span></strong><span class="koboSpan" id="kobo.205.1">: There are two role </span><span class="No-Break"><span class="koboSpan" id="kobo.206.1">assignments here:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.207.1">System role</span></strong><span class="koboSpan" id="kobo.208.1">: The “system” role is crucial in providing</span><a id="_idIndexMarker016"/><span class="koboSpan" id="kobo.209.1"> context. </span><span class="koboSpan" id="kobo.209.2">It functions as a vessel for information delivery and maintains the historical thread of the conversation with </span><span class="No-Break"><span class="koboSpan" id="kobo.210.1">the LLM.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.211.1">User role</span></strong><span class="koboSpan" id="kobo.212.1">: Toward the end</span><a id="_idIndexMarker017"/><span class="koboSpan" id="kobo.213.1"> of the process, a “user” role is assigned. </span><span class="koboSpan" id="kobo.213.2">This role is pivotal in guiding GPT to determine the subsequent command to execute. </span><span class="koboSpan" id="kobo.213.3">It adheres to a predefined format, ensuring consistency </span><span class="No-Break"><span class="koboSpan" id="kobo.214.1">in interactions.</span></span></li></ul></li>
				<li><strong class="bold"><span class="koboSpan" id="kobo.215.1">Command options and decision-making</span></strong><span class="koboSpan" id="kobo.216.1">: GPT is equipped with various command options, including </span><span class="No-Break"><span class="koboSpan" id="kobo.217.1">the following:</span></span><ul><li><span class="koboSpan" id="kobo.218.1">Ask the </span><span class="No-Break"><span class="koboSpan" id="kobo.219.1">user (</span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.220.1">ask_user</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.221.1">)</span></span></li><li><span class="koboSpan" id="kobo.222.1">Sending </span><span class="No-Break"><span class="koboSpan" id="kobo.223.1">messages (</span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.224.1">send_message</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.225.1">)</span></span></li><li><span class="No-Break"><span class="koboSpan" id="kobo.226.1">Browsing (</span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.227.1">browse</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.228.1">)</span></span></li><li><span class="koboSpan" id="kobo.229.1">Executing </span><span class="No-Break"><span class="koboSpan" id="kobo.230.1">code (</span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.231.1">execute_code</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.232.1">)</span></span></li></ul></li>
			</ul>
			<p><span class="koboSpan" id="kobo.233.1">In some instances, Auto-GPT</span><a id="_idIndexMarker018"/><span class="koboSpan" id="kobo.234.1"> may opt not to select any command. </span><span class="koboSpan" id="kobo.234.2">This typically occurs in situations of confusion, such as when the provided task is unclear or when Auto-GPT completes a task and requires user feedback for </span><span class="No-Break"><span class="koboSpan" id="kobo.235.1">further action.</span></span></p>
			<p><span class="koboSpan" id="kobo.236.1">Either way, each response is only one text and just a text that is being autocompleted, meaning the LLM only responds once with such </span><span class="No-Break"><span class="koboSpan" id="kobo.237.1">a response.</span></span></p>
			<p><span class="koboSpan" id="kobo.238.1">In the following example, I have the planner plugin activated; more on </span><span class="No-Break"><span class="koboSpan" id="kobo.239.1">plugins later:</span></span></p>
			<pre class="source-code"><span class="koboSpan" id="kobo.240.1">
{
"thoughts": {
"text": "I need to start the planning cycle to create a plan for the book.",
"reasoning": "Starting the planning cycle will help me outline the steps needed to achieve my goals.",
"plan":
"- run_planning_cycle
- research Auto-GPT and its plugins
- collaborate with user
- create book structure
- write content
- refine content based on feedback",
"criticism": "I should have started the planning cycle earlier to ensure a smooth start.",
"speak": "I'm going to start the planning cycle to create a plan for the book."
</span><span class="koboSpan" id="kobo.240.2">},
"command": {
"name": "run_planning_cycle",
"args": {}
}
}</span></pre>			<p><span class="koboSpan" id="kobo.241.1">Each thought property</span><a id="_idIndexMarker019"/><span class="koboSpan" id="kobo.242.1"> is then displayed to the user and the “speak” output is read aloud if text-to-speech </span><span class="No-Break"><span class="koboSpan" id="kobo.243.1">is enabled:</span></span></p>
			<pre class="source-code"><span class="koboSpan" id="kobo.244.1">
"I am going to start the planning cycle to create a plan for the book. </span><span class="koboSpan" id="kobo.244.2">I want to run planning cycle."</span></pre>			<p><span class="koboSpan" id="kobo.245.1">The user can now respond in one of the </span><span class="No-Break"><span class="koboSpan" id="kobo.246.1">following ways:</span></span></p>
			<ul>
				<li><strong class="source-inline"><span class="koboSpan" id="kobo.247.1">y</span></strong><span class="koboSpan" id="kobo.248.1">: To accept </span><span class="No-Break"><span class="koboSpan" id="kobo.249.1">the execution.</span></span></li>
				<li><strong class="source-inline"><span class="koboSpan" id="kobo.250.1">n</span></strong><span class="koboSpan" id="kobo.251.1">: To decline the execution and </span><span class="No-Break"><span class="koboSpan" id="kobo.252.1">close Auto-GPT.</span></span></li>
				<li><strong class="source-inline"><span class="koboSpan" id="kobo.253.1">s</span></strong><span class="koboSpan" id="kobo.254.1">: To let Auto-GPT re-evaluate </span><span class="No-Break"><span class="koboSpan" id="kobo.255.1">its decisions.</span></span></li>
				<li><strong class="source-inline"><span class="koboSpan" id="kobo.256.1">y -n</span></strong><span class="koboSpan" id="kobo.257.1">: To tell Auto-GPT to just keep going for the number of steps (for example, enter </span><strong class="source-inline"><span class="koboSpan" id="kobo.258.1">y -5</span></strong><span class="koboSpan" id="kobo.259.1"> to allow it to run on its own for 5 steps). </span><span class="koboSpan" id="kobo.259.2">Here, </span><strong class="source-inline"><span class="koboSpan" id="kobo.260.1">n</span></strong><span class="koboSpan" id="kobo.261.1"> is always </span><span class="No-Break"><span class="koboSpan" id="kobo.262.1">a number.</span></span></li>
			</ul>
			<p><span class="koboSpan" id="kobo.263.1">If the user confirms, the command is executed and the result of that command is added as </span><span class="No-Break"><span class="koboSpan" id="kobo.264.1">system content:</span></span></p>
			<pre class="source-code"><span class="koboSpan" id="kobo.265.1">
# Check if there is a result from the command append it to the message
# history
if result is not None:
self.history.add("system", result, "action_result")</span></pre>			<p><span class="koboSpan" id="kobo.266.1">At this point, you’re probably wondering what history is in this context and </span><span class="No-Break"><span class="koboSpan" id="kobo.267.1">why </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.268.1">self</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.269.1">?</span></span></p>
			<p><span class="koboSpan" id="kobo.270.1">Auto-GPT uses agents and the instance of the agent has its own history that acts as a short-term memory. </span><span class="koboSpan" id="kobo.270.2">It contains the context of what the previous messages and </span><span class="No-Break"><span class="koboSpan" id="kobo.271.1">results were.</span></span></p>
			<p><span class="koboSpan" id="kobo.272.1">The history is trimmed down</span><a id="_idIndexMarker020"/><span class="koboSpan" id="kobo.273.1"> on every run cycle of the agent to make sure it doesn’t reach its </span><span class="No-Break"><span class="koboSpan" id="kobo.274.1">token limit.</span></span></p>
			<p><span class="koboSpan" id="kobo.275.1">So, why not directly ask the LLM for a solution? </span><span class="koboSpan" id="kobo.275.2">There are several reasons </span><span class="No-Break"><span class="koboSpan" id="kobo.276.1">for this:</span></span></p>
			<ul>
				<li><span class="koboSpan" id="kobo.277.1">While LLMs are incredibly sophisticated, they cannot solve complex, multi-step problems in a single query. </span><span class="koboSpan" id="kobo.277.2">Instead, they need to be asked a series of interconnected questions that guide them toward a final solution. </span><span class="koboSpan" id="kobo.277.3">This is where Auto-GPT shines – it can strategically ask these questions and digest </span><span class="No-Break"><span class="koboSpan" id="kobo.278.1">the responses.</span></span></li>
				<li><span class="koboSpan" id="kobo.279.1">LLMs can’t maintain their context. </span><span class="koboSpan" id="kobo.279.2">They don’t remember previous queries or answers, which means they cannot build on past knowledge to answer future questions. </span><span class="koboSpan" id="kobo.279.3">Auto-GPT compensates for this by maintaining a history of the conversation, allowing it to understand the context of previous queries and responses and use that information to craft </span><span class="No-Break"><span class="koboSpan" id="kobo.280.1">new queries.</span></span></li>
				<li><span class="koboSpan" id="kobo.281.1">While LLMs are powerful tools for generating human-like text, they cannot take initiative. </span><span class="koboSpan" id="kobo.281.2">They respond to prompts but don’t actively seek out new tasks or knowledge. </span><span class="koboSpan" id="kobo.281.3">Auto-GPT, on the other hand, is designed to be more proactive. </span><span class="koboSpan" id="kobo.281.4">It not only responds to the tasks that have been assigned to it but also proactively explores diverse ways to accomplish those tasks, making it a true </span><span class="No-Break"><span class="koboSpan" id="kobo.282.1">autonomous agent.</span></span></li>
			</ul>
			<p><span class="koboSpan" id="kobo.283.1">Before we delve deeper into how Auto-GPT utilizes LLMs, it’s important to understand a key component of how these models process </span><span class="No-Break"><span class="koboSpan" id="kobo.284.1">information: </span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.285.1">tokens</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.286.1">.</span></span></p>
			<h1 id="_idParaDest-22"><a id="_idTextAnchor021"/><span class="koboSpan" id="kobo.287.1">Understanding tokens in LLMs</span></h1>
			<p><span class="koboSpan" id="kobo.288.1">Tokens are the fundamental</span><a id="_idIndexMarker021"/><span class="koboSpan" id="kobo.289.1"> building blocks in LLMs</span><a id="_idIndexMarker022"/><span class="koboSpan" id="kobo.290.1"> such as GPT-3 and GPT-4. </span><span class="koboSpan" id="kobo.290.2">They are pieces of knowledge that vary in proximity to each other based on the given context. </span><span class="koboSpan" id="kobo.290.3">A token can represent a word, a symbol, or even</span><a id="_idIndexMarker023"/><span class="koboSpan" id="kobo.291.1"> fragments</span><a id="_idIndexMarker024"/> <span class="No-Break"><span class="koboSpan" id="kobo.292.1">of words.</span></span></p>
			<h2 id="_idParaDest-23"><a id="_idTextAnchor022"/><span class="koboSpan" id="kobo.293.1">Tokenization in language processing</span></h2>
			<p><span class="koboSpan" id="kobo.294.1">When training LLMs, text data</span><a id="_idIndexMarker025"/><span class="koboSpan" id="kobo.295.1"> is broken down into smaller</span><a id="_idIndexMarker026"/><span class="koboSpan" id="kobo.296.1"> units, or tokens. </span><span class="koboSpan" id="kobo.296.2">For instance, the sentence “ChatGPT is great!” </span><span class="koboSpan" id="kobo.296.3">would be divided into tokens such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.297.1">["ChatGPT", "is", "great", "!"]</span></strong><span class="koboSpan" id="kobo.298.1">. </span><span class="koboSpan" id="kobo.298.2">The nature of a token can differ significantly across languages and </span><span class="No-Break"><span class="koboSpan" id="kobo.299.1">coding paradigms:</span></span></p>
			<ul>
				<li><span class="koboSpan" id="kobo.300.1">In English, a token typically signifies a word or part of </span><span class="No-Break"><span class="koboSpan" id="kobo.301.1">a word</span></span></li>
				<li><span class="koboSpan" id="kobo.302.1">In other languages, a token may represent a syllable or </span><span class="No-Break"><span class="koboSpan" id="kobo.303.1">a character</span></span></li>
				<li><span class="koboSpan" id="kobo.304.1">In programming languages, tokens can include keywords, operators, </span><span class="No-Break"><span class="koboSpan" id="kobo.305.1">or variables</span></span></li>
			</ul>
			<p><span class="koboSpan" id="kobo.306.1">Let’s look at some examples</span><a id="_idIndexMarker027"/> <span class="No-Break"><span class="koboSpan" id="kobo.307.1">of tokenization:</span></span></p>
			<ul>
				<li><strong class="bold"><span class="koboSpan" id="kobo.308.1">Natural language</span></strong><span class="koboSpan" id="kobo.309.1">: The sentence “ChatGPT is great!” </span><span class="koboSpan" id="kobo.309.2">tokenizes into </span><strong class="source-inline"><span class="koboSpan" id="kobo.310.1">["ChatGPT", "is", "</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.311.1">great", "!"]</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.312.1">.</span></span></li>
				<li><strong class="bold"><span class="koboSpan" id="kobo.313.1">Programming language</span></strong><span class="koboSpan" id="kobo.314.1">: A Python code line such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.315.1">print("Hello, World!")</span></strong><span class="koboSpan" id="kobo.316.1"> is tokenized as </span><strong class="source-inline"><span class="koboSpan" id="kobo.317.1">["print", "(", " ", "Hello", "," , " ", "World", "!"", ")"]</span></strong><span class="koboSpan" id="kobo.318.1">.</span></li>
			</ul>
			<h2 id="_idParaDest-24"><a id="_idTextAnchor023"/><span class="koboSpan" id="kobo.319.1">Balancing detail and computational resources</span></h2>
			<p><span class="koboSpan" id="kobo.320.1">Tokenization strategies aim to balance detail and computational efficiency. </span><span class="koboSpan" id="kobo.320.2">More tokens provide greater detail but require more resources for processing. </span><span class="koboSpan" id="kobo.320.3">This balance is crucial for the model’s ability to understand and generate text at a </span><span class="No-Break"><span class="koboSpan" id="kobo.321.1">granular level.</span></span></p>
			<h3><span class="koboSpan" id="kobo.322.1">Token limits in LLMs</span></h3>
			<p><span class="koboSpan" id="kobo.323.1">The token limit </span><a id="_idIndexMarker028"/><span class="koboSpan" id="kobo.324.1">signifies the maximum number of tokens that a model</span><a id="_idIndexMarker029"/><span class="koboSpan" id="kobo.325.1"> such as GPT-3 or GPT-4 can handle in a single interaction. </span><span class="koboSpan" id="kobo.325.2">This limit is in place due to the computational resources needed to process large numbers </span><span class="No-Break"><span class="koboSpan" id="kobo.326.1">of tokens.</span></span></p>
			<p><span class="koboSpan" id="kobo.327.1">The token limit also influences the model’s “attention” capability – its ability to prioritize different parts</span><a id="_idIndexMarker030"/><span class="koboSpan" id="kobo.328.1"> of the input during </span><span class="No-Break"><span class="koboSpan" id="kobo.329.1">output</span></span><span class="No-Break"><a id="_idIndexMarker031"/></span><span class="No-Break"><span class="koboSpan" id="kobo.330.1"> generation.</span></span></p>
			<h3><span class="koboSpan" id="kobo.331.1">Implications of token limits</span></h3>
			<p><span class="koboSpan" id="kobo.332.1">A model with a token limit</span><a id="_idIndexMarker032"/><span class="koboSpan" id="kobo.333.1"> may not fully process inputs that exceed this limit. </span><span class="koboSpan" id="kobo.333.2">For example, with a 20-token limit, a 30-token text would need to be broken into smaller segments for the model to process </span><span class="No-Break"><span class="koboSpan" id="kobo.334.1">them effectively.</span></span></p>
			<p><span class="koboSpan" id="kobo.335.1">In programming, tokenization aids in understanding code structure and syntax, which is vital for tasks such as code generation </span><span class="No-Break"><span class="koboSpan" id="kobo.336.1">or interpretation.</span></span></p>
			<p><span class="koboSpan" id="kobo.337.1">In summary, tokenization</span><a id="_idIndexMarker033"/><span class="koboSpan" id="kobo.338.1"> is a critical component in </span><strong class="bold"><span class="koboSpan" id="kobo.339.1">natural language processing</span></strong><span class="koboSpan" id="kobo.340.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.341.1">NLP</span></strong><span class="koboSpan" id="kobo.342.1">), enabling LLMs to interpret and generate text in a meaningful and contextually </span><span class="No-Break"><span class="koboSpan" id="kobo.343.1">accurate manner.</span></span></p>
			<p><span class="koboSpan" id="kobo.344.1">For instance, if you’re using the model to generate Python code and you input </span><strong class="source-inline"><span class="koboSpan" id="kobo.345.1">["print", "("]</span></strong><span class="koboSpan" id="kobo.346.1"> as a token, you’d expect the model to generate tokens that form a valid argument to the print function – for example, </span><strong class="source-inline"><span class="koboSpan" id="kobo.347.1">[""Hello, </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.348.1">World!"", ")"]</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.349.1">.</span></span></p>
			<p><span class="koboSpan" id="kobo.350.1">In the following chapters, we will delve deeper into how Auto-GPT works, its capabilities, and how you can use it to solve complex problems or automate tasks. </span><span class="koboSpan" id="kobo.350.2">We will also cover its plugins, which extend its functionality and allow it to interact with external systems so that it can order a pizza, </span><span class="No-Break"><span class="koboSpan" id="kobo.351.1">for instance.</span></span></p>
			<p><span class="koboSpan" id="kobo.352.1">In a nutshell, Auto-GPT is like a very smart, very persistent assistant that leverages the power of the most advanced AI to accomplish the goals you set for it. </span><span class="koboSpan" id="kobo.352.2">Whether you’re an AI researcher, a developer, or simply someone who is fascinated by the potential of AI, I hope this book will provide you with the knowledge and inspiration you need to make the most </span><span class="No-Break"><span class="koboSpan" id="kobo.353.1">of Auto-GPT.</span></span></p>
			<p><span class="koboSpan" id="kobo.354.1">At the time of writing (June 1, 2023), Auto-GPT can give you feedback not only through the terminal. </span><span class="koboSpan" id="kobo.354.2">There are a variety of text-to-speech engines that are currently built into Auto-GPT. </span><span class="koboSpan" id="kobo.354.3">Depending on what you prefer, you can either use the default, which is Google’s text-to-speech option, ElevenLabs, macOS’ </span><strong class="source-inline"><span class="koboSpan" id="kobo.355.1">say</span></strong><span class="koboSpan" id="kobo.356.1"> command (a low-quality Siri voice pack), or </span><span class="No-Break"><span class="koboSpan" id="kobo.357.1">Silero TTS.</span></span></p>
			<p><span class="koboSpan" id="kobo.358.1">When it comes to plugins, Auto-GPT becomes even more powerful. </span><span class="koboSpan" id="kobo.358.2">Currently, there is an official repository for plugins that contains a list of awesome plugins such as Planner Plugin, Discord, Telegram, Text Generation</span><a id="_idIndexMarker034"/><span class="koboSpan" id="kobo.359.1"> for local or different LLMs, </span><span class="No-Break"><span class="koboSpan" id="kobo.360.1">and more.</span></span></p>
			<p><span class="koboSpan" id="kobo.361.1">This modularity makes Auto-GPT the most exciting thing I’ve ever laid my </span><span class="No-Break"><span class="koboSpan" id="kobo.362.1">hands on.</span></span></p>
			<h1 id="_idParaDest-25"><a id="_idTextAnchor024"/><span class="koboSpan" id="kobo.363.1">Launching and advancing Auto-GPT – a story of innovation and community</span></h1>
			<p><span class="koboSpan" id="kobo.364.1">Auto-GPT’s development </span><a id="_idIndexMarker035"/><span class="koboSpan" id="kobo.365.1">began with a bold vision to make the sophisticated technology of GPT-4 accessible and user-friendly. </span><span class="koboSpan" id="kobo.365.2">This initiative marked the start of an ongoing journey, with the project continually evolving through the integration of new features and improvements. </span><span class="koboSpan" id="kobo.365.3">At its core, Auto-GPT is a collaborative effort, continuously shaped by the input of a dedicated community of developers </span><span class="No-Break"><span class="koboSpan" id="kobo.366.1">and researchers.</span></span></p>
			<p><span class="koboSpan" id="kobo.367.1">The genesis of Auto-GPT</span><a id="_idIndexMarker036"/><span class="koboSpan" id="kobo.368.1"> can be traced back to the discovery of GPT-4’s potential for autonomous task completion. </span><span class="koboSpan" id="kobo.368.2">This breakthrough was the catalyst for creating a platform that could fully utilize GPT-4’s capabilities, offering users extensive control and </span><span class="No-Break"><span class="koboSpan" id="kobo.369.1">customization options.</span></span></p>
			<p><span class="koboSpan" id="kobo.370.1">The project gained initial popularity</span><a id="_idIndexMarker037"/><span class="koboSpan" id="kobo.371.1"> with an early version known as </span><em class="italic"><span class="koboSpan" id="kobo.372.1">Entrepreneur-GPT</span></em><span class="koboSpan" id="kobo.373.1">, a key milestone that showcased Auto-GPT’s capabilities at the time. </span><span class="koboSpan" id="kobo.373.2">This phase of the project (</span><span class="No-Break"><span class="koboSpan" id="kobo.374.1">documented here:</span></span></p>
			<p><a href="https://github.com/PacktPublishing/Unlocking-the-Power-of-Auto-GPT-and-Its-Plugins/blob/main/Entrepreneur-GPT.md"><span class="koboSpan" id="kobo.375.1">https://github.com/PacktPublishing/Unlocking-the-Power-of-Auto-GPT-and-Its-Plugins/blob/main/Entrepreneur-GPT.md</span></a><span class="koboSpan" id="kobo.376.1">) indicates the differences in prompts and functionalities compared to later stages. </span><span class="koboSpan" id="kobo.376.2">A review of the git history reveals Auto-GPT’s early abilities, including online research and using a local database for </span><span class="No-Break"><span class="koboSpan" id="kobo.377.1">long-term memory.</span></span></p>
			<p><span class="koboSpan" id="kobo.378.1">The ascent of Auto-GPT was swift, attracting contributors – including myself – early in its development. </span><span class="koboSpan" id="kobo.378.2">My experience with this open source project was transformative, offering an addictive blend of passion and excitement for innovation. </span><span class="koboSpan" id="kobo.378.3">The dedication of the contributors brought a sense of pride, especially when you can see your work recognized by a wider audience, including </span><span class="No-Break"><span class="koboSpan" id="kobo.379.1">popular YouTubers.</span></span></p>
			<p><span class="koboSpan" id="kobo.380.1">As an open source project, Auto-GPT thrived on voluntary contributions, leading to the formation of a team that significantly enhanced its structure. </span><span class="koboSpan" id="kobo.380.2">This team played a crucial role in managing incoming pull requests and guiding the development paths, thereby continually improving </span><span class="No-Break"><span class="koboSpan" id="kobo.381.1">Auto-GPT’s core.</span></span></p>
			<p><span class="koboSpan" id="kobo.382.1">Despite its growing</span><a id="_idIndexMarker038"/><span class="koboSpan" id="kobo.383.1"> popularity, each new release of Auto-GPT brought enhanced power and functionality. </span><span class="koboSpan" id="kobo.383.2">These releases are stable versions that are meticulously tested by the community to ensure they are bug-free and ready for </span><span class="No-Break"><span class="koboSpan" id="kobo.384.1">public use.</span></span></p>
			<p><span class="koboSpan" id="kobo.385.1">A critical component of Auto-GPT’s evolution</span><a id="_idIndexMarker039"/><span class="koboSpan" id="kobo.386.1"> is its plugins. </span><span class="koboSpan" id="kobo.386.2">These play a major role in the customization of the platform, allowing users to tailor it to their specific needs. </span><span class="koboSpan" id="kobo.386.3">Future discussions will delve deeper into these plugins and will explore their installation, usage, and impact on enhancing Auto-GPT’s capabilities. </span><span class="koboSpan" id="kobo.386.4">This exploration is vital as most customization happens through plugins unless significant contributions are made directly to the core platform through </span><span class="No-Break"><span class="koboSpan" id="kobo.387.1">pull requests.</span></span></p>
			<h1 id="_idParaDest-26"><a id="_idTextAnchor025"/><span class="koboSpan" id="kobo.388.1">Introduction to LangChain</span></h1>
			<p><span class="koboSpan" id="kobo.389.1">Although </span><em class="italic"><span class="koboSpan" id="kobo.390.1">LangChain</span></em><span class="koboSpan" id="kobo.391.1"> itself is not part of Auto-GPT, it is a crucial</span><a id="_idIndexMarker040"/><span class="koboSpan" id="kobo.392.1"> component of Auto-GPT’s development as it focuses on the process using control. </span><span class="koboSpan" id="kobo.392.2">This is in contrast to Auto-GPT’s emphasis on results </span><span class="No-Break"><span class="koboSpan" id="kobo.393.1">without control.</span></span></p>
			<p><span class="koboSpan" id="kobo.394.1">LangChain is a powerful tool that enables users to build implementations of their own Auto-GPT using LLM primitives. </span><span class="koboSpan" id="kobo.394.2">It allows for explicit reasoning and the potential for Auto-GPT to become an </span><span class="No-Break"><span class="koboSpan" id="kobo.395.1">autonomous agent.</span></span></p>
			<p><span class="koboSpan" id="kobo.396.1">With multiple alternatives of Auto-GPT arising, LangChain has become a part of many of them. </span><span class="koboSpan" id="kobo.396.2">One such example </span><span class="No-Break"><span class="koboSpan" id="kobo.397.1">is AgentGPT.</span></span></p>
			<p><span class="koboSpan" id="kobo.398.1">LangChain’s unique approach to language processing and control makes it an essential part of AgentGPT’s functionality. </span><span class="koboSpan" id="kobo.398.2">By combining the strengths of LangChain and Auto-GPT, users can create powerful, customized solutions that leverage the full potential </span><span class="No-Break"><span class="koboSpan" id="kobo.399.1">of GPT.</span></span></p>
			<h2 id="_idParaDest-27"><a id="_idTextAnchor026"/><span class="koboSpan" id="kobo.400.1">The intersection of LangChain and Auto-GPT</span></h2>
			<p><span class="koboSpan" id="kobo.401.1">LangChain and Auto-GPT</span><a id="_idIndexMarker041"/><span class="koboSpan" id="kobo.402.1"> may have different areas of focus, but their shared goal of enhancing the capabilities of LLMs creates a natural synergy between them. </span><span class="koboSpan" id="kobo.402.2">LangChain’s ability to provide a structured, controllable process pairs well with Auto-GPT’s focus on autonomous task completion. </span><span class="koboSpan" id="kobo.402.3">Together, they provide an integrated solution that both controls the method and achieves the goal, striking a balance between the process and </span><span class="No-Break"><span class="koboSpan" id="kobo.403.1">the result.</span></span></p>
			<p><span class="koboSpan" id="kobo.404.1">LangChain enables the explicit reasoning potential within Auto-GPT. </span><span class="koboSpan" id="kobo.404.2">It provides a pathway to transition the model from being a tool for human-directed tasks to a self-governing agent capable of making informed, </span><span class="No-Break"><span class="koboSpan" id="kobo.405.1">reasoned decisions.</span></span></p>
			<p><span class="koboSpan" id="kobo.406.1">In addition, LangChain’s control</span><a id="_idIndexMarker042"/><span class="koboSpan" id="kobo.407.1"> over language processing enhances Auto-GPT’s ability to communicate user-friendly information in JSON format, making it an even more accessible platform for users. </span><span class="koboSpan" id="kobo.407.2">By optimizing language processing and control, LangChain significantly improves Auto-GPT’s interaction </span><span class="No-Break"><span class="koboSpan" id="kobo.408.1">with users.</span></span></p>
			<p><span class="koboSpan" id="kobo.409.1">You can read more</span><a id="_idIndexMarker043"/><span class="koboSpan" id="kobo.410.1"> about </span><span class="No-Break"><span class="koboSpan" id="kobo.411.1">it: </span></span><a href="https://docs.langchain.com/docs/"><span class="No-Break"><span class="koboSpan" id="kobo.412.1">https://docs.langchain.com/docs/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.413.1">.</span></span></p>
			<h1 id="_idParaDest-28"><a id="_idTextAnchor027"/><span class="koboSpan" id="kobo.414.1">Summary</span></h1>
			<p><span class="koboSpan" id="kobo.415.1">In this chapter, we embarked on the exciting journey of exploring Auto-GPT, an innovative AI application that leverages the power of GPT-4 to autonomously solve tasks and operate in a browser environment. </span><span class="koboSpan" id="kobo.415.2">We delved into the history of Auto-GPT, understanding how it evolved from an ambitious experiment to a powerful tool that’s transforming the way we interact </span><span class="No-Break"><span class="koboSpan" id="kobo.416.1">with AI.</span></span></p>
			<p><span class="koboSpan" id="kobo.417.1">We also explored the concept of tokens, which play a crucial role in how LLMs such as GPT-4 process information. </span><span class="koboSpan" id="kobo.417.2">Understanding this fundamental concept will help us better comprehend how Auto-GPT interacts with LLMs to generate meaningful and contextually </span><span class="No-Break"><span class="koboSpan" id="kobo.418.1">relevant responses.</span></span></p>
			<p><span class="koboSpan" id="kobo.419.1">Furthermore, we touched on the role of LangChain, a tool that complements Auto-GPT by providing structured control over language processing. </span><span class="koboSpan" id="kobo.419.2">The intersection of LangChain and Auto-GPT creates a powerful synergy, enhancing the capabilities of Auto-GPT and paving the way for more advanced </span><span class="No-Break"><span class="koboSpan" id="kobo.420.1">AI applications.</span></span></p>
			<p><span class="koboSpan" id="kobo.421.1">As we move forward, we will dive deeper into the workings of Auto-GPT, exploring its plugins, installation process, and how to craft effective prompts. </span><span class="koboSpan" id="kobo.421.2">We will also delve into more advanced topics, such as integrating your own LLM with Auto-GPT, setting up Docker, and safely and effectively using </span><span class="No-Break"><span class="koboSpan" id="kobo.422.1">continuous mode.</span></span></p>
			<p><span class="koboSpan" id="kobo.423.1">Whether you’re an AI enthusiast, a developer, or simply someone curious about the potential of AI, this journey promises to be a fascinating one. </span><span class="koboSpan" id="kobo.423.2">So, buckle up, and let’s continue to unravel the immense potential of </span><span class="No-Break"><span class="koboSpan" id="kobo.424.1">Auto-GPT together!</span></span></p>
		</div>
	</body></html>