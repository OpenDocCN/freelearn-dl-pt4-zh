["```py\nwget http://vision.grasp.upenn.edu/video/FLIC-full.zip\n```", "```py\nunzip FLIC-full.zip\n```", "```py\nrm -rf FLIC-full.zip\n```", "```py\ncd FLIC-full\n```", "```py\nwget http://cims.nyu.edu/~tompson/data/tr_plus_indices.mat\n```", "```py\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport os\nimport random\nimport glob\nimport h5py\nfrom scipy.io import loadmat\nimport numpy as np\nimport pandas as pd\nimport cv2 as cv\nfrom __future__ import print_function\n\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.models import Sequential, Model\nfrom keras.layers.core import Flatten, Dense, Dropout\nfrom keras.optimizers import Adam\nfrom keras import backend as K\nfrom keras import applications\nK.clear_session()\n```", "```py\n# set seed for reproducibility\nseed_val = 9000\nnp.random.seed(seed_val)\nrandom.seed(seed_val)\n```", "```py\n# load the examples file\nexamples = loadmat('FLIC-full/examples.mat')\n\n# print type of the loaded file\nprint('examples variable is of', type(examples))\n\n# print keys in the dictionary examples\nprint('keys in the dictionary examples:\\n', examples.keys())ut\n```", "```py\n# print type and shape of values in examples key\nprint('Shape of value in examples key: ',examples['examples'].shape)\n\n# print examples\nprint('Type: ',type(examples['examples']))\n\n# reshape the examples array \nexamples = examples['examples'].reshape(-1,)\n\n# print shape of examples array\nprint(\"Shape of reshaped 'examples' array:\", examples.shape)\n```", "```py\nprint('Coordinates at location/index 3 of example 0:\\n' ,examples[0][2].T)\n\nprint('\\n Data type in which the coordinates are stored: ',type(examples[0][2]))\n\nprint('\\n Shape of the coordinates:', examples[0][2].shape)\n\nprint('\\n Name of the image file the above coordinates correspond to :\\n ',examples[0][3][0])\n```", "```py\n# each coordinate corresponds to the the below listed body joints/locations and in the same order\njoint_labels = ['lsho', 'lelb', 'lwri', 'rsho', 'relb', 'rwri', 'lhip',\n               'lkne', 'lank', 'rhip', 'rkne', 'rank', 'leye', 'reye',\n                'lear', 'rear', 'nose', 'msho', 'mhip', 'mear', 'mtorso',\n                'mluarm', 'mruarm', 'mllarm', 'mrlarm', 'mluleg', 'mruleg',\n                'mllleg', 'mrlleg']\n\n# print joint_labels\nprint(joint_labels)\n```", "```py\n# print list of known joints\nknown_joints = [x for i,x in enumerate(joint_labels) if i in np.r_[0:7, 9, 12:14, 16]]\nprint(known_joints)\n```", "```py\n# print needed joints for the task\ntarget_joints = ['lsho', 'lelb', 'lwri', 'rsho', 'relb',\n                 'rwri', 'leye', 'reye', 'nose']\nprint('Joints necessary for the project:\\n', target_joints)\n\n# print the indices of the needed joints in the coordinates array\njoints_loc_id = np.r_[0:6, 12:14, 16]\nprint('\\nIndices of joints necessary for the project:\\n',joints_loc_id)\n```", "```py\ndef joint_coordinates(joint):\n    \"\"\"Store necessary coordinates to a list\"\"\"\n    joint_coor = []\n    # Take mean of the leye, reye, nose to obtain coordinates for the head\n    joint['head'] = (joint['leye']+joint['reye']+joint['nose'])/3\n    joint_coor.extend(joint['lwri'].tolist())\n    joint_coor.extend(joint['lelb'].tolist())\n    joint_coor.extend(joint['lsho'].tolist())\n    joint_coor.extend(joint['head'].tolist())\n    joint_coor.extend(joint['rsho'].tolist())\n    joint_coor.extend(joint['relb'].tolist())\n    joint_coor.extend(joint['rwri'].tolist())\n    return joint_coor\n```", "```py\n# load the indices matlab file\ntrain_indices = loadmat('FLIC-full/tr_plus_indices.mat')\n\n# print type of the loaded file\nprint('train_indices variable is of', type(train_indices))\n\n# print keys in the dictionary training_indices\nprint('keys in the dictionary train_indices:\\n', train_indices.keys())\n```", "```py\n# print type and shape of values in tr_plus_indices key\nprint('Shape of values in tr_plus_indices key: ',train_indices['tr_plus_indices'].shape)\n\n# print tr_plus_indices\nprint('Type: ',type(train_indices['tr_plus_indices']))\n\n# reshape the training_indices array \ntrain_indices = train_indices['tr_plus_indices'].reshape(-1,)\n\n# print shape of train_indices array\nprint(\"Shape of reshaped 'train_indices' array:\", train_indices.shape)\n```", "```py\n# empty list to store train image ids\ntrain_ids = []\n# empty list to store train joints\ntrain_jts = []\n# empty list to store test image ids\ntest_ids = []\n# empty list to store test joints\ntest_jts = []\n\nfor i, example in enumerate(examples):\n    # image id\n    file_name = example[3][0]\n    # joint coordinates\n    joint = example[2].T\n    # dictionary that goes into the joint_coordinates function\n    joints = dict(zip(target_joints, [x for k,x in enumerate(joint) if k in joints_loc_id]))\n    # obtain joints for the task\n    joints = joint_coordinates(joints)\n    # use train indices list to decide if an image is to be used for training or testing\n    if i in train_indices:\n        train_ids.append(file_name)\n        train_jts.append(joints)\n    else:\n        test_ids.append(file_name)\n        test_jts.append(joints)\n\n# Concatenate image ids dataframe and the joints dataframe and save it as a csv\n```", "```py\n# load train_joints.csv\ntrain_data = pd.read_csv('FLIC-full/train_joints.csv', header=None)\n\n# load test_joints.csv\ntest_data = pd.read_csv('FLIC-full/test_joints.csv', header = None)\n\n# train image ids\ntrain_image_ids = train_data[0].values\nprint('train_image_ids shape', train_image_ids.shape)\n\n# train joints\ntrain_joints = train_data.iloc[:,1:].values\nprint('train_image_ids shape', train_joints.shape)\n\n# test image ids\ntest_image_ids = test_data[0].values\nprint('train_image_ids shape', test_image_ids.shape)\n\n# test joints\ntest_joints = test_data.iloc[:,1:].values\nprint('train_image_ids shape', test_joints.shape)\n```", "```py\nimport glob\nimage_list = glob.glob('FLIC-full/images/*.jpg')[0:8]\n\nplt.figure(figsize=(12,5))\nfor i in range(8):\n    plt.subplot(2,4,(i+1))\n    img = plt.imread(image_list[i])\n    plt.imshow(img, aspect='auto')\n    plt.axis('off')\n    plt.title('Shape: '+str(img.shape))\n\nplt.tight_layout()\nplt.show()\n```", "```py\ndef image_cropping(image_id, joints, crop_pad_inf = 1.4, crop_pad_sup=1.6, shift = 5, min_dim = 100):\n    \"\"\"Function to crop original images\"\"\"\n    ## image cropping\n # load the image \n    image = cv.imread('FLIC-full/images/%s' % (image_id))\n    # convert joint list to array \n    joints = np.asarray([int(float(p)) for p in joints])\n    # reshape joints to shape (7*2)\n    joints = joints.reshape((len(joints) // 2, 2))\n    # transform joints to list of (x,y) tuples\n    posi_joints = [(j[0], j[1]) for j in joints if j[0] > 0 and j[1] > 0]\n    # obtain the bounding rectangle using opencv boundingRect\n    x_loc, y_loc, width, height = cv.boundingRect(np.asarray([posi_joints]))\n    if width < min_dim:\n        width = min_dim\n    if height < min_dim:\n        height = min_dim\n\n    ## bounding rect extending\n    inf, sup = crop_pad_inf, crop_pad_sup\n    r = sup - inf\n    # define width padding\n    pad_w_r = np.random.rand() * r + inf # inf~sup\n    # define height padding\n    pad_h_r = np.random.rand() * r + inf # inf~sup\n    # adjust x, y, w and h by the defined padding\n    x_loc -= (width * pad_w_r - width) / 2\n    y_loc -= (height * pad_h_r - height) / 2\n    width *= pad_w_r\n    height *= pad_h_r\n\n    ## shifting\n    ## clipping\n    ## joint shifting\n```", "```py\n# plot the original image \nplt.figure(figsize = (15,5))\nplt.subplot(1,2,1)\nplt.title('Original')\nplt.imshow(plt.imread('FLIC-full/images/'+train_image_ids[0]))\n\n# plot the cropped image\nimage, joint = image_cropping(train_image_ids[0], train_joints[0])\nplt.subplot(1,2,2)\nplt.title('Cropped')\nplt.imshow(image)\n```", "```py\ndef image_resize(image, joints, new_size = 224):\n    \"\"\"Function resize cropped images\"\"\"\n    orig_h, orig_w = image.shape[:2]\n    joints[0::2] = joints[0::2] / float(orig_w) * new_size\n    joints[1::2] = joints[1::2] / float(orig_h) * new_size\n    image = cv.resize(image, (new_size, new_size), interpolation=cv.INTER_NEAREST)\n    return image, joints\n# plot resized image\nimage, joint = image_resize(image, joint)\nplt.title('Cropped + Resized')\nplt.imshow(image)\n```", "```py\ndef plot_limb(img, joints, i, j, color):\n    \"\"\"Function to plot the limbs\"\"\"\n    cv.line(img, joints[i], joints[j], (255, 255, 255), thickness=2, lineType=16)\n    cv.line(img, joints[i], joints[j], color, thickness=1, lineType=16)\n    return img\n\ndef plot_joints(img, joints, groundtruth=True, text_scale=0.5):\n    \"\"\"Function to draw the joints\"\"\"\n    h, w, c = img.shape\n    if groundtruth:\n        # left hand to left elbow\n        img = plot_limb(img, joints, 0, 1, (0, 255, 0))\n\n        # left elbow to left shoulder\n        img = plot_limb(img, joints, 1, 2, (0, 255, 0))\n\n        # left shoulder to right shoulder\n        img = plot_limb(img, joints, 2, 4, (0, 255, 0))\n\n        # right shoulder to right elbow\n        img = plot_limb(img, joints, 4, 5, (0, 255, 0))\n\n        # right elbow to right hand\n        img = plot_limb(img, joints, 5, 6, (0, 255, 0))\n\n        # neck coordinate\n        neck = tuple((np.array(joints[2]) + np.array(joints[4])) // 2)\n        joints.append(neck)\n        # neck to head\n        img = plot_limb(img, joints, 3, 7, (0, 255, 0))\n        joints.pop()\n\n    # joints\n    for j, joint in enumerate(joints):\n        # plot joints\n        cv.circle(img, joint, 5, (0, 255, 0), -1)\n        # plot joint number black\n        cv.putText(img, '%d' % j, joint, cv.FONT_HERSHEY_SIMPLEX, text_scale,\n                   (0, 0, 0), thickness=2, lineType=16)\n        # plot joint number white\n        cv.putText(img, '%d' % j, joint, cv.FONT_HERSHEY_SIMPLEX, text_scale,\n                   (255, 255, 255), thickness=1, lineType=16)\n\n    else:\n```", "```py\ndef model_data(image_ids, joints, train = True):\n    \"\"\"Function to generate train and test data.\"\"\"\n    if train:\n        # empty list \n        train_img_joints = []\n\n        # create train directory inside FLIC-full\n        if not os.path.exists(os.path.join(os.getcwd(), 'FLIC-full/train')):\n            os.mkdir('FLIC-full/train')\n\n        for i, (image, joint) in enumerate(zip(image_ids, joints)):\n            # crop the image using the joint coordinates\n            image, joint = image_cropping(image, joint)\n\n            # resize the cropped image to shape (224*224*3)\n            image, joint = image_resize(image, joint)\n\n            # save the image in train folder\n            cv.imwrite('FLIC-full/train/train{}.jpg'.format(i), image)\n\n            # store joints and image id/file name of the saved image in the initialized list\n            train_img_joints.append(['train{}.jpg'.format(i)] + joint.tolist())\n\n        # convert to a dataframe and save as a csv\n        pd.DataFrame(train_img_joints).to_csv('FLIC-full/train/train_joints.csv', index=False, header=False)\n    else:\n        # empty list \n        test_img_joints = []\n```", "```py\n# Number of epochs\nepochs = 3\n\n# Batchsize\nbatch_size = 128\n\n# Optimizer for the model\noptimizer = Adam(lr=0.0001, beta_1=0.5)\n\n# Shape of the input image\ninput_shape = (224, 224, 3)\n\n# Batch interval at which loss is to be stored\nstore = 40\n```", "```py\n# load the VGG16 model \nmodel = applications.VGG16(weights = \"imagenet\", include_top=False, input_shape = input_shape)\n\n# print summary of VGG16 model\nmodel.summary()\n```", "```py\n# set layers as non trainable\nfor layer in model.layers:\n    layer.trainable = False\n```", "```py\n# Adding custom Layers\nx = model.output\nx = Flatten()(x)\nx = Dense(1024, activation=\"relu\")(x)\nx = Dropout(0.5)(x)\nx = Dense(1024, activation=\"relu\")(x)\n\n# Dense layer with 14 neurons for predicting 14 numeric values\npredictions = Dense(14, activation=\"relu\")(x)\n```", "```py\n# creating the final model \nmodel_final = Model(inputs = model.input, outputs = predictions)\n\n# print summary\nmodel_final.summary()\n```", "```py\n# compile the model \nmodel_final.compile(loss = \"mean_squared_error\", optimizer = optimizer)\n```", "```py\n# load the train data\ntrain = pd.read_csv('FLIC-full/train/train_joints.csv', header = None)\n\n# split train into train and validation\ntrain_img_ids, val_img_ids, train_jts, val_jts = train_test_split(train.iloc[:,0], train.iloc[:,1:], test_size=0.2, random_state=42)\n\n# load validation images\nval_images = np.array([cv.imread('FLIC-full/train/{}'.format(x)) for x in val_img_ids.values])\n\n# convert validation images to dtype float \nval_images = val_images.astype(float)\n```", "```py\ndef training(model, image_ids, joints ,val_images, val_jts, batch_size = 128, epochs=3, store = 40):\n    # empty train loss list\n    loss_lst = []\n\n    # empty validation loss list\n    val_loss_lst = []\n\n    # counter\n    count = 0\n    count_lst = []\n\n    # create shuffled batches\n    batches = np.arange(len(image_ids)//batch_size)\n    data_idx = np.arange(len(image_ids))\n    random.shuffle(data_idx)\n    print('......Training......')\n    for epoch in range(epochs):\n        for batch in (batches):\n            # batch of training image ids\n            imgs = image_ids[data_idx[batch*batch_size : (batch+1)*batch_size:]]\n\n            # corresponding joints for the above images\n            jts = joints[data_idx[batch*batch_size : (batch+1)*batch_size:]]\n\n            # load the training image batch\n            batch_imgs = np.array([cv.imread('FLIC-full/train/{}'.format(x)) for x in imgs])\n\n            # fit model on the batch\n            loss = model.train_on_batch(batch_imgs.astype(float), jts)\n\n            if batch%store==0:\n```", "```py\nplt.style.use('ggplot')\nplt.figure(figsize=(10, 6))\nplt.plot(count_lst, loss_lst, marker='D', label = 'training_loss')\nplt.plot(count_lst, val_loss_lst, marker='o', label = 'validation_loss')\nplt.ylabel('Mean Squared Error')\nplt.title('Plot of MSE over time')\nplt.legend(loc = 'upper right')\nplt.show()\n```", "```py\ndef test(model, nrows=200, batch_size=128):\n    # load the train data\n    test = pd.read_csv('FLIC-full/test/test_joints.csv', header = None, nrows=nrows)\n    test_img_ids = test.iloc[:,0].values\n\n    # load validation images\n    test_images = np.array([cv.imread('FLIC-full/test/{}'.format(x)) for x in test_img_ids])\n\n    # convert validation images to dtype float \n    test_images = test_images.astype(float)\n\n    # joints\n    test_joints = test.iloc[:,1:].values\n\n    # evaluate\n    test_loss = model.evaluate(test_images, test_joints, verbose = 0, batch_size=batch_size)\n\n    # predict\n    predictions = model.predict(test_images, verbose = 0, batch_size=batch_size)\n\n    # folder to save the results\n    if not os.path.exists(os.path.join(os.getcwd(), 'FLIC-full/test_plot')):\n        os.mkdir('FLIC-full/test_plot')\n\n    for i, (ids, image, joint, pred) in enumerate(zip(test_img_ids, test_images, test_joints, predictions)):\n        joints = joint.tolist()\n        joints = list(zip(joints[0::2], joints[1::2]))\n\n        # plot original joints\n        image = plot_joints(image.astype(np.uint8), joints, groundtruth=True, text_scale=0.5)\n\n        pred = pred.astype(np.uint8).tolist()\n        pred = list(zip(pred[0::2], pred[1::2]))\n\n        # plot predicted joints\n        image = plot_joints(image.astype(np.uint8), pred, groundtruth=False, text_scale=0.5)\n\n        # save resulting images with the same id\n        plt.imsave('FLIC-full/test_plot/'+ids, image)\n    return test_loss\n\n# test and save results\ntest_loss = test(m, batch_size)\n\n# print test loss\nprint('Test Loss:', test_loss)\n```", "```py\nimage_list = glob.glob('FLIC-full/test_plot/*.jpg')[8:16]\n\nplt.figure(figsize=(16,8))\nfor i in range(8):\n    plt.subplot(2,4,(i+1))\n    img = cv.imread(image_list[i])\n    plt.imshow(img, aspect='auto')\n    plt.axis('off')\n    plt.title('Green-True/Red-Predicted Joints')\n\nplt.tight_layout()\nplt.show()\n```", "```py\n\"\"\"This module contains functions to crop and resize images.\"\"\"\n\nimport os\nimport cv2 as cv\nimport numpy as np\nimport pandas as pd\n\ndef image_cropping(image_id, joints, crop_pad_inf=1.4, crop_pad_sup=1.6,\n                   shift=5, min_dim=100):\n    \"\"\"Crop Function.\"\"\"\n    # # image cropping\n    # load the image\n    image = cv.imread('FLIC-full/images/%s' % (image_id))\n    # convert joint list to array\n    joints = np.asarray([int(float(p)) for p in joints])\n    # reshape joints to shape (7*2)\n    joints = joints.reshape((len(joints) // 2, 2))\n    # transform joints to list of (x,y) tuples\n    posi_joints = [(j[0], j[1]) for j in joints if j[0] > 0 and j[1] > 0]\n    # obtain the bounding rectangle using opencv boundingRect\n    x_loc, y_loc, width, height = cv.boundingRect(np.asarray([posi_joints]))\n    if width < min_dim:\n        width = min_dim\n    if height < min_dim:\n        height = min_dim\n\n    # # bounding rect extending\n    inf, sup = crop_pad_inf, crop_pad_sup\n    r = sup - inf\n    # define width padding\n    pad_w_r = np.random.rand() * r + inf # inf~sup\n    # define height padding\n    pad_h_r = np.random.rand() * r + inf # inf~sup\n    # adjust x, y, w and h by the defined padding\n    x_loc -= (width * pad_w_r - width) / 2\n    y_loc -= (height * pad_h_r - height) / 2\n    width *= pad_w_r\n    height *= pad_h_r\n\n    # # shifting\n    x_loc += np.random.rand() * shift * 2 - shift\n    y_loc += np.random.rand() * shift * 2 - shift\n\n    # # clipping\n    x_loc, y_loc, width, height = [int(z) for z in [x_loc, y_loc,\n                                                    width, height]]\n    x_loc = np.clip(x_loc, 0, image.shape[1] - 1)\n    y_loc = np.clip(y_loc, 0, image.shape[0] - 1)\n    width = np.clip(width, 1, image.shape[1] - (x_loc + 1))\n    height = np.clip(height, 1, image.shape[0] - (y_loc + 1))\n    image = image[y_loc: y_loc + height, x_loc: x_loc + width]\n\n    # # joint shifting\n    # adjust joint coordinates onto the padded image\n    joints = np.asarray([(j[0] - x_loc, j[1] - y_loc) for j in joints])\n    joints = joints.flatten()\n\n    return image, joints\n\ndef image_resize(image, joints, new_size=224):\n    \"\"\"Resize Function.\"\"\"\n    orig_h, orig_w = image.shape[:2]\n    joints[0::2] = joints[0::2] / float(orig_w) * new_size\n    joints[1::2] = joints[1::2] / float(orig_h) * new_size\n    image = cv.resize(image, (new_size, new_size),\n                      interpolation=cv.INTER_NEAREST)\n    return image, joints\n\ndef model_data(image_ids, joints, train=True):\n    \"\"\"Function to generate train and test data.\"\"\"\n    if train:\n        # empty list\n        train_img_joints = []\n        # create train directory inside FLIC-full\n        if not os.path.exists(os.path.join(os.getcwd(), 'FLIC-full/train')):\n            os.mkdir('FLIC-full/train')\n\n        for i, (image, joint) in enumerate(zip(image_ids, joints)):\n            # crop the image using the joint coordinates\n            image, joint = image_cropping(image, joint)\n            # resize the cropped image to shape (224*224*3)\n            image, joint = image_resize(image, joint)\n            # save the image in train folder\n            cv.imwrite('FLIC-full/train/train{}.jpg'.format(i), image)\n            # store joints and image id/file name of the saved image in\n            # the initialized list\n            train_img_joints.append(['train{}.jpg'.format(i)] + joint.tolist())\n\n        # convert to a dataframe and save as a csv\n        pd.DataFrame(train_img_joints\n                     ).to_csv('FLIC-full/train/train_joints.csv',\n                              index=False, header=False)\n    else:\n        # empty list\n        test_img_joints = []\n        # create test directory inside FLIC-full\n        if not os.path.exists(os.path.join(os.getcwd(), 'FLIC-full/test')):\n            os.mkdir('FLIC-full/test')\n\n        for i, (image, joint) in enumerate(zip(image_ids, joints)):\n            # crop the image using the joint coordinates\n            image, joint = image_cropping(image, joint)\n            # resize the cropped image to shape (224*224*3)\n            image, joint = image_resize(image, joint)\n            # save the image in test folder\n            cv.imwrite('FLIC-full/test/test{}.jpg'.format(i), image)\n            # store joints and image id/file name of the saved image\n            # in the initialized list\n            test_img_joints.append(['test{}.jpg'.format(i)] + joint.tolist())\n\n        # convert to a dataframe and save as a csv\n        pd.DataFrame(test_img_joints).to_csv('FLIC-full/test/test_joints.csv',\n                                             index=False, header=False)\n```", "```py\n\"\"\"This module contains functions to plot the joints and the limbs.\"\"\"\nimport cv2 as cv\nimport numpy as np\n\ndef plot_limb(img, joints, i, j, color):\n    \"\"\"Limb plot function.\"\"\"\n    cv.line(img, joints[i], joints[j], (255, 255, 255), thickness=2,\n            lineType=16)\n    cv.line(img, joints[i], joints[j], color, thickness=1, lineType=16)\n    return img\n\ndef plot_joints(img, joints, groundtruth=True, text_scale=0.5):\n    \"\"\"Joint and Limb plot function.\"\"\"\n    h, w, c = img.shape\n    if groundtruth:\n        # left hand to left elbow\n        img = plot_limb(img, joints, 0, 1, (0, 255, 0))\n\n        # left elbow to left shoulder\n        img = plot_limb(img, joints, 1, 2, (0, 255, 0))\n\n        # left shoulder to right shoulder\n        img = plot_limb(img, joints, 2, 4, (0, 255, 0))\n\n        # right shoulder to right elbow\n        img = plot_limb(img, joints, 4, 5, (0, 255, 0))\n\n        # right elbow to right hand\n        img = plot_limb(img, joints, 5, 6, (0, 255, 0))\n\n        # neck coordinate\n        neck = tuple((np.array(joints[2]) + np.array(joints[4])) // 2)\n        joints.append(neck)\n        # neck to head\n        img = plot_limb(img, joints, 3, 7, (0, 255, 0))\n        joints.pop()\n\n    # joints\n    for j, joint in enumerate(joints):\n        # plot joints\n        cv.circle(img, joint, 5, (0, 255, 0), -1)\n        # plot joint number black\n        cv.putText(img, '%d' % j, joint, cv.FONT_HERSHEY_SIMPLEX, text_scale,\n                   (0, 0, 0), thickness=2, lineType=16)\n        # plot joint number white\n        cv.putText(img, '%d' % j, joint, cv.FONT_HERSHEY_SIMPLEX, text_scale,\n                   (255, 255, 255), thickness=1, lineType=16)\n\n    else:\n        # left hand to left elbow\n        img = plot_limb(img, joints, 0, 1, (0, 0, 255))\n\n        # left elbow to left shoulder\n        img = plot_limb(img, joints, 1, 2, (0, 0, 255))\n\n        # left shoulder to right shoulder\n        img = plot_limb(img, joints, 2, 4, (0, 0, 255))\n\n        # right shoulder to right elbow\n        img = plot_limb(img, joints, 4, 5, (0, 0, 255))\n\n        # right elbow to right hand\n        img = plot_limb(img, joints, 5, 6, (0, 0, 255))\n\n        # neck coordinate\n        neck = tuple((np.array(joints[2]) + np.array(joints[4])) // 2)\n        joints.append(neck)\n\n        # neck to head\n        img = plot_limb(img, joints, 3, 7, (0, 0, 255))\n        joints.pop()\n\n    # joints\n    for j, joint in enumerate(joints):\n        # plot joints\n        cv.circle(img, joint, 5, (0, 0, 255), -1)\n        # plot joint number black\n        cv.putText(img, '%d' % j, joint, cv.FONT_HERSHEY_SIMPLEX, text_scale,\n                   (0, 0, 0), thickness=3, lineType=16)\n        # plot joint number white\n        cv.putText(img, '%d' % j, joint, cv.FONT_HERSHEY_SIMPLEX, text_scale,\n                   (255, 255, 255), thickness=1, lineType=16)\n\n    return img\n```", "```py\n\"\"\"This module contains the function to test the vgg16 model performance.\"\"\"\nfrom plotting import *\n\nimport os\nimport pandas as pd\nimport numpy as np\nimport cv2 as cv\nimport matplotlib.pyplot as plt\n\ndef test(model, nrows=200, batch_size=128):\n    \"\"\"Test trained vgg16.\"\"\"\n    # load the train data\n    test = pd.read_csv('FLIC-full/test/test_joints.csv', header=None,\n                       nrows=nrows)\n    test_img_ids = test.iloc[:, 0].values\n\n    # load validation images\n    test_images = np.array(\n            [cv.imread('FLIC-full/test/{}'.format(x)) for x in test_img_ids])\n\n    # convert validation images to dtype float\n    test_images = test_images.astype(float)\n\n    # joints\n    test_joints = test.iloc[:, 1:].values\n\n    # evaluate\n    test_loss = model.evaluate(test_images, test_joints,\n                               verbose=0, batch_size=batch_size)\n\n    # predict\n    predictions = model.predict(test_images, verbose=0, batch_size=batch_size)\n\n    # folder to save the results\n    if not os.path.exists(os.path.join(os.getcwd(), 'FLIC-full/test_plot')):\n        os.mkdir('FLIC-full/test_plot')\n\n    for i, (ids, image, joint, pred) in enumerate(zip(test_img_ids,\n                                                      test_images,\n                                                      test_joints,\n                                                      predictions)):\n        joints = joint.tolist()\n        joints = list(zip(joints[0::2], joints[1::2]))\n\n        # plot original joints\n        image = plot_joints(image.astype(np.uint8), joints,\n                            groundtruth=True, text_scale=0.5)\n\n        pred = pred.astype(np.uint8).tolist()\n        pred = list(zip(pred[0::2], pred[1::2]))\n\n        # plot predicted joints\n        image = plot_joints(image.astype(np.uint8), pred,\n                            groundtruth=False, text_scale=0.5)\n\n        # save resulting images with the same id\n        plt.imsave('FLIC-full/test_plot/'+ids, image)\n    return test_loss\n```", "```py\n\"\"\"This module imports other modules to train the vgg16 model.\"\"\"\nfrom __future__ import print_function\n\nfrom crop_resize_transform import model_data\nfrom test import test\n\nimport matplotlib.pyplot as plt\n\nimport random\nfrom scipy.io import loadmat\nimport numpy as np\nimport pandas as pd\nimport cv2 as cv\nimport glob\n\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom keras.layers import Flatten, Dense, Dropout\nfrom keras import backend as K\nfrom keras import applications\nK.clear_session()\n\n# set seed for reproducibility\nseed_val = 9000\nnp.random.seed(seed_val)\nrandom.seed(seed_val)\n\n# load the examples file\nexamples = loadmat('FLIC-full/examples.mat')\n# reshape the examples array\nexamples = examples['examples'].reshape(-1,)\n\n# each coordinate corresponds to the the below listed body joints/locations\n# in the same order\njoint_labels = ['lsho', 'lelb', 'lwri', 'rsho', 'relb', 'rwri', 'lhip',\n                'lkne', 'lank', 'rhip', 'rkne', 'rank', 'leye', 'reye',\n                'lear', 'rear', 'nose', 'msho', 'mhip', 'mear', 'mtorso',\n                'mluarm', 'mruarm', 'mllarm', 'mrlarm', 'mluleg', 'mruleg',\n                'mllleg', 'mrlleg']\n\n# print list of known joints\nknown_joints = [x for i, x in enumerate(joint_labels) if i in np.r_[0:7, 9,\n                                                                    12:14, 16]]\ntarget_joints = ['lsho', 'lelb', 'lwri', 'rsho', 'relb',\n                 'rwri', 'leye', 'reye', 'nose']\n# indices of the needed joints in the coordinates array\njoints_loc_id = np.r_[0:6, 12:14, 16]\n\ndef joint_coordinates(joint):\n    \"\"\"Store necessary coordinates to a list.\"\"\"\n    joint_coor = []\n    # Take mean of the leye, reye, nose to obtain coordinates for the head\n    joint['head'] = (joint['leye']+joint['reye']+joint['nose'])/3\n    joint_coor.extend(joint['lwri'].tolist())\n    joint_coor.extend(joint['lelb'].tolist())\n    joint_coor.extend(joint['lsho'].tolist())\n    joint_coor.extend(joint['head'].tolist())\n    joint_coor.extend(joint['rsho'].tolist())\n    joint_coor.extend(joint['relb'].tolist())\n    joint_coor.extend(joint['rwri'].tolist())\n    return joint_coor\n\n# load the indices matlab file\ntrain_indices = loadmat('FLIC-full/tr_plus_indices.mat')\n# reshape the training_indices array\ntrain_indices = train_indices['tr_plus_indices'].reshape(-1,)\n\n# empty list to store train image ids\ntrain_ids = []\n# empty list to store train joints\ntrain_jts = []\n# empty list to store test image ids\ntest_ids = []\n# empty list to store test joints\ntest_jts = []\n\nfor i, example in enumerate(examples):\n    # image id\n    file_name = example[3][0]\n    # joint coordinates\n    joint = example[2].T\n    # dictionary that goes into the joint_coordinates function\n    joints = dict(zip(target_joints,\n                      [x for k, x in enumerate(joint) if k in joints_loc_id]))\n    # obtain joints for the task\n    joints = joint_coordinates(joints)\n    # use train indices list to decide if an image is to be used for training\n    # or testing\n    if i in train_indices:\n        train_ids.append(file_name)\n        train_jts.append(joints)\n    else:\n        test_ids.append(file_name)\n        test_jts.append(joints)\n\n# Concatenate image ids dataframe and the joints dataframe and save it as a csv\ntrain_df = pd.concat([pd.DataFrame(train_ids), pd.DataFrame(train_jts)],\n                     axis=1)\ntest_df = pd.concat([pd.DataFrame(test_ids), pd.DataFrame(test_jts)], axis=1)\ntrain_df.to_csv('FLIC-full/train_joints.csv', index=False, header=False)\ntest_df.to_csv('FLIC-full/test_joints.csv', index=False, header=False)\n\n# load train_joints.csv\ntrain_data = pd.read_csv('FLIC-full/train_joints.csv', header=None)\n# load test_joints.csv\ntest_data = pd.read_csv('FLIC-full/test_joints.csv', header=None)\n\n# train image ids\ntrain_image_ids = train_data[0].values\n# train joints\ntrain_joints = train_data.iloc[:, 1:].values\n# test image ids\ntest_image_ids = test_data[0].values\n# test joints\ntest_joints = test_data.iloc[:, 1:].values\n\nmodel_data(train_image_ids, train_joints, train=True)\nmodel_data(test_image_ids, test_joints, train=False)\n\n# Number of epochs\nepochs = 3\n# Batchsize\nbatch_size = 128\n# Optimizer for the model\noptimizer = Adam(lr=0.0001, beta_1=0.5)\n# Shape of the input image\ninput_shape = (224, 224, 3)\n# Batch interval at which loss is to be stores\nstore = 40\n\n# load the vgg16 model\nmodel = applications.VGG16(weights=\"imagenet\", include_top=False,\n                           input_shape=input_shape)\n\n# set layers as non trainable\nfor layer in model.layers:\n    layer.trainable = False\n\n# Adding custom Layers\nx = model.output\nx = Flatten()(x)\nx = Dense(1024, activation=\"relu\")(x)\nx = Dropout(0.5)(x)\nx = Dense(1024, activation=\"relu\")(x)\n\n# Dense layer with 14 neurons for predicting 14 numeric values\npredictions = Dense(14, activation=\"relu\")(x)\n# creating the final model\nmodel_final = Model(inputs=model.input, outputs=predictions)\n# compile the model\nmodel_final.compile(loss=\"mean_squared_error\", optimizer=optimizer)\n# load the train data\ntrain = pd.read_csv('FLIC-full/train/train_joints.csv', header=None)\n# split train into train and validation\ntrain_img_ids, val_img_ids, train_jts, val_jts = train_test_split(\n        train.iloc[:, 0], train.iloc[:, 1:], test_size=0.2, random_state=42)\n\n# load validation images\nval_images = np.array(\n    [cv.imread('FLIC-full/train/{}'.format(w)) for w in val_img_ids.values])\n\n# convert validation images to dtype float\nval_images = val_images.astype(float)\n\ndef training(model, image_ids, joints, val_images, val_jts,\n             batch_size=128, epochs=2):\n    \"\"\"Train vgg16.\"\"\"\n    # empty train loss and validation loss list\n    loss_lst = []\n    val_loss_lst = []\n    count = 0 # counter\n    count_lst = []\n\n    # create shuffled batches\n    batches = np.arange(len(image_ids)//batch_size)\n    data_idx = np.arange(len(image_ids))\n    random.shuffle(data_idx)\n    print('......Training......')\n    for epoch in range(epochs):\n        for batch in (batches):\n            # batch of training image ids\n            imgs = image_ids[data_idx[batch*batch_size:(batch+1)*batch_size:]]\n            # corresponding joints for the above images\n            jts = joints[data_idx[batch*batch_size:(batch+1)*batch_size:]]\n            # load the training image batch\n            batch_imgs = np.array(\n                    [cv.imread('FLIC-full/train/{}'.format(x)) for x in imgs])\n            # fit model on the batch\n            loss = model.train_on_batch(batch_imgs.astype(float), jts)\n            if batch % 40 == 0:\n                # evaluate model on validation set\n                val_loss = model.evaluate(val_images, val_jts, verbose=0,\n                                          batch_size=batch_size)\n                # store train and val loss\n                loss_lst.append(loss)\n                val_loss_lst.append(val_loss)\n                print('Epoch:{}, End of batch:{}, loss:{:.2f},val_loss:{:.2f}\\\n                '.format(epoch+1, batch+1, loss, val_loss))\n\n                count_lst.append(count)\n            else:\n                print('Epoch:{}, End of batch:{}, loss:{:.2f}\\\n                '.format(epoch+1, batch+1, loss))\n            count += 1\n    count_lst.append(count)\n    loss_lst.append(loss)\n    val_loss = model.evaluate(val_images, val_jts, verbose=0,\n                              batch_size=batch_size)\n    val_loss_lst.append(val_loss)\n    print('Epoch:{}, End of batch:{}, VAL_LOSS:{:.2f}\\\n    '.format(epoch+1, batch+1, val_loss))\n    return model, loss_lst, val_loss_lst, count_lst\n\nm, loss_lst, val_loss_lst, count_lst = training(model_final,\n                                                train_img_ids.values,\n                                                train_jts.values,\n                                                val_images,\n                                                val_jts.values,\n                                                epochs=epochs,\n                                                batch_size=batch_size)\n\n# plot the learning\nplt.style.use('ggplot')\nplt.figure(figsize=(10, 6))\nplt.plot(count_lst, loss_lst, marker='D', label='training_loss')\nplt.plot(count_lst, val_loss_lst, marker='o', label='validation_loss')\nplt.xlabel('Batches')\nplt.ylabel('Mean Squared Error')\nplt.title('Plot of MSE over time')\nplt.legend(loc='upper right')\nplt.show()\n\n# test and save results\ntest_loss = test(m)\n\n# print test_loss\nprint('Test Loss:', test_loss)\n\nimage_list = glob.glob('FLIC-full/test_plot/*.jpg')[8:16]\n\nplt.figure(figsize=(16, 8))\nfor i in range(8):\n    plt.subplot(2, 4, (i+1))\n    img = cv.imread(image_list[i])\n    plt.imshow(img, aspect='auto')\n    plt.axis('off')\n    plt.title('Green-True/Red-Predicted Joints')\n\nplt.tight_layout()\nplt.show()\n```"]