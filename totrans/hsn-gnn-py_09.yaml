- en: '9'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Defining Expressiveness for Graph Classification
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we traded accuracy for scalability. We saw that it
    was instrumental in applications such as recommender systems. However, it raises
    several questions about what makes GNNs “accurate.” Where does this precision
    come from? Can we use this knowledge to design better GNNs?
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will clarify what makes a GNN powerful by introducing the **Weisfeiler-Leman**
    (**WL**) test. This test will give us the framework to understand an essential
    concept in GNNs – **expressiveness**. We will use it to compare different GNN
    layers and see which one is the most expressive. This result will then be used
    to design a more powerful GNN than GCNs, GATs, and GraphSAGE.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we will implement it using PyTorch Geometric to perform a new task
    – graph classification. We will implement a new GNN on the `PROTEINS` dataset,
    comprising 1,113 graphs representing proteins. We will compare different methods
    for graph classification and analyze our results.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, you will understand what makes a GNN expressive
    and how to measure it. You will be able to implement a new GNN architecture based
    on the WL test and perform graph classification using various techniques.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following main topics:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: Defining expressiveness
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing the GIN
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Classifying graphs with GIN
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All the code examples from this chapter can be found on GitHub at [https://github.com/PacktPublishing/Hands-On-Graph-Neural-Networks-Using-Python/tree/main/Chapter09](https://github.com/PacktPublishing/Hands-On-Graph-Neural-Networks-Using-Python/tree/main/Chapter09).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: Installation steps required to run the code on your local machine can be found
    in the *Preface* section of this book.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: Defining expressiveness
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Neural networks are used to approximate functions. This is justified by the
    **universal approximation theorem**, which states that a feedforward neural network
    with only one layer can approximate any smooth function. But what about universal
    function approximation on graphs? This is a more complex problem that requires
    the ability to distinguish graph structures.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: With GNNs, our goal is to produce the best node embeddings possible. This means
    that different nodes must have different embeddings, and similar nodes must have
    similar embeddings. But how do we know that two nodes are similar? Embeddings
    are computed using node features and connections. Therefore, we have to compare
    their features and neighbors to distinguish nodes.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: In graph theory, this is referred to as the graph **isomorphism** problem. Two
    graphs are isomorphic (“the same”) if they have the same connections, and their
    only difference is a permutation of their nodes (see *Figure 9**.1*). In 1968,
    Weisfeiler and Lehman [1] proposed an efficient algorithm to solve this problem,
    now known as the WL test.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.1 – An example of two isomorphic graphs](img/B19153_09_001.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
- en: Figure 9.1 – An example of two isomorphic graphs
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.1 – 两个同构图的示例
- en: The WL test aims to build the **canonical form** of a graph. We can then compare
    the canonical form of two graphs to check whether they are isomorphic or not.
    However, this test is not perfect, and non-isomorphic graphs can share the same
    canonical form. This can be surprising, but it is an intricate problem that is
    still not completely understood; for instance, the complexity of the WL algorithm
    is unknown.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: WL 测试旨在构建图的**标准形式**。我们可以比较两个图的标准形式，以检查它们是否同构。然而，这个测试并不完美，非同构图也可能具有相同的标准形式。这可能令人惊讶，但这是一个复杂的问题，目前仍未完全理解；例如，WL
    算法的复杂度尚不清楚。
- en: 'The WL test works as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: WL 测试如下进行：
- en: At the beginning, each node in the graph receives the same color.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在开始时，图中的每个节点都会获得相同的颜色。
- en: Each node aggregates its own color and the colors of its neighbors.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个节点都会聚合自身的颜色以及邻居节点的颜色。
- en: The result is fed to a hash function that produces a new color.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 结果会输入到一个哈希函数中，产生一个新的颜色。
- en: Each node aggregates its new color and the new colors of its neighbors.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个节点聚合其新的颜色和邻居节点的新颜色。
- en: The result is fed to a hash function that produces a new color.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 结果会输入到一个哈希函数中，产生一个新的颜色。
- en: These steps are repeated until no more nodes change color.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这些步骤会重复进行，直到没有节点的颜色发生变化。
- en: The following figure summarizes the WL algorithm.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 下图总结了 WL 算法。
- en: '![Figure 9.2 – An application of the WL algorithm to get the canonical form
    of a graph](img/B19153_09_002.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.2 – WL 算法应用于获取图的标准形式](img/B19153_09_002.jpg)'
- en: Figure 9.2 – An application of the WL algorithm to get the canonical form of
    a graph
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.2 – WL 算法应用于获取图的标准形式
- en: The resulting colors give us the canonical form of the graph. If two graphs
    do not share the same colors, they are not isomorphic. Conversely, we cannot be
    sure they are isomorphic if they obtain the same colors.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 结果颜色为我们提供了图的标准形式。如果两个图的颜色不相同，它们就不是同构的。相反，如果它们获得了相同的颜色，我们不能确定它们是同构的。
- en: The steps we described should be familiar; they are surprisingly close to what
    GNNs perform. Colors are a form of embeddings, and the hash function is an aggregator.
    But it is not just any aggregator; the hash function is particularly suited for
    this task. Would it still be as efficient if we were to replace it with another
    function, such as a mean or max aggregator (as seen in [*Chapter 8*](B19153_08.xhtml#_idTextAnchor096))?
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们描述的步骤应该是熟悉的；它们与 GNN 执行的操作非常相似。颜色是一种嵌入形式，而哈希函数则是一个聚合器。但它不仅仅是任何一个聚合器；哈希函数特别适合这个任务。如果我们将其替换为另一个函数，例如平均值或最大值聚合器（如在[*第8章*](B19153_08.xhtml#_idTextAnchor096)中所见），它仍然会高效吗？
- en: 'Let’s see the result for each operator:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下每个操作符的结果：
- en: With the mean aggregator, having 1 blue node and 1 red node, or 10 blue nodes
    and 10 red nodes, results in the same embedding (half blue and half red).
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用平均值聚合器时，1个蓝色节点和1个红色节点，或者10个蓝色节点和10个红色节点，会产生相同的嵌入（蓝色和红色各占一半）。
- en: With the max aggregator, half of the nodes would be ignored in the previous
    example; the embedding would only consider the blue or red color.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用最大值聚合器时，上一示例中一半的节点将被忽略；嵌入只会考虑蓝色或红色。
- en: With the sum aggregator, however, every node contributes to the final embedding;
    having 1 red node and 1 blue node is different from having 10 blue nodes and 10
    red nodes.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然而，使用和法聚合器时，每个节点都参与最终嵌入的计算；拥有1个红色节点和1个蓝色节点与拥有10个蓝色节点和10个红色节点是不同的。
- en: Indeed, the sum aggregator can discriminate more graph structures than the other
    two. If we follow this logic, this can only mean one thing – the aggregators we
    have been using so far are suboptimal, since they are strictly less expressive
    than a sum. Can we use this knowledge to build better GNNs? In the next section,
    we will introduce the **Graph Isomorphism Network** (**GIN**) based on this idea.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 确实，和法聚合器能够区分比其他两种聚合器更多的图结构。如果我们遵循这一逻辑，这只能意味着一件事——我们迄今为止使用的聚合器是次优的，因为它们的表达能力严格低于和法。我们能否利用这一知识构建更好的
    GNN？在下一节中，我们将基于这个想法介绍**图同构网络**（**GIN**）。
- en: Introducing the GIN
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引入 GIN
- en: In the previous section, we saw that the GNNs introduced in the previous chapters
    were less expressive than the WL test. This is an issue because the ability to
    distinguish more graph structures seems to be connected to the quality of the
    resulting embeddings. In this section, we will translate the theoretical framework
    into a new GNN architecture – the GIN.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: 'Introduced in 2018 by Xu et al. in a paper called “*How Powerful are Graph
    Neural Networks?*” [2], the GIN is designed to be as expressive as the WL test.
    The authors generalized our observations on aggregation by dividing it into two
    functions:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '**Aggregate**: This function, ![](img/Formula_B19153_09_001.png), selects the
    neighboring nodes that the GNN considers'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Combine**: This function, ![](img/Formula_B19153_09_002.png), combines the
    embeddings from the selected nodes to produce the new embedding of the target
    node'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The embedding of the ![](img/Formula_B19153_09_003.png) node can be written
    as the following:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B19153_09_004.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
- en: In the case of a GCN, the ![](img/Formula_B19153_09_005.png) function aggregates
    every neighbor of the ![](img/Formula_B19153_09_006.png) node, and ![](img/Formula_B19153_09_007.png)
    applies a specific mean aggregator. In the case of GraphSAGE, the neighborhood
    sampling is the ![](img/Formula_B19153_09_008.png) function, and we saw three
    options for ![](img/Formula_B19153_09_009.png) – the mean, LSTM, and max aggregators.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: So, what are these functions in the GIN? Xu et al. argue that they have to be
    **injective**. As shown in *Figure 9**.3*, injective functions map distinct inputs
    to distinct outputs. This is precisely what we want to distinguish graph structures.
    If the functions were not injective, we would end up with the same output for
    different inputs. In this case, our embeddings would be less valuable because
    they would contain less information.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.3 – A mapping diagram of an injective function](img/B19153_09_003.jpg)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
- en: Figure 9.3 – A mapping diagram of an injective function
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: 'The GIN’s authors use a clever trick to design these two functions – they simply
    approximate them. In the GAT layer, we learned the self-attention weights. In
    this example, we can learn both functions using a single MLP, thanks to the universal
    approximation theorem:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B19153_09_010.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/Formula_B19153_09_011.png) is a learnable parameter or a fixed
    scalar, representing the importance of the target node’s embedding compared to
    its neighbors’. The authors also emphasize that the MLP must have more than one
    layer to distinguish specific graph structures.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: We now have a GNN that is as expressive as the WL test. Can we do even better?
    The answer is yes. The WL test can be generalized to a hierarchy of higher-level
    tests known as **k-WL**. Instead of considering individual nodes, ![](img/Formula_B19153_09_012.png)-WL
    tests look at ![](img/Formula_B19153_09_013.png)-tuples of nodes. It means that
    they are non-local, since they can look at distant nodes. This is also why ![](img/Formula_B19153_09_014.png)-WL
    tests can distinguish more graph structures than ![](img/Formula_B19153_09_015.png)-WL
    tests for ![](img/Formula_B19153_09_016.png).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一个与WL测试一样具有表现力的GNN。我们还能做得更好吗？答案是肯定的。WL测试可以推广到更高层次的测试层次，称为**k-WL**。与考虑单个节点不同，![](img/Formula_B19153_09_012.png)-WL测试查看的是![](img/Formula_B19153_09_013.png)-元组节点。这意味着它们是非局部的，因为它们可以查看远距离的节点。这也是为什么![](img/Formula_B19153_09_014.png)-WL测试能够区分比![](img/Formula_B19153_09_015.png)-WL测试更多的图结构的原因。
- en: Several architectures based on ![](img/Formula_B19153_09_017.png)-WL tests have
    been proposed, such as the **k-GNN** by Morris et al. [3]. While these architectures
    help us better understand how GNNs work, they tend to underperform in practice
    compared to less expressive models, such as GNNs or GATs [4]. But all hope is
    not lost, as we will see in the next section in the particular context of graph
    classification.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 已提出了多种基于![](img/Formula_B19153_09_017.png)-WL测试的架构，例如Morris等人提出的**k-GNN** [3]。虽然这些架构帮助我们更好地理解GNN的工作原理，但它们在实践中往往比不太具有表现力的模型（如GNN或GAT）表现差[4]。但希望并未完全破灭，我们将在下节中看到，在图分类的特定背景下，情况会有所不同。
- en: Classifying graphs using GIN
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用GIN进行图分类
- en: We could directly implement a GIN model for node classification, but this architecture
    is more interesting for performing graph classification. In this section, we will
    see how to transform node embeddings into graph embeddings using `PROTEINS` dataset
    and compare our results using GIN and GCN models.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以直接实现一个GIN模型来进行节点分类，但该架构对于执行图分类更为有趣。在本节中，我们将看到如何使用`PROTEINS`数据集将节点嵌入转换为图嵌入，并比较我们使用GIN和GCN模型的结果。
- en: Graph classification
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图分类
- en: 'Graph classification is based on the node embeddings that a GNN produces. This
    operation is often called global pooling or **graph-level readout**. There are
    three simple ways of implementing it:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图分类是基于GNN生成的节点嵌入。这一操作通常称为全局池化或**图级读出**。实现这一操作有三种简单的方法：
- en: '**Mean global pooling**: The graph embedding ![](img/Formula_B19153_09_018.png)
    is obtained by averaging the embeddings of every node in the graph:'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**均值全局池化**：图嵌入![](img/Formula_B19153_09_018.png)是通过对图中每个节点的嵌入取平均值获得的：'
- en: '![](img/Formula_B19153_09_019.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_B19153_09_019.jpg)'
- en: '**Max global pooling**: The graph embedding is obtained by selecting the highest
    value for each node dimension:![](img/Formula_B19153_09_020.jpg)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最大全局池化**：图嵌入是通过为每个节点维度选择最高值来获得的：![](img/Formula_B19153_09_020.jpg)'
- en: '**Sum global pooling**: The graph embedding is obtained by summing the embeddings
    of every node in the graph:'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**求和全局池化**：图嵌入是通过对图中每个节点的嵌入求和来获得的：'
- en: '![](img/Formula_B19153_09_021.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_B19153_09_021.jpg)'
- en: 'According to what we saw in the first section, the sum global pooling is strictly
    more expressive than the two other techniques. The GIN’s authors also note that
    to consider all structural information, it is necessary to consider embeddings
    produced by every layer of the GNN. In summary, we concatenate the sum of node
    embeddings produced by each of the *k* layers of our GNN:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们在第一节中看到的，求和全局池化在表现力上严格优于其他两种技术。GIN的作者也指出，为了考虑所有结构信息，有必要考虑GNN每一层生成的嵌入。总之，我们将每一层的节点嵌入的和进行连接：
- en: '![](img/Formula_B19153_09_022.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_B19153_09_022.jpg)'
- en: This solution elegantly combines the expressive power of the sum operator with
    the memory of each layer provided by the concatenation.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 该方案优雅地将求和运算符的表达能力与每层通过连接提供的记忆相结合。
- en: Implementing the GIN
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现GIN
- en: We will now implement a GIN model with the previous graph-level readout function
    on the `PROTEINS [5, 6,` `7]` dataset.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将实现一个GIN模型，并在`PROTEINS [5, 6,` `7]`数据集上使用之前的图级读出函数。
- en: This dataset comprises 1,113 graphs representing proteins, where every node
    is an amino acid. An edge connects two nodes when their distance is lower than
    0.6 nanometers. The goal of this dataset is to classify each protein as an **enzyme**.
    Enzymes are a particular type of protein that act as catalysts to speed up chemical
    reactions in a cell. For instance, enzymes called lipases aid in the digestion
    of food. *Figure 9**.4* shows the 3D plot of a protein.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.4 – An example of a protein in 3D](img/B19153_09_004.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
- en: Figure 9.4 – An example of a protein in 3D
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s implement a GIN model on this dataset:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we import the `PROTEINS` dataset using the `TUDataset` class from PyTorch
    Geometric and print the information:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We split the data (graphs) into training, validation, and test sets with an
    80/10/10 split respectively:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This gives us the following output:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We convert these splits into mini-batches using the `DataLoader` object with
    a batch size of 64\. This means that each batch will contain up to 64 graphs:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We can verify that by printing information about each batch, as follows:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Let’s start implementing a GIN model. The first question we have to answer
    is the composition of our GIN layer. We need an MLP with at least two layers.
    Following the authors’ guidelines, we can also introduce batch normalization to
    standardize the inputs of each hidden layer, which stabilizes and speeds up training.
    In summary, our GIN layer has the following composition:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B19153_09_023.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
- en: 'In code, it is defined as follows:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Note
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: PyTorch Geometric also offers the GINE layer, a modified version of the GIN
    layer. It was introduced in 2019 by Hu et al. in “*Strategies for Pre-training
    Graph Neural Networks*” [8]. Its major improvement over the previous GIN version
    is the ability to consider edge features during the aggregation process. The `PROTEINS`
    dataset does not have edge features, which is why we will implement the classic
    GIN model instead.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: 'Our model is not complete yet. We must not forget that we want to perform graph
    classification. It requires the sum of every node embedding in the graph for each
    layer. In other words, we will need to store one vector of `dim_h` size per layer
    – three, in this example. This is why we add a linear layer with `3*dim_h` size
    before the final linear layer for binary classification (`data.num_classes` =
    2):'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We must implement the logic to connect our initialized layers. Each layer produces
    a different embedding tensor – `h1`, `h2`, and `h3`. We sum them using the `global_add_pool()`
    function and then concatenate them with `torch.cat()`. This gives us the input
    to our classifier, which acts as a regular neural network with a dropout layer:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We can now implement a regular training loop with mini-batching for 100 epochs:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We print the training and validation accuracy every 20 epochs and return the
    trained model:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Unlike the `test` function from the previous chapter, this one must also include
    mini-batching, since our validation and test loaders contain more than one batch:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与上一章中的 `test` 函数不同，这个函数还必须包括小批量处理，因为我们的验证和测试加载器包含多个批次：
- en: '[PRE10]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We define the function we will use to calculate the accuracy score:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们定义将用于计算准确率得分的函数：
- en: '[PRE11]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Let’s instantiate and train our GIN model:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们实例化并训练我们的 GIN 模型：
- en: '[PRE12]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Finally, let’s test it using the test loader:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们使用测试加载器进行测试：
- en: '[PRE13]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: To better understand this final test score, we can implement a GCN that performs
    graph classification with a simple global mean pooling (`global_mean_pool()` in
    PyTorch Geometric). With the exact same setting, it achieves an average accuracy
    score of 53.72% (± 0.73%) on 100 experiments. This is much lower than the average
    76.56% (± 1.77%) obtained by the GIN model.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解这个最终测试得分，我们可以实现一个 GCN，该 GCN 使用简单的全局平均池化（在 PyTorch Geometric 中为 `global_mean_pool()`）执行图分类。在完全相同的设置下，它在
    100 次实验中获得了平均准确率 53.72%（± 0.73%）。这远低于 GIN 模型的平均准确率 76.56%（± 1.77%）。
- en: 'We can conclude that the entire GIN architecture is much more suited for this
    graph classification task than GCNs. According to the theoretical framework we
    used, this is explained by the fact that GCNs are strictly less expressive than
    GINs. In other words, GINs can distinguish more graph structures than GCNs, which
    is why they are more accurate. We can verify this assumption by visualizing the
    mistakes made by both models:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以得出结论，整个 GIN 架构比 GCN 更适合这个图分类任务。根据我们使用的理论框架，这可以通过 GCN 在表达能力上严格低于 GIN 来解释。换句话说，GIN
    可以区分比 GCN 更多的图结构，这就是为什么它们更准确的原因。我们可以通过可视化两个模型的错误来验证这个假设：
- en: 'We import the `matplotlib` and `networkx` libraries to make a 4x4 plot of proteins:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们导入 `matplotlib` 和 `networkx` 库，以绘制一个 4x4 的蛋白质图：
- en: '[PRE14]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'For each protein, we get the final classification from our GNN (the GIN in
    this case). We give the prediction a green color if it is correct (red otherwise):'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个蛋白质，我们从我们的 GNN（此处为 GIN）中获取最终分类。如果预测正确，我们给它绿色（否则为红色）：
- en: '[PRE15]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We convert our protein into a `networkx` graph for convenience. We can then
    draw it using the `nx.draw_networkx()` function:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们为了方便将蛋白质转化为 `networkx` 图。然后，我们可以使用 `nx.draw_networkx()` 函数绘制它：
- en: '[PRE16]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We obtain the following plot for the GIN model.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们为 GIN 模型获得了以下图示。
- en: '![Figure 9.5 – Graph classifications produced by the GIN model](img/B19153_09_005.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.5 – GIN 模型生成的图分类](img/B19153_09_005.jpg)'
- en: Figure 9.5 – Graph classifications produced by the GIN model
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.5 – GIN 模型生成的图分类
- en: We repeat this process for the GCN and get the following visualization.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们为 GCN 重复这个过程，并获得以下可视化结果。
- en: '![Figure 9.6 – Graph classifications produced by the GCN model](img/B19153_09_006.jpg)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.6 – GCN 模型生成的图分类](img/B19153_09_006.jpg)'
- en: Figure 9.6 – Graph classifications produced by the GCN model
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.6 – GCN 模型生成的图分类
- en: As expected, the GCN model makes more mistakes. Understanding which graph structures
    are not adequately captured would require extensive analysis for each protein
    correctly classified by GIN. However, we can see that the GIN also makes different
    mistakes. This is interesting because it shows that these models can be complementary.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，GCN 模型犯了更多的错误。要理解哪些图结构没有被充分捕捉，需要对每个被 GIN 正确分类的蛋白质进行广泛分析。然而，我们可以看到，GIN
    也会犯不同的错误。这一点很有趣，因为它表明这些模型可以互为补充。
- en: 'Creating ensembles from models that make different mistakes is a common technique
    in machine learning. We could use different approaches, such as a third model
    trained on our final classifications. As creating ensembles is not the goal of
    this chapter, we will implement a simple model-averaging technique instead:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 从犯不同错误的模型创建集成是机器学习中的常见技术。我们可以使用不同的方法，例如训练一个新的模型来处理我们的最终分类。由于本章的目标不是创建集成模型，因此我们将实现一个简单的模型平均技术：
- en: 'First, we set the models in evaluation mode and define the variables to store
    accuracy scores:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将模型设置为评估模式，并定义用于存储准确率得分的变量：
- en: '[PRE17]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We get the final classifications for each model and combine them to get the
    ensemble’s predictions:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们获取每个模型的最终分类，并将它们结合起来获得集成模型的预测结果：
- en: '[PRE18]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We calculate the accuracy scores for the three sets of predictions:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们计算了三个预测集的准确率得分：
- en: '[PRE19]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Finally, let’s print the results:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们打印结果：
- en: '[PRE20]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: In this example, our ensemble outperforms both models with an accuracy score
    of 81.25% (compared to 72.14% for the GCN and 80.99% for the GIN). This result
    is significant, as it shows the possibilities offered by this kind of technique.
    However, this is not necessarily the case in general; even with this example,
    the ensemble model does not consistently outperform the GIN. We could enrich it
    with embeddings from other architectures, such as `Node2Vec`, and see whether
    it improves the final accuracy.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we defined the expressive power of GNNs. This definition is
    based on another algorithm, the WL method, which outputs the canonical form of
    a graph. This algorithm is not perfect, but it can distinguish most graph structures.
    It inspired the GIN architecture, designed to be as expressive as the WL test
    and, therefore, strictly more expressive than GCNs, GATs, or GraphSAGE.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: We then implemented this architecture for graph classification. We saw different
    methods to combine node embeddings into graph embeddings. GIN offers a new technique,
    which incorporates a sum operator and the concatenation of graph embeddings produced
    by every GIN layer. It significantly outperformed the classic global mean pooling
    obtained with GCN layers. Finally, we combined predictions made by both models
    into a simple ensemble, which increased the accuracy score even further.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: In [*Chapter 10*](B19153_10.xhtml#_idTextAnchor116)*, Predicting Links with
    Graph Neural Networks*, we will explore another popular task with GNNs – link
    prediction. In fact, this is not entirely new, as previous techniques we saw such
    as `DeepWalk` and `Node2Vec` were already based on this idea. We will explain
    why and introduce two new GNN frameworks – the Graph (Variational) Autoencoder
    and SEAL. Finally, we will implement and compare them on the `Cora` dataset on
    a link prediction task.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[1] Weisfeiler and Lehman, A.A. (1968) A Reduction of a Graph to a Canonical
    Form and an Algebra Arising during This Reduction. Nauchno-Technicheskaya Informatsia,
    9.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] K. Xu, W. Hu, J. Leskovec, and S. Jegelka, *How Powerful are Graph Neural
    Networks?* arXiv, 2018\. doi: 10.48550/ARXIV.1810.00826.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] C. Morris et al., *Weisfeiler and Leman Go Neural: Higher-order Graph Neural
    Networks*. arXiv, 2018\. doi: 10.48550/ARXIV.1810.02244.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] V. P. Dwivedi et al. *Benchmarking graph neural networks*. arXiv, 2020\.
    doi: 10.48550/ARXIV.2003.00982.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] K. M. Borgwardt, C. S. Ong, S. Schoenauer, S. V. N. Vishwanathan, A. J.
    Smola, and H. P. Kriegel. *Protein function prediction via graph kernels*. Bioinformatics,
    21(Suppl 1):i47–i56, Jun 2005.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] P. D. Dobson and A. J. Doig. *Distinguishing enzyme structures from non-enzymes
    without alignments*. J. Mol. Biol., 330(4):771–783, Jul 2003.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] Christopher Morris and Nils M. Kriege and Franka Bause and Kristian Kersting
    and Petra Mutzel and Marion Neumann. *TUDataset: A collection of benchmark datasets
    for learning with graphs*. In ICML 2020 Workshop on Graph Representation Learning
    and Beyond.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] Christopher Morris、Nils M. Kriege、Franka Bause、Kristian Kersting、Petra
    Mutzel 和 Marion Neumann。*TUDataset：一个用于图学习的基准数据集集合*。发表于2020年ICML图表示学习及其扩展研讨会。'
- en: '[8] W. Hu et al., *Strategies for Pre-training Graph Neural Networks*. arXiv,
    2019\. doi: 10.48550/ARXIV.1905.12265.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] W. Hu 等人，*预训练图神经网络的策略*。arXiv，2019年。doi: 10.48550/ARXIV.1905.12265。'
