["```py\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\n\nfrom torchvision import datasets, transforms\n\nprint(\"PyTorch version: {}\".format(torch.__version__))\nprint(\"CUDA version: {}\\n\".format(torch.version.cuda))\n```", "```py\nuse_cuda = True\ndevice = torch.device(\"cuda:0\" if use_cuda and torch.cuda.is_available() else \"cpu\")\n\nepsilons = [.05, .1, .15, .2, .25, .3]\n```", "```py\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 20, kernel_size=5)\n        self.conv2 = nn.Conv2d(20, 50, kernel_size=5)\n        self.fc1 = nn.Linear(800, 500)\n        self.fc2 = nn.Linear(500, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n        x = F.relu(self.fc1(x.view(-1, 800)))\n        x = self.fc2(x)\n        return x\n```", "```py\nbatch_size = 64\ntrain_data = datasets.MNIST('/home/john/Data/mnist', train=True, download=True,\n                            transform=transforms.Compose([\n                                transforms.ToTensor(),\n                                # transforms.Normalize((0.1307,), (0.3081,)),\n                                ]))\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n                                           shuffle=True, pin_memory=True)\n\ntest_data = datasets.MNIST('/home/john/Data/mnist', train=False, download=True,\n                           transform=transforms.Compose([\n                                transforms.ToTensor(),\n                                # transforms.Normalize((0.1307,), (0.3081,)),\n                                ]))\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=1000,\n                                          shuffle=False, pin_memory=True)\n```", "```py\nmodel = Net().to(device)\noptimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), weight_decay=3e-5)\ncriterion = nn.CrossEntropyLoss()\n```", "```py\ndef train(model, device, train_loader, optimizer):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % 250 == 0:\n            print('[{}/{}]\\tLoss: {:.6f}'.format(\n                batch_idx * batch_size, len(train_data), loss.item()))\n\ndef test(model, device, test_loader):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            test_loss += criterion(output, target).item()\n            pred = output.max(1, keepdim=True)[1]\n            correct += pred.eq(target.view_as(pred)).sum().item()\n    test_loss /= len(test_loader)\n    print('\\nTest loss: {:.4f}, accuracy: {:.4f}%\\n'.format(\n        test_loss, 100\\. * correct / len(test_data)))\n```", "```py\nmodel.train()\nfor epoch in range(5):\n print('Train Epoch: {}'.format(epoch))\n train(model, device, train_loader, optimizer)\n test(model, device, test_loader)\n```", "```py\nPyTorch version: 1.3.1\nCUDA version: 10.0.130\n\nTrain Epoch: 0\n[0/60000] Loss: 2.307504\n[16000/60000] Loss: 0.148560\n...\nTest loss: 0.0229, accuracy: 99.3100%\n```", "```py\ndef fgsm_attack(image, epsilon, data_grad):\n    sign_data_grad = data_grad.sign()\n    perturbed_image = image + epsilon*sign_data_grad\n    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n    return perturbed_image\n```", "```py\ndef adv_test(model, device, test_loader, epsilon):\n    model.eval()\n    correct = 0\n    adv_examples = []\n    #* grads of params are needed\n    for data, target in test_loader:\n        data, target = data.to(device), target.to(device)\n\n        # Set requires_grad attribute of tensor. Important for Attack\n        data.requires_grad = True\n        output = model(data)\n        init_pred = output.max(1, keepdim=True)[1]\n        init_pred = init_pred.view_as(target)\n        loss = criterion(output, target)\n        model.zero_grad()\n        loss.backward()\n\n        perturbed_data = fgsm_attack(data, epsilon, data.grad.data)\n        output = model(perturbed_data)\n        final_pred = output.max(1, keepdim=True)[1]\n        # final_pred has shape [1000, 1], target has shape [1000]. Must reshape final_pred\n        final_pred = final_pred.view_as(target)\n        correct += final_pred.eq(target).sum().item()\n        if len(adv_examples) < 5 and not (final_pred == target).all():\n            indices = torch.arange(5)\n            for i in range(indices.shape[0]):\n                adv_ex = perturbed_data[indices[i]].squeeze().detach().cpu().numpy()\n                adv_examples.append((init_pred[indices[i]].item(), final_pred[indices[i]].item(), adv_ex))\n                if (len(adv_examples) >= 5):\n                    break\n    final_acc = 100\\. * correct / len(test_data)\n    print(\"Epsilon: {}\\tTest Accuracy = {}/{} = {:.4f}\".format(\n        epsilon, correct, len(test_data), final_acc))\n    return final_acc, adv_examples\n\naccuracies = []\nexamples = []\n\n# Run test for each epsilon\nfor eps in epsilons:\n    acc, ex = adv_test(model, device, test_loader, eps)\n    accuracies.append(acc)\n    examples.append(ex)\n```", "```py\nindices = torch.ne(final_pred.ne(target), init_pred.ne(target)).nonzero()\n```", "```py\nEpsilon: 0.05 Test Accuracy = 9603/10000 = 96.0300\nEpsilon: 0.1 Test Accuracy = 8646/10000 = 86.4600\nEpsilon: 0.15 Test Accuracy = 6744/10000 = 67.4400\nEpsilon: 0.2 Test Accuracy = 4573/10000 = 45.7300\nEpsilon: 0.25 Test Accuracy = 2899/10000 = 28.9900\nEpsilon: 0.3 Test Accuracy = 1670/10000 = 16.7000\n```", "```py\ncnt = 0\nplt.figure(figsize=(8,10))\nfor i in range(len(epsilons)):\n    for j in range(len(examples[i])):\n        cnt += 1\n        plt.subplot(len(epsilons),len(examples[0]),cnt)\n        plt.xticks([], [])\n        plt.yticks([], [])\n        if j == 0:\n            plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n        orig,adv,ex = examples[i][j]\n        plt.title(\"{} -> {}\".format(orig, adv))\n        plt.imshow(ex, cmap=\"gray\")\nplt.tight_layout()\nplt.show()\n```", "```py\n/cats-dogs-kaggle\n    /cat\n        /cat.0.jpg\n        /cat.1.jpg\n        ...\n    /dog\n        /dog.0.jpg\n        /dog.1.jpg\n        ...\n```", "```py\nimport argparse\nimport os\nimport random\nimport sys\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.backends.cudnn as cudnn\nimport torch.utils.data\nimport torchvision\nimport torchvision.datasets as dset\nimport torchvision.utils as vutils\n\nimport utils\nfrom advGAN import AdvGAN_Attack\nfrom data_utils import data_prefetcher, _transforms_catsdogs\nfrom model_ensemble import transfer_init, ModelEnsemble\n```", "```py\nif __name__ == '__main__':\n    from utils import boolean_string\n    legal_models = ['resnet18', 'resnet34', 'mobilenet_v2', 'shufflenet_v2_x1_0',\n                    'squeezenet1_1', 'densenet121', 'googlenet', 'resnext50_32x4d',\n                    'vgg11']\n    parser = argparse.ArgumentParser(description='Hands-On GANs - Chapter 8')\n    parser.add_argument('--model', type=str, default='resnet18',\n                        help='one of {}'.format(legal_models))\n    parser.add_argument('--cuda', type=boolean_string,\n                        default=True, help='enable CUDA.')\n    parser.add_argument('--train_single', type=boolean_string,\n                        default=True, help='train single model.')\n    parser.add_argument('--train_ensemble', type=boolean_string,\n                        default=True, help='train final model.')\n    parser.add_argument('--data_split', type=float, default=0.8,\n                        help='split ratio for train and val data')\n    parser.add_argument('--data_dir', type=str,\n                        default='./cats_dogs_kaggle', help='Directory for dataset.')\n    parser.add_argument('--out_dir', type=str,\n                        default='./output', help='Directory for output.')\n    parser.add_argument('--epochs', type=int, default=60,\n                        help='number of epochs')\n    parser.add_argument('--batch_size', type=int,\n                        default=128, help='size of batches')\n    parser.add_argument('--lr', type=float, default=0.01, help='learning rate')\n    parser.add_argument('--classes', type=int, default=2,\n                        help='number of classes')\n    parser.add_argument('--img_size', type=int,\n                        default=224, help='size of images')\n    parser.add_argument('--channels', type=int, default=3,\n                        help='number of image channels')\n    parser.add_argument('--log_interval', type=int, default=100,\n                        help='interval between logging and image sampling')\n    parser.add_argument('--seed', type=int, default=1, help='random seed')\n\n    FLAGS = parser.parse_args()\n    FLAGS.cuda = FLAGS.cuda and torch.cuda.is_available()\n\n    if FLAGS.seed is not None:\n        torch.manual_seed(FLAGS.seed)\n        if FLAGS.cuda:\n            torch.cuda.manual_seed(FLAGS.seed)\n        np.random.seed(FLAGS.seed)\n\n    cudnn.benchmark = True\n\n    # if FLAGS.train:\n    if FLAGS.train_single or FLAGS.train_ensemble:\n        utils.clear_folder(FLAGS.out_dir)\n\n    log_file = os.path.join(FLAGS.out_dir, 'log.txt')\n    print(\"Logging to {}\\n\".format(log_file))\n    sys.stdout = utils.StdOut(log_file)\n\n    print(\"PyTorch version: {}\".format(torch.__version__))\n    print(\"CUDA version: {}\\n\".format(torch.version.cuda))\n\n    print(\" \" * 9 + \"Args\" + \" \" * 9 + \"| \" + \"Type\" +\n          \" | \" + \"Value\")\n    print(\"-\" * 50)\n    for arg in vars(FLAGS):\n        arg_str = str(arg)\n        var_str = str(getattr(FLAGS, arg))\n        type_str = str(type(getattr(FLAGS, arg)).__name__)\n        print(\" \" + arg_str + \" \" * (20-len(arg_str)) + \"|\" +\n              \" \" + type_str + \" \" * (10-len(type_str)) + \"|\" +\n              \" \" + var_str)\n\n    ...\n\n    try:\n        import accimage\n        torchvision.set_image_backend('accimage')\n        print('Image loader backend: accimage')\n    except:\n        print('Image loader backend: PIL')\n\n    ...\n\n    main()\n```", "```py\nFLAGS = None\n\ndef main():\n    device = torch.device(\"cuda:0\" if FLAGS.cuda else \"cpu\")\n\n    print('Loading data...\\n')\n    train_transform, _ = _transforms_catsdogs(FLAGS)\n    train_data = dset.ImageFolder(root=FLAGS.data_dir, transform=train_transform)\n    assert train_data\n\n    num_train = len(train_data)\n    indices = list(range(num_train))\n    random.shuffle(indices)\n    split = int(np.floor(FLAGS.data_split * num_train))\n\n    train_loader = torch.utils.data.DataLoader(\n        train_data, batch_size=FLAGS.batch_size,\n        sampler=torch.utils.data.sampler.SubsetRandomSampler(indices[:split]),\n        num_workers=2)\n\n    valid_loader = torch.utils.data.DataLoader(\n        train_data, batch_size=FLAGS.batch_size,\n        sampler=torch.utils.data.sampler.SubsetRandomSampler(indices[split:num_train]),\n        num_workers=2)\n```", "```py\nimport numpy as np\nimport torch\nimport torchvision.transforms as transforms\n\ndef _transforms_catsdogs(args):\n    train_transform = transforms.Compose([\n        transforms.Resize((args.img_size, args.img_size)),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n    ])\n\n    valid_transform = transforms.Compose([\n        transforms.ToTensor()\n        ])\n    return train_transform, valid_transform\n```", "```py\n    if FLAGS.train_single:\n        print('Transfer training model {}...\\n'.format(FLAGS.model))\n        model = torch.hub.load('pytorch/vision', FLAGS.model, pretrained=True)\n        for param in model.parameters():\n            param.requires_grad = False\n\n        model, param_to_train = transfer_init(model, FLAGS.model, FLAGS.classes)\n        model.to(device)\n\n        optimizer = torch.optim.SGD(\n            param_to_train, FLAGS.lr,\n            momentum=0.9, weight_decay=5e-4)\n        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n\n        criterion = nn.CrossEntropyLoss()\n\n        # Train\n        best_acc = 0.0\n        for epoch in range(25):\n            model.train()\n            scheduler.step()\n            print('Epoch {}, lr: {}'.format(epoch, scheduler.get_lr()[0]))\n            prefetcher = data_prefetcher(train_loader)\n            data, target = prefetcher.next()\n            batch_idx = 0\n            while data is not None:\n                optimizer.zero_grad()\n                output = model(data)\n                pred = output.max(1, keepdim=True)[1]\n                loss = criterion(output, target)\n                loss.backward()\n                optimizer.step()\n                correct = pred.eq(target.view_as(pred)).sum().item()\n                if batch_idx % FLAGS.log_interval == 0:\n                    print('[{}/{}]\\tloss: {:.4f}\\tbatch accuracy: {:.4f}%'.format(\n                        batch_idx * FLAGS.batch_size, num_train,\n                        loss.item(), 100 * correct / data.size(0)))\n                data, target = prefetcher.next()\n                batch_idx += 1\n            # Eval\n            ...\n```", "```py\nimport os\n\nimport torch\nimport torch.nn as nn\n\ndef transfer_init(model, model_name, num_class):\n    param_to_train = None\n    if model_name in ['resnet18', 'resnet34', 'shufflenet_v2_x1_0', 'googlenet', 'resnext50_32x4d']:\n        num_features = model.fc.in_features\n        model.fc = nn.Linear(num_features, num_class)\n        param_to_train = model.fc.parameters()\n    elif model_name in ['mobilenet_v2']:\n        num_features = model.classifier[1].in_features\n        model.classifier[1] = nn.Linear(num_features, num_class)\n        param_to_train = model.classifier[1].parameters()\n    elif model_name in ['squeezenet1_1']:\n        num_features = model.classifier[1].in_channels\n        model.classifier[1] = nn.Conv2d(num_features, num_class, kernel_size=1)\n        param_to_train = model.classifier[1].parameters()\n    elif model_name in ['densenet121']:\n        num_features = model.classifier.in_features\n        model.classifier = nn.Linear(num_features, num_class)\n        param_to_train = model.classifier.parameters()\n    elif model_name in ['vgg11']:\n        num_features = model.classifier[6].in_features\n        model.classifier[6] = nn.Linear(num_features, num_class)\n        param_to_train = model.classifier[6].parameters()\n    return model, param_to_train\n```", "```py\nclass data_prefetcher():\n    def __init__(self, loader):\n        self.loader = iter(loader)\n        self.stream = torch.cuda.Stream()\n        self.preload()\n\n    def preload(self):\n        try:\n            self.next_input, self.next_target = next(self.loader)\n        except StopIteration:\n            self.next_input = None\n            self.next_target = None\n            return\n        with torch.cuda.stream(self.stream):\n            self.next_input = self.next_input.cuda(non_blocking=True)\n            self.next_target = self.next_target.cuda(non_blocking=True)\n            self.next_input = self.next_input.float()\n\n    def next(self):\n        torch.cuda.current_stream().wait_stream(self.stream)\n        input = self.next_input\n        target = self.next_target\n        self.preload()\n        return input, target\n```", "```py\nclass ModelEnsemble(nn.Module):\n    def __init__(self, model_names, num_class, model_path):\n        super(ModelEnsemble, self).__init__()\n        self.model_names = model_names\n        self.num_class = num_class\n        models = []\n        for m in self.model_names:\n            model = torch.load(os.path.join(model_path, '{}.pth'.format(m)))\n            for param in model.parameters():\n                param.requires_grad = False\n            models.append(model)\n        self.models = nn.Sequential(*models)\n        self.vote_layer = nn.Linear(len(self.model_names)*self.num_class, self.num_class)\n\n    def forward(self, input):\n        raw_outputs = []\n        for m in self.models:\n            _out = m(input)\n            raw_outputs.append(_out)\n        raw_out = torch.cat(raw_outputs, dim=1)\n        output = self.vote_layer(raw_out)\n        return output\n```", "```py\n elif FLAGS.train_ensemble:\n print('Loading model...\\n')\n model_names = ['mobilenet_v2', 'resnet18', 'densenet121',\n 'googlenet', 'resnext50_32x4d']\n model = ModelEnsemble(model_names, FLAGS.classes, FLAGS.model_dir)\n model.to(device)\n\n optimizer = torch.optim.SGD(\n model.vote_layer.parameters(), FLAGS.lr,\n momentum=0.9, weight_decay=5e-4)\n scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n\n criterion = nn.CrossEntropyLoss()\n\n # Train\n print('Training ensemble model...\\n')\n for epoch in range(2):\n model.train()\n scheduler.step()\n print('Epoch {}, lr: {}'.format(epoch, scheduler.get_lr()[0]))\n prefetcher = data_prefetcher(train_loader)\n data, target = prefetcher.next()\n batch_idx = 0\n while data is not None:\n optimizer.zero_grad()\n output = model(data)\n pred = output.max(1, keepdim=True)[1]\n loss = criterion(output, target)\n loss.backward()\n optimizer.step()\n correct = pred.eq(target.view_as(pred)).sum().item()\n if batch_idx % FLAGS.log_interval == 0:\n print('[{}/{}]\\tloss: {:.4f}\\tbatch accuracy: {:.4f}%'.format(\n batch_idx * FLAGS.batch_size, num_train,\n loss.item(), 100 * correct / data.size(0)))\n data, target = prefetcher.next()\n batch_idx += 1\n # Eval\n ...\n```", "```py\nimport torch.nn as nn\nimport torch\nimport numpy as np\nimport models\nimport torch.nn.functional as F\nimport torchvision\nimport os\n\ndef weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        nn.init.normal_(m.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        nn.init.normal_(m.weight.data, 1.0, 0.02)\n        nn.init.constant_(m.bias.data, 0)\n\nclass AdvGAN_Attack:\n    def __init__(self,\n                 device,\n                 model,\n                 model_num_labels,\n                 image_nc,\n                 box_min,\n                 box_max,\n                 model_path):\n        output_nc = image_nc\n        self.device = device\n        self.model_num_labels = model_num_labels\n        self.model = model\n        self.input_nc = image_nc\n        self.output_nc = output_nc\n        self.box_min = box_min\n        self.box_max = box_max\n        self.model_path = model_path\n\n        self.gen_input_nc = image_nc\n        self.netG = models.Generator(self.gen_input_nc, image_nc).to(device)\n        self.netDisc = models.Discriminator(image_nc).to(device)\n\n        # initialize all weights\n        self.netG.apply(weights_init)\n        self.netDisc.apply(weights_init)\n\n        # initialize optimizers\n        self.optimizer_G = torch.optim.Adam(self.netG.parameters(),\n                                            lr=0.001)\n        self.optimizer_D = torch.optim.Adam(self.netDisc.parameters(),\n                                            lr=0.001)\n\n    def train_batch(self, x, labels):\n        # optimize D\n        for i in range(1):\n            perturbation = self.netG(x)\n\n            adv_images = torch.clamp(perturbation, -0.3, 0.3) + x\n            adv_images = torch.clamp(adv_images, self.box_min, \n              self.box_max)\n\n            self.optimizer_D.zero_grad()\n            pred_real = self.netDisc(x)\n            loss_D_real = F.mse_loss(pred_real, \n              torch.ones_like(pred_real, device=self.device))\n            loss_D_real.backward()\n\n            pred_fake = self.netDisc(adv_images.detach())\n            loss_D_fake = F.mse_loss(pred_fake, \n              torch.zeros_like(pred_fake, device=self.device))\n            loss_D_fake.backward()\n            loss_D_GAN = loss_D_fake + loss_D_real\n            self.optimizer_D.step()\n\n        # optimize G\n        for i in range(1):\n            self.optimizer_G.zero_grad()\n\n            pred_fake = self.netDisc(adv_images)\n            loss_G_fake = F.mse_loss(pred_fake, \n              torch.ones_like(pred_fake, device=self.device))\n            loss_G_fake.backward(retain_graph=True)\n\n            C = 0.1\n            loss_perturb = torch.mean(torch.norm(perturbation.view(perturbation.shape[0], -1), 2, dim=1))\n\n            logits_model = self.model(adv_images)\n            probs_model = F.softmax(logits_model, dim=1)\n            onehot_labels = torch.eye(self.model_num_labels, device=self.device)[labels]\n\n            real = torch.sum(onehot_labels * probs_model, dim=1)\n            other, _ = torch.max((1 - onehot_labels) * probs_model - onehot_labels * 10000, dim=1)\n            zeros = torch.zeros_like(other)\n            loss_adv = torch.max(real - other, zeros)\n            loss_adv = torch.sum(loss_adv)\n\n            adv_lambda = 10\n            pert_lambda = 1\n            loss_G = adv_lambda * loss_adv + pert_lambda *  \n             loss_perturb\n            loss_G.backward()\n            self.optimizer_G.step()\n\n        return loss_D_GAN.item(), loss_G_fake.item(), \n         loss_perturb.item(), loss_adv.item()\n\n    def train(self, train_dataloader, epochs):\n        ...\n\n    def adv_example(self, data):\n        perturbation = self.netG(data)\n        adv_images = torch.clamp(perturbation, -0.3, 0.3) + data\n        adv_images = torch.clamp(adv_images, self.box_min,  \n          self.box_max)\n        return adv_images\n```", "```py\n        print('Training GAN for adversarial attack...\\n')\n        train_loader = torch.utils.data.DataLoader(\n            train_data, batch_size=16,\n\n        sampler=torch.utils.data.sampler.SubsetRandomSampler\n            (indices[:split]),\n            num_workers=2)\n```", "```py\n        model.eval()\n        advGAN = AdvGAN_Attack(device, model, FLAGS.classes,\n                               FLAGS.channels, 0, 1, FLAGS.model_dir)\n        advGAN.train(train_loader, FLAGS.epochs)\n```", "```py\n        print('Attacking ensemble model...\\n')\n        test_loss = 0\n        test_correct = 0\n        adv_examples = []\n        with torch.no_grad():\n            valid_prefetcher = data_prefetcher(valid_loader)\n            data, target = valid_prefetcher.next()\n            while data is not None:\n                output = model(data)\n                init_pred = output.max(1, keepdim=True)[1]\n                init_pred = init_pred.view_as(target)\n\n                perturbed_data = advGAN.adv_example(data)\n                output = model(perturbed_data)\n                test_loss += criterion(output, target).item()\n                final_pred = output.max(1, keepdim=True)[1]\n                final_pred = final_pred.view_as(target)\n                test_correct += final_pred.eq(target).sum().item()\n                if len(adv_examples) < 64 and not (final_pred == target).all():\n                    indices = torch.ne(final_pred.ne(target), init_pred.ne(target)).nonzero()\n                    for i in range(indices.shape[0]):\n                        adv_ex = perturbed_data[indices[i]].squeeze().detach().cpu().numpy()\n                        adv_examples.append((init_pred[indices[i]].item(), final_pred[indices[i]].item(), adv_ex))\n                        if (len(adv_examples) >= 64):\n                            break\n                data, target = valid_prefetcher.next()\n        test_loss /= len(valid_loader)\n        print('Eval loss: {:.4f}, accuracy: {:.4f}'.format(\n            test_loss, 100 * test_correct / (1-FLAGS.data_split) / num_train))\n```", "```py\nAttacking ensemble model...\n\nEval loss: 2.1465, accuracy: 10.3000\n```", "```py\n        cnt = 0\n        plt.figure(figsize=(8,10))\n        for i in range(8):\n            for j in range(8):\n                cnt += 1\n                plt.subplot(8, 8, cnt)\n                plt.xticks([], [])\n                plt.yticks([], [])\n                orig, adv, ex = adv_examples[i*8+j]\n                ex = np.transpose(ex, (1, 2, 0))\n                plt.title(\"{} -> {}\".format(orig, adv))\n                plt.imshow(ex)\n        plt.tight_layout()\n        plt.show()\n```", "```py\n$ python cats_dogs.py --model resnet34 --train_single True\n$ python cats_dogs.py --model mobilenet_v2 --train_single True --data_dir ./cats-dogs-kaggle\n$ python cats_dogs.py --model shufflenet_v2_x1_0 --train_single True --data_dir ./cats-dogs-kaggle\n$ python cats_dogs.py --model squeezenet1_1 --train_single True --data_dir ./cats-dogs-kaggle \n$ python cats_dogs.py --model densenet121 --train_single True --data_dir ./cats-dogs-kaggle\n$ python cats_dogs.py --model googlenet --train_single True --data_dir ./cats-dogs-kaggle\n$ python cats_dogs.py --model resnext50_32x4d --train_single True --data_dir ./cats-dogs-kaggle\n$ python cats_dogs.py --model vgg11 --train_single True --data_dir ./cats-dogs-kaggle\n```", "```py\n$ python cats_dogs.py --train_single False --train_ensemble True\n```"]