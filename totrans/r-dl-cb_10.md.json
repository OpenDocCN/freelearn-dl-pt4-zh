["```py\nrequire(RCurl) \nURL <- 'http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz' \ndownload.file(URL,destfile=\"vgg_16_2016_08_28.tar.gz\",method=\"libcurl\") \n\n```", "```py\nrequire(tensorflow) \n\n```", "```py\nslimobj = tf$contrib$slim \n\n```", "```py\ntf$reset_default_graph() \n\n```", "```py\n# Resizing the images \ninput.img= tf$placeholder(tf$float32, shape(NULL, NULL, NULL, 3)) \nscaled.img = tf$image$resize_images(input.img, shape(224,224))\n\n```", "```py\n# Define VGG16 network \nlibrary(magrittr) \nVGG16.model<-function(slim, input.image){ \n  vgg16.network = slim$conv2d(input.image, 64, shape(3,3), scope='vgg_16/conv1/conv1_1') %>%  \n    slim$conv2d(64, shape(3,3), scope='vgg_16/conv1/conv1_2')  %>% \n    slim$max_pool2d( shape(2, 2), scope='vgg_16/pool1')  %>% \n\n    slim$conv2d(128, shape(3,3), scope='vgg_16/conv2/conv2_1')  %>% \n    slim$conv2d(128, shape(3,3), scope='vgg_16/conv2/conv2_2')  %>% \n    slim$max_pool2d( shape(2, 2), scope='vgg_16/pool2')  %>% \n\n    slim$conv2d(256, shape(3,3), scope='vgg_16/conv3/conv3_1')  %>% \n    slim$conv2d(256, shape(3,3), scope='vgg_16/conv3/conv3_2')  %>% \n    slim$conv2d(256, shape(3,3), scope='vgg_16/conv3/conv3_3')  %>% \n    slim$max_pool2d(shape(2, 2), scope='vgg_16/pool3')  %>% \n\n    slim$conv2d(512, shape(3,3), scope='vgg_16/conv4/conv4_1')  %>% \n    slim$conv2d(512, shape(3,3), scope='vgg_16/conv4/conv4_2')  %>% \n    slim$conv2d(512, shape(3,3), scope='vgg_16/conv4/conv4_3')  %>% \n    slim$max_pool2d(shape(2, 2), scope='vgg_16/pool4')  %>% \n\n    slim$conv2d(512, shape(3,3), scope='vgg_16/conv5/conv5_1')  %>% \n    slim$conv2d(512, shape(3,3), scope='vgg_16/conv5/conv5_2')  %>% \n    slim$conv2d(512, shape(3,3), scope='vgg_16/conv5/conv5_3')  %>% \n    slim$max_pool2d(shape(2, 2), scope='vgg_16/pool5')  %>% \n\n    slim$conv2d(4096, shape(7, 7), padding='VALID', scope='vgg_16/fc6')  %>% \n    slim$conv2d(4096, shape(1, 1), scope='vgg_16/fc7') %>%  \n\n    slim$conv2d(1000, shape(1, 1), scope='vgg_16/fc8')  %>% \n    tf$squeeze(shape(1, 2), name='vgg_16/fc8/squeezed') \n  return(vgg16.network) \n} \n\n```", "```py\nvgg16.network<-VGG16.model(slim, input.image = scaled.img) \n\n```", "```py\n# Restore the weights \nrestorer = tf$train$Saver() \nsess = tf$Session() \nrestorer$restore(sess, 'vgg_16.ckpt')\n\n```", "```py\n# Evaluating using VGG16 network \ntestImgURL<-\"http://farm4.static.flickr.com/3155/2591264041_273abea408.jpg\" \nimg.test<-tempfile() \ndownload.file(testImgURL,img.test, mode=\"wb\") \nread.image <- readJPEG(img.test) \n# Clean-up the temp file \nfile.remove(img.test)  \n\n```", "```py\n## Evaluate  \nsize = dim(read.image) \nimgs = array(255*read.image, dim = c(1, size[1], size[2], size[3])) \nVGG16_eval = sess$run(vgg16.network, dict(images = imgs)) \nprobs = exp(VGG16_eval)/sum(exp(VGG16_eval))  \n\n```", "```py\ninstall.packages(\"imager\")\n\n```", "```py\n# Load packages \nrequire(imager) \nsource(\"download_cifar_data.R\") \nThe download_cifar_data consists of function to download and read CIFAR10 dataset. \n\n```", "```py\n# Read Dataset and labels  \nDATA_PATH<-paste(SOURCE_PATH, \"/Chapter 4/data/cifar-10-batches-bin/\", sep=\"\") \nlabels <- read.table(paste(DATA_PATH, \"batches.meta.txt\", sep=\"\")) \ncifar_train <- read.cifar.data(filenames = c(\"data_batch_1.bin\",\"data_batch_2.bin\",\"data_batch_3.bin\",\"data_batch_4.bin\")) \n\n```", "```py\n# Filter data for Aeroplane and Automobile with label 1 and 2, respectively \nClasses = c(1, 2)  \nimages.rgb.train <- cifar_train$images.rgb \nimages.lab.train <- cifar_train$images.lab \nix<-images.lab.train%in%Classes \nimages.rgb.train<-images.rgb.train[ix] \nimages.lab.train<-images.lab.train[ix] \nrm(cifar_train)   \n\n```", "```py\n# Function to transform to image \ntransform.Image <- function(index, images.rgb) { \n  # Convert each color layer into a matrix,  \n  # combine into an rgb object, and display as a plot \n  img <- images.rgb[[index]] \n  img.r.mat <- as.cimg(matrix(img$r, ncol=32, byrow = FALSE)) \n  img.g.mat <- as.cimg(matrix(img$g, ncol=32, byrow = FALSE)) \n  img.b.mat <- as.cimg(matrix(img$b, ncol=32, byrow = FALSE)) \n\n  # Bind the three channels into one image \n  img.col.mat <- imappend(list(img.r.mat,img.g.mat,img.b.mat),\"c\")  \n  return(img.col.mat) \n} \n\n```", "```py\n  # Function to pad image \n  image.padding <- function(x) { \n  img_width <- max(dim(x)[1:2]) \n  img_height <- min(dim(x)[1:2]) \n  pad.img <- pad(x, nPix = img_width - img_height, \n                 axes = ifelse(dim(x)[1] < dim(x)[2], \"x\", \"y\")) \n  return(pad.img) \n}\n\n```", "```py\n# Save train images \nMAX_IMAGE<-length(images.rgb.train) \n\n# Write Aeroplane images to aero folder \nsapply(1:MAX_IMAGE, FUN=function(x, images.rgb.train, images.lab.train){ \n  if(images.lab.train[[x]]==1){ \n    img<-transform.Image(x, images.rgb.train)   \n    pad_img <- image.padding(img) \n    res_img <- resize(pad_img, size_x = 224, size_y = 224) \n    imager::save.image(res_img, paste(\"train/aero/aero\", x, \".jpeg\", sep=\"\"))     \n  } \n}, images.rgb.train=images.rgb.train, images.lab.train=images.lab.train) \n\n# Write Automobile images to auto folder \nsapply(1:MAX_IMAGE, FUN=function(x, images.rgb.train, images.lab.train){ \n  if(images.lab.train[[x]]==2){ \n    img<-transform.Image(x, images.rgb.train)   \n    pad_img <- image.padding(img) \n    res_img <- resize(pad_img, size_x = 224, size_y = 224) \n    imager::save.image(res_img, paste(\"train/auto/auto\", x, \".jpeg\", sep=\"\"))     \n  } \n}, images.rgb.train=images.rgb.train, images.lab.train=images.lab.train) \n\n```", "```py\nSystem(\"python ~/mxnet/tools/im2rec.py --list True --recursive True --train-ratio 0.90 cifar_224/pks.lst cifar_224/trainf/\")\n\n```", "```py\n# Creating .rec file from training sample list \nSystem(\"python ~/mxnet/tools/im2rec.py --num-thread=4 --pass-through=1 /home/prakash/deep\\ learning/cifar_224/pks.lst_train.lst /home/prakash/deep\\ learning/cifar_224/trainf/\")   \n\n# Creating .rec file from validation sample list \nSystem(\"python ~/mxnet/tools/im2rec.py --num-thread=4 --pass-through=1 /home/prakash/deep\\ learning/cifar_224/pks.lst_val.lst /home/prakash/deep\\ learning/cifar_224/trainf/\") \n\n```", "```py\n# Function to load data as iterators \ndata.iterator <- function(data.shape, train.data, val.data, BATCHSIZE = 128) { \n\n  # Load training data as iterator \n  train <- mx.io.ImageRecordIter( \n    path.imgrec = train.data, \n    batch.size  = BATCHSIZE, \n    data.shape  = data.shape, \n    rand.crop   = TRUE, \n    rand.mirror = TRUE) \n\n  # Load validation data as iterator \n  val <- mx.io.ImageRecordIter( \n    path.imgrec = val.data, \n    batch.size  = BATCHSIZE, \n    data.shape  = data.shape, \n    rand.crop   = FALSE, \n    rand.mirror = FALSE \n  ) \n\n  return(list(train = train, val = val)) \n} \n\n```", "```py\n# Load dataset \ndata  <- data.iterator(data.shape = c(224, 224, 3), \n                      train.data = \"pks.lst_train.rec\", \n                      val.data  = \"pks.lst_val.rec\", \n                      BATCHSIZE = 8) \ntrain <- data$train \nval   <- data$val \n\n```", "```py\n# Load Inception-BN model \ninception_bn <- mx.model.load(\"Inception-BN\", iteration = 126) \nsymbol <- inception_bn$symbol \nThe different layers of the model can be viewed using function symbol$arguments \n\n```", "```py\n# Load model information \ninternals <- symbol$get.internals() \noutputs <- internals$outputs \nflatten <- internals$get.output(which(outputs == \"flatten_output\")) \n\n```", "```py\n# Define new layer \nnew_fc <- mx.symbol.FullyConnected(data = flatten,  \n                                   num_hidden = 2,  \n                                   name = \"fc1\")  \nnew_soft <- mx.symbol.SoftmaxOutput(data = new_fc,  \n                                    name = \"softmax\") \n\n```", "```py\n# Re-initialize the weights for new layer \narg_params_new <- mxnet:::mx.model.init.params( \n  symbol = new_soft,  \n  input.shape = c(224, 224, 3, 8),  \n  output.shape = NULL,  \n  initializer = mxnet:::mx.init.uniform(0.2),  \n  ctx = mx.cpu(0) \n)$arg.params \nfc1_weights_new <- arg_params_new[[\"fc1_weight\"]] \nfc1_bias_new <- arg_params_new[[\"fc1_bias\"]] \n\n```", "```py\n# Mode re-train \nmodel <- mx.model.FeedForward.create( \n  symbol             = new_soft, \n  X                  = train, \n  eval.data          = val, \n  ctx                = mx.cpu(0), \n  eval.metric        = mx.metric.accuracy, \n  num.round          = 5, \n  learning.rate      = 0.05, \n  momentum           = 0.85, \n  wd                 = 0.00001, \n  kvstore            = \"local\", \n  array.batch.size   = 128, \n  epoch.end.callback = mx.callback.save.checkpoint(\"inception_bn\"), \n  batch.end.callback = mx.callback.log.train.metric(150), \n  initializer        = mx.init.Xavier(factor_type = \"in\", magnitude = 2.34), \n  optimizer          = \"sgd\", \n  arg.params         = arg_params_new, \n  aux.params         = inception_bn$aux.params \n)  \n\n```", "```py\n# Mode re-train \nmodel <- mx.model.FeedForward.create( \n  symbol             = new_soft, \n  X                  = train, \n  eval.data          = val, \n  ctx                = mx.gpu(0), \n  eval.metric        = mx.metric.accuracy, \n  num.round          = 5, \n  learning.rate      = 0.05, \n  momentum           = 0.85, \n  wd                 = 0.00001, \n  kvstore            = \"local\", \n  array.batch.size   = 128, \n  epoch.end.callback = mx.callback.save.checkpoint(\"inception_bn\"), \n  batch.end.callback = mx.callback.log.train.metric(150), \n  initializer        = mx.init.Xavier(factor_type = \"in\", magnitude = 2.34), \n  optimizer          = \"sgd\", \n  arg.params         = arg_params_new, \n  aux.params         = inception_bn$aux.params \n)  \n\n```", "```py\ninstall.packages(\"gpuR\") \n\n```", "```py\nlibrary(gpuR) \n# verify you have valid GPUs \ndetectGPUs()  \n\n```", "```py\nlibrary(\"gpuR\") \noptions(gpuR.default.type = \"float\") \n\n```", "```py\n# Assigning a matrix to GPU \nA<-matrix(rnorm(1000), nrow=10) \n\nvcl1 = vclMatrix(A)\n\n```", "```py\n> vcl1 \nAn object of class \"fvclMatrix\" \nSlot \"address\": \n<pointer: 0x000000001822e180> \n\nSlot \".context_index\": \n[1] 1 \n\nSlot \".platform_index\": \n[1] 1 \n\nSlot \".platform\": \n[1] \"Intel(R) OpenCL\" \n\nSlot \".device_index\": \n[1] 1 \n\nSlot \".device\": \n[1] \"Intel(R) HD Graphics 530\" \n\n```", "```py\n# CPU vs GPU performance \nDF <- data.frame() \nevalSeq<-seq(1,2501,500) \nfor (dimpower in evalSeq){ \n  print(dimpower) \n  Mat1 = matrix(rnorm(dimpower^2), nrow=dimpower) \n  Mat2 = matrix(rnorm(dimpower^2), nrow=dimpower) \n\n  now <- Sys.time() \n  Matfin = Mat1%*%Mat2 \n  cpu <- Sys.time()-now \n\n  now <- Sys.time() \n  vcl1 = vclMatrix(Mat1) \n  vcl2 = vclMatrix(Mat2) \n  vclC = vcl1 %*% vcl2 \n  gpu <- Sys.time()-now \n\n  DF <- rbind(DF,c(nrow(Mat1), cpu, gpu))  \n} \nDF<-data.frame(DF) \ncolnames(DF) <- c(\"nrow\", \"CPU_time\", \"gpu_time\")   \n\n```"]