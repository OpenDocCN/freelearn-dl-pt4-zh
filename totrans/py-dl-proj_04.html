<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Building an NLP Pipeline for Building Chatbots</h1>
                </header>
            
            <article>
                
<p>Our project has expanded once again, thanks to the good work that we've been doing. We started off working for a restaurant chain, helping them to classify handwritten digits for use in a text notification system, used to alert their waiting guests that their table was ready. Based on this success, and when the owners realized that their customers were actually responding to the texts, we were asked to contribute a deep learning solution using <strong>Natural Language Processing</strong> (<strong>NLP</strong>) to accurately classify text into a meaningful sentiment category that would give the owners an indication as to their satisfaction with the dining experience.</p>
<div class="mce-root packt_tip"><span>Do you know what happens to deep learning engineers that do good work? </span><span>They get asked to do more!</span></div>
<p class="p1">This project for the next business use case is pretty cool. What we're being asked to do is to create a natural language pipeline that would power a chatbot for open domain question answering.<span class="Apple-converted-space"> </span>The (hypothetical) restaurant chain has a website with their menu, history, location, hours, and other information, and they would like to add the ability for a website visitor to ask a question in a query box, and have our deep learning NLP chatbot find the relevant information and present that back.<span class="Apple-converted-space"> </span>They think that getting the right information back to the website visitor quickly would help drive in-store visits and improve the general customer experience.</p>
<p class="p1"><strong>Named Entity Recognition</strong> (<strong>NER</strong>) is the approach we will be using, which will give us the power we need to quickly classify the input text, which we can then match to the relevant content for a response. It's a great way to take advantage of a large corpus of unstructured data that changes without using hardcoded heuristics.</p>
<p class="mce-root">In this chapter, we will learn about the building blocks of the NLP model, including pre-processing, tokenizing, and tagging parts of speech. We will use this understanding to build a system able to read an unstructured piece of text, in order to formulate an answer for a specific question. We will also describe how to include this deep learning component in a classic NLP pipeline to retrieve information, in order to provide an open-domain question answering system that doesn't require a structured knowledge base.</p>
<p>In this chapter, we will do the following:</p>
<ul>
<li>Build a basic FAQ-based chatbot using statistical modeling in a framework, capable of detecting intents and entities for answering open-domain questions</li>
<li>Learn to generate dense representations of sentences</li>
<li>Build a document reader for extracting answers from unstructured text</li>
<li>Learn how to integrate deep learning models into a classic NLP pipeline</li>
</ul>
<div class="packt_tip"><strong>Define the goal</strong>: To b<span>uild a chatbot that understands the context (intent) and can also extract the entities. To do this, we need an NLP pipeline that can perform intent classification, along with NER extraction to then provide an accurate response.<br/></span><strong><br/>
Skills learned</strong>: You will learn how to build an open-domain question answering system using a classic NLP pipeline, with a document reader component that uses deep learning techniques to generate sentence representations.</div>
<p>Let's get started!</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Basics of NLP pipelines</h1>
                </header>
            
            <article>
                
<p><span>Textual data is a very large source of information, and properly handling it is crucial to success. So, to handle this textual data, we need to follow some basic text processing steps.</span></p>
<div class="packt_tip"><span>Most of the processing steps covered in this section are commonly used in NLP and involve combining a number of steps into one executable flow. This is what we refer to as the NLP pipeline. </span><span>This flow can be a combination of tokenization, stemming, word frequency, parts of speech tagging, and many more elements.</span></div>
<p class="mce-root"/>
<p>Let's look into the details on how to implement the steps in the NLP pipeline and, specifically, what each stage of processing does. We will use the <span><strong>Natural Language Toolkit</strong> (<strong>NLTK</strong>) package—an NLP toolkit written in Python, which you can install with the following:</span></p>
<pre>import nltk<br/>nltk.download('punkt')<br/>nltk.download('averaged_perceptron_tagger')</pre>
<div class="packt_infobox"><span>The code for this project is available at <a href="https://github.com/PacktPublishing/Python-Deep-Learning-Projects/blob/master/Chapter04/Basic%20NLP%20Pipeline.ipynb" target="_blank">https://github.com/PacktPublishing/Python-Deep-Learning-Projects/blob/master/Chapter04/Basic%20NLP%20Pipeline.ipynb</a>.<a href="https://github.com/PacktPublishing/Python-Deep-Learning-Projects/blob/master/Chapter04/Basic%20NLP%20Pipeline.ipynb" target="_blank"/></span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Tokenization</h1>
                </header>
            
            <article>
                
<p class="graf graf--p graf-after--h3">Tokenization separates a corpus into sentences, words, or tokens. Tokenization is needed to make our texts ready for further processing and is the first step in creating an NLP pipeline. A<span> </span>token can vary according to the task we are performing or the domain in which we are working, so keep an open mind as to what you consider as a token! </p>
<div class="packt_infobox"><strong>Know the code</strong>: NLTK is powerful, as much of the hard coding work is already done in the library. You can read more about NLTK tokenization at <a href="http://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.api.TokenizerI.tokenize_sents">http://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.api.TokenizerI.tokenize_sents</a>.</div>
<p class="graf graf--p graf-after--h3">Let's try to load a corpus and use NLTK tokenizer to first tokenize the raw corpus into sentences, and then tokenize each sentence further into words:</p>
<pre>text = u"""<br/>Dealing with textual data is very crucial so to handle these text data we need some <br/>basic text processing steps. Most of the processing steps covered in this section are <br/>commonly used in NLP and involve the combination of several steps into a single <br/>executable flow. This is usually referred to as the NLP pipeline. These flow <br/>can be a combination of tokenization, stemming, word frequency, parts of <br/>speech tagging, etc.<br/>"""<br/><br/># Sentence Tokenization<br/>sentenses = nltk.sent_tokenize(text)<br/><br/># Word Tokenization<br/>words = [nltk.word_tokenize(s) for s in sentenses]<br/><br/><strong>OUTPUT</strong>:<br/><strong>SENTENCES:</strong><br/><span>[u'\nDealing with textual data is very crucial so to handle these text data we need some \nbasic text processing steps.', <br/>u'Most of the processing steps covered in this section are \ncommonly used in NLP and involve the combination of several steps into a single \nexecutable flow.', <br/>u'This is usually referred to as the NLP pipeline.', <br/>u'These flow \ncan be a combination of tokenization, stemming, word frequency, parts of \nspeech tagging, etc.']<br/><br/><strong>WORDS:</strong><br/>[[u'Dealing', u'with', u'textual', u'data', u'is', u'very', u'crucial', u'so', u'to', u'handle', u'these', u'text', u'data', u'we', u'need', u'some', u'basic', u'text', u'processing', u'steps', u'.'], [u'Most', u'of', u'the', u'processing', u'steps', u'covered', u'in', u'this', u'section', u'are', u'commonly', u'used', u'in', u'NLP', u'and', u'involve', u'the', u'combination', u'of', u'several', u'steps', u'into', u'a', u'single', u'executable', u'flow', u'.'], [u'This', u'is', u'usually', u'referred', u'to', u'as', u'the', u'NLP', u'pipeline', u'.'], [u'These', u'flow', u'can', u'be', u'a', u'combination', u'of', u'tokenization', u',', u'stemming', u',', u'word', u'frequency', u',', u'parts', u'of', u'speech', u'tagging', u',', u'etc', u'.']]<br/></span></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Part-of-Speech tagging</h1>
                </header>
            
            <article>
                
<p><span>Some words have multiple meanings, for example, <em>charge</em> is a noun, but can also be a verb, (<em>to) charge</em>. Knowing a <strong>Part-of-Speech</strong> (<strong>POS</strong>) can help to disambiguate the meaning. Each token in a sentence has several attributes that we can use for our analysis. The POS of a word is one example: nouns are a person, place, or thing; verbs are actions or occurrences and adjectives are words that describe nouns. Using these attributes, it becomes straightforward to create a summary of a piece of text by counting the most common nouns, verbs, and adjectives:</span></p>
<pre>tagged_wt = [nltk.pos_tag(w)for w in words]<br/><br/><span>[[('One', 'CD'), ('way', 'NN'), ('to', 'TO'), ('extract', 'VB'), ('meaning', 'VBG'), ('from', 'IN'), ('text', 'NN'), ('is', 'VBZ'), ('to', 'TO'), ('analyze', 'VB'), ('individual', 'JJ'), ('words', 'NNS'), ('.', '.')], [('The', 'DT'), ('processes', 'NNS'), ('of', 'IN'), ('breaking', 'VBG'), ('up', 'RP'), ('a', 'DT'), ('text', 'NN'), ('into', 'IN'), ('words', 'NNS'), ('is', 'VBZ'), ('called', 'VBN'), ('tokenization', 'NN'), ('--', ':'), ('the', 'DT'), ('resulting', 'JJ'), ('words', 'NNS'), ('are', 'VBP'), ('referred', 'VBN'), ('to', 'TO'), ('as', 'IN'), ('tokens', 'NNS'), ('.', '.')], [('Punctuation', 'NN'), ('marks', 'NNS'), ('are', 'VBP'), ('also', 'RB'), ('tokens', 'NNS'), ('.', '.')], [('Each', 'DT'), ('token', 'NN'), ('in', 'IN'), ('a', 'DT'), ('sentence', 'NN'), ('has', 'VBZ'), ('several', 'JJ'), ('attributes', 'IN'), ('we', 'PRP'), ('can', 'MD'), ('use', 'VB'), ('for', 'IN'), ('analysis', 'NN'), ('.', '.')]]<br/><br/></span><span><br/></span>patternPOS= []<br/>for tag in tagged_wt:<br/>  patternPOS.append([v for k,v in tag])<br/><br/><span>[['CD', 'NN', 'TO', 'VB', 'VBG', 'IN', 'NN', 'VBZ', 'TO', 'VB', 'JJ', 'NNS', '.'], ['DT', 'NNS', 'IN', 'VBG', 'RP', 'DT', 'NN', 'IN', 'NNS', 'VBZ', 'VBN', 'NN', ':', 'DT', 'JJ', 'NNS', 'VBP', 'VBN', 'TO', 'IN', 'NNS', '.'], ['NN', 'NNS', 'VBP', 'RB', 'NNS', '.'], ['DT', 'NN', 'IN', 'DT', 'NN', 'VBZ', 'JJ', 'IN', 'PRP', 'MD', 'VB', 'IN', 'NN', '.'], ['DT', 'NN', 'IN', 'NN', 'IN', 'DT', 'NN', 'VBZ', 'CD', 'NN', ':', 'NNS', 'VBP', 'DT', 'NN', ',', 'NN', ',', 'CC', 'NN', ':', 'NNS', 'VBP', 'NNS', 'CC', 'NNS', ':', 'NNS', 'VBP', 'NNS', 'IN', 'NN', 'NNS', '.'], ['VBG', 'DT', 'NNS', ',', 'PRP', 'VBZ', 'JJ', 'TO', 'VB', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'NN', 'IN', 'VBG', 'DT', 'RBS', 'JJ', 'NNS', ',', 'NNS', ',', 'CC', 'NNS', '.']]<br/></span></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Extracting nouns</h1>
                </header>
            
            <article>
                
<p>Let's extract all of the nouns present in the corpus. This is very useful practice when you want to extract something specific. We are using <kbd>NN</kbd>, <kbd>NNS</kbd>, <kbd>NNP</kbd>, and <kbd>NNPS</kbd> tags to extract the nouns:</p>
<pre>nouns = [] <br/>for tag in tagged_wt:<br/>nouns.append([k for k,v in tag if v in ['NN','NNS','NNP','NNPS']])<br/><br/><span>[['way', 'text', 'words'], ['processes', 'text', 'words', 'tokenization', 'words', 'tokens'], ['Punctuation', 'marks', 'tokens'], ['token', 'sentence', 'analysis'], ['part', 'speech', 'word', 'example', 'nouns', 'person', 'place', 'thing', 'verbs', 'actions', 'occurences', 'adjectives', 'words', 'describe', 'nouns'], ['attributes', 'summary', 'piece', 'text', 'nouns', 'verbs', 'adjectives']]</span></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Extracting verbs</h1>
                </header>
            
            <article>
                
<p><span>Let's extract all of the verbs present in the corpus. In this case, we are using <kbd>VB</kbd>, <kbd>VBD</kbd>, <kbd>VBG</kbd>, <kbd>VBN</kbd>, <kbd>VBP</kbd>, and <kbd>VBZ</kbd></span> as <span>verb tags:</span></p>
<pre class="mce-root">verbs = [] <br/>for tag in tagged_wt:<br/>verbs.append([k for k,v in tag if v in ['VB','VBD','VBG','VBN','VBP','VBZ']])<br/><br/><span>[['extract', 'meaning', 'is', 'analyze'], ['breaking', 'is', 'called', 'are', 'referred'], ['are'], ['has', 'use'], ['is', 'are', 'are', 'are'], ['Using', "'s", 'create', 'counting']]<br/></span></pre>
<p><span>Now, let's use <kbd>spacy</kbd> to</span><span> tokenize a piece of text and access the POS attribute for each token. As an example application, we'll tokenize the previous paragraph and count the most common nouns with the following code. We'll also lemmatize the tokens, which gives the root form a word, to help us standardize across forms of a word:</span></p>
<pre>! pip install -q spacy <br/>! pip install -q tabulate<br/>! python -m spacy download en_core_web_lg<br/><br/><br/><br/>from collections import Counter<br/>import spacy<br/>from tabulate import tabulate<br/>nlp = spacy.load('en_core_web_lg')<br/><br/>doc = nlp(text)<br/>noun_counter = Counter(token.lemma_ for token in doc if token.pos_ == 'NOUN')<br/><br/>print(tabulate(noun_counter.most_common(5), headers=['Noun', 'Count']))</pre>
<p>Following is the output:</p>
<pre><strong><span>Noun         Count <br/>-----------  ------- <br/>step          3 <br/>combination   2 <br/>text          2 <br/>processing    2 <br/>datum         2</span></strong></pre>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Dependency parsing</h1>
                </header>
            
            <article>
                
<p><span>Dependency parsing is a way to understand the relationships between words in a sentence. Dependency relations are a more fine-grained attribute, available to help build the model's understanding of the words through their relationships in a sentence: </span></p>
<pre>doc = nlp(sentenses[2])<br/>spacy.displacy.render(doc,style='dep', options={'distance' : 140}, jupyter=True)</pre>
<p><span> These relationships between words can get complicated, depending on how sentences are structured. The result of dependency-parsing a sentence is a tree data structure, with the verb as the root, as shown in the following diagram:</span></p>
<div class="CDPAlignCenter CDPAlign packt_figref">
<p><img src="assets/6669edc6-66ac-4c9d-955d-3a31c46118e2.png"/></p>
</div>
<div class="CDPAlignCenter CDPAlign packt_figref">The tree structure of the dependency parsing of a sentence, with the verb as the root.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">NER</h1>
                </header>
            
            <article>
                
<p><span>Finally, there's NER. </span>Named entities are the proper nouns of sentences. Computers have gotten pretty good at figuring out if they're in a sentence and at classifying what type of entity they are. <kbd>spacy</kbd> handles NER at the document level, since the name of an entity can span several tokens:</p>
<pre>doc = nlp(u"My name is Jack and I live in India.")<br/>entity_types = ((ent.text, ent.label_) for ent in doc.ents)<br/>print(tabulate(entity_types, headers=['Entity', 'Entity Type']))<br/><br/><br/><strong>Output:</strong><br/><span>Entity     Entity Type <br/>--------   ------------- <br/>Jack       PERSON <br/>India      GPE</span></pre>
<p>So, we just saw some of the basic building blocks of the NLP pipeline. These pipelines are consistently used in various NLP projects, be it in machine learning or in the deep learning space. </p>
<div class="packt_tip"><span class="packt_screen">Does something look familiar?</span><br/>
We used a few of these NLP pipeline building blocks in the previous chapter, <a href="4dcd4b65-934b-4a8a-a252-9af7513a4787.xhtml" target="_blank">Chapter 3</a>, <em>Word Representation Using word2vec</em>, to build our word2vec models. This more in-depth explanation of the building blocks of the NLP pipeline helps us take the next step in our projects, as we look to deploy more and more complex models!</div>
<p>As with everything in this book on <em>Python Deep Learning Projects</em><span>,</span> we encourage you to also try your own combinations of the previous processes for the use cases you work on in your data science career. <span>Now, let's implement a chatbot using these pipelines!</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Building conversational bots</h1>
                </header>
            
            <article>
                
<p>In this section, we will learn about some basic statistical modeling approaches to build an information retrieval system using <strong>term frequency</strong>-<strong>inverse document frequency</strong> (<strong>TF-IDF</strong>), which we can use with the NLP pipelines to build fully functional chatbots. Also, later on, we will learn to build a much more advanced conversational bot that can extract a specific piece of information, such as location, capture time, and so on, using NER.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">What is TF-IDF?</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span>TF-IDFs are a way to represent documents as feature vectors. But what are they? TF-IDFs can be understood as a modification of the </span>raw <strong>term frequency</strong> <span>(</span><strong>TF</strong><span>) and <strong>inverse document frequency</strong> (</span><strong>IDF</strong><span>). The TF</span><span> is the count of how often a particular word occurs in a given document. The concept behind the TF-IDF is to downweight terms proportionally to the number of documents in which they occur. Here, the idea is that terms that occur in many different documents are likely to be unimportant, or don't contain any useful information for NLP tasks, such as document classification.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Preparing the dataset</h1>
                </header>
            
            <article>
                
<p class="cell border-box-sizing text_cell rendered">If we think about building a chatbot with the TF-IDF approach, we first need to form a data structure that supports training data with labels. Now, let's take an example of a chatbot built to answer questions from users.</p>
<p class="cell border-box-sizing text_cell rendered">In this case, using historical data, we can form a dataset where we have two columns, one of which is the question, and the second of which is the answer to that question, as shown in the following table:</p>
<table border="1" style="border-collapse: collapse">
<tbody>
<tr>
<td>
<p><strong>Question</strong></p>
</td>
<td>
<p><strong>Answer</strong></p>
</td>
</tr>
<tr>
<td>
<p>When does your shop open?</p>
</td>
<td>
<p>Our shop timings are 9:00 A.M-9:00 P.M on weekdays and 11:00 A.M-12:00 midnight on weekends.</p>
</td>
</tr>
<tr>
<td>
<p>What is today's special?</p>
</td>
<td>
<p>Today, we have a variety of Italian pasta, with special sauce and a lot more other options in the bakery.</p>
</td>
</tr>
<tr>
<td>
<p>What is the cost of an Americano?</p>
</td>
<td>
<p>Americano with a single shot will cost $1.4 and the double shot will cost $2.3.</p>
</td>
</tr>
<tr>
<td>
<p>Do you sell ice-creams?</p>
</td>
<td>
<p>We do have desserts such as ice-cream, brownies, and pastries.</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p class="cell border-box-sizing text_cell rendered">Let's take the previous example, and consider it a sample dataset. It is a very small example and, in the original hypothetical scenario, we will have a much larger dataset to work with. The typical process will be as follows: the user will interact with the bot and write a random query about the store. The bot will simply send that query to the NLP engine, using an API, and then it is up to the NLP model to decide what to return for a new query (test data). In reference to our dataset, all of the questions are the training data and the answers are labels. In the event of a new query, the TF-IDF algorithm will match it to one of the questions with a confidence score, which tells us that the new question asked by the user is close to some specific question from the dataset, and the answer against that question is the answer that our bots return.</p>
<p class="cell border-box-sizing text_cell rendered">Let's take the preceding example even further. When the user queries, "Can I get an Americano, btw how much it will cost?", we can see that words like <em>I</em>, <em>an</em>, and <em>it</em> are the ones that will have a higher occurrence frequency in other questions as well.</p>
<p class="cell border-box-sizing text_cell rendered">Now, if we match our remaining important words, we will see that this question is most close to: "What is the cost of an Americano?"<em><span> </span></em>So, our bot will respond back with the historical answer to this type of question: "Americano with a single shot will cost $1.4 and the double shot will cost $2.3."</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementation</h1>
                </header>
            
            <article>
                
<p class="cell border-box-sizing text_cell rendered">After creating the data structure in tabular format, as mentioned previously, we will be calculating the predicted answer to a question every time a user queries our bot. We load all of the question-answer pairs from the dataset.</p>
<p class="cell border-box-sizing text_cell rendered">Let's load our CSV file using <kbd>pandas</kbd>, and perform some pre-processing on the dataset:</p>
<pre>import pandas as pd<br/><br/>filepath = 'sample_data.csv'<br/>csv_reader=pd.read_csv(filepath)<br/><br/>question_list = csv_reader[csv_reader.columns[0]].values.tolist()<br/>answers_list = csv_reader[csv_reader.columns[1]].values.tolist()<br/><br/>query= '<span>Can I get an </span>Americano<span>, btw how much it will cost ?</span>'</pre>
<div class="cell border-box-sizing text_cell rendered packt_infobox">The code for this project can be found at <a href="https://github.com/PacktPublishing/Python-Deep-Learning-Projects/tree/master/Chapter04/tfidf_version" target="_blank">https://github.com/PacktPublishing/Python-Deep-Learning-Projects/tree/master/Chapter04/tfidf_version</a>.<a href="https://github.com/PacktPublishing/Python-Deep-Learning-Projects/tree/master/Chapter04/tfidf_version" target="_blank"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating the vectorizer</h1>
                </header>
            
            <article>
                
<p class="cell border-box-sizing text_cell rendered">Now, let's initialize the TF-IDF vectorizer and define a few parameters:</p>
<ul>
<li class="cell border-box-sizing text_cell rendered"><kbd>min_df</kbd>: W<span>hen building the vocabulary, ignore terms that have a document frequency strictly lower than the given threshold</span></li>
<li class="cell border-box-sizing text_cell rendered"><kbd>ngram_range</kbd>: Configures our vectorizer to capture <em>n</em>-words at a time</li>
<li class="cell border-box-sizing text_cell rendered"><kbd>norm</kbd>: <span>This is used to normalize term vectors using L1 or L2 norms</span></li>
<li class="cell border-box-sizing text_cell rendered"><kbd>encoding</kbd>: Handles Unicode characters</li>
</ul>
<p>There are many more parameters that you can look into, configure, and play around with:</p>
<pre>from sklearn.feature_extraction.text import TfidfVectorizer<br/><br/>vectorizer = TfidfVectorizer(min_df=0, ngram_range=(2, 4), strip_accents='unicode',norm='l2' , encoding='ISO-8859-1')</pre>
<p class="mce-root">Now, we train the model on the questions:</p>
<pre># We create an array for our train data set (questions)<br/>X_train = vectorizer.fit_transform(np.array([''.join(que) for que in question_list]))<br/><br/># Next step is to transform the query sent by user to bot (test data)<br/>X_query=vectorizer.transform(query)</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Processing the query</h1>
                </header>
            
            <article>
                
<p class="mce-root">To process the query, we find out its similarity with other questions. We do this by taking a dot product of the training data matrix with a transpose of the query data:</p>
<pre>XX_similarity=np.dot(X_train.todense(), X_query.transpose().todense())</pre>
<p class="mce-root">Now, we take out the similarity between the query and train data as a list:</p>
<pre>XX_sim_scores= np.array(XX_similarity).flatten().tolist()</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Rank results</h1>
                </header>
            
            <article>
                
<p class="mce-root">We create a sorted dictionary of similarities for a query:</p>
<pre>dict_sim= dict(enumerate(XX_sim_scores))<br/><br/>sorted_dict_sim = sorted(dict_sim.items(), key=operator.itemgetter(1), reverse =True)</pre>
<p class="mce-root">Finally, in the sorted dictionary, we check for the index of the most similar question, and the response with the value at that index in the answers column. If nothing is found, then we can return our default answer:</p>
<pre>if sorted_dict_sim[0][1]==0:<br/>       print("Sorry I have no answer, please try asking again in a nicer way :)")<br/>elif sorted_dic_sim[0][1]&gt;0:<br/>       print answer_list [sorted_dic_sim[0][0]]</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Advanced chatbots using NER</h1>
                </header>
            
            <article>
                
<p>We just created a very basic chatbot that can understand the user's query and then respond to the customer accordingly. But it is not yet capable of understanding the context, because it can not extract information such as the product name, places, or any other entities.</p>
<p>To build a bot that understands the context (intent) and can also extract the entities, we need an NLP pipeline that can perform intent classification, along with NER extraction, and then provide an accurate response. </p>
<div class="packt_tip">Keep your eyes on the goal! This is the goal of our open-domain question answering bot. </div>
<p>To do that, we will use an open source project called Rasa NLU (<a href="https://github.com/RasaHQ/rasa_nlu">https://github.com/RasaHQ/rasa_nlu</a>).</p>
<p class="mce-root"><span><span>Rasa NLU is a <strong>Natural Language Understanding</strong> tool for understanding a text; in particular, what is being said in short pieces of text. For example, imagine that the system is given a short message like the following:</span></span></p>
<pre class="mce-root">"I'm looking for an Italian restaurant in the center of town"</pre>
<p class="mce-root"><span><span>In such a case, the system returns the following:</span></span></p>
<pre class="mce-root">intent: search_restaurant<br/>entities:<span class="Apple-converted-space">     <br/></span>      - cuisine : Italian <span class="Apple-converted-space">   <br/></span>     - location : center of town</pre>
<p class="mce-root">So, by harnessing the power of RASA, we can build a chatbot that can do intent classification and NER extraction.</p>
<p>Great, let's do it!</p>
<div class="packt_infobox"><span>The code for this project can be found at <a href="https://github.com/PacktPublishing/Python-Deep-Learning-Projects/tree/master/Chapter04/rasa_version" target="_blank">https://github.com/PacktPublishing/Python-Deep-Learning-Projects/tree/master/Chapter04/rasa_version</a></span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Installing Rasa</h1>
                </header>
            
            <article>
                
<p>Let's install Rasa in our local environment or server using these commands:</p>
<div class="highlight-bash">
<pre class="highlight">pip install rasa_nlu<br/>pip install coloredlogs sklearn_crfsuite spacy<br/>python -m spacy download en</pre></div>
<p>If it fails to install, then you can look into a detailed approach at <a href="https://nlu.rasa.com/installation.html">https://nlu.rasa.com/installation.html</a>.</p>
<p>Rasa uses a variety of NLP pipelines such as <kbd>spacy</kbd><span>, <kbd>sklearn</kbd>, or MITIE. You can use any one of them or build your own custom pipelines, which can include any deep model, such as CNN with word2vec, which we created in the previous chapter. In our case, we will be using <kbd>spacy</kbd> with <kbd>sklearn</kbd>.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Preparing dataset</h1>
                </header>
            
            <article>
                
<p><span>In our previous project, w</span>e created a dataset in a CSV file with two columns for question and answer pairs. We need to do this again, but in a different format. In this case, we need questions associated with its intent, as shown in the following diagram, so we have a query as <strong>hello</strong> with its intent labeled as <strong>greet</strong>. Similarly, we will label all of the questions with their respective intents.</p>
<p>Once we have all of the forms of questions and intents ready, we need to label the entities. In this case, as shown in the following diagram, we have a <strong>location</strong> entity with a <strong>centre</strong> <span>value, </span>and a <strong>cuisine</strong> entity with the value as <strong>mexican</strong>:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1383 image-border" src="assets/859b52cc-ab9e-4a95-be06-7ae12bd2b065.png" style="width:162.50em;height:73.17em;"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">The figure illustrated the content of the data what we are preparing for the chatbot. Lest most is the list of all intents which we need out bot to understand. Then we have respective sample utterneces for each intent. And the right most part represents the annotation of the specific entity with its label 'location' and 'cuisine' in this case.</div>
<p>To feed data into Rasa, we need to store this information in a specific JSON format, which looks like the following:</p>
<pre><span class="p"><strong># intent_list : Only intent part</strong><br/></span><span class="p">[<br/>  {<br/>    "text": "hey",<br/>    "intent": "greet"<br/>  },<br/>  {<br/>    "text": "hello",<br/>    "intent": "greet"<br/>  }<br/>]<br/><br/></span><span class="p"><strong># entity_list : Intent with entities</strong><br/>[{</span>
  <span class="nt">"text"</span><span class="p">:</span> <span class="s2">"show me indian restaurants"</span><span class="p">,</span>
  <span class="nt">"intent"</span><span class="p">:</span> <span class="s2">"restaurant_search"</span><span class="p">,</span>
  <span class="nt">"entities"</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span>
      <span class="nt">"start"</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
      <span class="nt">"end"</span><span class="p">:</span> <span class="mi">15</span><span class="p">,</span>
      <span class="nt">"value"</span><span class="p">:</span> <span class="s2">"indian"</span><span class="p">,</span>
      <span class="nt">"entity"</span><span class="p">:</span> <span class="s2">"cuisine"</span>
    <span class="p">}</span>
  <span class="p">]</span>
<span class="p">},<br/>]<br/><br/></span></pre>
<p>The final version of the JSON should have this structure:</p>
<pre>{<br/>  "rasa_nlu_data": {<br/>    "entity_examples": [entity_list],<br/>    "intent_examples": [intent_list]<br/>  }<br/>}</pre>
<div class="packt_tip">To make it simple, there is an online tool into which you can feed and annotate all of the data, and download the JSON version of it. You can run the editor locally by following the instructions from <a href="https://github.com/RasaHQ/rasa-nlu-trainer">https://github.com/RasaHQ/rasa-nlu-trainer</a> or simply use the online version of it from <a href="https://rasahq.github.io/rasa-nlu-trainer/">https://rasahq.github.io/rasa-nlu-trainer/</a>.</div>
<p>Save this JSON file as <kbd>restaurant.json</kbd> in the current working directory. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Training the model</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span>Now we're going to create a configuration file. This configuration file will define the pipeline that is to be used in the process of training and building of the model.</span></p>
<p class="mce-root"><span>Create a file called <kbd>config_spacy.yml</kbd> in </span><span>your working directory, and insert the following code into it:</span></p>
<pre><span class="l l-Scalar l-Scalar-Plain">language</span><span class="p p-Indicator">:</span> <span class="s">"en"</span>
<span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span> <span class="s">"spacy_sklearn"<br/>fine_tune_spacy_ner: true</span></pre>
<p class="mce-root"/>
<p class="mce-root"/>
<pre><span class="s"> </span></pre>
<div class="packt_infobox"><br/>
<strong>Know the code</strong>: spaCy configuration customization is there for a reason. Other data scientists have found some utility in the ability to change values here, and it's good practice to explore this as you get more familiar with this technology. There is a huge list of configurations, which you can look into at <a href="https://nlu.rasa.com/config.html">https://nlu.rasa.com/config.html</a>.</div>
<p class="mce-root">This configuration states that we will be using English language models, and the pipeline running on the backend will be spaCy with scikit-learn. Now, to begin the training process, execute the following command:</p>
<pre><strong>python -m rasa_nlu.train <span class="se">\</span>
    --config config_spacy.yml <span class="se">\</span>
    --data restaurant.json <span class="se">\</span>
    --path projects</strong></pre>
<p class="mce-root">This takes the configuration file and the training data file as input. The <kbd>--path</kbd> parameter is the location where the trained model will be stored.</p>
<p class="mce-root">Once the model training process is completed,<span> you'll see a new folder named in the <kbd>projects/default/model_YYYYMMDD-HHMMSS</kbd></span><span> format, </span><span>with the timestamp when the training finished. The complete project structure will look as shown in the following screenshot:</span></p>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/8d457b2a-fa48-40f8-a2b0-c9bbbf791ba1.png"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">The folder structure after the training process is completed. The model folder will contain all the binary files and metadata which was learned during the training process.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deploying the model</h1>
                </header>
            
            <article>
                
<p class="mce-root">Now it's the moment to make your bot go live! While using Rasa, you don't need to write any API services—everything is available in the package itself. So, to expose the trained model as a service, you need to execute the following command, which takes the path of the stored trained model:</p>
<pre><strong>python -m rasa_nlu.server --path projects</strong></pre>
<p class="mce-root">If everything goes fine, then a RESTful API will be exposed at port <kbd>5000</kbd>, and you should see this log on the console screen:</p>
<pre class="p1"><span class="s1">2018-05-23 21:34:23+0530 [-] Log opened.<br/></span><span class="s1">2018-05-23 21:34:23+0530 [-] Site starting on 5000<br/></span><span class="s1">2018-05-23 21:34:23+0530 [-] Starting factory &lt;twisted.web.server.Site instance at 0x1062207e8&gt;<br/></span></pre>
<p class="mce-root">To access the API, you can use the following command. We are querying the model, making a statement such as "<kbd>I am looking for Mexican food</kbd>":</p>
<pre><strong>curl -X POST localhost:5000/parse -d <span class="s1">'{"q":"I am looking for Mexican food"}'</span> <span class="p">|</span> python -m json.tool</strong><br/><br/><br/><span><strong>Output:</strong><br/></span><strong>{</strong><br/><strong>  "entities": [</strong><br/><strong>    {</strong><br/><strong>      "confidence": 0.5348393725109971,</strong><br/><strong>      "end": 24,</strong><br/><strong>      "entity": "cuisine",</strong><br/><strong>      "extractor": "ner_crf",</strong><br/><strong>      "start": 17,</strong><br/><strong>      "value": "mexican"</strong><br/><strong>    }</strong><br/><strong>  ],</strong><br/><strong>  "intent": {</strong><br/><strong>    "confidence": 0.7584285478135262,</strong><br/><strong>    "name": "restaurant_search"</strong><br/><strong>  },</strong><br/><strong>  "intent_ranking": [</strong><br/><strong>    {</strong><br/><strong>      "confidence": 0.7584285478135262,</strong><br/><strong>      "name": "restaurant_search"</strong><br/><strong>    },</strong><br/><strong>    {</strong><br/><strong>      "confidence": 0.11009204166074991,</strong><br/><strong>      "name": "goodbye"</strong><br/><strong>    },</strong><br/><strong>    {</strong><br/><strong>      "confidence": 0.08219245368495268,</strong><br/><strong>      "name": "affirm"</strong><br/><strong>    },</strong><br/><strong>    {</strong><br/><strong>      "confidence": 0.049286956840770876,</strong><br/><strong>      "name": "greet"</strong><br/><strong>    }</strong><br/><strong>  ],</strong><br/><strong>  "model": "model_20180523-213216",</strong><br/><strong>  "project": "default",</strong><br/><strong>  "text": "I am looking for Mexican food"</strong><br/><strong>}</strong></pre>
<p>So here, we can see that model has performed quite accurately with the intent classification and the entity extraction process. It is able to classify the intent as <kbd>restaurant_search</kbd> with 75.8% of accuracy, and is also able to detect the <kbd>cuisine</kbd> entity with the value as <kbd>mexican</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Serving chatbots</h1>
                </header>
            
            <article>
                
<p>Up to now, we have seen how to build chatbots using the two methods of TF-IDF and Rasa NLU. Let's expose both of them as APIs. The architecture of this simple chatbot framework will look like this:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/c640950b-e21d-4dfc-9bd8-c4c61eb06454.png" style="width:35.33em;height:21.50em;"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">This chatbot pipeline illustrates that we can have any User Interface (Slack, Skype, and so on) integrated with the chatbot_api which we exposed . And under the hood we can setup any number of algorithms 'TFIDF' and 'RASA'</div>
<p>Refer to the Packt repository for this chapter (available at <a href="https://github.com/PacktPublishing/Python-Deep-Learning-Projects/tree/master/Chapter04" target="_blank">https://github.com/PacktPublishing/Python-Deep-Learning-Projects/tree/master/Chapter04</a>) for the API code and look into the <kbd>chatbot_api.py</kbd><strong> </strong>file. Here, we have implemented a common API that can load both versions of bot, and you can now build a whole framework on top of this. </p>
<p>To execute the serving of the APIs, follow these steps:</p>
<ol>
<li>Enter the chapter directory using the following command:</li>
</ol>
<pre style="padding-left: 90px"><strong>cd Chapter04/</strong></pre>
<ol start="2">
<li>This will expose the Rasa module at <kbd>localhost:5000</kbd>. If you have not trained the Rasa engine, then please apply the following command:</li>
</ol>
<pre style="padding-left: 90px"><strong>python -m rasa_nlu.server --path ./rasa_version/projects</strong></pre>
<ol start="3">
<li>In a separate console, execute the following command. This will expose an API at <kbd>localhost:8080</kbd>:</li>
</ol>
<pre style="padding-left: 90px"><strong>python chatbot_api.py</strong></pre>
<ol start="4">
<li>Now your chatbot is ready to be accessed via API. Try the following:</li>
</ol>
<ul>
<li style="list-style-type: none">
<ul>
<li><span>Call the following API to execute the TFIDF version:</span></li>
</ul>
</li>
</ul>
<pre style="padding-left: 120px"><strong><span>curl http://localhost:8080/version1?query=Can I get an Americano</span></strong></pre>
<ul>
<li style="list-style-type: none">
<ul>
<li>Call the following API to execute the Rasa version:</li>
</ul>
</li>
</ul>
<pre style="padding-left: 120px"><strong>http://localhost:8080/version2?query=where is Indian cafe</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary </h1>
                </header>
            
            <article>
                
<p class="p1">In this project, we were asked to create a natural language pipeline that would power a chatbot for open domain question answering. <span>A </span>(hypothetical) restaurant chain has much text-based data on their website, including their menu, history, location, hours, and other information, and they would like to add the ability for a website visitor to ask a question in a query box. Our deep learning NLP chatbot would then find the relevant information and present that back to the visitor.</p>
<p>We got started by showing how we could build a simple FAQ chatbot that took in random queries, matched that up to predefined questions, and returned a response with a confidence score that indicated the similarity between the input question and the question in our database. But this was only a stepping stone to our real goal, which was to create a chatbot that could capture the intent of the question and prepare an appropriate response.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="p1">We explored an NER approach to give us the added power that we needed to quickly classify input text, which we could then match to the relevant content for a response. <span>This was determined to fit our goal of allowing for open-domain question answering and to</span> take advantage of a large corpus of unstructured data that changes without using<span> </span>hardcoded<span> </span>heuristics (as in our hypothetical restaurant example).</p>
<p class="mce-root">We learned to use the building blocks of the NLP model, including pre-processing, tokenizing, and tagging POS. We used this understanding to build a system able to read an unstructured text in order to comprehend an answer<span> </span>to<span> </span>a specific question.</p>
<p class="mce-root">Specifically, we gained these skills in this project:</p>
<ul>
<li>Building a basic FAQ-based chatbot using statistical modeling in a framework capable of detecting intents and entities for answering open-domain questions</li>
<li>Generating<span> </span>a dense<span> </span>representation of sentences</li>
<li>Building a document reader for extracting answers from unstructured text</li>
<li>Learned how to integrate deep learning models into a classic NLP pipeline</li>
</ul>
<p>These skills will come very much in handy in your career, as you see similar business use cases, and also as conversational user interfaces continue to gain in popularity. Well done—let's see what's in store for our next deep learning project in Python!</p>


            </article>

            
        </section>
    </body></html>