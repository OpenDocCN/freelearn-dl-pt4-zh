- en: '15'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Forecasting Traffic Using A3T-GCN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We introduced T-GNNs in [*Chapter 13*](B19153_13.xhtml#_idTextAnchor153), but
    we did not elaborate on their main application: **traffic forecasting**. In recent
    years, the concept of smart cities has become increasingly popular. This idea
    refers to cities where data is used to manage and improve operations and services.
    In this context, one of the main sources of appeal is the creation of intelligent
    transportation systems. Accurate traffic forecasts can help traffic managers to
    optimize traffic signals, plan infrastructure, and reduce congestion. However,
    traffic forecasting is a challenging problem due to complex spatial and temporal
    dependencies.'
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will apply T-GNNs to a particular case of traffic forecasting.
    First, we will explore and process a new dataset to create a temporal graph from
    raw CSV files. We will then apply a new type of T-GNN to predict future traffic
    speed. Finally, we will visualize and compare the results to a baseline solution
    to verify that our architecture is relevant.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, you will know how to create a temporal graph dataset
    from tabular data. In particular, we will see how to create a weighted adjacency
    matrix that will provide us with edge weights. Finally, you will learn how to
    apply a T-GNN to a traffic forecasting task and evaluate the results.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the PeMS-M dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Processing the dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing a temporal GNN
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All the code examples from this chapter can be found on GitHub at [https://github.com/PacktPublishing/Hands-On-Graph-Neural-Networks-Using-Python/tree/main/Chapter15](https://github.com/PacktPublishing/Hands-On-Graph-Neural-Networks-Using-Python/tree/main/Chapter15).
  prefs: []
  type: TYPE_NORMAL
- en: Installation steps required to run the code on your local machine can be found
    in the *Preface* of this book. This chapter requires a large amount of GPU. You
    can lower it by decreasing the size of the training set in the code.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the PeMS-M dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will explore our dataset to find patterns and get insights
    that will be useful to the task of interest.
  prefs: []
  type: TYPE_NORMAL
- en: 'The dataset we will use for this application is the medium variant of the `PeMSD7`
    dataset [1]. The original dataset was obtained by collecting traffic speed from
    39,000 sensor stations on the weekdays of May and June 2012 using the Caltrans
    **Performance Measurement System** (**PeMS**). We will only consider 228 stations
    across District 7 of California in the medium variant. These stations output 30-second
    speed measurements that are aggregated into 5-minute intervals in this dataset.
    For example, the following figure shows the Caltrans PeMS ([pems.dot.ca.gov](https://pems.dot.ca.gov))
    with various traffic speeds:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 15.1 – Traffic data from Caltrans PeMS with high speed (>60 mph) in
    green and low speed (<35 mph) in red](img/B19153_15_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 15.1 – Traffic data from Caltrans PeMS with high speed (>60 mph) in green
    and low speed (<35 mph) in red
  prefs: []
  type: TYPE_NORMAL
- en: 'We can directly load the dataset from GitHub and unzip it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting folder contains two files: `V_228.csv` and `W_228.csv`. The `V_228.csv`
    file contains the traffic speed collected by the 228 sensor stations, and `W_228.csv`
    stores the distances between these stations.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s load them using `pandas`. We will rename the columns using `range()`
    for easy access:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The first thing we want to do with this dataset is to visualize the evolution
    of traffic speed. This is a classic in time series forecasting since characteristics
    such as seasonality can be extremely helpful. On the other hand, non-stationary
    time series might need further processing before they can be used.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s plot the traffic speed over time using `matplotlib`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We import `NumPy` and `matplotlib`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We use `plt.plot()` to create a line plot for every row in our DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We obtain the following plot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 15.2 – Traffic speed over time for each of the 228 sensor stations](img/B19153_15_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 15.2 – Traffic speed over time for each of the 228 sensor stations
  prefs: []
  type: TYPE_NORMAL
- en: 'Unfortunately, the data is too noisy to give us any insight using this approach.
    Instead, we could plot the data corresponding to a few sensor stations. However,
    it might not be representative of the entire dataset. There is another option:
    we can plot the mean traffic speed with standard deviation. That way, we can visualize
    a summary of the dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In practice, we would use both approaches, but let’s try the second option
    now:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We calculate the mean traffic speed with the corresponding standard deviation
    for each column (time step):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We plot the mean values in black with a solid line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We plot the standard deviation around the mean values using `plt.fill_between()`
    in light red:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The code generates the following plot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 15.3 – Mean traffic speed over time with a standard deviation](img/B19153_15_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 15.3 – Mean traffic speed over time with a standard deviation
  prefs: []
  type: TYPE_NORMAL
- en: 'This figure is much more comprehensible. We can see a clear seasonality (pattern)
    in the time series data, except around the 5,800th data sample. The traffic speed
    has a lot of variability with important spikes. This is understandable because
    the sensor stations are spread throughout District 7 of California: traffic might
    be jammed for some sensors but not for others.'
  prefs: []
  type: TYPE_NORMAL
- en: We can verify that by plotting the correlation between the speed values from
    every sensor. In addition to that, we can compare it with the distances between
    each station. Stations close to each other should display similar values more
    often than distant ones.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s compare these two plots on the same figure:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We create a figure with two horizontal subplots and some padding between them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'First, we use the `matshow()` function to plot the distance matrix:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, we calculate the Pearson correlation coefficients for each sensor station.
    We must transpose the speed matrix or we will get the correlation coefficients
    for each time step instead. Finally, we invert them, so the two plots are easier
    to compare:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We obtain the following plot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 15.4 – Distance and correlation matrices with darker colors representing
    short distances and high correlation, while brighter colors represent long distances
    and low correlation](img/B19153_15_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 15.4 – Distance and correlation matrices with darker colors representing
    short distances and high correlation, while brighter colors represent long distances
    and low correlation
  prefs: []
  type: TYPE_NORMAL
- en: 'Interestingly, long distances between stations do not mean they are not highly
    correlated (and vice versa). This is particularly important if we only consider
    a subset of this dataset: close stations might have very different outputs, making
    traffic forecasting more difficult. In this chapter, we will take into account
    every sensor station in the dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: Processing the dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have more information about this dataset, it is time to process
    it before we can feed it to a T-GNN.
  prefs: []
  type: TYPE_NORMAL
- en: The first step consists of transforming the tabular dataset into a temporal
    graph. So, first, we need to create a graph from the raw data. In other words,
    we must connect the different sensor stations in a meaningful way. Fortunately,
    we have access to the distance matrix, which should be a good way to connect the
    stations.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several options to compute the adjacency matrix from the distance
    matrix. For example, we could assign a link when the distance between two stations
    is inferior to the mean distance. Instead, we will perform a more advanced processing
    introduced in [2] to calculate a weighted adjacency matrix. Instead of binary
    values, we calculate weights between 0 (no connection) and 1 (strong connection)
    using the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B19153_15_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/Formula_B19153_15_002.png) represents the weight of the edge from
    node ![](img/Formula_B19153_15_003.png) to node ![](img/Formula_B19153_15_004.png),
    ![](img/Formula_B19153_15_005.png) is the distance between these two nodes, and
    ![](img/Formula_B19153_15_006.png) and ![](img/Formula_B19153_15_007.png) are
    two thresholds to control the distribution and sparsity of the adjacency matrix.
    The official implementation of [2] is available on GitHub ([https://github.com/VeritasYin/STGCN_IJCAI-18](https://github.com/VeritasYin/STGCN_IJCAI-18)).
    We will reuse the same threshold values ![](img/Formula_B19153_15_008.png) and
    ![](img/Formula_B19153_15_009.png).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s implement it in Python and plot the resulting adjacency matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We create a function to compute the adjacency matrix that takes three parameters:
    the distance matrix and the two thresholds ![](img/Formula_B19153_15_010.png)
    and ![](img/Formula_B19153_15_011.png). Like in the official implementation, we
    divide the distances by 10,000 and calculate ![](img/Formula_B19153_15_012.png):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here, we want weights when their values are greater than or equal to ![](img/Formula_B19153_15_013.png)
    (otherwise, they should be equal to zero). When we test whether the weights are
    greater than or equal to ![](img/Formula_B19153_15_014.png), the results are `True`
    or `False` statements. This is why we need a mask of ones (`w_mask`) to convert
    it back into 0 and 1 values. We multiply it a second time so that we only obtain
    the real values of weights that are greater than or equal to ![](img/Formula_B19153_15_015.png):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s compute our adjacency matrix and print the result for one line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We can see a value of `0.61266012`, representing the weight of the edge from
    node 1 to node 2.
  prefs: []
  type: TYPE_NORMAL
- en: 'A more efficient way to visualize this matrix is to use `matplotlib`’s `matshow`
    again:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We get the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 15.5 – The PeMS-M dataset’s weighted adjacency matrix](img/B19153_15_005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 15.5 – The PeMS-M dataset’s weighted adjacency matrix
  prefs: []
  type: TYPE_NORMAL
- en: This is a great way to summarize this first processing step. We can compare
    it to the distance matrix we previously plotted to find similarities.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also directly plot it as a graph using `networkx`. In this case, connections
    are binary, so we can simply consider every weight higher than 0\. We could display
    these values using edge labels, but the graph would be extremely difficult to
    read:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Even without labels, the resulting graph is not easy to read:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'It gives us the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 15.6 – The PeMS-M dataset as a graph (every node represents a sensor
    station)](img/B19153_15_006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 15.6 – The PeMS-M dataset as a graph (every node represents a sensor
    station)
  prefs: []
  type: TYPE_NORMAL
- en: Indeed, many nodes are interconnected because they are very close to each other.
    Yet, despite that, we can distinguish several branches that could correspond to
    actual roads.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have a graph, we can focus on the time series aspect of this problem.
    The first step consists of normalizing the speed values so they can be fed to
    a neural network. In the traffic forecasting literature, many authors choose a
    z-score normalization (or standardization), which we will implement here:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We create a function to calculate z-scores:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We apply it to our dataset to create a normalized version of it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can check the result:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **0** | **1** | **2** | **3** | **4** | **5** | **6** | **…** |'
  prefs: []
  type: TYPE_TB
- en: '| **0** | 0.950754 | 0.548255 | 0.502211 | 0.831672 | 0.793696 | 1.193806 |
    … |'
  prefs: []
  type: TYPE_TB
- en: Figure 15.7 – An example of standardized speed values
  prefs: []
  type: TYPE_NORMAL
- en: 'These values are correctly standardized. Now, we can use them to create time
    series for each node. We want ![](img/Formula_B19153_15_016.png) input data samples
    at each time step, ![](img/Formula_B19153_15_017.png), to predict the speed value
    at ![](img/Formula_B19153_15_018.png). A high number of input data samples also
    increases the memory footprint of the dataset. The value for ![](img/Formula_B19153_15_019.png),
    also called the horizon, depends on the task we want to perform: short-term or
    long-term traffic forecasting.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, let’s take a high value of 48 to predict the traffic speed
    in 4 hours:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We initialize the variables: the number of `lags` (number of input data samples),
    `horizon`, the input matrix, and the ground-truth matrix:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'For each time step ![](img/Formula_B19153_15_020.png), we store the 12 (lags)
    previous values in `xs` and the value at ![](img/Formula_B19153_15_021.png) in
    `ys`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we can create the temporal graph using PyTorch Geometric Temporal.
    We need to give the edge index in COO format and the edge weight from the weighted
    adjacency matrix:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s print information about the first graph to see whether everything looks
    good:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s not forget the train/test split to finalize our dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The final temporal graph has 228 nodes with 12 values and 1,664 connections.
    We are now ready to apply a T-GNN to predict traffic.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the A3T-GCN architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will train an **Attention Temporal Graph Convolutional
    Network** (**A3T-GCN**), designed for traffic forecasting. This architecture allows
    us to consider complex spatial and temporal dependencies:'
  prefs: []
  type: TYPE_NORMAL
- en: Spatial dependencies refer to the fact that the traffic condition of a location
    can be influenced by the traffic condition of nearby locations. For example, traffic
    jams often spread to neighboring roads.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Temporal dependencies refer to the fact that the traffic condition of a location
    at a time can be influenced by the traffic condition of the same location at previous
    times. For example, if a road is congested during the morning peak, it is likely
    to remain congested until the evening peak.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A3T-GCN is an improvement over the **temporal GCN** (**TGCN**) architecture.
    The TGCN is a combination of a GCN and GRU that produces hidden vectors from each
    input time series. The combination of these two layers captures spatial and temporal
    information from the input. An attention model is then used to calculate weights
    and output a context vector. The final prediction is based on the resulting context
    vector. The addition of this attention model is motivated by the need to understand
    global trends.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 15.8 – The A3T-GCN framework](img/B19153_15_007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 15.8 – The A3T-GCN framework
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now implement it using the PyTorch Geometric Temporal library:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we import the required libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We create a T-GNN with an `A3TGCN` layer and a linear layer with 32 hidden
    dimensions. The `edge_attr` parameter will store our edge weights:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We instantiate the T-GNN and the `Adam` optimizer with a learning rate of `0.005`.
    Due to implementation details, we will train this model using a CPU instead of
    a GPU, which is faster in this case:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We train the model for 30 epochs using the `loss` function. The `loss` value
    is backpropagated after each epoch:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We obtain the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now that our model is trained, we have to evaluate it. Beyond classic metrics
    such as **Root Mean Squared Error** (**RMSE**) and **Mean Absolute Error** (**MAE**),
    it is particularly helpful to compare our model to a baseline solution with time
    series data. In the following list, we will introduce two methods:'
  prefs: []
  type: TYPE_NORMAL
- en: Using **Random Walk** (**RW**) as a naïve forecaster. In this case, RW refers
    to using the last observation as the predicted value. In other words, the value
    at ![](img/Formula_B19153_15_022.png) is the same one as at ![](img/Formula_B19153_15_023.png).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using **Historical Average** (**HA**) as a slightly more evolved solution. In
    this case, we calculate the mean traffic speed of ![](img/Formula_B19153_15_024.png)
    previous samples as the value at ![](img/Formula_B19153_15_025.png). In this example,
    we will use the number of lags as our ![](img/Formula_B19153_15_026.png) value,
    but we could also take the overall historical average.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s start by evaluating the model’s predictions on the test set:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We create a function to invert the z-score and get back to the original values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We use it to recalculate the speeds we want to predict from their normalized
    values. The following loop is not very efficient, but it is clearer to understand
    than more optimized code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We apply the same strategy to the predictions made by the GNN:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We do the same thing for the RW and HA techniques:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We create functions to calculate the MAE, RMSE, and the **Mean Absolute Percentage**
    **Error** (**MAPE**):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We evaluate the GNN’s predictions in the following block and repeat this process
    for every technique:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the end, we obtain the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | RMSE | MAE | MAPE |'
  prefs: []
  type: TYPE_TB
- en: '| A3T-GCN | **11.9396** | **8.3293** | **14.95%** |'
  prefs: []
  type: TYPE_TB
- en: '| Random Walk | 17.6501 | 11.0469 | 29.99% |'
  prefs: []
  type: TYPE_TB
- en: '| Historical Average | 17.9009 | 11.7308 | 28.93% |'
  prefs: []
  type: TYPE_TB
- en: Figure 15.9 – Output table of predictions
  prefs: []
  type: TYPE_NORMAL
- en: We see that the baseline techniques are outperformed by the A3T-GCN model in
    every metric. This is an important result because baselines can often be difficult
    to beat. It would be interesting to compare these metrics to the predictions provided
    by LSTM or GRU networks to measure the importance of the topological information.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we can plot the mean predictions to obtain a visualization that is
    similar to *Figure 15**.3*:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We obtain the mean predictions using a list comprehension that is a little
    faster than the previous method (but harder to read):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We calculate the mean and standard deviation of the original dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We plot the mean traffic speed with standard deviation and compare it to the
    predicted values (![](img/Formula_B19153_15_027.png) hours):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We obtain the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 15.10 – Mean traffic speeds predicted by the A3T-GCN model on the
    test set](img/B19153_15_008.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 15.10 – Mean traffic speeds predicted by the A3T-GCN model on the test
    set
  prefs: []
  type: TYPE_NORMAL
- en: The T-GNN correctly predicts spikes and follows the general trend. However,
    the predicted speeds are closer to the overall average value, as it is more costly
    for the model to make serious mistakes due to the MSE loss. Despite that, the
    GNN is quite accurate and could be fine-tuned to output more extreme values.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter focused on a traffic forecasting task using T-GNNs. First, we explored
    the PeMS-M dataset and converted it from tabular data into a static graph dataset
    with a temporal signal. In practice, we created a weighted adjacency matrix based
    on the input distance matrix and converted the traffic speeds into time series.
    Finally, we implemented an A3T-GCN model, a T-GNN designed for traffic forecasting.
    We compared the results to two baselines and validated the predictions made by
    our model.
  prefs: []
  type: TYPE_NORMAL
- en: In [*Chapter 16*](B19153_16.xhtml#_idTextAnchor187)*, Building a Recommender
    System Using LightGCN*, we will see the most popular application of GNNs. We will
    implement a lightweight GNN on a massive dataset and evaluate it using techniques
    from recommender systems.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[1] B. Yu, H. Yin, and Z. Zhu. *Spatio-Temporal Graph Convolutional Networks:
    A Deep Learning Framework for Traffic Forecasting*. Jul. 2018\. doi: 10.24963/ijcai.2018/505\.
    Available at [https://arxiv.org/abs/1709.04875](https://arxiv.org/abs/1709.04875).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] Y. Li, R. Yu, C. Shahabi, and Y. Liu. *Diffusion Convolutional Recurrent
    Neural Network: Data-Driven Traffic Forecasting*. arXiv, 2017\. doi: 10.48550/ARXIV.1707.01926\.
    Available at [https://arxiv.org/abs/1707.01926](https://arxiv.org/abs/1707.01926).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
