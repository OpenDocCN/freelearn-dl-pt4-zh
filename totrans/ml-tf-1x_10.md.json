["```py\n import av \n import os \n import random \n import tensorflow as tf \n from tqdm import tqdm \n\n FLAGS = tf.app.flags.FLAGS \n tf.app.flags.DEFINE_string( \n    'dataset_dir', '/mnt/DATA02/Dataset/UCF101', \n    'The folder that contains the extracted content of UCF101.rar' \n ) \n\n tf.app.flags.DEFINE_string( \n    'train_test_list_dir',   \n '/mnt/DATA02/Dataset/UCF101/ucfTrainTestlist', \n    'The folder that contains the extracted content of  \n UCF101TrainTestSplits-RecognitionTask.zip' \n ) \n\n tf.app.flags.DEFINE_string( \n    'target_dir', '/home/ubuntu/datasets/ucf101', \n    'The location where all the images will be stored' \n ) \n\n tf.app.flags.DEFINE_integer( \n    'fps', 4, \n    'Framerate to export' \n ) \n\n def ensure_folder_exists(folder_path): \n    if not os.path.exists(folder_path): \n        os.mkdir(folder_path) \n\n    return folder_path \n```", "```py\n def main(_): \n    if not FLAGS.dataset_dir: \n        raise ValueError(\"You must supply the dataset directory with  \n --dataset_dir\") \n\n    ensure_folder_exists(FLAGS.target_dir) \n    convert_data([\"trainlist01.txt\", \"trainlist02.txt\",  \n \"trainlist03.txt\"], training=True) \n    convert_data([\"testlist01.txt\", \"testlist02.txt\",  \n \"testlist03.txt\"], training=False) \n\n if __name__ == \"__main__\": \n    tf.app.run() \n```", "```py\nApplyEyeMakeup/v_ApplyEyeMakeup_g08_c01.avi 1\nApplyEyeMakeup/v_ApplyEyeMakeup_g08_c02.avi 1\nApplyEyeMakeup/v_ApplyEyeMakeup_g08_c03.avi 1\n```", "```py\n def convert_data(list_files, training=False): \n    lines = [] \n    for txt in list_files: \n        lines += [line.strip() for line in  \n open(os.path.join(FLAGS.train_test_list_dir, txt))] \n\n    output_name = \"train\" if training else \"test\" \n\n    random.shuffle(lines) \n\n    target_dir = ensure_folder_exists(os.path.join(FLAGS.target_dir,  \n output_name)) \n    class_index_file = os.path.join(FLAGS.train_test_list_dir,  \n \"classInd.txt\") \n    class_index = {line.split(\" \")[1].strip(): int(line.split(\" \") \n [0]) - 1 for line in open(class_index_file)} \n\n    with open(os.path.join(FLAGS.target_dir, output_name + \".txt\"),  \n \"w\") as f: \n        for line in tqdm(lines): \n            if training: \n                filename, _ = line.strip().split(\" \") \n            else: \n                filename = line.strip() \n            class_folder, video_name = filename.split(\"/\") \n\n            label = class_index[class_folder] \n            video_name = video_name.replace(\".avi\", \"\") \n            target_class_folder =  \n ensure_folder_exists(os.path.join(target_dir, class_folder)) \n            target_folder =  \n ensure_folder_exists(os.path.join(target_class_folder, video_name)) \n\n            container = av.open(os.path.join(FLAGS.dataset_dir,  \n            filename)) \n            frame_to_skip = int(25.0 / FLAGS.fps) \n            last_frame = -1 \n            frame_index = 0 \n            for frame in container.decode(video=0): \n                if last_frame < 0 or frame.index > last_frame +  \n                frame_to_skip: \n                    last_frame = frame.index \n                    image = frame.to_image() \n                    target_file = os.path.join(target_folder,  \n                   \"%04d.jpg\" % frame_index) \n                    image.save(target_file) \n                    frame_index += 1 \n            f.write(\"{} {} {}\\n\".format(\"%s/%s\" % (class_folder,  \n           video_name), label, frame_index)) \n\n    if training: \n        with open(os.path.join(FLAGS.target_dir, \"label.txt\"), \"w\")  \n        as f: \n            for class_name in sorted(class_index,  \n            key=class_index.get): \n                f.write(\"%s\\n\" % class_name) \n```", "```py\npython scripts/convert_ucf101.py\n```", "```py\nlabel.txt  test  test.txt  train  train.txt\n```", "```py\nPunch/v_Punch_g25_c03 70 43\nHaircut/v_Haircut_g20_c01 33 36\nBrushingTeeth/v_BrushingTeeth_g25_c02 19 33\nNunchucks/v_Nunchucks_g03_c04 55 36\nBoxingSpeedBag/v_BoxingSpeedBag_g16_c04 17 21\n```", "```py\n<Folder location of the video> <Label> <Number of frames in the folder>  \n```", "```py\ndef lines_from_file(filename, repeat=False): \n    with open(filename) as handle: \n        while True: \n            try: \n                line = next(handle) \n                yield line.strip() \n            except StopIteration as e: \n                if repeat: \n                    handle.seek(0) \n                else: \n                    raise \n\nif __name__ == \"__main__\": \n    data_reader = lines_from_file(\"/home/ubuntu/datasets/ucf101/train.txt\", repeat=True) \n\n    for i in range(15): \n        print(next(data_reader)) \n```", "```py\npython utils.py \n```", "```py\n import tensorflow as tf \n import cv2 \n import os \n import random \n\n from tensorflow.python.ops import data_flow_ops \n from utils import lines_from_file \n\n def sample_videos(data_reader, root_folder, num_samples,  \n num_frames): \n    image_paths = list() \n    labels = list() \n    while True: \n        if len(labels) >= num_samples: \n            break \n        line = next(data_reader) \n        video_folder, label, max_frames = line.strip().split(\" \") \n        max_frames = int(max_frames) \n        label = int(label) \n        if max_frames > num_frames: \n            start_index = random.randint(0, max_frames - num_frames) \n            frame_paths = list() \n            for index in range(start_index, start_index +  \n num_frames): \n                frame_path = os.path.join(root_folder, video_folder,  \n \"%04d.jpg\" % index) \n                frame_paths.append(frame_path) \n            image_paths.append(frame_paths) \n            labels.append(label) \n    return image_paths, labels \n\n if __name__ == \"__main__\": \n    num_frames = 5 \n    root_folder = \"/home/ubuntu/datasets/ucf101/train/\" \n    data_reader =  \n lines_from_file(\"/home/ubuntu/datasets/ucf101/train.txt\",  \n repeat=True) \n image_paths, labels = sample_videos(data_reader,  \n root_folder=root_folder, \n num_samples=3,  \n num_frames=num_frames) \n    print(\"image_paths\", image_paths) \n    print(\"labels\", labels) \n```", "```py\npython datasets.py\n```", "```py\n def input_pipeline(input_queue, batch_size=32, num_threads=8,  \n image_size=112): \n    frames_and_labels = [] \n    for _ in range(num_threads): \n        frame_paths, label = input_queue.dequeue() \n        frames = [] \n        for filename in tf.unstack(frame_paths): \n            file_contents = tf.read_file(filename) \n            image = tf.image.decode_jpeg(file_contents) \n            image = _aspect_preserving_resize(image, image_size) \n            image = tf.image.resize_image_with_crop_or_pad(image,  \n            image_size, image_size) \n            image = tf.image.per_image_standardization(image) \n            image.set_shape((image_size, image_size, 3)) \n            frames.append(image) \n        frames_and_labels.append([frames, label]) \n\n    frames_batch, labels_batch = tf.train.batch_join( \n        frames_and_labels, batch_size=batch_size, \n        capacity=4 * num_threads * batch_size, \n    ) \n    return frames_batch, labels_batch \n```", "```py\n def _smallest_size_at_least(height, width, smallest_side): \n    smallest_side = tf.convert_to_tensor(smallest_side,  \n dtype=tf.int32) \n\n    height = tf.to_float(height) \n    width = tf.to_float(width) \n    smallest_side = tf.to_float(smallest_side) \n\n    scale = tf.cond(tf.greater(height, width), \n                    lambda: smallest_side / width, \n                    lambda: smallest_side / height) \n    new_height = tf.to_int32(height * scale) \n    new_width = tf.to_int32(width * scale) \n    return new_height, new_width \n\n def _aspect_preserving_resize(image, smallest_side): \n    smallest_side = tf.convert_to_tensor(smallest_side,  \n dtype=tf.int32) \n    shape = tf.shape(image) \n    height = shape[0] \n    width = shape[1] \n    new_height, new_width = _smallest_size_at_least(height, width,  \n smallest_side) \n    image = tf.expand_dims(image, 0) \n    resized_image = tf.image.resize_bilinear(image, [new_height,  \n new_width], align_corners=False) \n    resized_image = tf.squeeze(resized_image) \n    resized_image.set_shape([None, None, 3]) \n    return resized_image \n```", "```py\n import tensorflow as tf \n from utils import print_variables, print_layers \n from tensorflow.contrib.layers.python.layers.layers import  \n batch_norm \n def inference(input_data, is_training=False): \n    conv1 = _conv3d(input_data, 3, 3, 3, 64, 1, 1, 1, \"conv1\") \n    pool1 = _max_pool3d(conv1, 1, 2, 2, 1, 2, 2, \"pool1\") \n\n    conv2 = _conv3d(pool1, 3, 3, 3, 128, 1, 1, 1, \"conv2\") \n    pool2 = _max_pool3d(conv2, 2, 2, 2, 2, 2, 2, \"pool2\") \n\n    conv3a = _conv3d(pool2, 3, 3, 3, 256, 1, 1, 1, \"conv3a\") \n    conv3b = _conv3d(conv3a, 3, 3, 3, 256, 1, 1, 1, \"conv3b\") \n    pool3 = _max_pool3d(conv3b, 2, 2, 2, 2, 2, 2, \"pool3\") \n\n    conv4a = _conv3d(pool3, 3, 3, 3, 512, 1, 1, 1, \"conv4a\") \n    conv4b = _conv3d(conv4a, 3, 3, 3, 512, 1, 1, 1, \"conv4b\") \n    pool4 = _max_pool3d(conv4b, 2, 2, 2, 2, 2, 2, \"pool4\") \n\n    conv5a = _conv3d(pool4, 3, 3, 3, 512, 1, 1, 1, \"conv5a\") \n    conv5b = _conv3d(conv5a, 3, 3, 3, 512, 1, 1, 1, \"conv5b\") \n    pool5 = _max_pool3d(conv5b, 2, 2, 2, 2, 2, 2, \"pool5\") \n\n    fc6 = _fully_connected(pool5, 4096, name=\"fc6\") \n    fc7 = _fully_connected(fc6, 4096, name=\"fc7\") \n    if is_training: \n        fc7 = tf.nn.dropout(fc7, keep_prob=0.5) \n    fc8 = _fully_connected(fc7, 101, name='fc8', relu=False) \n\n    endpoints = dict() \n    endpoints[\"conv1\"] = conv1 \n    endpoints[\"pool1\"] = pool1 \n    endpoints[\"conv2\"] = conv2 \n    endpoints[\"pool2\"] = pool2 \n    endpoints[\"conv3a\"] = conv3a \n    endpoints[\"conv3b\"] = conv3b \n    endpoints[\"pool3\"] = pool3 \n    endpoints[\"conv4a\"] = conv4a \n    endpoints[\"conv4b\"] = conv4b \n    endpoints[\"pool4\"] = pool4 \n    endpoints[\"conv5a\"] = conv5a \n    endpoints[\"conv5b\"] = conv5b \n    endpoints[\"pool5\"] = pool5 \n    endpoints[\"fc6\"] = fc6 \n    endpoints[\"fc7\"] = fc7 \n    endpoints[\"fc8\"] = fc8 \n\n    return fc8, endpoints \n\n if __name__ == \"__main__\": \n    inputs = tf.placeholder(tf.float32, [None, 10, 112, 112, 3],  \n name=\"inputs\") \n    outputs, endpoints = inference(inputs) \n\n    print_variables(tf.global_variables()) \n    print_variables([inputs, outputs]) \n    print_layers(endpoints) \n```", "```py\n def _conv3d(input_data, k_d, k_h, k_w, c_o, s_d, s_h, s_w, name,  \n relu=True, padding=\"SAME\"): \n    c_i = input_data.get_shape()[-1].value \n    convolve = lambda i, k: tf.nn.conv3d(i, k, [1, s_d, s_h, s_w,  \n 1], padding=padding) \n    with tf.variable_scope(name) as scope: \n        weights = tf.get_variable(name=\"weights\",  \n shape=[k_d, k_h, k_w, c_i, c_o], \n regularizer = tf.contrib.layers.l2_regularizer(scale=0.0001), \n\n initializer=tf.truncated_normal_initializer(stddev=1e-1,  \n dtype=tf.float32)) \n        conv = convolve(input_data, weights) \n        biases = tf.get_variable(name=\"biases\",  \n shape=[c_o], dtype=tf.float32, \n initializer = tf.constant_initializer(value=0.0)) \n        output = tf.nn.bias_add(conv, biases) \n        if relu: \n            output = tf.nn.relu(output, name=scope.name) \n        return batch_norm(output) \n\n def _max_pool3d(input_data, k_d, k_h, k_w, s_d, s_h, s_w, name,  \n padding=\"SAME\"): \n    return tf.nn.max_pool3d(input_data,  \n ksize=[1, k_d, k_h, k_w, 1], \n strides=[1, s_d, s_h, s_w, 1], padding=padding, name=name) \n```", "```py\n def _fully_connected(input_data, num_output, name, relu=True): \n    with tf.variable_scope(name) as scope: \n        input_shape = input_data.get_shape() \n        if input_shape.ndims == 5: \n            dim = 1 \n            for d in input_shape[1:].as_list(): \n                dim *= d \n            feed_in = tf.reshape(input_data, [-1, dim]) \n        else: \n            feed_in, dim = (input_data, input_shape[-1].value) \n        weights = tf.get_variable(name=\"weights\",  \n shape=[dim, num_output],  \n regularizer = tf.contrib.layers.l2_regularizer(scale=0.0001),                                   \n initializer=tf.truncated_normal_initializer(stddev=1e-1,  \n dtype=tf.float32)) \n        biases = tf.get_variable(name=\"biases\", \n shape=[num_output], dtype=tf.float32, \n\n initializer=tf.constant_initializer(value=0.0)) \n        op = tf.nn.relu_layer if relu else tf.nn.xw_plus_b \n        output = op(feed_in, weights, biases, name=scope.name) \n        return batch_norm(output) \n```", "```py\n from prettytable import PrettyTable \n def print_variables(variables): \n    table = PrettyTable([\"Variable Name\", \"Shape\"]) \n    for var in variables: \n        table.add_row([var.name, var.get_shape()]) \n    print(table) \n    print(\"\") \n\n def print_layers(layers): \n    table = PrettyTable([\"Layer Name\", \"Shape\"]) \n    for var in layers.values(): \n        table.add_row([var.name, var.get_shape()]) \n    print(table) \n    print(\"\") \n```", "```py\n    python nets.py\n```", "```py\n    +------------------------------------+---------------------+\n    |           Variable Name            |        Shape        |\n    +------------------------------------+---------------------+\n    |          conv1/weights:0           |   (3, 3, 3, 3, 64)  |\n    |           conv1/biases:0           |        (64,)        |\n    |       conv1/BatchNorm/beta:0       |        (64,)        |\n    |   conv1/BatchNorm/moving_mean:0    |        (64,)        |\n    | conv1/BatchNorm/moving_variance:0  |        (64,)        |\n    |               ...                  |         ...         |\n    |           fc8/weights:0            |     (4096, 101)     |\n    |            fc8/biases:0            |        (101,)       |\n    |        fc8/BatchNorm/beta:0        |        (101,)       |\n    |    fc8/BatchNorm/moving_mean:0     |        (101,)       |\n    |  fc8/BatchNorm/moving_variance:0   |        (101,)       |\n    +------------------------------------+---------------------+ \n```", "```py\n    +---------------------------------+----------------------+\n    |          Variable Name          |        Shape         |\n    +---------------------------------+----------------------+\n    |             inputs:0            | (?, 10, 112, 112, 3) |\n    | fc8/BatchNorm/batchnorm/add_1:0 |       (?, 101)       |\n    +---------------------------------+----------------------+\n```", "```py\n    +------------------------------------+-----------------------+\n    |             Layer Name             |         Shape         |\n    +------------------------------------+-----------------------+\n    |  fc6/BatchNorm/batchnorm/add_1:0   |       (?, 4096)       |\n    |  fc7/BatchNorm/batchnorm/add_1:0   |       (?, 4096)       |\n    |  fc8/BatchNorm/batchnorm/add_1:0   |        (?, 101)       |\n    |               ...                  |         ...           |\n    | conv1/BatchNorm/batchnorm/add_1:0  | (?, 10, 112, 112, 64) |\n    | conv2/BatchNorm/batchnorm/add_1:0  |  (?, 10, 56, 56, 128) |\n    +------------------------------------+-----------------------+\n```", "```py\n import tensorflow as tf \n\n def compute_loss(logits, labels): \n    labels = tf.squeeze(tf.cast(labels, tf.int32)) \n\n    cross_entropy =  \n tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,  \n labels=labels) \n    cross_entropy_loss= tf.reduce_mean(cross_entropy) \n    reg_loss =  \n tf.reduce_mean(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES \n )) \n\n    return cross_entropy_loss + reg_loss, cross_entropy_loss,  \n reg_loss \n\n def compute_accuracy(logits, labels): \n    labels = tf.squeeze(tf.cast(labels, tf.int32)) \n    batch_predictions = tf.cast(tf.argmax(logits, 1), tf.int32) \n    predicted_correctly = tf.equal(batch_predictions, labels) \n    accuracy = tf.reduce_mean(tf.cast(predicted_correctly,  \n    tf.float32)) \n    return accuracy \n\n def get_learning_rate(global_step, initial_value, decay_steps,  \n decay_rate): \n    learning_rate = tf.train.exponential_decay(initial_value,  \n    global_step, decay_steps, decay_rate, staircase=True) \n    return learning_rate \n\n def train(total_loss, learning_rate, global_step): \n    optimizer = tf.train.AdamOptimizer(learning_rate) \n    train_op = optimizer.minimize(total_loss, global_step) \n    return train_op \n```", "```py\n import tensorflow as tf \n import os \n import sys \n from datetime import datetime \n from tensorflow.python.ops import data_flow_ops \n\n import nets \n import models \n from utils import lines_from_file \n from datasets import sample_videos, input_pipeline \n\n # Dataset \n num_frames = 16 \n train_folder = \"/home/ubuntu/datasets/ucf101/train/\" \n train_txt = \"/home/ubuntu/datasets/ucf101/train.txt\" \n\n # Learning rate \n initial_learning_rate = 0.001 \n decay_steps = 1000 \n decay_rate = 0.7 \n\n # Training \n image_size = 112 \n batch_size = 24 \n num_epochs = 20 \n epoch_size = 28747 \n\n train_enqueue_steps = 100 \n min_queue_size = 1000 \n\n save_steps = 200  # Number of steps to perform saving checkpoints \n test_steps = 20  # Number of times to test for test accuracy \n start_test_step = 50 \n\n max_checkpoints_to_keep = 2 \n save_dir = \"/home/ubuntu/checkpoints/ucf101\" \n```", "```py\n train_data_reader = lines_from_file(train_txt, repeat=True) \n\n image_paths_placeholder = tf.placeholder(tf.string, shape=(None,  \n num_frames), name='image_paths') \n labels_placeholder = tf.placeholder(tf.int64, shape=(None,),  \n name='labels') \n\n train_input_queue =  \n data_flow_ops.RandomShuffleQueue(capacity=10000, \n\n min_after_dequeue=batch_size, \n dtypes= [tf.string, tf.int64], \n shapes= [(num_frames,), ()]) \n\n train_enqueue_op =  \n train_input_queue.enqueue_many([image_paths_placeholder,  \n labels_placeholder]) \n\n frames_batch, labels_batch = input_pipeline(train_input_queue,   \n batch_size=batch_size, image_size=image_size) \n\n with tf.variable_scope(\"models\") as scope: \n    logits, _ = nets.inference(frames_batch, is_training=True) \n\n total_loss, cross_entropy_loss, reg_loss =  \n models.compute_loss(logits, labels_batch) \n train_accuracy = models.compute_accuracy(logits, labels_batch) \n\n global_step = tf.Variable(0, trainable=False) \n learning_rate = models.get_learning_rate(global_step,  \n initial_learning_rate, decay_steps, decay_rate) \n train_op = models.train(total_loss, learning_rate, global_step) \n```", "```py\n tf.summary.scalar(\"learning_rate\", learning_rate) \n tf.summary.scalar(\"train/accuracy\", train_accuracy) \n tf.summary.scalar(\"train/total_loss\", total_loss) \n tf.summary.scalar(\"train/cross_entropy_loss\", cross_entropy_loss) \n tf.summary.scalar(\"train/regularization_loss\", reg_loss) \n\n summary_op = tf.summary.merge_all() \n\n saver = tf.train.Saver(max_to_keep=max_checkpoints_to_keep) \n time_stamp = datetime.now().strftime(\"single_%Y-%m-%d_%H-%M-%S\") \n checkpoints_dir = os.path.join(save_dir, time_stamp) \n summary_dir = os.path.join(checkpoints_dir, \"summaries\") \n\n train_writer = tf.summary.FileWriter(summary_dir, flush_secs=10) \n\n if not os.path.exists(save_dir): \n    os.mkdir(save_dir) \n if not os.path.exists(checkpoints_dir): \n    os.mkdir(checkpoints_dir) \n if not os.path.exists(summary_dir): \n    os.mkdir(summary_dir) \n```", "```py\n config = tf.ConfigProto() \n config.gpu_options.allow_growth = True \n\n with tf.Session(config=config) as sess: \n    coords = tf.train.Coordinator() \n    threads = tf.train.start_queue_runners(sess=sess, coord=coords) \n\n    sess.run(tf.global_variables_initializer()) \n\n    num_batches = int(epoch_size / batch_size) \n\n    for i_epoch in range(num_epochs): \n        for i_batch in range(num_batches): \n            # Prefetch some data into queue \n            if i_batch % train_enqueue_steps == 0: \n                num_samples = batch_size * (train_enqueue_steps + 1) \n\n                image_paths, labels =  \n sample_videos(train_data_reader, root_folder=train_folder, \n\n num_samples=num_samples, num_frames=num_frames) \n                print(\"\\nEpoch {} Batch {} Enqueue {}  \n videos\".format(i_epoch, i_batch, num_samples)) \n\n                sess.run(train_enqueue_op, feed_dict={ \n                    image_paths_placeholder: image_paths, \n                    labels_placeholder: labels \n                }) \n\n            if (i_batch + 1) >= start_test_step and (i_batch + 1) %  \n test_steps == 0: \n                _, lr_val, loss_val, ce_loss_val, reg_loss_val,  \n summary_val, global_step_val, train_acc_val = sess.run([ \n                    train_op, learning_rate, total_loss,  \n cross_entropy_loss, reg_loss, \n                    summary_op, global_step, train_accuracy \n                ]) \n                train_writer.add_summary(summary_val, \n global_step=global_step_val) \n\n                print(\"\\nEpochs {}, Batch {} Step {}: Learning Rate  \n {} Loss {} CE Loss {} Reg Loss {} Train Accuracy {}\".format( \n                    i_epoch, i_batch, global_step_val, lr_val,  \n loss_val, ce_loss_val, reg_loss_val, train_acc_val \n                )) \n            else: \n                _ = sess.run(train_op) \n                sys.stdout.write(\".\") \n                sys.stdout.flush() \n\n          if (i_batch + 1) > 0 and (i_batch + 1) % save_steps ==  0: \n                saved_file = saver.save(sess, \n\n os.path.join(checkpoints_dir, 'model.ckpt'), \n                                        global_step=global_step) \n                print(\"Save steps: Save to file %s \" % saved_file) \n\n    coords.request_stop() \n    coords.join(threads) \n```", "```py\nexport PYTHONPATH=.\npython scripts/train.py\n```", "```py\ntensorboard --logdir .\n```", "```py\n import tensorflow as tf \n import os \n import sys \n from datetime import datetime \n from tensorflow.python.ops import data_flow_ops \n\n import nets \n import models \n from utils import lines_from_file \n from datasets import sample_videos, input_pipeline \n\n # Dataset \n num_frames = 10 \n train_folder = \"/home/aiteam/quan/datasets/ucf101/train/\" \n train_txt = \"/home/aiteam/quan/datasets/ucf101/train.txt\" \n\n # Learning rate \n initial_learning_rate = 0.001 \n decay_steps = 1000 \n decay_rate = 0.7 \n\n # Training \n num_gpu = 2 \n\n image_size = 112 \n batch_size = 32 * num_gpu \n num_epochs = 20 \n epoch_size = 28747 \n\n train_enqueue_steps = 50 \n\n save_steps = 200  # Number of steps to perform saving checkpoints \n test_steps = 20  # Number of times to test for test accuracy \n start_test_step = 50 \n\n max_checkpoints_to_keep = 2 \n save_dir = \"/home/aiteam/quan/checkpoints/ucf101\" \n```", "```py\n train_data_reader = lines_from_file(train_txt, repeat=True) \n\n image_paths_placeholder = tf.placeholder(tf.string, shape=(None,  \n num_frames), name='image_paths') \n labels_placeholder = tf.placeholder(tf.int64, shape=(None,),  \n name='labels') \n\n train_input_queue =  \n data_flow_ops.RandomShuffleQueue(capacity=10000, \n\n min_after_dequeue=batch_size, \n dtypes= [tf.string, tf.int64], \n shapes= [(num_frames,), ()]) \n\n train_enqueue_op =  \n train_input_queue.enqueue_many([image_paths_placeholder,  \n labels_placeholder]) \n\n frames_batch, labels_batch = input_pipeline(train_input_queue,  \n batch_size=batch_size, image_size=image_size) \n\n global_step = tf.Variable(0, trainable=False) \n learning_rate = models.get_learning_rate(global_step,  \n initial_learning_rate, decay_steps, decay_rate) \n ```", "```py \n optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate) \n\n total_gradients = [] \n\n frames_batch_split = tf.split(frames_batch, num_gpu) \n labels_batch_split = tf.split(labels_batch, num_gpu) \n for i in range(num_gpu): \n    with tf.device('/gpu:%d' % i): \n        with tf.variable_scope(tf.get_variable_scope(), reuse=(i >  \n 0)): \n            logits_split, _ = nets.inference(frames_batch_split[i],  \n is_training=True) \n            labels_split = labels_batch_split[i] \n            total_loss, cross_entropy_loss, reg_loss =  \n models.compute_loss(logits_split, labels_split) \n            grads = optimizer.compute_gradients(total_loss) \n            total_gradients.append(grads) \n            tf.get_variable_scope().reuse_variables() \n\n with tf.device('/cpu:0'): \n    gradients = models.average_gradients(total_gradients) \n    train_op = optimizer.apply_gradients(gradients, global_step) \n\n    train_accuracy = models.compute_accuracy(logits_split,   \n labels_split) \n```", "```py\n def average_gradients(gradients): \n    average_grads = [] \n    for grad_and_vars in zip(*gradients): \n        grads = [] \n        for g, _ in grad_and_vars: \n            grads.append(tf.expand_dims(g, 0)) \n\n        grad = tf.concat(grads, 0) \n        grad = tf.reduce_mean(grad, 0) \n\n        v = grad_and_vars[0][1] \n        grad_and_var = (grad, v) \n        average_grads.append(grad_and_var) \n    return average_grads \n```", "```py\n tf.summary.scalar(\"learning_rate\", learning_rate) \n tf.summary.scalar(\"train/accuracy\", train_accuracy) \n tf.summary.scalar(\"train/total_loss\", total_loss) \n tf.summary.scalar(\"train/cross_entropy_loss\", cross_entropy_loss) \n tf.summary.scalar(\"train/regularization_loss\", reg_loss) \n\n summary_op = tf.summary.merge_all() \n\n saver = tf.train.Saver(max_to_keep=max_checkpoints_to_keep) \n time_stamp = datetime.now().strftime(\"multi_%Y-%m-%d_%H-%M-%S\") \n checkpoints_dir = os.path.join(save_dir, time_stamp) \n summary_dir = os.path.join(checkpoints_dir, \"summaries\") \n\n train_writer = tf.summary.FileWriter(summary_dir, flush_secs=10) \n\n if not os.path.exists(save_dir): \n    os.mkdir(save_dir) \n if not os.path.exists(checkpoints_dir): \n    os.mkdir(checkpoints_dir) \n if not os.path.exists(summary_dir): \n    os.mkdir(summary_dir) \n```", "```py\n config = tf.ConfigProto(allow_soft_placement=True) \n config.gpu_options.allow_growth = True \n\n sess = tf.Session(config=config) \n coords = tf.train.Coordinator() \n threads = tf.train.start_queue_runners(sess=sess, coord=coords) \n\n sess.run(tf.global_variables_initializer()) \n\n num_batches = int(epoch_size / batch_size) \n\n for i_epoch in range(num_epochs): \n    for i_batch in range(num_batches): \n        # Prefetch some data into queue \n        if i_batch % train_enqueue_steps == 0: \n            num_samples = batch_size * (train_enqueue_steps + 1) \n            image_paths, labels = sample_videos(train_data_reader,  \n root_folder=train_folder, \n\n num_samples=num_samples, num_frames=num_frames) \n            print(\"\\nEpoch {} Batch {} Enqueue {} \n videos\".format(i_epoch, i_batch, num_samples)) \n\n            sess.run(train_enqueue_op, feed_dict={ \n                image_paths_placeholder: image_paths, \n                labels_placeholder: labels \n            }) \n\n        if (i_batch + 1) >= start_test_step and (i_batch + 1) %  \n test_steps == 0: \n            _, lr_val, loss_val, ce_loss_val, reg_loss_val, \n summary_val, global_step_val, train_acc_val = sess.run([ \n                train_op, learning_rate, total_loss, \n cross_entropy_loss, reg_loss, \n                summary_op, global_step, train_accuracy \n            ]) \n            train_writer.add_summary(summary_val,  \n global_step=global_step_val) \n\n            print(\"\\nEpochs {}, Batch {} Step {}: Learning Rate {} \n Loss {} CE Loss {} Reg Loss {} Train Accuracy {}\".format( \n                i_epoch, i_batch, global_step_val, lr_val, loss_val, \n ce_loss_val, reg_loss_val, train_acc_val \n            )) \n        else: \n            _ = sess.run([train_op]) \n            sys.stdout.write(\".\") \n            sys.stdout.flush() \n\n        if (i_batch + 1) > 0 and (i_batch + 1) % save_steps == 0: \n            saved_file = saver.save(sess, \n                                    os.path.join(checkpoints_dir,  \n 'model.ckpt'), \n                                    global_step=global_step) \n            print(\"Save steps: Save to file %s \" % saved_file) \n\n coords.request_stop() \n coords.join(threads) \n```", "```py\npython scripts/train_multi.py\n```"]