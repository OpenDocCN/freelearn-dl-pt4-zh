["```py\nfrom keras.models import Sequential\nmodel = Sequential()\nmodel.add(Dense(12, input_dim=8, kernel_initializer='random_uniform'))\n\n```", "```py\nfrom __future__ import print_function\nimport numpy as np\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Activation\nfrom keras.optimizers import SGD\nfrom keras.utils import np_utils\nnp.random.seed(1671) # for reproducibility\n\n# network and training\nNB_EPOCH = 200\nBATCH_SIZE = 128\nVERBOSE = 1\nNB_CLASSES = 10 # number of outputs = number of digits\nOPTIMIZER = SGD() # SGD optimizer, explained later in this chapter\nN_HIDDEN = 128\nVALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n\n# data: shuffled and split between train and test sets\n#\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\n#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\nRESHAPED = 784\n#\nX_train = X_train.reshape(60000, RESHAPED)\nX_test = X_test.reshape(10000, RESHAPED)\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\n# normalize\n#\nX_train /= 255\nX_test /= 255\nprint(X_train.shape[0], 'train samples')\nprint(X_test.shape[0], 'test samples')\n# convert class vectors to binary class matrices\nY_train = np_utils.to_categorical(y_train, NB_CLASSES)\nY_test = np_utils.to_categorical(y_test, NB_CLASSES)\n\n```", "```py\n# 10 outputs\n# final stage is softmax\nmodel = Sequential()\nmodel.add(Dense(NB_CLASSES, input_shape=(RESHAPED,)))\nmodel.add(Activation('softmax'))\nmodel.summary()\n\n```", "```py\nmodel.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n\n```", "```py\nhistory = model.fit(X_train, Y_train,\nbatch_size=BATCH_SIZE, epochs=NB_EPOCH,\nverbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n\n```", "```py\nscore = model.evaluate(X_test, Y_test, verbose=VERBOSE)\nprint(\"Test score:\", score[0])\nprint('Test accuracy:', score[1])\n\n```", "```py\nfrom __future__ import print_function\nimport numpy as np\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Activation\nfrom keras.optimizers import SGD\nfrom keras.utils import np_utils\nnp.random.seed(1671) # for reproducibility\n# network and training\nNB_EPOCH = 20\nBATCH_SIZE = 128\nVERBOSE = 1\nNB_CLASSES = 10 # number of outputs = number of digits\nOPTIMIZER = SGD() # optimizer, explained later in this chapter\nN_HIDDEN = 128\nVALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n# data: shuffled and split between train and test sets\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\n#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\nRESHAPED = 784\n#\nX_train = X_train.reshape(60000, RESHAPED)\nX_test = X_test.reshape(10000, RESHAPED)\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\n# normalize\nX_train /= 255\nX_test /= 255\nprint(X_train.shape[0], 'train samples')\nprint(X_test.shape[0], 'test samples')\n# convert class vectors to binary class matrices\nY_train = np_utils.to_categorical(y_train, NB_CLASSES)\nY_test = np_utils.to_categorical(y_test, NB_CLASSES)\n# M_HIDDEN hidden layers\n# 10 outputs\n# final stage is softmax\nmodel = Sequential()\nmodel.add(Dense(N_HIDDEN, input_shape=(RESHAPED,)))\nmodel.add(Activation('relu'))\nmodel.add(Dense(N_HIDDEN))\nmodel.add(Activation('relu'))\nmodel.add(Dense(NB_CLASSES))\nmodel.add(Activation('softmax'))\nmodel.summary()\nmodel.compile(loss='categorical_crossentropy',\noptimizer=OPTIMIZER,\nmetrics=['accuracy'])\nhistory = model.fit(X_train, Y_train,\nbatch_size=BATCH_SIZE, epochs=NB_EPOCH,\nverbose=VERBOSE, validation_split=VALIDATION_SPLIT)\nscore = model.evaluate(X_test, Y_test, verbose=VERBOSE)\nprint(\"Test score:\", score[0])\nprint('Test accuracy:', score[1])\n\n```", "```py\nfrom __future__ import print_function\nimport numpy as np\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation\nfrom keras.optimizers import SGD\nfrom keras.utils import np_utils\nnp.random.seed(1671) # for reproducibility\n# network and training\nNB_EPOCH = 250\nBATCH_SIZE = 128\nVERBOSE = 1\nNB_CLASSES = 10 # number of outputs = number of digits\nOPTIMIZER = SGD() # optimizer, explained later in this chapter\nN_HIDDEN = 128\nVALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\nDROPOUT = 0.3\n# data: shuffled and split between train and test sets\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\n#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\nRESHAPED = 784\n#\nX_train = X_train.reshape(60000, RESHAPED)\nX_test = X_test.reshape(10000, RESHAPED)\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\n# normalize\nX_train /= 255\nX_test /= 255\n# convert class vectors to binary class matrices\nY_train = np_utils.to_categorical(y_train, NB_CLASSES)\nY_test = np_utils.to_categorical(y_test, NB_CLASSES)\n# M_HIDDEN hidden layers 10 outputs\nmodel = Sequential()\nmodel.add(Dense(N_HIDDEN, input_shape=(RESHAPED,)))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(DROPOUT))\nmodel.add(Dense(N_HIDDEN))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(DROPOUT))\nmodel.add(Dense(NB_CLASSES))\nmodel.add(Activation('softmax'))\nmodel.summary()\nmodel.compile(loss='categorical_crossentropy',\noptimizer=OPTIMIZER,\nmetrics=['accuracy'])\nhistory = model.fit(X_train, Y_train,\nbatch_size=BATCH_SIZE, epochs=NB_EPOCH,\nverbose=VERBOSE, validation_split=VALIDATION_SPLIT)\nscore = model.evaluate(X_test, Y_test, verbose=VERBOSE)\nprint(\"Test score:\", score[0])\nprint('Test accuracy:', score[1])\n\n```", "```py\nfrom keras.optimizers import RMSprop, Adam\n...\nOPTIMIZER = RMSprop() # optimizer,\n\n```", "```py\nOPTIMIZER = Adam() # optimizer\n\n```", "```py\nfrom keras import regularizers model.add(Dense(64, input_dim=64, kernel_regularizer=regularizers.l2(0.01)))\n\n```", "```py\n# calculate predictions\npredictions = model.predict(X)\n\n```", "```py\n#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\nX_train = X_train.reshape(60000, 784)\nX_test = X_test.reshape(10000, 784)\n\n```"]