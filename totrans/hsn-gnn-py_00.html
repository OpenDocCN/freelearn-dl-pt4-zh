<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer004">
<h1 id="_idParaDest-5"><a id="_idTextAnchor004"/>Preface</h1>
<p>In just ten years, <strong class="bold">Graph Neural Networks</strong> (<strong class="bold">GNNs</strong>) have become an essential and popular deep learning architecture. They have already had a significant impact various industries, such as in drug discovery, where GNNs predicted a new antibiotic, named halicin, and have improved estimated time of arrival calculations on Google Maps. Tech companies and universities are exploring the potential of GNNs in various applications, including recommender systems, fake news detection, and chip design. GNNs have enormous potential and many yet-to-be-discovered applications, making them a critical tool for solving <span class="No-Break">global problems.</span></p>
<p>In this book, we aim to provide a comprehensive and practical overview of the world of GNNs. We will begin by exploring the fundamental concepts of graph theory and graph learning and then delve into the most widely used and well-established GNN architectures. As we progress, we will also cover the latest advances in GNNs and introduce specialized architectures that are designed to tackle specific tasks, such as graph generation, link prediction, <span class="No-Break">and more.</span></p>
<p>In addition to these specialized chapters, we will provide hands-on experience through three practical projects. These projects will cover critical real-world applications of GNNs, including traffic forecasting, anomaly detection, and recommender systems. Through these projects, you will gain a deeper understanding of how GNNs work and also develop the skills to implement them in <span class="No-Break">practical scenarios.</span></p>
<p>Finally, this book provides a hands-on learning experience with readable code for every chapter’s techniques and relevant applications, which are readily accessible on GitHub and <span class="No-Break">Google Colab.</span></p>
<p>By the end of this book, you will have a comprehensive understanding of the field of graph learning and GNNs and will be well-equipped to design and implement these models for a wide range <span class="No-Break">of applications.</span></p>
<h1 id="_idParaDest-6"><a id="_idTextAnchor005"/>Who this book is for</h1>
<p>This book is intended for individuals interested in learning about GNNs and how they can be applied to various real-world problems. This book is ideal for <strong class="bold">data scientists</strong>, <strong class="bold">machine learning engineers</strong>, and <strong class="bold">artificial intelligence</strong> (<strong class="bold">AI</strong>) professionals who want to gain practical experience in designing and implementing GNNs. This book is written for individuals with prior knowledge of deep learning and machine learning. However, it provides a comprehensive introduction to the fundamental concepts of graph theory and graph learning for those new to the field. It will also be useful for researchers and students in computer science, mathematics, and engineering who want to expand their knowledge in this rapidly growing area <span class="No-Break">of research.</span></p>
<h1 id="_idParaDest-7"><a id="_idTextAnchor006"/>What this book covers</h1>
<p><a href="B19153_01.xhtml#_idTextAnchor015"><span class="No-Break"><em class="italic">Chapter 1</em></span></a>, <em class="italic">Getting Started with Graph Learning</em>, provides a comprehensive introduction to GNNs, including their importance in modern data analysis and machine learning. The chapter starts by exploring the relevance of graphs as a representation of data and their widespread use in various domains. It then delves into the importance of graph learning, including different applications and techniques. Finally, the chapter focuses on the GNN architecture and highlights its unique features and performance compared to <span class="No-Break">other methods.</span></p>
<p><a href="B19153_02.xhtml#_idTextAnchor023"><span class="No-Break"><em class="italic">Chapter 2</em></span></a>, <em class="italic">Graph Theory for Graph Neural Networks</em>, covers the basics of graph theory and introduces various types of graphs, including their properties and applications. This chapter also covers fundamental graph concepts, such as the adjacency matrix, graph measures, such as centrality, and graph algorithms, <strong class="bold">Breadth-First Search</strong> (<strong class="bold">BFS</strong>) and <strong class="bold">Depth-First </strong><span class="No-Break"><strong class="bold">Search</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">DFS</strong></span><span class="No-Break">).</span></p>
<p><a href="B19153_03.xhtml#_idTextAnchor041"><span class="No-Break"><em class="italic">Chapter 3</em></span></a>, <em class="italic">Creating Node Representations with DeepWalk</em>, focuses on DeepWalk, a pioneer in applying machine learning to graph data. The main objective of the DeepWalk architecture is to generate node representations that other models can utilize for downstream tasks such as node classification. The chapter covers two key components of DeepWalk – Word2Vec and random walks – with a particular emphasis on the Word2Vec <span class="No-Break">skip-gram model.</span></p>
<p><a href="B19153_04.xhtml#_idTextAnchor054"><span class="No-Break"><em class="italic">Chapter 4</em></span></a>, <em class="italic">Improving Embeddings with Biased Random Walks in Node2Vec</em>, focuses on the Node2Vec architecture, which is based on the DeepWalk architecture covered in the previous chapter. The chapter covers the modifications made to the random walk generation in Node2Vec and how to select the best parameters for a specific graph. The implementation of Node2Vec is compared to DeepWalk on Zachary’s Karate Club to highlight the differences between the two architectures. The chapter concludes with a practical application of Node2Vec, building a movie <span class="No-Break">recommendation system.</span></p>
<p><a href="B19153_05.xhtml#_idTextAnchor064"><span class="No-Break"><em class="italic">Chapter 5</em></span></a>, <em class="italic">Including Node Features with Vanilla Neural Networks</em>, explores the integration of additional information, such as node and edge features, into the graph embeddings to produce more accurate results. The chapter starts with a comparison of vanilla neural networks’ performance on node features only, treated as tabular datasets. Then, we will experiment with adding topological information to the neural networks, leading to the creation of a simple vanilla <span class="No-Break">GNN architecture.</span></p>
<p><a href="B19153_06.xhtml#_idTextAnchor074"><span class="No-Break"><em class="italic">Chapter 6</em></span></a>, <em class="italic">Introducing Graph Convolutional Networks</em>, focuses on the <strong class="bold">Graph Convolutional Network</strong> (<strong class="bold">GCN</strong>) architecture and its importance as a blueprint for GNNs. It covers the limitations of previous vanilla GNN layers and explains the motivation behind GCNs. The chapter details how the GCN layer works, its performance improvements over the vanilla GNN layer, and its implementation on the Cora and Facebook Page-Page datasets using PyTorch Geometric. The chapter also touches upon the task of node regression and the benefits of transforming tabular data into <span class="No-Break">a graph.</span></p>
<p><a href="B19153_07.xhtml#_idTextAnchor082"><span class="No-Break"><em class="italic">Chapter 7</em></span></a>, <em class="italic">Graph Attention Networks</em>, focuses on <strong class="bold">Graph Attention Networks </strong>(<strong class="bold">GATs</strong>), which are an improvement over GCNs. The chapter explains how GATs work by using the concept of self-attention and provides a step-by-step understanding of the graph attention layer. The chapter also implements a graph attention layer from scratch using NumPy. The final section of the chapter discusses the use of a GAT on two node classification datasets, Cora and CiteSeer, and compares the accuracy with that of <span class="No-Break">a GCN.</span></p>
<p><a href="B19153_08.xhtml#_idTextAnchor096"><span class="No-Break"><em class="italic">Chapter 8</em></span></a>, <em class="italic">Scaling up Graph Neural Networks with GraphSAGE</em>, focuses on the GraphSAGE architecture and its ability to handle large graphs effectively. The chapter covers the two main ideas behind GraphSAGE, including its neighbor sampling technique and aggregation operators. You will learn about the variants proposed by tech companies such as Uber Eats and Pinterest, as well as the benefits of GraphSAGE’s inductive approach. The chapter concludes by implementing GraphSAGE for node classification and multi-label <span class="No-Break">classification tasks.</span></p>
<p><a href="B19153_09.xhtml#_idTextAnchor106"><span class="No-Break"><em class="italic">Chapter 9</em></span></a>, <em class="italic">Defining Expressiveness for Graph Classification</em>, explores the concept of expressiveness in GNNs and how it can be used to design better models. It introduces the <strong class="bold">Weisfeiler-Leman</strong> (<strong class="bold">WL</strong>) test, which provides the framework for understanding expressiveness in GNNs. The chapter uses the WL test to compare different GNN layers and determine the most expressive one. Based on this result, a more powerful GNN is designed and implemented using PyTorch Geometric. The chapter concludes with a comparison of different methods for graph classification on the <span class="No-Break">PROTEINS dataset.</span></p>
<p><a href="B19153_10.xhtml#_idTextAnchor116"><span class="No-Break"><em class="italic">Chapter 10</em></span></a>, <em class="italic">Predicting Links with Graph Neural Networks</em>, focuses on link prediction in graphs. It covers traditional techniques, such as matrix factorization and GNN-based methods. The chapter explains the concept of link prediction and its importance in social networks and recommender systems. You will learn about the limitations of traditional techniques and the benefits of using GNN-based methods. We will explore three GNN-based techniques from two different families, including node embeddings and subgraph representation. Finally, you will implement various link prediction techniques in PyTorch Geometric and choose the best method for a <span class="No-Break">given problem.</span></p>
<p><a href="B19153_11.xhtml#_idTextAnchor131"><span class="No-Break"><em class="italic">Chapter 11</em></span></a>, <em class="italic">Generating Graphs Using Graph Neural Networks</em>, explores the field of graph generation, which involves finding methods to create new graphs. The chapter first introduces you to traditional techniques such as Erdős–Rényi and small-world models. Then you will focus on three families of solutions for GNN-based graph generation: VAE-based, autoregressive, and GAN-based models. The chapter concludes with an implementation of a GAN-based framework with <strong class="bold">Reinforcement Learning</strong> (<strong class="bold">RL</strong>) to generate new chemical compounds using the DeepChem library <span class="No-Break">with TensorFlow.</span></p>
<p><a href="B19153_12.xhtml#_idTextAnchor144"><span class="No-Break"><em class="italic">Chapter 12</em></span></a>, <em class="italic">Learning from Heterogeneous Graphs</em>, focuses on heterogeneous GNNs. Heterogeneous graphs contain different types of nodes and edges, in contrast to homogeneous graphs, which only involve one type of node and one type of edge. The chapter begins by reviewing the <strong class="bold">Message Passing Neural Network</strong> (<strong class="bold">MPNN</strong>) framework for homogeneous GNNs, then expands the framework to heterogeneous networks. Finally, we introduce a technique for creating a heterogeneous dataset, transforming homogeneous architectures into heterogeneous ones, and discussing an architecture specifically designed for processing <span class="No-Break">heterogeneous networks.</span></p>
<p><a href="B19153_13.xhtml#_idTextAnchor153"><span class="No-Break"><em class="italic">Chapter 13</em></span></a>, <em class="italic">Temporal Graph Neural Networks</em>, focuses on Temporal GNNs, or Spatio-Temporal GNNs, which are a type of GNN that can handle graphs with changing edges and features over time. The chapter first explains the concept of dynamic graphs and the applications of temporal GNNs, focusing on time series forecasting. The chapter then moves on to the application of temporal GNNs to web traffic forecasting to improve results using temporal information. Finally, the chapter describes another temporal GNN architecture specifically designed for dynamic graphs and applies it to the task of <span class="No-Break">epidemic forecasting.</span></p>
<p><a href="B19153_14.xhtml#_idTextAnchor165"><span class="No-Break"><em class="italic">Chapter 14</em></span></a>, <em class="italic">Explaining Graph Neural Networks</em>, covers various techniques to better understand the predictions and behavior of a GNN model. The chapter highlights two popular explanation methods: GNNExplainer and integrated gradients. Then, you will see the application of these techniques on a graph classification task using the MUTAG dataset and a node classification task using the Twitch <span class="No-Break">social network.</span></p>
<p><a href="B19153_15.xhtml#_idTextAnchor179"><span class="No-Break"><em class="italic">Chapter 15</em></span></a>, <em class="italic">Forecasting Traffic Using A3T-GCN</em>, focuses on the application of Temporal Graph Neural Networks in the field of traffic forecasting. It highlights the importance of accurate traffic forecasts in smart cities and the challenges of traffic forecasting due to complex spatial and temporal dependencies. The chapter covers the steps involved in processing a new dataset to create a temporal graph and the implementation of a new type of temporal GNN to predict future traffic speed. Finally, the results are compared to a baseline solution to verify the relevance of <span class="No-Break">the architecture.</span></p>
<p><a href="B19153_16.xhtml#_idTextAnchor187"><span class="No-Break"><em class="italic">Chapter 16</em></span></a>, <em class="italic">Detecting Anomalies Using Heterogeneous GNNs</em>, focuses on the application of GNNs in anomaly detection. GNNs, with their ability to capture complex relationships, make them well-suited for detecting anomalies and can handle large amounts of data efficiently. In this chapter, you will learn how to implement a GNN for intrusion detection in computer networks using the CIDDS-001 dataset. The chapter covers processing the dataset, building relevant features, implementing a heterogenous GNN, and evaluating the results to determine its effectiveness in detecting anomalies in <span class="No-Break">network traffic.</span></p>
<p><a href="B19153_17.xhtml#_idTextAnchor195"><span class="No-Break"><em class="italic">Chapter 17</em></span></a>, <em class="italic">Recommending Books Using LightGCN</em>, focuses on the application of GNNs in recommender systems. The goal of recommender systems is to provide personalized recommendations to users based on their interests and past interactions. GNNs are well-suited for this task as they can effectively incorporate complex relationships between users and items. In this chapter, the LightGCN architecture is introduced as a GNN specifically designed for recommender systems. Using the Book-Crossing dataset, the chapter demonstrates how to build a book recommender system with collaborative filtering using the <span class="No-Break">LightGCN architecture.</span></p>
<p><a href="B19153_18.xhtml#_idTextAnchor203"><span class="No-Break"><em class="italic">Chapter 18</em></span></a>, <em class="italic">Unlocking the Potential of Graph Neural Networks for Real-Word Applications</em>, summarizes what we have learned throughout the book, and looks ahead to the future <span class="No-Break">of GNNs.</span></p>
<h1 id="_idParaDest-8"><a id="_idTextAnchor007"/>To get the most out of this book</h1>
<p>You should have a basic understanding of graph theory and machine learning concepts, such as supervised and unsupervised learning, training, and the evaluation of models to maximize your learning experience. Familiarity with deep learning frameworks, such as PyTorch, will also be useful, although not essential, as the book will provide a comprehensive introduction to the mathematical concepts and <span class="No-Break">their implementation.</span></p>
<table class="No-Table-Style" id="table001">
<colgroup>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="bold">Software covered in </strong><span class="No-Break"><strong class="bold">the book</strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="bold">Operating </strong><span class="No-Break"><strong class="bold">system requirements</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">Python 3.8.15</span></p>
</td>
<td class="No-Table-Style">
<p>Windows, macOS, <span class="No-Break">or Linux</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">PyTorch 1.13.1</span></p>
</td>
<td class="No-Table-Style">
<p>Windows, macOS, <span class="No-Break">or Linux</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>PyTorch <span class="No-Break">Geometric 2.2.0</span></p>
</td>
<td class="No-Table-Style">
<p>Windows, macOS, <span class="No-Break">or Linux</span></p>
</td>
</tr>
</tbody>
</table>
<p>To install Python 3.8.15, you can download the latest version from the official Python website: <a href="https://www.python.org/downloads/">https://www.python.org/downloads/</a>. We strongly recommend using a virtual environment, such as <strong class="source-inline">venv</strong> <span class="No-Break">or </span><span class="No-Break"><strong class="source-inline">conda</strong></span><span class="No-Break">.</span></p>
<p>Optionally, if you want to use a <strong class="bold">Graphics Processing Unit</strong> (<strong class="bold">GPU</strong>) from NVIDIA to accelerate training and inference, you will need to install <strong class="bold">CUDA</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="bold">cuDNN</strong></span><span class="No-Break">:</span></p>
<p>CUDA is a parallel computing platform and API developed by NVIDIA for general computing on GPUs. To install CUDA, you can follow the instructions on the NVIDIA <span class="No-Break">website: </span><a href="https://developer.nvidia.com/cuda-downloads"><span class="No-Break">https://developer.nvidia.com/cuda-downloads</span></a><span class="No-Break">.</span></p>
<p>cuDNN is a library developed by NVIDIA, which provides highly optimized GPU implementations of primitives for deep learning algorithms. To install cuDNN, you need to create an account on the NVIDIA website and download the library from the cuDNN download <span class="No-Break">page: </span><a href="https://developer.nvidia.com/cudnn"><span class="No-Break">https://developer.nvidia.com/cudnn</span></a><span class="No-Break">.</span></p>
<p>You can check out the list of CUDA-enabled GPU products on the NVIDIA <span class="No-Break">website: </span><a href="https://developer.nvidia.com/cuda-gpus"><span class="No-Break">https://developer.nvidia.com/cuda-gpus</span></a><span class="No-Break">.</span></p>
<p>To install PyTorch 1.13.1, you can follow the instructions on the official PyTorch website: <a href="https://pytorch.org/">https://pytorch.org/</a>. You can choose the installation method that is most appropriate for your system (including CUDA <span class="No-Break">and cuDNN).</span></p>
<p>To install PyTorch Geometric 2.2.0, you can follow the instructions in the GitHub repository: <a href="https://pytorch-geometric.readthedocs.io/en/2.2.0/notes/installation.xhtml">https://pytorch-geometric.readthedocs.io/en/2.2.0/notes/installation.xhtml</a>. You will need to have PyTorch installed on your <span class="No-Break">system first.</span></p>
<p><a href="B19153_11.xhtml#_idTextAnchor131"><span class="No-Break"><em class="italic">Chapter 11</em></span></a> requires TensorFlow 2.4. To install it, you can follow the instructions on the official TensorFlow website: <a href="https://www.tensorflow.org/install">https://www.tensorflow.org/install</a>. You can choose the installation method that is most appropriate for your system and the version of TensorFlow you want <span class="No-Break">to use.</span></p>
<p><a href="B19153_14.xhtml#_idTextAnchor165"><span class="No-Break"><em class="italic">Chapter 14</em></span></a> requires an older version of PyTorch Geometric (version 2.0.4). It is recommended to create a specific virtual environment for <span class="No-Break">this chapter.</span></p>
<p><a href="B19153_15.xhtml#_idTextAnchor179"><span class="No-Break"><em class="italic">Chapter 15</em></span></a>, <a href="B19153_16.xhtml#_idTextAnchor187"><span class="No-Break"><em class="italic">Chapter 16</em></span></a>, and <a href="B19153_17.xhtml#_idTextAnchor195"><span class="No-Break"><em class="italic">Chapter 17</em></span></a> require a high GPU memory usage. You can lower it by decreasing the size of the training set in <span class="No-Break">the code.</span></p>
<p>Other Python libraries are required in some or most chapters. You can install them using <strong class="source-inline">pip install &lt;name==version&gt;</strong>, or using another installer depending on your configuration (such as <strong class="source-inline">conda</strong>). Here is the complete list of required packages with the <span class="No-Break">corresponding versions:</span></p>
<ul>
<li><strong class="source-inline">pandas</strong>==1.5.2</li>
<li><strong class="source-inline">gensim</strong>==4.3.0</li>
<li><strong class="source-inline">networkx</strong>==2.8.8</li>
<li><strong class="source-inline">matplotlib</strong>==3.6.3</li>
<li><strong class="source-inline">node2vec</strong>==0.4.6</li>
<li><strong class="source-inline">seaborn</strong>==0.12.2</li>
<li><strong class="source-inline">scikit-learn</strong>==1.2.0</li>
<li><strong class="source-inline">deepchem</strong>==2.7.1</li>
<li><strong class="source-inline">torch-geometric-temporal</strong>==0.54.0</li>
<li><strong class="source-inline">captum</strong>==0.6.0</li>
</ul>
<p>The complete list of requirements is available on GitHub at <a href="https://github.com/PacktPublishing/Hands-On-Graph-Neural-Networks-Using-Python">https://github.com/PacktPublishing/Hands-On-Graph-Neural-Networks-Using-Python</a>. Alternatively, you can directly import notebooks in Google Colab <span class="No-Break">at </span><a href="https://colab.research.google.com"><span class="No-Break">https://colab.research.google.com</span></a><span class="No-Break">.</span></p>
<p><strong class="bold">If you are using the digital version of this book, we advise you to type the code yourself or access the code from the book’s GitHub repository (a link is available in the next section). Doing so will help you avoid any potential errors related to the copying and pasting </strong><span class="No-Break"><strong class="bold">of code.</strong></span></p>
<h1 id="_idParaDest-9"><a id="_idTextAnchor008"/>Download the example code files</h1>
<p>You can download the example code files for this book from GitHub at <a href="https://github.com/PacktPublishing/Hands-On-Graph-Neural-Networks-Using-Python">https://github.com/PacktPublishing/Hands-On-Graph-Neural-Networks-Using-Python</a>. If there’s an update to the code, it will be updated in the <span class="No-Break">GitHub repository.</span></p>
<p>We also have other code bundles from our rich catalog of books and videos available at <a href="https://github.com/PacktPublishing/">https://github.com/PacktPublishing/</a>. Check <span class="No-Break">them out!</span></p>
<h1 id="_idParaDest-10"><a id="_idTextAnchor009"/>Download the color images</h1>
<p>We also provide a PDF file that has color images of the screenshots and diagrams used in this book. You can download it <span class="No-Break">here: </span><a href="https://packt.link/gaFU6"><span class="No-Break">https://packt.link/gaFU6</span></a><span class="No-Break">.</span></p>
<h1 id="_idParaDest-11"><a id="_idTextAnchor010"/>Conventions used</h1>
<p>There are a number of text conventions used throughout <span class="No-Break">this book.</span></p>
<p><strong class="source-inline">Code in text</strong>: Indicates code words in text, database table names, folder names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles. Here is an example: “We initialize two lists (<strong class="source-inline">visited</strong> and <strong class="source-inline">queue</strong>) and add the <span class="No-Break">starting node.”</span></p>
<p>A block of code is set <span class="No-Break">as follows:</span></p>
<pre class="source-code">
DG = nx.DiGraph()
DG.add_edges_from([('A', 'B'), ('A', 'C'), ('B', 'D'), ('B', 'E'), ('C', 'F'), ('C', 'G')])</pre>
<p class="callout-heading">Tips or important notes</p>
<p class="callout">Appear like this.</p>
<h1 id="_idParaDest-12"><a id="_idTextAnchor011"/>Get in touch</h1>
<p>Feedback from our readers is <span class="No-Break">always welcome.</span></p>
<p><strong class="bold">General feedback</strong>: If you have questions about any aspect of this book, email us at <strong class="source-inline">customercare@packtpub.com</strong> and mention the book title in the subject of <span class="No-Break">your message.</span></p>
<p><strong class="bold">Errata</strong>: Although we have taken every care to ensure the accuracy of our content, mistakes do happen. If you have found a mistake in this book, we would be grateful if you would report this to us. Please visit <a href="http://www.packtpub.com/support/errata">www.packtpub.com/support/errata</a> and fill in <span class="No-Break">the form.</span></p>
<p><strong class="bold">Piracy</strong>: If you come across any illegal copies of our works in any form on the internet, we would be grateful if you would provide us with the location address or website name. Please contact us at <strong class="source-inline">copyright@packt.com</strong> with a link to <span class="No-Break">the material.</span></p>
<p><strong class="bold">If you are interested in becoming an author</strong>: If there is a topic that you have expertise in and you are interested in either writing or contributing to a book, please <span class="No-Break">visit </span><a href="http://authors.packtpub.com"><span class="No-Break">authors.packtpub.com</span></a><span class="No-Break">.</span></p>
<h1 id="_idParaDest-13"><a id="_idTextAnchor012"/>Share your thoughts</h1>
<p>Once you’ve read Hands-On Graph Neural Networks Using Python, we’d love to hear your thoughts! Please <a href="https://packt.link/r/1-804-61752-0">click here to go straight to the Amazon review page</a> for this book and share <span class="No-Break">your feedback.</span></p>
<p>Your review is important to us and the tech community and will help us make sure we’re delivering excellent <span class="No-Break">quality content.</span></p>
<h1 id="_idParaDest-14"><a id="_idTextAnchor013"/>Download a free PDF copy of this book</h1>
<p>Thanks for purchasing <span class="No-Break">this book!</span></p>
<p>Do you like to read on the go but are unable to carry your print <span class="No-Break">books everywhere?</span></p>
<p>Is your eBook purchase not compatible with the device of <span class="No-Break">your choice?</span></p>
<p>Don’t worry, now with every Packt book you get a DRM-free PDF version of that book at <span class="No-Break">no cost.</span></p>
<p>Read anywhere, any place, on any device. Search, copy, and paste code from your favorite technical books directly into your application. </p>
<p>The perks don’t stop there, you can get exclusive access to discounts, newsletters, and great free content in your <span class="No-Break">inbox daily</span></p>
<p>Follow these simple steps to get <span class="No-Break">the benefits:</span></p>
<ol>
<li>Scan the QR code or visit the link below</li>
</ol>
<p> </p>
<div>
<div class="IMG---Figure" id="_idContainer003">
<img alt="" height="200" src="image/B19153_QR_Free_PDF.jpg" width="200"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><a href="https://packt.link/free-ebook/9781804617526">https://packt.link/free-ebook/9781804617526</a></p>
<ol>
<li value="2">Submit your proof of purchase</li>
<li>That’s it! We’ll send your free PDF and other benefits to your email directly</li>
</ol>
</div>
</div>

<div id="sbo-rt-content"><div class="Content" id="_idContainer005">
<h1 id="_idParaDest-15"><a id="_idTextAnchor014"/>Part 1: Introduction to Graph Learning</h1>
<p>In recent years, graph representation of data has become increasingly prevalent across various domains, from social networks to molecular biology. It is crucial to have a deep understanding of <strong class="bold">Graph Neural Networks</strong> (<strong class="bold">GNNs</strong>), which are designed specifically to handle graph-structured data, to unlock the full potential of <span class="No-Break">this representation.</span></p>
<p>This first part consists of two chapters and serves as a solid foundation for the rest of the book. It introduces the concepts of graph learning and GNNs and their relevance in numerous tasks and industries. It also covers the fundamental concepts of graph theory and its applications in graph learning, such as graph centrality measures. This part also highlights the unique features and performance of the GNN architecture compared to <span class="No-Break">other methods.</span></p>
<p>By the end of this part, you will have a solid understanding of the importance of GNNs in solving many real-world problems. You will be acquainted with the essentials of graph learning and how it is used in various domains. Furthermore, you will have a comprehensive overview of the main concepts of graph theory that we will use in later chapters. With this solid foundation, you will be well equipped to move on to the more advanced concepts in graph learning and GNNs in the following parts of <span class="No-Break">the book.</span></p>
<p>This part comprises the <span class="No-Break">following chapters:</span></p>
<ul>
<li><a href="B19153_01.xhtml#_idTextAnchor015"><em class="italic">Chapter 1</em></a><em class="italic">, Getting Started with Graph Learning</em></li>
<li><a href="B19153_02.xhtml#_idTextAnchor023"><em class="italic">Chapter 2</em></a><em class="italic">, Graph Theory for Graph Neural Networks</em></li>
</ul>
</div>
<div>
<div id="_idContainer006">
</div>
</div>
</div></body></html>