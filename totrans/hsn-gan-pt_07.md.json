["```py\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\n```", "```py\nclass Generator(nn.Module):\n    def __init__(self, classes, channels, img_size, latent_dim):\n        super(Generator, self).__init__()\n        self.classes = classes\n        self.channels = channels\n        self.img_size = img_size\n        self.latent_dim = latent_dim\n        self.img_shape = (self.channels, self.img_size, self.img_size)\n        self.label_embedding = nn.Embedding(self.classes, self.classes)\n\n        self.model = nn.Sequential(\n            *self._create_layer(self.latent_dim + self.classes, 128, False),\n            *self._create_layer(128, 256),\n            *self._create_layer(256, 512),\n            *self._create_layer(512, 1024),\n            nn.Linear(1024, int(np.prod(self.img_shape))),\n            nn.Tanh()\n        )\n\n    def _create_layer(self, size_in, size_out, normalize=True):\n        layers = [nn.Linear(size_in, size_out)]\n        if normalize:\n            layers.append(nn.BatchNorm1d(size_out))\n        layers.append(nn.LeakyReLU(0.2, inplace=True))\n        return layers\n\n    def forward(self, noise, labels):\n        z = torch.cat((self.label_embedding(labels), noise), -1)\n        x = self.model(z)\n        x = x.view(x.size(0), *self.img_shape)\n        return x\n```", "```py\nclass Discriminator(nn.Module):\n    def __init__(self, classes, channels, img_size, latent_dim):\n        super(Discriminator, self).__init__()\n        self.classes = classes\n        self.channels = channels\n        self.img_size = img_size\n        self.latent_dim = latent_dim\n        self.img_shape = (self.channels, self.img_size, self.img_size)\n        self.label_embedding = nn.Embedding(self.classes, self.classes)\n        self.adv_loss = torch.nn.BCELoss()\n\n        self.model = nn.Sequential(\n            *self._create_layer(self.classes + int(np.prod(self.img_shape)), 1024, False, True),\n            *self._create_layer(1024, 512, True, True),\n            *self._create_layer(512, 256, True, True),\n            *self._create_layer(256, 128, False, False),\n            *self._create_layer(128, 1, False, False),\n            nn.Sigmoid()\n        )\n\n    def _create_layer(self, size_in, size_out, drop_out=True, act_func=True):\n        layers = [nn.Linear(size_in, size_out)]\n        if drop_out:\n            layers.append(nn.Dropout(0.4))\n        if act_func:\n            layers.append(nn.LeakyReLU(0.2, inplace=True))\n        return layers\n\n    def forward(self, image, labels):\n        x = torch.cat((image.view(image.size(0), -1), self.label_embedding(labels)), -1)\n        return self.model(x)\n\n    def loss(self, output, label):\n        return self.adv_loss(output, label)\n```", "```py\nimport os\n\nimport numpy as np\nimport torch\nimport torchvision.utils as vutils\n\nfrom cgan import Generator as cganG\nfrom cgan import Discriminator as cganD\n```", "```py\nclass Model(object):\n    def __init__(self,\n                 name,\n                 device,\n                 data_loader,\n                 classes,\n                 channels,\n                 img_size,\n                 latent_dim):\n        self.name = name\n        self.device = device\n        self.data_loader = data_loader\n        self.classes = classes\n        self.channels = channels\n        self.img_size = img_size\n        self.latent_dim = latent_dim\n        if self.name == 'cgan':\n            self.netG = cganG(self.classes, self.channels, \n              self.img_size, self.latent_dim)\n        self.netG.to(self.device)\n        if self.name == 'cgan':\n            self.netD = cganD(self.classes, self.channels, \n              self.img_size, self.latent_dim)\n        self.netD.to(self.device)\n        self.optim_G = None\n        self.optim_D = None\n```", "```py\n    def create_optim(self, lr, alpha=0.5, beta=0.999):\n        self.optim_G = torch.optim.Adam(filter(lambda p: p.requires_grad,\n                                        self.netG.parameters()),\n                                        lr=lr,\n                                        betas=(alpha, beta))\n        self.optim_D = torch.optim.Adam(filter(lambda p: p.requires_grad,\n                                        self.netD.parameters()),\n                                        lr=lr,\n                                        betas=(alpha, beta))\n```", "```py\n    def train(self,\n              epochs,\n              log_interval=100,\n              out_dir='',\n              verbose=True):\n        self.netG.train()\n        self.netD.train()\n        viz_noise = torch.randn(self.data_loader.batch_size, self.latent_dim, device=self.device)\n        viz_label = torch.LongTensor(np.array([num for _ in range(nrows) for num in range(8)])).to(self.device)\n        for epoch in range(epochs):\n            for batch_idx, (data, target) in enumerate(self.data_loader):\n                data, target = data.to(self.device), target.to(self.device)\n                batch_size = data.size(0)\n                real_label = torch.full((batch_size, 1), 1., device=self.device)\n                fake_label = torch.full((batch_size, 1), 0., device=self.device)\n\n                # Train G\n                self.netG.zero_grad()\n                z_noise = torch.randn(batch_size, self.latent_dim, device=self.device)\n                x_fake_labels = torch.randint(0, self.classes, (batch_size,), device=self.device)\n                x_fake = self.netG(z_noise, x_fake_labels)\n                y_fake_g = self.netD(x_fake, x_fake_labels)\n                g_loss = self.netD.loss(y_fake_g, real_label)\n                g_loss.backward()\n                self.optim_G.step()\n\n                # Train D\n                self.netD.zero_grad()\n                y_real = self.netD(data, target)\n                d_real_loss = self.netD.loss(y_real, real_label)\n\n                y_fake_d = self.netD(x_fake.detach(), x_fake_labels)\n                d_fake_loss = self.netD.loss(y_fake_d, fake_label)\n                d_loss = (d_real_loss + d_fake_loss) / 2\n                d_loss.backward()\n                self.optim_D.step()\n```", "```py\n                if verbose and batch_idx % log_interval == 0 and batch_idx > 0:\n                    print('Epoch {} [{}/{}] loss_D: {:.4f} loss_G: {:.4f}'.format(\n                          epoch, batch_idx, len(self.data_loader),\n                          d_loss.mean().item(),\n                          g_loss.mean().item()))\n                    vutils.save_image(data, os.path.join(out_dir, 'real_samples.png'), normalize=True)\n                    with torch.no_grad():\n                        viz_sample = self.netG(viz_noise, viz_label)\n                        vutils.save_image(viz_sample, os.path.join(out_dir, 'fake_samples_{}.png'.format(epoch)), nrow=8, normalize=True)\n            self.save_to(path=out_dir, name=self.name, verbose=False)\n```", "```py\nimport argparse\nimport os\nimport sys\n\nimport numpy as np\nimport torch\nimport torch.backends.cudnn as cudnn\nimport torch.utils.data\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\n\nimport utils\n\nfrom build_gan import Model\n```", "```py\nFLAGS = None\n\ndef main():\n    device = torch.device(\"cuda:0\" if FLAGS.cuda else \"cpu\")\n\n    if FLAGS.train:\n        print('Loading data...\\n')\n        dataset = dset.MNIST(root=FLAGS.data_dir, download=True,\n                             transform=transforms.Compose([\n                             transforms.Resize(FLAGS.img_size),\n                             transforms.ToTensor(),\n                             transforms.Normalize((0.5,), (0.5,))\n                             ]))\n        assert dataset\n        dataloader = torch.utils.data.DataLoader(dataset, batch_size=FLAGS.batch_size,\n                                                 shuffle=True, num_workers=4, pin_memory=True)\n        print('Creating model...\\n')\n        model = Model(FLAGS.model, device, dataloader, FLAGS.classes, FLAGS.channels, FLAGS.img_size, FLAGS.latent_dim)\n        model.create_optim(FLAGS.lr)\n\n        # Train\n        model.train(FLAGS.epochs, FLAGS.log_interval, FLAGS.out_dir, True)\n\n        model.save_to('')\n    else:\n        model = Model(FLAGS.model, device, None, FLAGS.classes, FLAGS.channels, FLAGS.img_size, FLAGS.latent_dim)\n        model.load_from(FLAGS.out_dir)\n        model.eval(mode=0, batch_size=FLAGS.batch_size)\n```", "```py\nif __name__ == '__main__':\n    from utils import boolean_string\n    parser = argparse.ArgumentParser(description='Hands-On GANs - Chapter 5')\n    parser.add_argument('--model', type=str, default='cgan', help='one of `cgan` and `infogan`.')\n    parser.add_argument('--cuda', type=boolean_string, default=True, help='enable CUDA.')\n    parser.add_argument('--train', type=boolean_string, default=True, help='train mode or eval mode.')\n    parser.add_argument('--data_dir', type=str, default='~/Data/mnist', help='Directory for dataset.')\n    parser.add_argument('--out_dir', type=str, default='output', help='Directory for output.')\n    parser.add_argument('--epochs', type=int, default=200, help='number of epochs')\n    parser.add_argument('--batch_size', type=int, default=128, help='size of batches')\n    parser.add_argument('--lr', type=float, default=0.0002, help='learning rate')\n    parser.add_argument('--latent_dim', type=int, default=100, help='latent space dimension')\n    parser.add_argument('--classes', type=int, default=10, help='number of classes')\n    parser.add_argument('--img_size', type=int, default=64, help='size of images')\n    parser.add_argument('--channels', type=int, default=1, help='number of image channels')\n    parser.add_argument('--log_interval', type=int, default=100, help='interval between logging and image sampling')\n    parser.add_argument('--seed', type=int, default=1, help='random seed')\n\n    FLAGS = parser.parse_args()\n```", "```py\ndef boolean_string(s):\n    if s not in {'False', 'True'}:\n        raise ValueError('Not a valid boolean string')\n    return s == 'True'\n```", "```py\n    FLAGS.cuda = FLAGS.cuda and torch.cuda.is_available()\n\n    if FLAGS.seed is not None:\n        torch.manual_seed(FLAGS.seed)\n        if FLAGS.cuda:\n            torch.cuda.manual_seed(FLAGS.seed)\n        np.random.seed(FLAGS.seed)\n\n    cudnn.benchmark = True\n\n    if FLAGS.train:\n        utils.clear_folder(FLAGS.out_dir)\n\n    log_file = os.path.join(FLAGS.out_dir, 'log.txt')\n    print(\"Logging to {}\\n\".format(log_file))\n    sys.stdout = utils.StdOut(log_file)\n\n    print(\"PyTorch version: {}\".format(torch.__version__))\n    print(\"CUDA version: {}\\n\".format(torch.version.cuda))\n\n    print(\" \" * 9 + \"Args\" + \" \" * 9 + \"| \" + \"Type\" + \\\n          \" | \" + \"Value\")\n    print(\"-\" * 50)\n    for arg in vars(FLAGS):\n        arg_str = str(arg)\n        var_str = str(getattr(FLAGS, arg))\n        type_str = str(type(getattr(FLAGS, arg)).__name__)\n        print(\" \" + arg_str + \" \" * (20-len(arg_str)) + \"|\" + \\\n              \" \" + type_str + \" \" * (10-len(type_str)) + \"|\" + \\\n              \" \" + var_str)\n\n    main()\n```", "```py\n       $ conda activate torch\n(torch)$ python main.py --model cgan --train True --data_dir DATA_DIRECTORY\n```", "```py\nLogging to output/log.txt\n\nPyTorch version: 1.0.1.post2\nCUDA version: 10.0.130\n\n         Args         |   Type    |   Value\n--------------------------------------------------\n  model               | str       | cgan\n  cuda                | bool      | True\n  train               | bool      | True\n  data_dir            | str       | ~/Data/mnist\n  out_dir             | str       | output\n  epochs              | int       | 200\n  batch_size          | int       | 128\n  lr                  | float     | 0.0002\n  latent_dim          | int       | 100\n  classes             | int       | 10\n  img_size            | int       | 64\n  channels            | int       | 1\n  log_interval        | int       | 100\n  seed                | int       | 1\nLoading data...\n\nCreating model...\n\nEpoch 0 [100/469] loss_D: 0.6747 loss_G: 0.6119\nEpoch 0 [200/469] loss_D: 0.4745 loss_G: 0.8135\n...\n```", "```py\ndataset = dset.MNIST(root=FLAGS.data_dir, download=True,\n                     transform=transforms.Compose([\n                     transforms.Resize(FLAGS.img_size),\n                     transforms.ToTensor(),\n                     transforms.Normalize((0.5,), (0.5,))\n                     ]))\n```", "```py\ndataset = dset.FashionMNIST(root=FLAGS.data_dir, download=True,\n                            transform=transforms.Compose([\n                            transforms.Resize(FLAGS.img_size),\n                            transforms.ToTensor(),\n                            transforms.Normalize((0.5,), (0.5,))\n                            ]))\n```", "```py\n(torch)$ python fashion_main.py --model cgan --train True --data_dir DATA_DIRECTORY\n```", "```py\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./Data/fashion/FashionMNIST/raw/train-images-idx3-ubyte.gz\n26427392it [00:06, 4212673.42it/s] \nExtracting ./Data/fashion/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./Data/fashion/FashionMNIST/raw\n...\n```", "```py\nclass Upsample(nn.Module):\n    def __init__(self, scale_factor):\n        super(Upsample, self).__init__()\n        self.scale_factor = scale_factor\n\n    def forward(self, x):\n        return F.interpolate(x, scale_factor=self.scale_factor, mode='bilinear', align_corners=False)\n```", "```py\nclass Generator(nn.Module):\n    def __init__(self, classes, channels, img_size, latent_dim, code_dim):\n        super(Generator, self).__init__()\n        self.classes = classes\n        self.channels = channels\n        self.img_size = img_size\n        self.img_init_size = self.img_size // 4\n        self.latent_dim = latent_dim\n        self.code_dim = code_dim\n        self.img_init_shape = (128, self.img_init_size, self.img_init_size)\n        self.img_shape = (self.channels, self.img_size, self.img_size)\n        self.stem_linear = nn.Sequential(\n            nn.Linear(latent_dim + classes + code_dim,\n                      int(np.prod(self.img_init_shape)))\n        )\n        self.model = nn.Sequential(\n            nn.BatchNorm2d(128),\n            *self._create_deconv_layer(128, 128, upsample=True),\n            *self._create_deconv_layer(128, 64, upsample=True),\n            *self._create_deconv_layer(64, self.channels, upsample=False, normalize=False),\n            nn.Tanh()\n        )\n\n    def _create_deconv_layer(self, size_in, size_out, upsample=True,  \n      normalize=True):\n        layers = []\n        if upsample:\n            layers.append(Upsample(scale_factor=2))\n        layers.append(nn.Conv2d(size_in, size_out, 3, stride=1, \n          padding=1))\n        if normalize:\n            layers.append(nn.BatchNorm2d(size_out, 0.8))\n            layers.append(nn.LeakyReLU(0.2, inplace=True))\n        return layers\n\n    def forward(self, noise, labels, code):\n        z = torch.cat((noise, labels, code), -1)\n        z_vec = self.stem_linear(z)\n        z_img = z_vec.view(z_vec.shape[0], *self.img_init_shape)\n        x = self.model(z_img)\n        return x\n```", "```py\nclass Discriminator(nn.Module):\n def __init__(self, classes, channels, img_size, latent_dim, code_dim):\n super(Discriminator, self).__init__()\n self.classes = classes\n self.channels = channels\n self.img_size = img_size\n self.latent_dim = latent_dim\n self.code_dim = code_dim\n self.img_shape = (self.channels, self.img_size, self.img_size)\n self.model = nn.Sequential(\n *self._create_conv_layer(self.channels, 16, True, False),\n *self._create_conv_layer(16, 32, True, True),\n *self._create_conv_layer(32, 64, True, True),\n *self._create_conv_layer(64, 128, True, True),\n )\n out_linear_dim = 128 * (self.img_size // 16) * (self.img_size // 16)\n self.adv_linear = nn.Linear(out_linear_dim, 1)\n self.class_linear = nn.Sequential(\n nn.Linear(out_linear_dim, 128),\n nn.BatchNorm1d(128),\n nn.LeakyReLU(0.2, inplace=True),\n nn.Linear(128, self.classes)\n )\n self.code_linear = nn.Sequential(\n nn.Linear(out_linear_dim, 128),\n nn.BatchNorm1d(128),\n nn.LeakyReLU(0.2, inplace=True),\n nn.Linear(128, self.code_dim)\n )\n self.adv_loss = torch.nn.MSELoss()\n self.class_loss = torch.nn.CrossEntropyLoss()\n self.style_loss = torch.nn.MSELoss()\n\n def _create_conv_layer(self, size_in, size_out, drop_out=True, normalize=True):\n layers = [nn.Conv2d(size_in, size_out, 3, 2, 1)]\n if drop_out:\n layers.append(nn.LeakyReLU(0.2, inplace=True))\n layers.append(nn.Dropout(0.4))\n if normalize:\n layers.append(nn.BatchNorm2d(size_out, 0.8))\n return layers\n\n def forward(self, image):\n y_img = self.model(image)\n y_vec = y_img.view(y_img.shape[0], -1)\n y = self.adv_linear(y_vec)\n label = F.softmax(self.class_linear(y_vec), dim=1)\n code = self.code_linear(y_vec)\n return y, label, code\n```", "```py\nimport itertools\n\nfrom infogan import Generator as infoganG\nfrom infogan import Discriminator as infoganD\n```", "```py\ndef _weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n        torch.nn.init.constant_(m.bias.data, 0.0)\n```", "```py\n        self.style_dim = 2\n        self.infogan = self.name == 'infogan'\n        self.optim_info = None\n```", "```py\n        if self.name == 'cgan':\n            self.netG = cganG(self.classes, self.channels, self.img_size, self.latent_dim)\n        elif self.name == 'infogan':\n            self.netG = infoganG(self.classes, self.channels, self.img_size, self.latent_dim, self.style_dim)\n            self.netG.apply(_weights_init)\n        self.netG.to(self.device)\n        if self.name == 'cgan':\n            self.netD = cganD(self.classes, self.channels, self.img_size, self.latent_dim)\n        elif self.name == 'infogan':\n            self.netD = infoganD(self.classes, self.channels, self.img_size, self.latent_dim, self.style_dim)\n            self.netD.apply(_weights_init)\n        self.netD.to(self.device)\n```", "```py\n        if self.infogan:\n            self.optim_info = torch.optim.Adam(itertools.chain(self.netG.parameters(), self.netD.parameters()),\n                                               lr=lr, betas=(alpha, beta))\n```", "```py\n        viz_noise = torch.randn(self.data_loader.batch_size, self.latent_dim, device=self.device)\n        nrows = self.data_loader.batch_size // 8\n        viz_label = torch.LongTensor(np.array([num for _ in range(nrows) for num in range(8)])).to(self.device)\n        viz_onehot = self._to_onehot(viz_label, dim=self.classes)\n        viz_style = torch.zeros((self.data_loader.batch_size, self.style_dim), device=self.device)\n```", "```py\n    def _to_onehot(self, var, dim):\n        res = torch.zeros((var.shape[0], dim), device=self.device)\n        res[range(var.shape[0]), var] = 1.\n        return res\n```", "```py\n        for epoch in range(epochs):\n            for batch_idx, (data, target) in enumerate(self.data_loader):\n                data, target = data.to(self.device), target.to(self.device)\n                batch_size = data.size(0)\n                real_label = torch.full((batch_size, 1), 1., \n                  device=self.device)\n                fake_label = torch.full((batch_size, 1), 0.,  \n                  device=self.device)\n\n                # Train G\n                self.netG.zero_grad()\n                z_noise = torch.randn(batch_size, self.latent_dim,  \n                  device=self.device)\n                x_fake_labels = torch.randint(0, self.classes, \n                  (batch_size,), device=self.device)\n                labels_onehot = self._to_onehot(x_fake_labels, \n                  dim=self.classes)\n                z_style = torch.zeros((batch_size, self.style_dim), \n                  device=self.device).normal_()\n                x_fake = self.netG(z_noise, labels_onehot, z_style)\n                y_fake_g, _, _ = self.netD(x_fake)\n                g_loss = self.netD.adv_loss(y_fake_g, real_label)\n                g_loss.backward()\n                self.optim_G.step()\n\n                # Train D\n                self.netD.zero_grad()\n                y_real, _, _ = self.netD(data)\n                d_real_loss = self.netD.adv_loss(y_real, real_label)\n                y_fake_d, _, _ = self.netD(x_fake.detach())\n                d_fake_loss = self.netD.adv_loss(y_fake_d, fake_label)\n                d_loss = (d_real_loss + d_fake_loss) / 2\n                d_loss.backward()\n                self.optim_D.step()\n\n                # Update mutual information\n                self.optim_info.zero_grad()\n                z_noise.normal_()\n                x_fake_labels = torch.randint(0, self.classes,  \n                  (batch_size,), device=self.device)\n                labels_onehot = self._to_onehot(x_fake_labels, \n                  dim=self.classes)\n                z_style.normal_()\n                x_fake = self.netG(z_noise, labels_onehot, z_style)\n                _, label_fake, style_fake = self.netD(x_fake)\n                info_loss = self.netD.class_loss(label_fake, \n                  x_fake_labels) +\\\n                            self.netD.style_loss(style_fake, z_style)\n                info_loss.backward()\n                self.optim_info.step()\n```", "```py\n(torch)$ python main.py --model infogan --latent_dim 62 --img_size 32 --batch_size 64 --data_dir DATA_DIRECTORY\n```", "```py\n(torch)$ python main.py --model infogan --latent_dim 62 --img_size 32 --batch_size 64 --train False\n```"]