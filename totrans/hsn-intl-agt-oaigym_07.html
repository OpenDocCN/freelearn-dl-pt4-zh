<html><head></head><body>
        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Creating Custom OpenAI Gym Environments - CARLA Driving Simulator</h1>
                
            
            <article>
                
<p class="calibre2">In the first chapter, we looked at the various categories of learning environments available in the OpenAI Gym environment catalog. We then explored the list of environments and their nomenclature in <a href="part0078.html#2ACBS0-22c7fc7f93b64d07be225c00ead6ce12" class="calibre9">Chapter 5</a>, <em class="calibre13">Implementing your First Learning Agent – Solving the Mountain Car problem</em>, as well as a sneak peek into some of them. We also developed our agents to solve the Mountain Car and Cart Pole problems, and a few Atari game environments. By now, then, you should have a good understanding of the various environment types and flavors that are available with OpenAI Gym. Most often, once we learn how to develop our own intelligent agents, we want to use that knowledge and skill to develop intelligent agents to solve new problems, problems that we already face, or even problems that are of interest to us. For instance, you might be a game developer wanting to add intelligent behaviors to your game characters or a robotics engineer wanting to instill artificial intelligence to your robot, or you could be an autonomous driving engineer wanting to apply reinforcement learning to autonomous driving. You might be a tinkerer wanting to turn a gadget into an intelligent <strong class="calibre4">Internet of Things</strong> (<strong class="calibre4">IoT</strong>) device, or you might even be a healthcare professional wanting to improve your lab's diagnostic capabilities using machine learning. The potential for application is almost limitless.</p>
<p class="calibre2">One of the reasons we have chosen OpenAI Gym as our learning environment is because of its simple yet standard interface that decouples the type and nature of the environment from the environment-agent interface. In this chapter, we will look at how you can <span class="calibre5">create your own environment based on your own personal or professional needs. This will enable you to use agent implementations, training and testing scripts, the parameter manager, and the logging and visualization routines that we developed in earlier chapters with your own design or problem.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Understanding the anatomy of Gym environments</h1>
                
            
            <article>
                
<p class="calibre2">Any Gym-compatible environment should subclass the <kbd class="calibre12">gym.Env</kbd> class and implement the <kbd class="calibre12">reset</kbd> and <kbd class="calibre12">step</kbd> methods and the <kbd class="calibre12">observation_space</kbd> and <kbd class="calibre12">action_space</kbd> properties and attributes. There is also the opportunity to implement other, optional methods that can add additional functionality to our custom environments. The following table lists and describes the other methods available:</p>
<table border="1" class="calibre41">
<tbody class="calibre36">
<tr class="calibre37">
<td class="calibre75">
<div class="cdpaligncenter"><strong class="calibre1">Method</strong></div>
</td>
<td class="calibre76">
<div class="cdpaligncenter"><strong class="calibre1"> Functionality description</strong></div>
</td>
</tr>
<tr class="calibre37">
<td class="calibre75">
<div class="cdpaligncenter"><kbd class="calibre12">observation_space</kbd></div>
</td>
<td class="calibre76">The shape and type of the observations returned by the environment.</td>
</tr>
<tr class="calibre37">
<td class="calibre75">
<div class="cdpaligncenter"><kbd class="calibre12">action_space</kbd></div>
</td>
<td class="calibre76">The shape and type of the actions accepted by the environment.</td>
</tr>
<tr class="calibre37">
<td class="calibre75">
<div class="cdpaligncenter"><kbd class="calibre12">reset()</kbd></div>
</td>
<td class="calibre76">Routines to reset the environment at the start or end of an episode.</td>
</tr>
<tr class="calibre37">
<td class="calibre75">
<div class="cdpaligncenter"><kbd class="calibre12">step(...)</kbd></div>
</td>
<td class="calibre76">Routines that calculate the necessary information to advance the environment, simulation, or game to the next step. The routine includes applying the chosen action in the environment, calculating the reward, producing the next observation, and determining if an episode has ended.</td>
</tr>
<tr class="calibre37">
<td class="calibre75">
<div class="cdpaligncenter"><kbd class="calibre12">_render()</kbd></div>
</td>
<td class="calibre76">(Optional) This renders the state or observation of the Gym environment.</td>
</tr>
<tr class="calibre37">
<td class="calibre75">
<div class="cdpaligncenter"><kbd class="calibre12">_close()</kbd></div>
</td>
<td class="calibre76">(Optional) This closes the Gym environment.</td>
</tr>
<tr class="calibre37">
<td class="calibre75">
<div class="cdpaligncenter"><kbd class="calibre12">_seed</kbd></div>
</td>
<td class="calibre76">(Optional) This seeds the random functions in the Gym environment with a custom seed that makes the environment behave in a reproducible way for a given seed.</td>
</tr>
<tr class="calibre37">
<td class="calibre75">
<div class="cdpaligncenter"><kbd class="calibre12">_configure</kbd></div>
</td>
<td class="calibre76">(Optional) This enables additional environment configuration.</td>
</tr>
</tbody>
</table>
<p class="calibre2"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Creating a template for custom Gym environment implementations</h1>
                
            
            <article>
                
<p class="calibre2">Based on the anatomy of the Gym environment we have already discussed, we will now lay out a basic version of a custom environment class implementation named <kbd class="calibre12">CustomEnv</kbd>, which will be a subclass of <kbd class="calibre12">gym.Env</kbd> and implement the essential methods and arguments required to make it a Gym-compatible environment. A template for a minimal implementation is as follows:</p>
<pre class="calibre17">import gym<br class="title-page-name"/><br class="title-page-name"/>class CustomEnv(gym.Env):<br class="title-page-name"/>    """<br class="title-page-name"/>    A template to implement custom OpenAI Gym environments<br class="title-page-name"/><br class="title-page-name"/>    """<br class="title-page-name"/><br class="title-page-name"/>    metadata = {'render.modes': ['human']}<br class="title-page-name"/>    def __init__(self):<br class="title-page-name"/>        self.__version__ = "0.0.1"<br class="title-page-name"/>        # Modify the observation space, low, high and shape values according to your custom environment's needs<br class="title-page-name"/>        self.observation_space = gym.spaces.Box(low=0.0, high=1.0, shape=(3,))<br class="title-page-name"/>        # Modify the action space, and dimension according to your custom environment's needs<br class="title-page-name"/>        self.action_space = gym.spaces.Box(4)<br class="title-page-name"/><br class="title-page-name"/>    def step(self, action):<br class="title-page-name"/>        """<br class="title-page-name"/>        Runs one time-step of the environment's dynamics. The reset() method is called at the end of every episode<br class="title-page-name"/>        :param action: The action to be executed in the environment<br class="title-page-name"/>        :return: (observation, reward, done, info)<br class="title-page-name"/>            observation (object):<br class="title-page-name"/>                Observation from the environment at the current time-step<br class="title-page-name"/>            reward (float):<br class="title-page-name"/>                Reward from the environment due to the previous action performed<br class="title-page-name"/>            done (bool):<br class="title-page-name"/>                a boolean, indicating whether the episode has ended<br class="title-page-name"/>            info (dict):<br class="title-page-name"/>                a dictionary containing additional information about the previous action<br class="title-page-name"/>        """</pre>
<pre class="calibre17"><br class="title-page-name"/>        # Implement your step method here<br class="title-page-name"/>        #   - Calculate reward based on the action<br class="title-page-name"/>        #   - Calculate next observation<br class="title-page-name"/>        #   - Set done to True if end of episode else set done to False<br class="title-page-name"/>        #   - Optionally, set values to the info dict<br class="title-page-name"/>        # return (observation, reward, done, info)<br class="title-page-name"/><br class="title-page-name"/>    def reset(self):<br class="title-page-name"/>        """<br class="title-page-name"/>        Reset the environment state and returns an initial observation<br class="title-page-name"/><br class="title-page-name"/>        Returns<br class="title-page-name"/>        -------<br class="title-page-name"/>        observation (object): The initial observation for the new episode after reset<br class="title-page-name"/>        :return:<br class="title-page-name"/>        """<br class="title-page-name"/><br class="title-page-name"/>        # Implement your reset method here<br class="title-page-name"/>        # return observation<br class="title-page-name"/><br class="title-page-name"/>    def render(self, mode='human', close=False):<br class="title-page-name"/>        """<br class="title-page-name"/><br class="title-page-name"/>        :param mode:<br class="title-page-name"/>        :return:<br class="title-page-name"/>        """<br class="title-page-name"/>        return</pre>
<p class="calibre2">After we have finished our environment class implementation, we should register it with the OpenAI Gym registry so that we can use <kbd class="calibre12">gym.make(ENV_NAME)</kbd> to create an instance of the environment, as we have previously with Gym environments.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Registering custom environments with OpenAI Gym</h1>
                
            
            <article>
                
<p class="calibre2">The registration of a custom Gym environment is easy with the use of the <kbd class="calibre12">gym.envs.registration.register</kbd> module; this provides the <kbd class="calibre12">register</kbd> method, which in turn takes as an argument <kbd class="calibre12">id</kbd>, which is the name of the environment we want to use when calling <kbd class="calibre12">gym.make(...)</kbd> and <kbd class="calibre12">entry_point</kbd> , the class name for the custom environment implementation we discussed earlier. The code snippet to register the <kbd class="calibre12">CustomEnv</kbd> class we implemented is as follows:</p>
<pre class="calibre17">from gym.envs.registration import register<br class="title-page-name"/><br class="title-page-name"/>register(<br class="title-page-name"/>    id='CustomEnv-v0',<br class="title-page-name"/>    entry_point='custom_environments.envs:CustomEnv',<br class="title-page-name"/>)</pre>
<p class="calibre2"><span class="calibre5">We will make use of this template later on in this chapter to create a custom Gym environment that uses a very sophisticated driving simulator.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Creating an OpenAI Gym-compatible CARLA driving simulator environment</h1>
                
            
            <article>
                
<p class="calibre2">CARLA is a driving simulator environment built on top of the UnrealEngine4 game engine with more realistic rendering compared to some of its competitors. You can read more about the CARLA simulator on their official website at <a href="https://carla.org" class="calibre9">https://carla.org</a>. In this section, we will look into how we can create a custom OpenAI Gym-compatible car driving environment to train our learning agents. This is a fairly complex environment and requires a GPU to run—which is unlike other Gym environments we have seen so far. Once you understand how to create a custom environment interface that is Gym-compatible for CARLA, you may well have enough information to develop interfaces for any of your own custom environments, no matter how complex they might be. </p>
<p class="calibre2">The latest version of CARLA is CARLA 0.8.2. While most (if not all) of the core environment interfaces, especially the <kbd class="calibre12">PythonClient</kbd> library, might stay the same, there is a chance of future changes that necessitate tweaks in this custom environment implementation. If that happens, the code repository of this book will be updated accordingly to support newer versions of CARLA. You may want to make sure you use the latest version of the code from the book's code repository when you work on this chapter (which is yet another reason to subscribe to notifications in GitHub). Nevertheless, the custom environment implementation building blocks discussed in this chapter will stay generally applicable, and will walk you through defining your own custom environments that are compatible with the OpenAI Gym interface. The complete code for the custom CARLA environment interface is available in the book's code repository under <kbd class="calibre12">ch7/carla-gym</kbd>.</p>
<p class="calibre2">Before we start a Gym-compatible CARLA environment, let's first take a look at the CARLA simulator. So, let's go ahead and download the CARLA release binaries. In the following section, we will use <kbd class="calibre12">VER_NUM</kbd> to denote the version number, so be sure to replace the <kbd class="calibre12">VER_NUM</kbd> text with the version number you are using before running the following commands:</p>
<ol class="calibre14">
<li class="calibre11" value="1"><span>First, create a folder named </span><kbd class="calibre12">software</kbd> <span>in your home directory using the following bash command: </span></li>
</ol>
<pre class="calibre77"><strong class="calibre1">mkdir ~/software &amp;&amp; cd ~/software</strong></pre>
<ol start="2" class="calibre14">
<li class="calibre11" value="2"> Download the CARLA binary release version for Linux<span> (</span><a href="https://drive.google.com/open?id=1ZtVt1AqdyGxgyTm69nzuwrOYoPUn_Dsm" class="calibre9">CARLA_VER_NUM.tar.gz</a>) using the link on the official release page at <a href="https://github.com/carla-simulator/carla/releases/tag/0.8.2" class="calibre9">https://github.com/carla-simulator/carla/releases/tag/VER_NUM</a>. (The direct link to version 0.8.2 is: <a href="https://drive.google.com/open?id=1ZtVt1AqdyGxgyTm69nzuwrOYoPUn_Dsm" class="calibre9">https://drive.google.com/open?id=1ZtVt1AqdyGxgyTm69nzuwrOYoPUn_Dsm</a>.) Then, extract it into <kbd class="calibre12">~/software</kbd>. You should now have a file named <kbd class="calibre12">CarlaUE4.sh</kbd> in the <kbd class="calibre12">~/software/CARLA_VER_NUM</kbd> folder.</li>
<li class="calibre11" value="3"><span> Set the </span><kbd class="calibre12">CARLA_SERVER</kbd> <span>environment variable to point to </span><kbd class="calibre12">CarlaUE4.sh</kbd> <span>on your computer using the following command: </span></li>
</ol>
<pre class="calibre77"><strong class="calibre1">export CARLA_SERVER=~/software/CARLA_VER_NUM/CarlaUE4.sh</strong></pre>
<p class="calibre2">Now you are ready to test-run the CARLA driving simulator! Just execute <kbd class="calibre12">$CARLA_SERVER</kbd> or, directly, <kbd class="calibre12"><span>~/software/CARLA_VER_NUM/CarlaUE4.sh</span></kbd>. For CARLA version 0.8.2, this command will be <kbd class="calibre12"><span>~/software/CARLA_0.8.2</span><span>/CarlaUE4.sh</span></kbd>. You should now see a CARLA simulator screen, as shown in the following screenshot:</p>
<p class="cdpaligncenter4"><img src="../images/00149.jpeg" class="calibre78"/></p>
<p class="calibre2">The previous screenshot shows the vehicle (the agent) in one of CARLA's starting positions. The following screenshot shows the vehicle in another starting position in the CARLA environment:</p>
<p class="cdpaligncenter4"><img src="../images/00150.jpeg" class="calibre79"/></p>
<p class="calibre2">Once the vehicle is initialized, you should be able to control the vehicle using the <em class="calibre13">w</em>, <em class="calibre13">a</em>, <em class="calibre13">s</em>, <em class="calibre13">d</em> keys on your keyboard. The <em class="calibre13">w</em> key will move the car forwards, the <em class="calibre13">a</em> key will turn the car to the left, and... you can probably figure out the rest! </p>
<p class="calibre2">Let's now move on and start our Gym-compatible CARLA environment implementation with configuration and initialization.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Configuration and initialization</h1>
                
            
            <article>
                
<p class="calibre2">We will first define some environment-specific configuration parameters, as well as briefly look at scenario configurations, as well. We will then start the initialization process for the <kbd class="calibre12">CarlaEnv</kbd> class implementation, which will inherit from the <kbd class="calibre12">Gym.Env</kbd> class.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Configuration</h1>
                
            
            <article>
                
<p class="calibre2">Let's first define a list of configuration parameters for the environment using a dictionary, shown as follows:</p>
<pre class="calibre17"># Default environment configuration<br class="title-page-name"/>ENV_CONFIG = {<br class="title-page-name"/>    "enable_planner": True,<br class="title-page-name"/>    "use_depth_camera": False,<br class="title-page-name"/>    "discrete_actions": True,<br class="title-page-name"/>    "server_map": "/Game/Maps/" + city,<br class="title-page-name"/>    "scenarios": [scenario_config["Lane_Keep_Town2"]],<br class="title-page-name"/>    "framestack": 2, # note: only [1, 2] currently supported<br class="title-page-name"/>    "early_terminate_on_collision": True,<br class="title-page-name"/>    "verbose": False,<br class="title-page-name"/>    "render_x_res": 800,<br class="title-page-name"/>    "render_y_res": 600,<br class="title-page-name"/>    "x_res": 80,<br class="title-page-name"/>    "y_res": 80<br class="title-page-name"/>}</pre>
<p class="calibre2"><kbd class="calibre12">scenario_config</kbd> defines several parameters that are useful for creating a variety of driving scenarios. The scenario configuration is described in the <kbd class="calibre12">scenarios.json</kbd> file, which can be found in the book's code repository at <kbd class="calibre12">ch7/carla-gym/carla_gym<br class="title-page-name"/>
/envs/scenarios.json</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Initialization</h1>
                
            
            <article>
                
<p class="calibre2">In the <kbd class="calibre12">__init__</kbd> method, we define the initialization parameters along with the action and state spaces, which, as we saw in the previous section, are necessary. The implementation is straight-forward, as follows:</p>
<pre class="calibre17">def __init__(self, config=ENV_CONFIG):<br class="title-page-name"/>        self.config = config<br class="title-page-name"/>        self.city = self.config["server_map"].split("/")[-1]<br class="title-page-name"/>        if self.config["enable_planner"]:<br class="title-page-name"/>            self.planner = Planner(self.city)<br class="title-page-name"/><br class="title-page-name"/>        if config["discrete_actions"]:<br class="title-page-name"/>            self.action_space = Discrete(len(DISCRETE_ACTIONS))<br class="title-page-name"/>        else:<br class="title-page-name"/>            self.action_space = Box(-1.0, 1.0, shape=(2,))<br class="title-page-name"/>        if config["use_depth_camera"]:<br class="title-page-name"/>            image_space = Box(<br class="title-page-name"/>                -1.0, 1.0, shape=(</pre>
<pre class="calibre17"><br class="title-page-name"/>                    config["y_res"], config["x_res"],<br class="title-page-name"/>                    1 * config["framestack"]))<br class="title-page-name"/>        else:<br class="title-page-name"/>            image_space = Box(<br class="title-page-name"/>                0.0, 255.0, shape=(<br class="title-page-name"/>                    config["y_res"], config["x_res"],<br class="title-page-name"/>                    3 * config["framestack"]))<br class="title-page-name"/>        self.observation_space = Tuple(<br class="title-page-name"/>            [image_space,<br class="title-page-name"/>             Discrete(len(COMMANDS_ENUM)),  # next_command<br class="title-page-name"/>             Box(-128.0, 128.0, shape=(2,))])  # forward_speed, dist to goal<br class="title-page-name"/><br class="title-page-name"/>        self._spec = lambda: None<br class="title-page-name"/>        self._spec.id = "Carla-v0"<br class="title-page-name"/><br class="title-page-name"/>        self.server_port = None<br class="title-page-name"/>        self.server_process = None<br class="title-page-name"/>        self.client = None<br class="title-page-name"/>        self.num_steps = 0<br class="title-page-name"/>        self.total_reward = 0<br class="title-page-name"/>        self.prev_measurement = None<br class="title-page-name"/>        self.prev_image = None<br class="title-page-name"/>        self.episode_id = None<br class="title-page-name"/>        self.measurements_file = None<br class="title-page-name"/>        self.weather = None<br class="title-page-name"/>        self.scenario = None<br class="title-page-name"/>        self.start_pos = None<br class="title-page-name"/>        self.end_pos = None<br class="title-page-name"/>        self.start_coord = None<br class="title-page-name"/>        self.end_coord = None<br class="title-page-name"/>        self.last_obs = None</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Implementing the reset method</h1>
                
            
            <article>
                
<p class="calibre2">As you may have noticed, at the beginning of every episode, we call the <kbd class="calibre12">reset</kbd> method of the Gym environment. For the CARLA environment, we want to update the CARLA server to restart the level through the CARLA client.</p>
<p class="calibre2">So, let's get on with starting our implementation of the <kbd class="calibre12">reset</kbd> method.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Customizing the CARLA simulation using the CarlaSettings object</h1>
                
            
            <article>
                
<p class="calibre2">When we start a new episode, we want to be able to configure the start state (where the agent or vehicle starts), the goal state (the agent or vehicle's intended destination), the complexity of the episode (measured by the number of vehicles or pedestrians in the episode), the type and sources of observations (the sensors configured on the vehicle), and so on.</p>
<p class="calibre2">The CARLA project manages the interface between the UE4 environment and the external configuration and control using a server-client architecture, for which there are two servers.</p>
<p class="calibre2">For the CARLA environment, we can configure the environment's start state, goal state, complexity level, and the sensor sources using the <kbd class="calibre12">CarlaSettings</kbd> object or the <kbd class="calibre12">CarlaSettings.ini</kbd> file.</p>
<p class="calibre2">Let's now create a <kbd class="calibre12">CarlaSettings</kbd> object and configure some of the settings, as follows:</p>
<pre class="calibre17">settings = CarlaSettings()  # Initialize a CarlaSettings object with default values<br class="title-page-name"/>settings.set(<br class="title-page-name"/>            SynchronousMode=True,<br class="title-page-name"/>            SendNonPlayerAgentsInfo=True,  # To receive info about all other objs<br class="title-page-name"/>            NumberOfVehicles=self.scenario["num_vehicles"],<br class="title-page-name"/>            NumberOfPedestrians=self.scenario["num_pedestrians"],<br class="title-page-name"/>            WeatherId=self.weather)</pre>
<p class="calibre2">In the previous code snippet, we are setting <kbd class="calibre12">SynchronousMode</kbd> to <kbd class="calibre12">True</kbd> to enable the synchronous mode, in which the CARLA server halts the execution of each frame until a control message is received. Control messages are based on the actions the agent takes and are sent through the CARLA client.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Adding cameras and sensors to a vehicle in CARLA</h1>
                
            
            <article>
                
<p class="calibre2">To add an RGB color camera in the CARLA environment, use the following code:</p>
<pre class="calibre17"># Create a RGB Camera Object<br class="title-page-name"/>camera1 = Camera('CameraRGB')<br class="title-page-name"/># Set the RGB camera image resolution in pixels<br class="title-page-name"/>camera1.set_image_size(640, 480)<br class="title-page-name"/># Set the camera/sensor position relative to the car in meters<br class="title-page-name"/>camera1.set_positions(0.25, 0, 1.30)<br class="title-page-name"/># Add the sensor to the Carla Settings object<br class="title-page-name"/>settings.add_sensor(camera1)</pre>
<p class="calibre2">You can also add a depth measuring sensor or camera using the following code snippet:</p>
<pre class="calibre17"># Create a depth camera object that can provide us the ground-truth depth of the driving scene<br class="title-page-name"/>camera2 = Camera("CameraDepth",PostProcessing="Depth")<br class="title-page-name"/># Set the depth camera image resolution in pixels<br class="title-page-name"/>camera2.set_image_size(640, 480)<br class="title-page-name"/># Set the camera/sensor position relative to the car in meters<br class="title-page-name"/>camera2.set_position(0.30, 0, 1.30)<br class="title-page-name"/># Add the sensor to the Carla settings object<br class="title-page-name"/>settings.add_sensor(camera)Setting up the start and end positions in the scene for the Carla Simulation</pre>
<p class="calibre2">To add <kbd class="calibre12">LIDAR</kbd> to the CARLA environment, use the following code:</p>
<pre class="calibre17"># Create a LIDAR object. The default LIDAR supports 32 beams<br class="title-page-name"/>lidar = Lidar('Lidar32')<br class="title-page-name"/># Set the LIDAR sensor's specifications<br class="title-page-name"/>lidar.set(<br class="title-page-name"/>    Channels=32,  # Number of beams/channels<br class="title-page-name"/>    Range=50,     # Range of the sensor in meters<br class="title-page-name"/>    PointsPerSecond=1000000,  # Sample rate<br class="title-page-name"/>    RotationFrequency=10,  # Frequency of rotation<br class="title-page-name"/>    UpperFovLimit=10,  # Vertical field of view upper limit angle<br class="title-page-name"/>    LowerFovLimit=-30) # Vertical field of view lower limit angle<br class="title-page-name"/># Set the LIDAR position &amp; rotation relative to the car in meters<br class="title-page-name"/>lidar.set_position(0, 0, 2.5)<br class="title-page-name"/>lidar.set_rotation(0, 0, 0)<br class="title-page-name"/># Add the sensor to the Carla settings object<br class="title-page-name"/>settings.add_sensor(lidar)</pre>
<p class="calibre2">Once we have created a CARLA settings object based on our desired driving simulation configuration, we can send it to the CARLA server to set up the environment and start the simulation.</p>
<p class="calibre2">Once we have sent the CARLA settings object to the CARLA server, it responds with a scene description object that contains the available start positions for the ego vehicle, as follows:</p>
<pre class="calibre17">scene = self.client.load_settings(settings)<br class="title-page-name"/>available_start_spots = scene.player_start_spots</pre>
<p class="calibre2">We can now choose a particular starting position for the host or ego vehicle, or even choose a starting spot at random, as shown in the following code snippet:</p>
<pre class="calibre17">start_spot = random.randint(0, max(0, available_start_spots))</pre>
<p class="calibre2">We can also send this start spot preference to the server and request the start of a new episode using the following code snippet:</p>
<pre class="calibre17">self.client.start_episode(start_spot)</pre>
<p class="calibre2">Note that the previous line is a blocking function call that will block action until the CARLA server actually starts the episode.</p>
<p class="calibre2">We can now step through the episode from this starting position until the end. In the next section, we will see what we need to implement the CARLA environment's <kbd class="calibre12">step()</kbd> method, which is used to step through the environment to the end of an episode:</p>
<pre class="calibre17">def _reset(self):<br class="title-page-name"/>        self.num_steps = 0<br class="title-page-name"/>        self.total_reward = 0<br class="title-page-name"/>        self.prev_measurement = None<br class="title-page-name"/>        self.prev_image = None<br class="title-page-name"/>        self.episode_id = datetime.today().strftime("%Y-%m-%d_%H-%M-%S_%f")<br class="title-page-name"/>        self.measurements_file = None<br class="title-page-name"/><br class="title-page-name"/>        # Create a CarlaSettings object. This object is a wrapper around<br class="title-page-name"/>        # the CarlaSettings.ini file. Here we set the configuration we<br class="title-page-name"/>        # want for the new episode.<br class="title-page-name"/>        settings = CarlaSettings()<br class="title-page-name"/>        # If config["scenarios"] is a single scenario, then use it if it's an array of scenarios, randomly choose one and init<br class="title-page-name"/>        self.config = update_scenarios_parameter(self.config)<br class="title-page-name"/><br class="title-page-name"/>        if isinstance(self.config["scenarios"],dict):<br class="title-page-name"/>            self.scenario = self.config["scenarios"]<br class="title-page-name"/>        else: #ininstance array of dict<br class="title-page-name"/>            self.scenario = random.choice(self.config["scenarios"])<br class="title-page-name"/>        assert self.scenario["city"] == self.city, (self.scenario, self.city)<br class="title-page-name"/>        self.weather = random.choice(self.scenario["weather_distribution"])<br class="title-page-name"/>        settings.set(<br class="title-page-name"/>            SynchronousMode=True,<br class="title-page-name"/>            SendNonPlayerAgentsInfo=True,<br class="title-page-name"/>            NumberOfVehicles=self.scenario["num_vehicles"],<br class="title-page-name"/>            NumberOfPedestrians=self.scenario["num_pedestrians"],<br class="title-page-name"/>            WeatherId=self.weather)<br class="title-page-name"/>        settings.randomize_seeds()<br class="title-page-name"/><br class="title-page-name"/>        if self.config["use_depth_camera"]:<br class="title-page-name"/>            camera1 = Camera("CameraDepth", PostProcessing="Depth")<br class="title-page-name"/>            camera1.set_image_size(<br class="title-page-name"/>                self.config["render_x_res"], self.config["render_y_res"])<br class="title-page-name"/>            camera1.set_position(30, 0, 130)<br class="title-page-name"/>            settings.add_sensor(camera1)<br class="title-page-name"/><br class="title-page-name"/>        camera2 = Camera("CameraRGB")<br class="title-page-name"/>        camera2.set_image_size(<br class="title-page-name"/>            self.config["render_x_res"], self.config["render_y_res"])<br class="title-page-name"/>        camera2.set_position(30, 0, 130)<br class="title-page-name"/>        settings.add_sensor(camera2)<br class="title-page-name"/><br class="title-page-name"/>        # Setup start and end positions<br class="title-page-name"/>        scene = self.client.load_settings(settings)<br class="title-page-name"/>        positions = scene.player_start_spots<br class="title-page-name"/>        self.start_pos = positions[self.scenario["start_pos_id"]]<br class="title-page-name"/>        self.end_pos = positions[self.scenario["end_pos_id"]]<br class="title-page-name"/>        self.start_coord = [<br class="title-page-name"/>            self.start_pos.location.x // 100, self.start_pos.location.y // 100]<br class="title-page-name"/>        self.end_coord = [<br class="title-page-name"/>            self.end_pos.location.x // 100, self.end_pos.location.y // 100]<br class="title-page-name"/>        print(<br class="title-page-name"/>            "Start pos {} ({}), end {} ({})".format(<br class="title-page-name"/>                self.scenario["start_pos_id"], self.start_coord,<br class="title-page-name"/>                self.scenario["end_pos_id"], self.end_coord))<br class="title-page-name"/><br class="title-page-name"/>        # Notify the server that we want to start the episode at the<br class="title-page-name"/>        # player_start index. This function blocks until the server is ready<br class="title-page-name"/>        # to start the episode.<br class="title-page-name"/>        print("Starting new episode...")<br class="title-page-name"/>        self.client.start_episode(self.scenario["start_pos_id"])<br class="title-page-name"/><br class="title-page-name"/>        image, py_measurements = self._read_observation()<br class="title-page-name"/>        self.prev_measurement = py_measurements<br class="title-page-name"/>        return self.encode_obs(self.preprocess_image(image), py_measurements)</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Implementing the step function for the CARLA environment</h1>
                
            
            <article>
                
<p class="calibre2">Once we have initialized the CARLA simulator by sending the CARLA settings object to the CARLA server and calling <kbd class="calibre12">client.start_episode(start_spot)</kbd>, the driving simulation will begin. We can then use the <kbd class="calibre12">client.read_data()</kbd> method to get the data produced by the simulation at a given step. We can do this using the following line of code:</p>
<pre class="calibre17">measurements, sensor_data = client.read_data()</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Accessing camera or sensor data</h1>
                
            
            <article>
                
<p class="calibre2">We can retrieve the sensor data at any given time step using the returned <kbd class="calibre12">sensor_data</kbd> object's <kbd class="calibre12">data</kbd> property. To retrieve the RGB camera frames, input the following code:</p>
<pre class="calibre77">rgb_image = sensor_data['CameraRGB'].data</pre>
<p class="calibre2"> <kbd class="calibre12">rgb_image</kbd> is a NumPy n-d array, which you can access and manipulate as you would usually access and manipulate a NumPy n-d array.</p>
<p class="calibre2">For example, to access the pixel value of the RGB camera image at the (<em class="calibre13">x</em>, <em class="calibre13">y</em>) image plane coordinates, you can do so using the following line:</p>
<pre class="calibre77">pixel_value_at_x_y = rgb_image[X, Y]</pre>
<p class="calibre2">To retrieve the depth camera frames, input the following code:</p>
<pre class="calibre77">depth_image = sensor_data['CameraDepth'].data</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Sending actions to control agents in CARLA</h1>
                
            
            <article>
                
<p class="calibre2">We can control the car in CARLA by sending the desired steer, throttle, brake, hand-brake, and reverse (gear) commands to the CARLA server through a TCP client. The following table displays the value, range, and a description of the commands that a car in CARLA will obey:</p>
<table border="1" class="calibre41">
<tbody class="calibre36">
<tr class="calibre37">
<td class="calibre48"><strong class="calibre1">Command/action name</strong></td>
<td class="calibre48"><strong class="calibre1">Value type, range</strong></td>
<td class="calibre48"><strong class="calibre1">Description</strong></td>
</tr>
<tr class="calibre37">
<td class="calibre48">Steer</td>
<td class="calibre48"><kbd class="calibre12">Float</kbd>, [-1.0, +1.0]</td>
<td class="calibre48">Normalized steering angle</td>
</tr>
<tr class="calibre37">
<td class="calibre48">Throttle</td>
<td class="calibre48"><kbd class="calibre12">Float</kbd>, [0.0, 1.0]</td>
<td class="calibre48">Normalized throttle input</td>
</tr>
<tr class="calibre37">
<td class="calibre48">Brake</td>
<td class="calibre48"><kbd class="calibre12">Float</kbd>, [0.0, 1.0]</td>
<td class="calibre48">Normalized brake input</td>
</tr>
<tr class="calibre37">
<td class="calibre48">Hand Brake</td>
<td class="calibre48"><kbd class="calibre12">Boolean</kbd>, True/False</td>
<td class="calibre48">This tells the car whether to engage the hand brake (<kbd class="calibre12">True</kbd>) or not (<kbd class="calibre12">False</kbd>)</td>
</tr>
<tr class="calibre37">
<td class="calibre48">Reverse</td>
<td class="calibre48"><kbd class="calibre12">Boolean</kbd>, True/False</td>
<td class="calibre48">This tells the car whether to be in reverse gear (<kbd class="calibre12">True</kbd>) or not (<kbd class="calibre12">False</kbd>)</td>
</tr>
</tbody>
</table>
<p class="calibre2"> </p>
<p class="calibre2">As noted in the CARLA documentation, the actual steering angle will depend on the vehicle. For example, the default Mustang vehicle has a maximum steering angle of 70 degrees, as defined in the vehicle's front wheel UE4 blueprint file. Those are the five different commands that are needed to control a car in CARLA. Among the five commands, three of them (steer, throttle, and brake) are real-value floating-point numbers. Though their range is limited between -1 and +1 or 0 and 1, the number of (unique) possible values is enormous. For example, if we use single precision floating point representation for throttle values that lie between 0 and 1, there are <img class="fm-editor-equation75" src="../images/00151.jpeg"/>, which means there are 1,056,964,608 different possible values for that throttle command. The same holds true for the brake command, as it also lies between 0 and 1. There are about twice as many possible float values for the steering command, as it lies between -1 and +1. Since a single control message is composed of a set of values for each of the five commands, the number of distinct actions (or control messages) is the product of the unique values for each of the commands, which are roughly in the order that follows:</p>
<div class="cdpaligncenter"><img class="fm-editor-equation76" src="../images/00152.jpeg"/></div>
<p class="calibre2">This generates a huge action space as you can see, and it might prove to be a very hard problem for a deep learning agent to regress onto such a huge action space. So, let's simplify the action space and define the action space in two flavors – one for continuous space and the other for discrete space, which is useful for applying different reinforcement learning algorithms. For example, the deep Q-learning based algorithms (without the naturalized advantage function) can only work on discrete action spaces.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Continuous action space in CARLA</h1>
                
            
            <article>
                
<p class="calibre2">While driving, we don't usually accelerate and brake at the same time; because the action space in CARLA is continuous, and the agent will apply an action at every step, it may be enough to have one command for accelerating and decelerating. Let's now combine the throttle and brake commands into one with a value range of -1 to +1, using the value range between -1 and 0 for the brake command and the value range between 0 and 1 for the throttle or acceleration command. We can define this using the following command:</p>
<pre class="calibre17">action_space = gym.space.Box(-1.0, 1.0, shape=2(,))</pre>
<p class="calibre2"><kbd class="calibre12">action[0]</kbd> signifies the command for steering, while <kbd class="calibre12">action[1]</kbd> signifies the value for our combined throttle and brake commands. For now, we will set both <kbd class="calibre12">hand_brake</kbd> and <kbd class="calibre12">reverse</kbd> to False. <span class="calibre5">Next, we will look at how we can define a discrete action space so we choose what we want for our agent.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Discrete action space in CARLA</h1>
                
            
            <article>
                
<p class="calibre2">We've already seen that the full action space is quite large (in the order of <img class="fm-editor-equation77" src="../images/00153.jpeg"/> ). You may have played video games where you only used a joystick with four arrow buttons or the arrow keys on a keyboard to control the speed and heading (the direction in which the car is pointed) to drive, so why can't we ask the agent to control the car in a similar way here? Well, that is the idea behind discretizing the action space. Although we won't be able to have precise control over the car, we can make sure that the discretized space gives us good control in a simulation environment.</p>
<p class="calibre2">Let's begin by using the similar convention we used in the continuous action space case – where we used one floating point value to represent the throttle (acceleration) and brake (deceleration) actions, thereby using a two-dimensional bounded space internally. This means the action space, in this case, can be defined as follows:</p>
<pre class="calibre17">action_space = gym.spaces.Discrete(NUM_DISCRETE_ACTIONS)</pre>
<p class="calibre2">As you can see here, <kbd class="calibre12">NUM_DISCRETE_ACTONS</kbd> is equal to the number of different actions available, which we will define later on in this section.</p>
<p class="calibre2">We will then discretize the space using two-dimensional bounded space and exposing this as the discrete action space to the agent. To keep the number of possible actions to a minimum while still allowing control over the car, we use the following list of actions:</p>
<table border="1" class="calibre41">
<tbody class="calibre36">
<tr class="calibre37">
<td class="calibre48"><strong class="calibre1">Action index</strong></td>
<td class="calibre48"><strong class="calibre1">Action description</strong></td>
<td class="calibre48"><strong class="calibre1"> Action array value</strong></td>
</tr>
<tr class="calibre37">
<td class="calibre48">0</td>
<td class="calibre48">Coast</td>
<td class="calibre48">[0.0, 0.0]</td>
</tr>
<tr class="calibre37">
<td class="calibre48">1</td>
<td class="calibre48">Turn Left</td>
<td class="calibre48">[0.0, -0.5]</td>
</tr>
<tr class="calibre37">
<td class="calibre48">2</td>
<td class="calibre48">Turn Right</td>
<td class="calibre48">[0.0, 0.5]</td>
</tr>
<tr class="calibre37">
<td class="calibre48">3</td>
<td class="calibre48">Forward</td>
<td class="calibre48">[1.0, 0.0]</td>
</tr>
<tr class="calibre37">
<td class="calibre48">4</td>
<td class="calibre48">Brake</td>
<td class="calibre48">[-0.5, 0.0]</td>
</tr>
<tr class="calibre37">
<td class="calibre48">5</td>
<td class="calibre48">Bear Left &amp; Accelerate</td>
<td class="calibre48">[1.0, -0.5]</td>
</tr>
<tr class="calibre37">
<td class="calibre48">6</td>
<td class="calibre48">Bear Right &amp; Accelerate</td>
<td class="calibre48">[1.0, 0.5]</td>
</tr>
<tr class="calibre37">
<td class="calibre48">7</td>
<td class="calibre48">Bear Left &amp; Decelerate</td>
<td class="calibre48">[-0.5, -0.5]</td>
</tr>
<tr class="calibre37">
<td class="calibre48">8</td>
<td class="calibre48">Bear Right &amp; Decelerate</td>
<td class="calibre48">[-0.5, 0.5]</td>
</tr>
</tbody>
</table>
<p class="calibre2"/>
<p class="calibre2">Let's now define the previous set of discrete actions in a <kbd class="calibre12">DISCRETE_ACTIONS</kbd> dictionary in our <kbd class="calibre12">carla_env</kbd> implementation script, shown as follows:</p>
<pre class="calibre17">DISCRETE_ACTIONS = {<br class="title-page-name"/>    0: [0.0, 0.0],    # Coast<br class="title-page-name"/>    1: [0.0, -0.5],   # Turn Left <br class="title-page-name"/>    2: [0.0, 0.5],    # Turn Right<br class="title-page-name"/>    3: [1.0, 0.0],    # Forward<br class="title-page-name"/>    4: [-0.5, 0.0],   # Brake<br class="title-page-name"/>    5: [1.0, -0.5],   # Bear Left &amp; accelerate<br class="title-page-name"/>    6: [1.0, 0.5],    # Bear Right &amp; accelerate<br class="title-page-name"/>    7: [-0.5, -0.5],  # Bear Left &amp; decelerate<br class="title-page-name"/>    8: [-0.5, 0.5],   # Bear Right &amp; decelerate<br class="title-page-name"/>}</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Sending actions to the CARLA simulation server</h1>
                
            
            <article>
                
<p class="calibre2">Now that we have the action space of the CARLA Gym environment defined, we can look at how to convert the continuous or discrete actions we have defined into values the CARLA simulation server will accept.</p>
<p class="calibre2">Since we have followed the same convention for two-dimensional bounded action values in both the continuous and discrete action spaces, we can simply convert the actions into steer, throttle, and brake commands using the following code snippet:</p>
<pre class="calibre17">throttle = float(np.clip(action[0], 0, 1)<br class="title-page-name"/>brake = float(np.abs(np.cllip(action[0], -1, 0)<br class="title-page-name"/>steer = float(p.clip(action[1], -1, 1)<br class="title-page-name"/>hand_brake = False<br class="title-page-name"/>reverse = False</pre>
<p class="calibre2">As you can see, this is where <kbd class="calibre12">action[0]</kbd> is for throttle and brake, and <kbd class="calibre12">action[1]</kbd> is for the steering angle.<span class="calibre5"> </span></p>
<p class="calibre2">We will make use of the <kbd class="calibre12">CarlaClient</kbd> class implementation in the CARLA <kbd class="calibre12">PythonClient</kbd> library to handle the communication with the CARLA server. You can look at the implementation of the <kbd class="calibre12">CarlaClient</kbd> class in <kbd class="calibre12">ch7/carla-gym/carla_gym/envs/carla/client.py</kbd>, if you want to understand how communication with the server is handled using protocol buffers.</p>
<p class="calibre2">To implement a reward function for the CARLA environment, input the following code:</p>
<pre class="calibre17">def calculate_reward(self, current_measurement):<br class="title-page-name"/>        """<br class="title-page-name"/>        Calculate the reward based on the effect of the action taken using the previous and the current measurements<br class="title-page-name"/>        :param current_measurement: The measurement obtained from the Carla engine after executing the current action<br class="title-page-name"/>        :return: The scalar reward<br class="title-page-name"/>        """<br class="title-page-name"/>        reward = 0.0<br class="title-page-name"/><br class="title-page-name"/>        cur_dist = current_measurement["distance_to_goal"]<br class="title-page-name"/><br class="title-page-name"/>        prev_dist = self.prev_measurement["distance_to_goal"]<br class="title-page-name"/><br class="title-page-name"/>        if env.config["verbose"]:<br class="title-page-name"/>            print("Cur dist {}, prev dist {}".format(cur_dist, prev_dist))<br class="title-page-name"/><br class="title-page-name"/>        # Distance travelled toward the goal in m<br class="title-page-name"/>        reward += np.clip(prev_dist - cur_dist, -10.0, 10.0)<br class="title-page-name"/><br class="title-page-name"/>        # Change in speed (km/hr)<br class="title-page-name"/>        reward += 0.05 * (current_measurement["forward_speed"] - self.prev_measurement["forward_speed"])<br class="title-page-name"/><br class="title-page-name"/>        # New collision damage<br class="title-page-name"/>        reward -= .00002 * (<br class="title-page-name"/>            current_measurement["collision_vehicles"] + current_measurement["collision_pedestrians"] +<br class="title-page-name"/>            current_measurement["collision_other"] - self.prev_measurement["collision_vehicles"] -<br class="title-page-name"/>            self.prev_measurement["collision_pedestrians"] - self.prev_measurement["collision_other"])<br class="title-page-name"/><br class="title-page-name"/>        # New sidewalk intersection<br class="title-page-name"/>        reward -= 2 * (<br class="title-page-name"/>            current_measurement["intersection_offroad"] - self.prev_measurement["intersection_offroad"])<br class="title-page-name"/><br class="title-page-name"/>        # New opposite lane intersection<br class="title-page-name"/>        reward -= 2 * (<br class="title-page-name"/>            current_measurement["intersection_otherlane"] - self.prev_measurement["intersection_otherlane"])<br class="title-page-name"/><br class="title-page-name"/>        return reward</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Determining the end of episodes in the CARLA environment</h1>
                
            
            <article>
                
<p class="calibre2">We have implemented <kbd class="calibre12">meta hod</kbd> to calculate the reward and defined the permitted actions, observations, and the reset method for the custom CARLA environment. According to our custom Gym environment creation template, those are the required methods we need to implement for creating a custom environment that is compatible with the OpenAI Gym interface.</p>
<p class="calibre2">While this is true, there is one more thing we need to take care of so that the agent can interact with our environment continuously. Remember when we were developing our Q-learning agent in <a href="part0078.html#2ACBS0-22c7fc7f93b64d07be225c00ead6ce12" class="calibre9">Chapter 5</a>, <em class="calibre13">Implementing your First Learning Agent – Solving the Mountain Car problem</em>, for the mountain car environment, the environment that always resets itself after 200 steps? Or in the cart pole environment, where the environment resets itself if the pole falls below a certain threshold value? Or how about in Atari games, where the environment is reset automatically if an agent loses their final life? Yes, we need to look at the routine that determines when to reset the environment, which is currently missing in our custom CARLA Gym environment implementation. </p>
<p class="calibre2">While we could pick any criteria to reset the CARLA Gym environment, there are three things to consider, as follows:</p>
<ul class="calibre10">
<li class="calibre11">When the host or ego car the agent is controlling collides with a car, pedestrian, building, or other roadside object, that can be fatal (similar to losing a life in Atari games)</li>
<li class="calibre11">When the host or ego car reaches its destination or end goal</li>
<li class="calibre11">When a time limit has been exceeded (similar to the 200 time step limit we have in the mountain car Gym environment)</li>
</ul>
<p class="calibre2">We can use these conditions to form the criteria that will determine the end of an episode. The pseudo-code to determine the value of the <kbd class="calibre12">done</kbd> variable that <kbd class="calibre12">.step(...)</kbd> will return is as follows (note that the complete code can be found in the book's code repository in <kbd class="calibre12">ch7/carla-gym/carla_gym/envs/</kbd>):</p>
<pre class="calibre17"># 1. Check if a collision has occured<br class="title-page-name"/>m = measurements_from_carla_server<br class="title-page-name"/>collided = m["collision_vehicles"] &gt; 0 or m["collision_pedestrians"] &gt; 0 or m["collision_other"] &gt; 0<br class="title-page-name"/><br class="title-page-name"/># 2. Check if the ego/host car has reached the destination/goal<br class="title-page-name"/>planner = carla_planner<br class="title-page-name"/>goal_reached = planner["next_command"] == "REACHED_GOAL"<br class="title-page-name"/><br class="title-page-name"/># 3. Check if the time-limit has been exceeded<br class="title-page-name"/>time_limit = scenario_max_steps_config<br class="title-page-name"/>time_limit_exceeded = num_steps &gt; time_limit<br class="title-page-name"/><br class="title-page-name"/># Set "done" to True if either of the above 3 criteria becomes true<br class="title-page-name"/>done = collided or goal_reached or time_limit_exceeded</pre>
<p class="calibre2">We have now gone through all the required components for creating our own custom Gym-compatible environment based on the CARLA driving simulator! In the next section, we will test the environment and finally see it in action.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Testing the CARLA Gym environment</h1>
                
            
            <article>
                
<p class="calibre2">To make it easy to test the basics of our environment implementation, we will implement a simple <kbd class="calibre12">main()</kbd> routine so we can run the environment as a script. This will show us if the basic interfaces have been set up correctly, as well as how the environment actually looks!</p>
<p class="calibre2">The main routine of the <kbd class="calibre12">carla_env.py</kbd> file is shown in the following snippet. This file creates an instance of the default <kbd class="calibre12">CarlaEnv</kbd> and runs five episodes with a fixed action of going forward. The <kbd class="calibre12">ENV_CONFIG</kbd> action, which we created during initialization, can be changed to use discrete or continuous action spaces, as follows:</p>
<pre class="calibre17"># Part of <a href="https://github.com/PacktPublishing/Hands-On-Intelligent-Agents-with-OpenAI-Gym/tree/master/ch6" class="calibre80">https://github.com/PacktPublishing/Hands-On-Intelligent-Agents-with-OpenAI-Gym/ch7/carla-gym/carla_gym/envs/carla_env.py</a><br class="title-page-name"/>if __name__ == "__main__":<br class="title-page-name"/>    for _ in range(5):<br class="title-page-name"/>        env = CarlaEnv()<br class="title-page-name"/>        obs = env.reset()<br class="title-page-name"/>        done = False<br class="title-page-name"/>        t = 0<br class="title-page-name"/>        total_reward = 0.0<br class="title-page-name"/>        while not done:<br class="title-page-name"/>            t += 1<br class="title-page-name"/>            if ENV_CONFIG["discrete_actions"]:<br class="title-page-name"/>                obs, reward, done, info = env.step(3) # Go Forward<br class="title-page-name"/>            else:<br class="title-page-name"/>                obs, reward, done, info = env.step([1.0, 0.0]) # Full throttle, zero steering angle<br class="title-page-name"/>            total_reward += reward<br class="title-page-name"/>            print("step#:", t, "reward:", round(reward, 4), "total_reward:", round(total_reward, 4), "done:", done)</pre>
<p class="calibre2">Now, go ahead and test the environment we just created! Keep in mind that CARLA requires a GPU to run smoothly, and the system environment <kbd class="calibre12">CARLA_SERVER</kbd> variable to be defined and pointing to the <kbd class="calibre12">CarlaUE4.sh</kbd> file on your system. Once you are ready, you can test the environment we created by running the following command inside the <kbd class="calibre12">rl_gym_book</kbd> conda environment:</p>
<pre class="calibre17"><strong class="calibre1">(rl_gym_book) praveen@ubuntu:~/rl_gym_book/ch7$ python carla-gym/carla_gym/envs/carla_env.py</strong></pre>
<p class="calibre2">The previous command should open a small CARLA simulator window and initialize the vehicle for the scenario configuration used in the <kbd class="calibre12">carla_env.py</kbd> script. This should look similar to the following screenshots:</p>
<div class="cdpaligncenter"><img src="../images/00154.jpeg" class="calibre81"/>  <img src="../images/00155.jpeg" class="calibre82"/></div>
<p class="calibre2">As you can see, by default, the vehicle is scripted to drive straight. Note that the <kbd class="calibre12">carla_env.py</kbd> script will also produce a console output to show the current time step in the environment, the calculated instantaneous reward, the total reward in the episode, and the value of <kbd class="calibre12">done</kbd> (True or False),  which is all useful for testing our environment. As the vehicle starts moving forward, you should see the reward value increasing!</p>
<p class="calibre2">The console output is as follows:</p>
<p class="cdpaligncenter4"><img src="../images/00156.jpeg" class="calibre83"/></p>
<p class="calibre2">So, you now have your custom CARLA Gym environment working! You can create several different driving scenarios using the definitions in the <kbd class="calibre12">ch7/carla-gym/carla_gym/envs/scenarios.json</kbd> file. You can then create new custom CARLA environments for each of those scenarios, which you can use with the usual <kbd class="calibre12">gym.make(...)</kbd> command after you have registered the custom environment, for example, <kbd class="calibre12">gym.make("Carla-v0")</kbd> .</p>
<p class="calibre2">The code in the book's code repository takes care of the environment registration with the OpenAI Gym registry using the method we discussed earlier in this chapter. You can now use OpenAI Gym to create an instance of the custom environment we built.</p>
<p class="calibre2">The following screenshot shows the Python commands you can use to test the custom Gym environment:</p>
<p class="cdpaligncenter4"><img src="../images/00157.jpeg" class="calibre84"/></p>
<p class="calibre2">And that's it! The rest is similar to any other Gym environment.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Summary</h1>
                
            
            <article>
                
<p class="calibre2">In this chapter, we went through a custom Gym environment implementation step-by-step, starting with a template that laid out the bare-bones structure of an OpenAI Gym environment that provided all of the necessary interfaces to the agents. We also looked at how to register a custom environment implementation in the Gym registry so that we can use the familiar <kbd class="calibre12">gym.make(ENV_NAME)</kbd> command to create an instance of an existing environment. We then looked at how to create a Gym-compatible environment implementation for the UnrealEngine based on the open-source driving simulator, CARLA. We then quickly walked through the steps required to install and run CARLA and then started implementing the <kbd class="calibre12">CarlaEnv</kbd> class piece-by-piece, carefully covering all the important details involved in implementing custom environments compatible with OpenAI Gym.</p>
<p class="calibre2"><span class="calibre5">In the next chapter, we will build an advanced agent from the ground up with hands-on examples, before eventually using the custom CARLA environment we created in this chapter to train an intelligent agent that can learn to drive the car around all by itself!</span></p>


            </article>

            
        </section>
    </body></html>