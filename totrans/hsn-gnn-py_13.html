<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer632">
<h1 class="chapter-number" id="_idParaDest-149"><a id="_idTextAnchor153"/>13</h1>
<h1 id="_idParaDest-150"><a id="_idTextAnchor154"/>Temporal Graph Neural Networks</h1>
<p>In the previous chapters, we have only considered graphs where edges and features do not change. However, in the real world, there are many applications where this is not the case. For instance, in social networks, people follow and unfollow other users, posts go viral, and profiles evolve over time. This dynamicity cannot be represented using the GNN architectures we previously described. Instead, we must embed a new temporal dimension to transform static graphs into dynamic ones. These dynamic networks will then<a id="_idIndexMarker748"/> be used as<a id="_idIndexMarker749"/> inputs for a new family of GNNs: <strong class="bold">Temporal Graph Neural Networks</strong> (<strong class="bold">T-GNNs</strong>), also called <span class="No-Break"><strong class="bold">Spatio-Temporal GNNs</strong></span><span class="No-Break">.</span></p>
<p>In this chapter, we will describe two kinds of <strong class="bold">dynamic graphs</strong> that include spatiotemporal information. We will list different applications and focus on time series forecasting, where temporal GNNs are mainly applied. The second section is dedicated to an application we previously looked at: web traffic forecasting. This time, we will exploit temporal information to improve our results and obtain reliable predictions. Finally, we will describe another temporal GNN architecture designed for dynamic graphs. We will apply it to epidemic forecasting to predict the number of cases of COVID-19 in different regions <span class="No-Break">of England.</span></p>
<p>By the end of this chapter, you will know the difference between the two main types of dynamic graphs. This is particularly useful for modeling your data into the right kind of graph. Moreover, you will learn about the design and architecture of two temporal GNNs and how to implement them using PyTorch Geometric Temporal. This is an essential step to creating your own applications with <span class="No-Break">temporal information.</span></p>
<p>In this chapter, we will cover the following <span class="No-Break">main topics:</span></p>
<ul>
<li>Introducing <span class="No-Break">dynamic graphs</span></li>
<li>Forecasting <span class="No-Break">web traffic</span></li>
<li>Predicting cases <span class="No-Break">of COVID-19</span></li>
</ul>
<h1 id="_idParaDest-151"><a id="_idTextAnchor155"/>Technical requirements</h1>
<p>All the code examples from this chapter can be found on GitHub <span class="No-Break">at </span><a href="https://github.com/PacktPublishing/Hands-On-Graph-Neural-Networks-Using-Python/tree/main/Chapter13"><span class="No-Break">https://github.com/PacktPublishing/Hands-On-Graph-Neural-Networks-Using-Python/tree/main/Chapter13</span></a><span class="No-Break">.</span></p>
<p>Installation steps required to run the code on your local machine can be found in the <em class="italic">Preface</em> of <span class="No-Break">this book.</span></p>
<h1 id="_idParaDest-152"><a id="_idTextAnchor156"/>Introducing dynamic graphs</h1>
<p>Dynamic graphs and temporal GNNs unlock a variety of new applications, such as transport and web traffic forecasting, motion classification, epidemiological forecasting, link prediction, power<a id="_idIndexMarker750"/> system forecasting, and so on. Time series forecasting is particularly popular with this kind of graph, as we can use historical data to predict the system’s <span class="No-Break">future behavior.</span></p>
<p>In this chapter, we focus on graphs with a temporal component. They can be divided into <span class="No-Break">two categories:</span></p>
<ul>
<li><strong class="bold">Static graphs with temporal signals</strong>: The underlying graph does not change, but features and<a id="_idIndexMarker751"/> labels evolve <span class="No-Break">over time.</span></li>
<li><strong class="bold">Dynamic graphs with temporal signals</strong>: The topology of the graph (the presence of <a id="_idIndexMarker752"/>nodes and edges), features, and labels evolve <span class="No-Break">over time.</span></li>
</ul>
<p>In the first case, the graph’s topology is <em class="italic">static</em>. For example, it can represent a network of cities within a country for traffic forecasting: features change over time, but the connections stay <span class="No-Break">the same.</span></p>
<p>In the second option, nodes and/or connections are <em class="italic">dynamic</em>. It is useful to represent a social network where links between users can appear or disappear over time. This variant is more general, but also harder to learn how <span class="No-Break">to implement.</span></p>
<p>In the following sections, we will see how to handle these two types of graphs with temporal signals using PyTorch <span class="No-Break">Geometric Temporal.</span></p>
<h1 id="_idParaDest-153"><a id="_idTextAnchor157"/>Forecasting web traffic</h1>
<p>In this section, we will predict<a id="_idIndexMarker753"/> the traffic of Wikipedia articles (as an example of a static graph with a temporal signal) using a temporal GNN. This regression task has already been covered in <a href="B19153_06.xhtml#_idTextAnchor074"><span class="No-Break"><em class="italic">Chapter 6</em></span></a>, <em class="italic">Introducing Graph Convolutional Networks</em>. However, in that version of the task, we performed traffic forecasting using a static dataset without a temporal signal: our model did not have any information about previous instances. This is an issue because it could not understand whether the traffic was currently increasing or decreasing, for example. We can now improve this model to include information about <span class="No-Break">past instances.</span></p>
<p>We will first introduce the temporal GNN architecture with its two variants and then implement it using PyTorch <span class="No-Break">Geometric Temporal.</span></p>
<h2 id="_idParaDest-154"><a id="_idTextAnchor158"/>Introducing EvolveGCN</h2>
<p>For this task, we will use the <strong class="bold">EvolveGCN</strong> architecture. Introduced by Pareja et al. [1] in 2019, it proposes a<a id="_idIndexMarker754"/> natural combination of GNNs and <strong class="bold">Recurrent Neural Networks</strong> (<strong class="bold">RNNs</strong>). Previous approaches, such <a id="_idIndexMarker755"/>as graph convolutional recurrent networks, applied RNNs with graph convolution operators to calculate node embeddings. By contrast, EvolveGCN applies RNNs to the GCN <a id="_idIndexMarker756"/>parameters themselves. As the name implies, the GCN evolves over time to produce relevant temporal node embeddings. The following figure illustrates a high-level view of <span class="No-Break">this process.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer589">
<img alt="Figure 13.1 – The EvolveGCN’s architecture to produce node embeddings for a static or dynamic graph with temporal signal" height="629" src="image/B19153_13_001.jpg" width="1352"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.1 – The EvolveGCN’s architecture to produce node embeddings for a static or dynamic graph with temporal signal</p>
<p>This architecture has <span class="No-Break">two variants:</span></p>
<ul>
<li><strong class="bold">EvolveGCN-H</strong>, where the recurrent neural<a id="_idIndexMarker757"/> network considers both the previous GCN parameters and the current <span class="No-Break">node embeddings</span></li>
<li><strong class="bold">EvolveGCN-O</strong>, where the recurrent <a id="_idIndexMarker758"/>neural network only considers the previous <span class="No-Break">GCN parameters</span></li>
</ul>
<p>EvolveGCN-H typically uses a <strong class="bold">Gated Recurrent Unit</strong> (<strong class="bold">GRU</strong>) instead of a vanilla RNN. The GRU is a <a id="_idIndexMarker759"/>streamlined version of the <strong class="bold">Long Short-Term Memory</strong> (<strong class="bold">LSTM</strong>) unit that achieves <a id="_idIndexMarker760"/>comparable performance with fewer parameters. It is comprised of a reset gate, an update gate, and a<a id="_idIndexMarker761"/> cell state. In this architecture, GRU updates the GCN’s weight matrix for layer <img alt="" height="40" src="image/Formula_B19153_13_001.png" width="21"/> at time <img alt="" height="31" src="image/Formula_B19153_13_002.png" width="19"/> <span class="No-Break">as follows:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer592">
<img alt="" height="67" src="image/Formula_B19153_13_003.jpg" width="426"/>
</div>
</div>
<p><img alt="" height="55" src="image/Formula_B19153_13_004.png" width="63"/> denotes the node embeddings produced at layer <img alt="" height="35" src="image/Formula_B19153_13_008.png" width="14"/> and time <img alt="" height="31" src="image/Formula_B19153_13_006.png" width="19"/>, and <img alt="" height="62" src="image/Formula_B19153_13_007.png" width="85"/> is the weight matrix for layer <img alt="" height="36" src="image/Formula_B19153_13_0081.png" width="15"/> from the previous <span class="No-Break">time step.</span></p>
<p>This resulting GCN weight matrix is then<a id="_idIndexMarker762"/> used to calculate the next layer’s <span class="No-Break">node embeddings:</span></p>
<p class="IMG---Figure"> <img alt="" height="75" src="image/Formula_B19153_13_009.png" width="549"/></p>
<p class="IMG---Figure"><img alt="" height="94" src="image/Formula_B19153_13_010.png" width="573"/></p>
<p>Here, <img alt="" height="38" src="image/Formula_B19153_13_011.png" width="29"/> is the<a id="_idIndexMarker763"/> adjacency matrix, including self-loops, and <img alt="" height="38" src="image/Formula_B19153_13_012.png" width="36"/> is the degree matrix <span class="No-Break">with self-loops.</span></p>
<p>These steps are summarized in the <span class="No-Break">following figure.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer602">
<img alt="Figure 13.2 – The EvolveGCN-H’s architecture with GRU and GNN" height="493" src="image/B19153_13_002.jpg" width="1554"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.2 – The EvolveGCN-H’s architecture with GRU and GNN</p>
<p>EvolveGCN-H can be implemented with a GRU that receives <span class="No-Break">two extensions:</span></p>
<ul>
<li>The inputs and hidden states are matrices instead of vectors to store the GCN weight <span class="No-Break">matrices properly</span></li>
<li>The column dimension of the input must match that of the hidden state, which requires summarizing the node embedding matrix <img alt="" height="68" src="image/Formula_B19153_13_013.png" width="77"/> to only keep the appropriate number <span class="No-Break">of columns</span></li>
</ul>
<p>These extensions are not<a id="_idIndexMarker764"/> required for the EvolveGCN-O variant. Indeed, EvolveGCN-O is based on an LSTM network to model the input-output relationship. We do not need to feed a hidden state to the<a id="_idIndexMarker765"/> LSTM, as it already includes a cell that remembers previous values. This mechanism simplifies the update step, which can be written <span class="No-Break">as follows:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer604">
<img alt="" height="63" src="image/Formula_B19153_13_014.jpg" width="371"/>
</div>
</div>
<p>The resulting GCN weight matrix is used in the same way to produce the next layer’s <span class="No-Break">node embeddings:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer605">
<img alt="" height="77" src="image/Formula_B19153_13_015.jpg" width="598"/>
</div>
</div>
<div>
<div class="IMG---Figure" id="_idContainer606">
<img alt="" height="100" src="image/Formula_B19153_13_016.jpg" width="610"/>
</div>
</div>
<p>This implementation is simpler since the temporal dimension entirely relies on a vanilla LSTM network. The following figure shows how EvolveGCN-O updates the weight matrix <img alt="" height="61" src="image/Formula_B19153_13_017.png" width="85"/> and calculates node <span class="No-Break">embeddings <img alt="" height="58" src="image/Formula_B19153_13_018.png" width="104"/>:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer609">
<img alt="Figure 13.3 – EvolveGCN-O’s architecture with LSTM and GCN" height="511" src="image/B19153_13_003.jpg" width="1603"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.3 – EvolveGCN-O’s architecture with LSTM and GCN</p>
<p>So which version <a id="_idIndexMarker766"/>should we use? As is often the case in machine learning, the best solution <span class="No-Break">is data-dependent:</span></p>
<ul>
<li>EvolveGCN-H works better when the node features are essential because its RNN explicitly<a id="_idIndexMarker767"/> incorporates <span class="No-Break">node embeddings</span></li>
<li>EvolveGCN-O works better when the graph structure plays an important role, as it focuses more on <span class="No-Break">topological changes</span></li>
</ul>
<p>Note that these remarks are primarily theoretical, which is why it can be helpful to test both variants in your applications. This is what we will do by implementing these models for web <span class="No-Break">traffic forecasting.</span></p>
<h2 id="_idParaDest-155"><a id="_idTextAnchor159"/>Implementing EvolveGCN</h2>
<p>In this section, we want to forecast <a id="_idIndexMarker768"/>web traffic on a static graph with a <a id="_idIndexMarker769"/>temporal signal. The <strong class="bold">WikiMaths</strong> dataset is comprised of 1,068 articles represented as nodes. Node features correspond to the past daily number of visits (eight features by default). Edges are weighted, and weights represent the number of links from the source page to the destination page. We want to predict the daily user visits to these Wikipedia pages between March 16, 2019, and March 15, 2021, which results in 731 snapshots. Each snapshot is a graph describing the state of the system at a <span class="No-Break">certain time.</span></p>
<p><span class="No-Break"><em class="italic">Figure 13</em></span><em class="italic">.4</em> shows a representation of WikiMaths made with Gephi, where the size and color of the nodes are proportional to their number <span class="No-Break">of connections.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer610">
<img alt="Figure 13.4 – WikiMaths dataset as an unweighted graph (t=0)" height="942" src="image/B19153_13_004.jpg" width="864"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.4 – WikiMaths dataset as an unweighted graph (t=0)</p>
<p>PyTorch Geometric does not natively support static or dynamic graphs with a temporal signal. Fortunately, an extension <a id="_idIndexMarker770"/>called PyTorch Geometric Temporal [2] fixes this issue and even implements various temporal GNN layers. The WikiMaths dataset was also made public during the development of PyTorch Geometric Temporal. In this chapter, we will use this library to simplify the code and focus <span class="No-Break">on applications:</span></p>
<ol>
<li>We need to install this library in an environment containing <span class="No-Break">PyTorch Geometric:</span><pre class="source-code">
pip install torch-geometric-temporal==0.54.0</pre></li>
<li>We import the WikiMaths dataset, called <strong class="source-inline">WikiMathDatasetLoader</strong>, a temporal-aware train-test split with <strong class="source-inline">temporal_signal_split</strong>, and our GNN <span class="No-Break">layer, </span><span class="No-Break"><strong class="source-inline">EvolveGCNH</strong></span><span class="No-Break">:</span><pre class="source-code">
from torch_geometric_temporal.signal import temporal_signal_split
from torch_geometric_temporal.dataset import WikiMathsDatasetLoader
from torch_geometric_temporal.nn.recurrent import EvolveGCNH</pre></li>
<li>We load the WikiMaths dataset, which is a <strong class="source-inline">StaticGraphTemporalSignal</strong> object. In this object, <strong class="source-inline">dataset[0]</strong> describes the graph (also called a snapshot in this context) at <img alt="" height="30" src="image/Formula_B19153_13_019.png" width="90"/> and <strong class="source-inline">dataset[500]</strong> at <img alt="" height="30" src="image/Formula_B19153_13_020.png" width="126"/>. We also create a train-test split with<a id="_idIndexMarker771"/> a ratio of <strong class="source-inline">0.5</strong>. The training set is composed of snapshots from the earlier time periods, while the test set regroups snapshots from the <span class="No-Break">later periods:</span><pre class="source-code">
dataset = WikiMathsDatasetLoader().get_dataset() train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)
dataset[0]
Data(x=[1068, 8], edge_index=[2, 27079], edge_attr=[27079], y=[1068])
dataset[500]
Data(x=[1068, 8], edge_index=[2, 27079], edge_attr=[27079], y=[1068])</pre></li>
<li>The graph is static, so the node and edge dimensions do not change. However, the values contained in these tensors are different. It is difficult to visualize the values of each of the 1,068 nodes. To better understand this dataset, we can calculate the mean and standard deviation values for each snapshot instead. The moving average is also helpful in smoothing out <span class="No-Break">short-term fluctuations.</span><pre class="source-code">
import pandas as pd
mean_cases = [snapshot.y.mean().item() for snapshot in dataset]
std_cases = [snapshot.y.std().item() for snapshot in dataset]
df = pd.DataFrame(mean_cases, columns=['mean'])
df['std'] = pd.DataFrame(std_cases, columns=['std'])
df['rolling'] = df['mean'].rolling(7).mean()</pre></li>
<li>We plot these<a id="_idIndexMarker772"/> time series with <strong class="source-inline">matplotlib</strong> to visualize <span class="No-Break">our task:</span><pre class="source-code">
plt.figure(figsize=(15,5))
plt.plot(df['mean'], 'k-', label='Mean')
plt.plot(df['rolling'], 'g-', label='Moving average')
plt.grid(linestyle=':')
plt.fill_between(df.index, df['mean']-df['std'], df['mean']+df['std'], color='r', alpha=0.1)
plt.axvline(x=360, color='b', linestyle='--')
plt.text(360, 1.5, 'Train/test split', rotation=-90, color='b')
plt.xlabel('Time (days)')
plt.ylabel('Normalized number of visits')
plt.legend(loc='upper right')</pre></li>
</ol>
<p>This produces <span class="No-Break"><em class="italic">Figure 13</em></span><span class="No-Break"><em class="italic">.5</em></span><span class="No-Break">.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer613">
<img alt="Figure 13.5 – WikiMaths’ mean normalized number of visits with moving average" height="810" src="image/B19153_13_005.jpg" width="1554"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.5 – WikiMaths’ mean normalized number of visits with moving average</p>
<p>Our data presents periodic patterns that the temporal GNN can hopefully learn. We can now implement it and see how <span class="No-Break">it performs.</span></p>
<ol>
<li value="6">The temporal GNN takes<a id="_idIndexMarker773"/> two parameters as inputs: the number of nodes (<strong class="source-inline">node_count</strong>) and the input dimension (<strong class="source-inline">dim_in</strong>). The GNN only has two layers: an EvolveGCN-H layer and a linear layer that outputs a predicted value for <span class="No-Break">each node:</span><pre class="source-code">
class TemporalGNN(torch.nn.Module):
    def __init__(self, node_count, dim_in):
        super().__init__()
        self.recurrent = EvolveGCNH(node_count, dim_in)
        self.linear = torch.nn.Linear(dim_in, 1)</pre></li>
<li>The <strong class="source-inline">forward()</strong> function applies both layers to the input with a ReLU <span class="No-Break">activation function:</span><pre class="source-code">
    def forward(self, x, edge_index, edge_weight):
        h = self.recurrent(x, edge_index, edge_weight).relu()
        h = self.linear(h)
        return h</pre></li>
<li>We create an instance of <strong class="source-inline">TemporalGNN</strong> and give it the number of nodes and input dimension from<a id="_idIndexMarker774"/> the WikiMaths dataset. We will train it using the <span class="No-Break"><strong class="source-inline">Adam</strong></span><span class="No-Break"> optimizer:</span><pre class="source-code">
model = TemporalGNN(dataset[0].x.shape[0], dataset[0].x.shape[1])
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
model.train()</pre></li>
<li>We can print the model to observe the layers contained <span class="No-Break">in </span><span class="No-Break"><strong class="source-inline">EvolveGCNH</strong></span><span class="No-Break">:</span><pre class="source-code">
model
TemporalGNN(
  (recurrent): EvolveGCNH(
    (pooling_layer): TopKPooling(8, ratio=0.00749063670411985, multiplier=1.0)
    (recurrent_layer): GRU(8, 8)
    (conv_layer): GCNConv_Fixed_W(8, 8)
  )
  (linear): Linear(in_features=8, out_features=1, bias=True)
)</pre></li>
</ol>
<p>We see three layers: <strong class="source-inline">TopKPooling</strong>, which summarizes the input matrix in eight columns; <strong class="source-inline">GRU</strong>, which updates the GCN weight matrix; and <strong class="source-inline">GCNConv</strong>, which produces the new node embedding. Finally, a linear layer outputs a predicted value for every node in <span class="No-Break">the graph.</span></p>
<ol>
<li value="10">We create a training loop that trains the model on every snapshot from the training set. The loss is backpropagated for <span class="No-Break">every snapshot:</span><pre class="source-code">
for epoch in range(50):
    for i, snapshot in enumerate(train_dataset):
        y_pred = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)
        loss = torch.mean((y_pred-snapshot.y)**2)
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()</pre></li>
<li>Likewise, we evaluate the <a id="_idIndexMarker775"/>model on the test set. The MSE is averaged on the entire test set to produce the <span class="No-Break">final score:</span><pre class="source-code">
model.eval()
loss = 0
for i, snapshot in enumerate(test_dataset):
    y_pred = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)
    mse = torch.mean((y_pred-snapshot.y)**2)
    loss += mse
loss = loss / (i+1)
print(f'MSE = {loss.item():.4f}')
MSE = 0.7559</pre></li>
<li>We obtain a loss value of 0.7559. Next, we will plot the mean values predicted by our model on the previous graph to interpret it. The process is straightforward: we must average the predictions and store them in a list. Then, we can add them to the <span class="No-Break">previous plot:</span><pre class="source-code">
 y_preds = [model(snapshot.x, snapshot.edge_index, snapshot.edge_attr).squeeze().detach().numpy().mean() for snapshot in test_dataset]
plt.figure(figsize=(10,5))
plt.plot(df['mean'], 'k-', label='Mean')
plt.plot(df['rolling'], 'g-', label='Moving average')
plt.plot(range(360,722), y_preds, 'r-', label='Prediction')
plt.grid(linestyle=':')
plt.fill_between(df.index, df['mean']-df['std'], df['mean']+df['std'], color='r', alpha=0.1)
plt.axvline(x=360, color='b', linestyle='--')
plt.text(360, 1.5, 'Train/test split', rotation=-90, color='b')
plt.xlabel('Time (days)')
plt.ylabel('Normalized number of visits')
plt.legend(loc='upper right')</pre></li>
</ol>
<p>That<a id="_idIndexMarker776"/> gives us <span class="No-Break"><em class="italic">Figure 13</em></span><span class="No-Break"><em class="italic">.6</em></span><span class="No-Break">.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer614">
<img alt="Figure 13.6 – Predicted mean normalized number of visits" height="859" src="image/B19153_13_006.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.6 – Predicted mean normalized number of visits</p>
<p>We can see that the predicted values follow the general trend in the data. This is an excellent result, considering the limited size of <span class="No-Break">the dataset.</span></p>
<ol>
<li value="13">Finally, let’s create a<a id="_idIndexMarker777"/> scatter plot to show how predicted and ground truth values differ for a <span class="No-Break">single snapshot:</span><pre class="source-code">
import seaborn as sns
y_pred = model(test_dataset[0].x, test_dataset[0].edge_index, test_dataset[0].edge_attr).detach().squeeze().numpy()
plt.figure(figsize=(10,5))
sns.regplot(x=test_dataset[0].y.numpy(), y=y_pred)</pre></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer615">
<img alt="Figure 13.7 – Predicted versus ground truth values for the WikiMaths dataset" height="804" src="image/B19153_13_007.jpg" width="1617"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.7 – Predicted versus ground truth values for the WikiMaths dataset</p>
<p>We observe a moderate positive correlation between predicted and real values. Our model is not remarkably accurate, but the previous figure showed that it understands the periodic nature of the data<a id="_idIndexMarker778"/> <span class="No-Break">very well.</span></p>
<p>Implementing the EvolveGCN-O variant is very similar. Instead of using the <strong class="source-inline">EvolveGCNH</strong> layer from PyTorch Geometric Temporal, we replace it with <strong class="source-inline">EvolveGCNO</strong>. This layer does not require the number of nodes, so we only give it the input dimension. It is implemented <span class="No-Break">as follows:</span></p>
<pre class="source-code">
from torch_geometric_temporal.nn.recurrent import EvolveGCNO
class TemporalGNN(torch.nn.Module):
    def __init__(self, dim_in):
        super().__init__()
        self.recurrent = EvolveGCNO(dim_in, 1)
        self.linear = torch.nn.Linear(dim_in, 1)
    def forward(self, x, edge_index, edge_weight):
        h = self.recurrent(x, edge_index, edge_weight).relu()
        h = self.linear(h)
        return h
model = TemporalGNN(dataset[0].x.shape[1])</pre>
<p>On average, the EvolveGCN-O model obtains similar results with an average MSE of 0.7524. In this case, the use of a GRU or LSTM network does not impact the predictions. This is understandable since both the past numbers of visits contained in node features (EvolveGCN-H) and the connections between pages (EvolveGCN-O) are essential. As a result, this GNN architecture is <a id="_idIndexMarker779"/>particularly well-suited to this traffic <span class="No-Break">forecasting task.</span></p>
<p>Now that we have seen an example of a static graph, let’s explore how to process <span class="No-Break">dynamic graphs.</span></p>
<h1 id="_idParaDest-156"><a id="_idTextAnchor160"/>Predicting cases of COVID-19</h1>
<p>This section will focus on a new application <a id="_idIndexMarker780"/>with epidemic forecasting. We will use the <strong class="bold">England Covid dataset</strong>, a dynamic graph with temporal information introduced by Panagopoulos et al. in 2021 [3]. While nodes are static, connections between and edge weights vary over time. This dataset<a id="_idIndexMarker781"/> represents the number of reported cases of COVID-19 in 129 England NUTS 3 regions between March 3 and May 12, 2020. Data was collected from mobile phones that installed the Facebook application and shared their location history. Our goal is to predict the number of cases in each node (region) in <span class="No-Break">1 day.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer616">
<img alt="Figure 13.8 – NUTS 3 areas in England are colored in red" height="1013" src="image/B19153_13_008.jpg" width="849"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.8 – NUTS 3 areas in England are colored in red</p>
<p>This dataset represents England as a graph <img alt="" height="40" src="image/Formula_B19153_13_021.png" width="178"/>. Due to the temporal nature of this dataset, it is composed of <a id="_idIndexMarker782"/>multiple graphs corresponding to each day of the studied period <img alt="" height="47" src="image/Formula_B19153_13_022.png" width="206"/>. In these graphs, node features correspond to the number of cases in each of the past <img alt="" height="31" src="image/Formula_B19153_13_023.png" width="22"/> days in this region. Edges are unidirectional and weighted: the weight <img alt="" height="56" src="image/Formula_B19153_13_024.png" width="67"/> of edge <img alt="" height="39" src="image/Formula_B19153_13_025.png" width="89"/> represents the number of people that moved from region <img alt="" height="21" src="image/Formula_B19153_13_026.png" width="22"/> to region <img alt="" height="21" src="image/Formula_B19153_13_027.png" width="23"/> at time <img alt="" height="30" src="image/Formula_B19153_13_028.png" width="17"/>. These graphs also contain self-loops corresponding to people moving within the <span class="No-Break">same region.</span></p>
<p>This section will introduce<a id="_idIndexMarker783"/> a new GNN architecture designed for this task and show how to implement it step <span class="No-Break">by step.</span></p>
<h2 id="_idParaDest-157"><a id="_idTextAnchor161"/>Introducing MPNN-LSTM</h2>
<p>As its name suggests, <strong class="bold">MPNN-LSTM</strong> architecture relies on combining an MPNN and an LSTM network. Like the England Covid dataset, it was also introduced by Panagopoulos et al. in <span class="No-Break">2021 [3].</span></p>
<p>The input node features<a id="_idIndexMarker784"/> with the corresponding edge indexes<a id="_idIndexMarker785"/> and weights are fed to a GCN layer. We apply a batch normalization layer and a dropout to this output. This process is repeated a second time with the outcome of the first MPNN. It produces a node embedding matrix <img alt="" height="42" src="image/Formula_B19153_13_029.png" width="72"/>. We create a sequence <img alt="" height="47" src="image/Formula_B19153_13_030.png" width="212"/> of node embedding representations by applying these MPNNs for each time step. This sequence is fed to a 2-layer LSTM network to capture the temporal information from the graphs. Finally, we apply a linear transformation and a ReLU function to this output to produce a prediction <span class="No-Break">at </span><span class="No-Break"><img alt="" height="33" src="image/Formula_B19153_13_031.png" width="86"/>.</span></p>
<p>The following figure shows a high-level view of the <span class="No-Break">MPNN-LSTM’s architecture.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer628">
<img alt="Figure 13.9 – MPNN-LSTM’s architecture" height="561" src="image/B19153_13_009.jpg" width="1524"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.9 – MPNN-LSTM’s architecture</p>
<p>The authors of MPNN-LSTM note that it is not the<a id="_idIndexMarker786"/> best-performing model on the England Covid dataset (the MPNN with a two-level GNN is). However, it is an interesting approach that could perform better in other scenarios. They<a id="_idIndexMarker787"/> also state that it is more suited for long-term forecasting, such as 14 days in the future instead of a single day, as in our<a id="_idIndexMarker788"/> version of this dataset. Despite this issue, we use the latter for convenience, as it does not impact the design of <span class="No-Break">the solution.</span></p>
<h2 id="_idParaDest-158"><a id="_idTextAnchor162"/>Implementing MPNN-LSTM</h2>
<p>First, it is important to visualize<a id="_idIndexMarker789"/> the number of cases we want to predict. As in the previous section, we will summarize the 129 different time series that <a id="_idIndexMarker790"/>composed the dataset by calculating their mean and <span class="No-Break">standard deviation:</span></p>
<ol>
<li>We import <strong class="source-inline">pandas</strong>, <strong class="source-inline">matplotlib</strong>, the England Covid dataset, and the temporal train-test split function from PyTorch <span class="No-Break">Geometric Temporal:</span><pre class="source-code">
import pandas as pd
import matplotlib.pyplot as plt
from torch_geometric_temporal.dataset import EnglandCovidDatasetLoader
from torch_geometric_temporal.signal import temporal_signal_split</pre></li>
<li>We load the dataset with 14 lags, corresponding to the number of <span class="No-Break">node features:</span><pre class="source-code">
dataset = EnglandCovidDatasetLoader().get_dataset(lags=14)</pre></li>
<li>We perform a temporal <a id="_idIndexMarker791"/>signal split with a training<a id="_idIndexMarker792"/> ratio <span class="No-Break">of </span><span class="No-Break"><strong class="source-inline">0.8</strong></span><span class="No-Break">:</span><pre class="source-code">
train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)</pre></li>
<li>We plot the following graph to show the mean normalized number of reported cases (they are reported approximately every day). The code is available on GitHub and adapts the snippet we used in the <span class="No-Break">last section.</span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer629">
<img alt="Figure 13.10 – England Covid dataset’s mean normalized number of cases" height="848" src="image/B19153_13_010.jpg" width="1649"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.10 – England Covid dataset’s mean normalized number of cases</p>
<p>This plot shows a lot of volatility and a low number of snapshots. This is why we use an 80/20 train-test split in this example. Obtaining good performance on such a small dataset might be <span class="No-Break">challenging, nonetheless.</span></p>
<p>Let’s now implement the <span class="No-Break">MPNN-LSTM architecture.</span></p>
<ol>
<li>We import the <strong class="source-inline">MPNNLSTM</strong> layer from PyTorch <span class="No-Break">Geometric Temporal:</span><pre class="source-code">
From torch_geometric_temporal.nn.recurrent import MPNNLSTM</pre></li>
<li>The temporal GNN takes three parameters as inputs: the input dimension, the hidden dimension, and <a id="_idIndexMarker793"/>the number of nodes. We<a id="_idIndexMarker794"/> declare three layers: the MPNN-LSTM layer, a dropout layer, and a linear layer with the right <span class="No-Break">input dimension:</span><pre class="source-code">
Class TemporalGNN(torch.nn.Module):
    def __init__(self, dim_in, dim_h, num_nodes):
        super().__init__()
        self.recurrent = MPNNLSTM(dim_in, dim_h, num_nodes, 1, 0.5)
        self.dropout = torch.nn.Dropout(0.5)
        self.linear = torch.nn.Linear(2*dim_h + dim_in, 1)</pre></li>
<li>The <strong class="source-inline">forward()</strong> function considers the edge weights, an essential piece of information in this dataset. Note that we are processing a dynamic graph, so a new set of values for <strong class="source-inline">edge_index</strong> and <strong class="source-inline">edge_weight</strong> are provided at each time step. Unlike the original MPNN-LSTM described previously, we replace the final ReLU function with a <strong class="source-inline">tanh</strong> function. The main motivation is that tanh outputs values between -1 and 1, instead of 0 and 1, which is closer to what we observed in <span class="No-Break">the dataset:</span><pre class="source-code">
    Def forward(self, x, edge_index, edge_weight):
        h = self.recurrent(x, edge_index, edge_weight).relu()
        h = self.dropout(h)
        h = self.linear(h).tanh()
        return h</pre></li>
<li>We create our<a id="_idIndexMarker795"/> MPNN-LSTM model with a hidden dimension of 64 and print it to observe the <span class="No-Break">different </span><span class="No-Break"><a id="_idIndexMarker796"/></span><span class="No-Break">layers:</span><pre class="source-code">
model = TemporalGNN(dataset[0].x.shape[1], 64, dataset[0].x.shape[0])
print(model)
TemporalGNN(
  (recurrent): MPNNLSTM(
    (_convolution_1): GCNConv(14, 64)
    (_convolution_2): GCNConv(64, 64)
    (_batch_norm_1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (_batch_norm_2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (_recurrent_1): LSTM(128, 64)
    (_recurrent_2): LSTM(64, 64)
  )
  (dropout): Dropout(p=0.5, inplace=False)
  (linear): Linear(in_features=142, out_features=1, bias=True)
)</pre></li>
</ol>
<p>We see that the MPNN-LSTM layer contains two GCN, two batch normalization, and two LSTM layers (but no dropout), which corresponds to our <span class="No-Break">previous description.</span></p>
<ol>
<li value="5">We train this model for <strong class="source-inline">100</strong> epochs with the <strong class="source-inline">Adam</strong> optimizer and a learning rate of <strong class="source-inline">0.001</strong>. This time, we <a id="_idIndexMarker797"/>backpropagate the loss after every snapshot instead of <span class="No-Break">every instance:</span><pre class="source-code">
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
model.train()
for epoch in range(100):
    loss = 0
    for i, snapshot in enumerate(train_dataset):
        y_pred = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)
        loss = loss + torch.mean((y_pred-snapshot.y)**2)
    loss = loss / (i+1)
    loss.backward()
    optimizer.step()
    optimizer.zero_grad()</pre></li>
<li>We evaluate the <a id="_idIndexMarker798"/>trained model on the test set and obtain the following <span class="No-Break">MSE loss:</span><pre class="source-code">
model.eval()
loss = 0
for i, snapshot in enumerate(test_dataset):
    y_pred = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)
    mse = torch.mean((y_pred-snapshot.y)**2)
    loss += mse
loss = loss / (i+1)
print(f'MSE: {loss.item():.4f}')
MSE: 1.3722</pre></li>
</ol>
<p>The MPNN-LSTM model obtained an MSE loss of 1.3722, which seems <span class="No-Break">relatively high.</span></p>
<p>We cannot invert the <a id="_idIndexMarker799"/>normalization process that was applied to this dataset, so we will use the normalized numbers of cases instead. First, let’s plot the mean normalized number of cases that our model predicted (code available <span class="No-Break">on GitHub).</span></p>
<div>
<div class="IMG---Figure" id="_idContainer630">
<img alt="Figure 13.11 – Mean normalized number of cases with true values in black and predicted values in red" height="848" src="image/B19153_13_011.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.11 – Mean normalized number of cases with true values in black and predicted values in red</p>
<p>As expected, the predicted<a id="_idIndexMarker800"/> values do not match the ground truth very well. This is probably due to the lack of data: our model learned an average value that minimizes the MSE loss but cannot fit the curve and understand <span class="No-Break">its periodicity.</span></p>
<p>Let’s inspect the scatter plot corresponding to the test set’s first snapshot (code available <span class="No-Break">on GitHub).</span></p>
<div>
<div class="IMG---Figure" id="_idContainer631">
<img alt="Figure 13.12 – Predicted versus ground truth values for the England Covid dataset" height="840" src="image/B19153_13_012.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.12 – Predicted versus ground truth values for the England Covid dataset</p>
<p>The scatter plot shows a weak correlation. We see that the predictions (y-axis) are mostly centered around 0.35 with little variance. This does not correspond to the ground truth values, spanning from -1.5 to 0.6. As per our experiments, adding a second linear layer did not improve the <span class="No-Break">MPNN-LSTM’s predictions.</span></p>
<p>Several strategies <a id="_idIndexMarker801"/>could be implemented to help the model. First, more data points could greatly help because this is a small dataset. Additionally, the time series contains two interesting characteristics: trends (continued increase and decrease over time) and seasonality (predictable pattern). We could add a preprocessing step to remove these characteristics, which <a id="_idIndexMarker802"/>add noise to the signal we want <span class="No-Break">to predict.</span></p>
<p>Beyond recurrent neural networks, self-attention is another popular technique to create temporal GNNs [4]. Attention can be restricted to temporal information or also consider spatial data, typically handled by graph convolution. Finally, temporal GNNs can also be extended to heterogeneous settings described in the previous chapter. Unfortunately, this combination requires even more data and is currently an active area <span class="No-Break">of research.</span></p>
<h1 id="_idParaDest-159"><a id="_idTextAnchor163"/>Summary</h1>
<p>This chapter introduced a new type of graph with spatiotemporal information. This temporal component is helpful in many applications, mostly related to time series forecasting. We described two types of graphs that fit this description: static graphs, where features evolve over time, and dynamic graphs, where features and topology can change. Both of them are handled by PyTorch Geometric Temporal, PyG’s extension dedicated to temporal graph <span class="No-Break">neural networks.</span></p>
<p>Additionally, we covered two applications of temporal GNNs. First, we implemented the EvolveGCN architecture, which uses a GRU or an LSTM network to update the GCN parameters. We applied it by revisiting web traffic forecasting, a task we encountered in <a href="B19153_06.xhtml#_idTextAnchor074"><span class="No-Break"><em class="italic">Chapter 6</em></span></a>, <em class="italic">Introducing Graph Convolutional Networks</em>, and achieved excellent results with a limited dataset. Secondly, we used the MPNN-LSTM architecture for epidemic forecasting. We applied to the England Covid dataset a dynamic graph with a temporal signal, but its small size did not allow us to obtain <span class="No-Break">comparable results.</span></p>
<p>In <a href="B19153_14.xhtml#_idTextAnchor165"><span class="No-Break"><em class="italic">Chapter 14</em></span></a>, <em class="italic">Explaining Graph Neural Networks</em>, we will focus on how to interpret our results. Beyond the different visualizations we have introduced so far, we will see how to apply techniques from <strong class="bold">eXplainable Artificial Intelligence</strong> (<strong class="bold">XAI</strong>) to graph neural networks. This field is a key component to build robust AI systems and improve machine learning adoption. In that chapter, we will introduce post hoc explanation methods and new layers to build models that are explainable <span class="No-Break">by design.</span></p>
<h1 id="_idParaDest-160"><a id="_idTextAnchor164"/>Further reading</h1>
<ul>
<li>[1] A. Pareja et al., <em class="italic">EvolveGCN: Evolving Graph Convolutional Networks for Dynamic Graphs</em>. arXiv, 2019. DOI: 10.48550/ARXIV.1902.10191. <span class="No-Break">Available: </span><a href="https://arxiv.org/abs/1902.10191"><span class="No-Break">https://arxiv.org/abs/1902.10191</span></a></li>
<li>[2] B. Rozemberczki et al., <em class="italic">PyTorch Geometric Temporal: Spatiotemporal Signal Processing with Neural Machine Learning Models</em>, in Proceedings of the 30th ACM International Conference on Information and Knowledge Management, 2021, pp. 4564–4573. <span class="No-Break">Available: </span><a href="https://arxiv.org/abs/2104.07788"><span class="No-Break">https://arxiv.org/abs/2104.07788</span></a></li>
<li>[3] G. Panagopoulos, G. Nikolentzos, and M. Vazirgiannis. <em class="italic">Transfer Graph Neural Networks for Pandemic Forecasting</em>. arXiv, 2020. DOI: 10.48550/ARXIV.2009.08388. <span class="No-Break">Available: </span><a href="https://arxiv.org/abs/2009.08388"><span class="No-Break">https://arxiv.org/abs/2009.08388</span></a></li>
<li>[4] Guo, S., Lin, Y., Feng, N., Song, C., &amp; Wan, H. (2019). Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting. Proceedings of the AAAI Conference on Artificial Intelligence, 33(01), <span class="No-Break">922-929. </span><a href="https://doi.org/10.1609/aaai.v33i01.3301922"><span class="No-Break">https://doi.org/10.1609/aaai.v33i01.3301922</span></a></li>
</ul>
</div>
<div>
<div class="IMG---Figure" id="_idContainer633">
</div>
</div>
</div></body></html>