<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Real Estate Value Prediction Using XGBoost</h1>
                </header>
            
            <article>
                
<p class="mce-root">The real estate market is one of the most competitive markets when it comes to pricing. This tends to vary significantly based on a number of factors such as the location, age of the property, size, and so on. Therefore, it has become a modern-day challenge to accurately predict the prices of properties (especially those in the housing market) in order to make better investment decisions. This chapter will deal with precisely that.</p>
<p class="mce-root">After going through this chapter, you will be able to:</p>
<ul>
<li>Downloading the King County Housing sales dataset</li>
<li>Performing exploratory analysis and visualization</li>
<li>Plotting correlation between price and other features</li>
<li><span>Predicting </span>the price of a house</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Downloading the King County House sales dataset</h1>
                </header>
            
            <article>
                
<p>We can't build a model without a dataset.  We will download our data in this section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>Kaggle (<a href="https://www.kaggle.com/" target="_blank">https://www.kaggle.com/</a>) i<span>s a platform for predictive modeling and analytics competitions in which statisticians and data miners compete to produce the best models for predicting and describing the datasets uploaded by companies and users. The King County House Sales dataset contains records of 21,613 houses sold in King County, New York between 1900 and 2015. The dataset also contains 21 different variables such as location, zip code, number of bedrooms, area of the living space, and so on, for each house.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>The dataset can be accessed from the following website:<span> <a href="https://www.kaggle.com/harlfoxem/housesalesprediction">https://www.kaggle.com/harlfoxem/housesalesprediction</a>. The dataset is from the public records of King County and is freely available to download and use in any analysis.</span></li>
<li>
<p class="CDPAlignLeft CDPAlign">Once you arrive at the website, you can click on the <span class="packt_screen">Download</span> button, as shown in the following screenshot:</p>
</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1445 image-border" src="assets/1418843f-ea70-4805-aefe-4217157d8bf5.png" style="width:75.42em;height:25.92em;"/></div>
<div class="mce-root CDPAlignCenter CDPAlign packt_figref">King County House Sales Dataset</div>
<ol start="3">
<li>One file named <kbd>kc_house_data.csv</kbd> appears from the zipped, downloaded file, <kbd>housesalesprediction.zip</kbd>.</li>
<li>Save the file named <kbd>kc_house_data.csv</kbd> in the current working directory as this will be our dataset. This will be loaded into the IPython notebook for analysis and predictions.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<ol>
<li>
<p>Install the necessary libraries for this chapter using the following code:</p>
</li>
</ol>
<pre style="padding-left: 60px">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>import mpl_toolkits<br/>from sklearn import preprocessing<br/>from sklearn.preprocessing import LabelEncoder, OneHotEncoder<br/>from sklearn.feature_selection import RFE<br/>from sklearn import linear_model<br/>from sklearn.cross_validation import train_test_split %matplotlib inline</pre>
<ol start="2">
<li>The preceding step should result in an output, as shown in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1446 image-border" src="assets/8468bb02-a4f0-4cc7-9c35-e9c233a25314.png" style="width:80.33em;height:22.92em;"/></div>
<ol start="3">
<li>It is always a good idea to check the current working directory and set it to the directory in which the dataset is stored. This is shown in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1447 image-border" src="assets/754ec71d-52f6-46c5-bb2a-d1ca6df174c2.png" style="width:31.25em;height:12.92em;"/></div>
<p class="CDPAlignLeft CDPAlign" style="padding-left: 60px">In our case, the folder named <kbd>Chapter 10</kbd> is set as the current working directory.</p>
<ol start="4">
<li>The data in the file is read into a Pandas dataframe named <kbd>dataframe</kbd> using the <kbd>read_csv()</kbd> function and the features/headers are listed out using the <kbd>list(dataframe)</kbd> command, as shown in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1448 image-border" src="assets/9571e0c5-a17f-4c80-90c2-630c6758a39d.png" style="width:33.58em;height:24.75em;"/></div>
<p class="CDPAlignLeft CDPAlign">As you may have noticed, the dataset contains 21 different variables such as <span class="packt_screen">id</span>, <span class="packt_screen">date</span>, <span class="packt_screen">price</span>, <span class="packt_screen">bedrooms</span>, <span class="packt_screen">bathrooms</span>, and so on.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>The libraries used as well as their functions in this chapter are as follows:</p>
<ul>
<li><kbd>Numpy</kbd>, which is used to wrangle data in the form of arrays as well as store lists of names in the form of arrays</li>
<li><kbd>Pandas</kbd>, which is used for all data wrangling and managing data in the form of dataframes</li>
<li><kbd>Seaborn</kbd>, which is a visualization library required for exploratory analysis and plots</li>
<li><kbd>MPL_Toolkits</kbd>, which contains a number of functions and dependencies required by <kbd>Matplotlib</kbd></li>
<li>Functions from the <kbd>Scikit Learn</kbd> library, which is the primary scientific and statistical library required in this chapter</li>
<li>We will also require some other libraries such as <kbd>XGBoost</kbd>, but those will be imported as required while building the model</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p>Further documentation about the different libraries can be found by visiting the following links:</p>
<ul>
<li><a href="http://scikit-learn.org/stable/modules/preprocessing.html">http://scikit-learn.org/stable/modules/preprocessing.html</a></li>
<li><a href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html">http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html</a></li>
<li><a href="https://seaborn.pydata.org/">https://seaborn.pydata.org/</a></li>
<li><a href="https://matplotlib.org/mpl_toolkits/index.html">https://matplotlib.org/mpl_toolkits/index.html</a></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Performing exploratory analysis and visualization</h1>
                </header>
            
            <article>
                
<p>In situations where the goal is to predict a variable such as <kbd>price</kbd>, it helps to visualize the data and figure out how the dependent variable is being influenced by other variables. The exploratory analysis gives a lot of insight which is not readily available by looking at the data. This section of the chapter will describe how to visualize and draw insights from big data.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<ul>
<li>The head of the <kbd>dataframe</kbd> can be printed using the <kbd>dataframe.head()</kbd> function which produces an output, as shown in the following screenshot:</li>
</ul>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1449 image-border" src="assets/dfba4c24-6df3-4862-a8a5-0c532014e7b4.png" style="width:98.75em;height:25.25em;"/></div>
<ul>
<li>Similarly, the tail of the <kbd>dataframe</kbd> can be printed using the <kbd>dataframe.tail()</kbd> function, which produces an output, as shown in the following screenshot:</li>
</ul>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1450 image-border" src="assets/c040272b-9388-4ddf-8b32-30a2b49bf7a1.png" style="width:69.25em;height:17.83em;"/></div>
<ul>
<li>The <kbd>dataframe.describe()</kbd> function is used to obtain some basic statistics such as the maximum, minimum, and mean values under each column. This is illustrated in the following screenshot:</li>
</ul>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1451 image-border" src="assets/04e8fb16-fcee-4045-bc2d-50dc46404791.png" style="width:66.25em;height:19.92em;"/></div>
<div class="mce-root CDPAlignCenter CDPAlign packt_figref">dataframe.describe() function output</div>
<ul>
<li>As you can observe, the dataset has 21,613 records of houses sold between 1900 and 2015.</li>
<li>On taking a closer look at the statistics, we realize that most houses sold have about three bedrooms on average. We can also see that the minimum number of bedrooms in a house is 0 and the largest house has 33 bedrooms and a living area of 13,540 square feet.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>Let's plot the count of bedrooms in the whole dataset to see how three bedroom houses stand compared to houses with two or one bedrooms. This is done using the following code:</li>
</ol>
<pre style="padding-left: 60px">dataframe['bedrooms'].value_counts().plot(kind='bar') plt.title('No. of bedrooms')<br/>plt.xlabel('Bedrooms')<br/>plt.ylabel('Count')<br/>sns.despine</pre>
<ol start="2">
<li>We can also plot a pie chart of the same data using the following commands:</li>
</ol>
<pre style="padding-left: 60px"> dataframe['bedrooms'].value_counts().plot(kind='pie')<br/>plt.title('No. of bedrooms')</pre>
<ol start="3">
<li>Next, let's try to see the number of floors in houses that are sold most frequently in King County. This may be done by plotting a bar graph using the following commands:</li>
</ol>
<pre style="padding-left: 60px">dataframe['floors'].value_counts().plot(kind='bar') plt.title('Number of floors')<br/>plt.xlabel('No. of floors')<br/>plt.ylabel('Count')<br/>sns.despine</pre>
<ol start="4">
<li>Next, we need to have an idea of what locations have the highest number of houses sold. We can do this by using the <kbd>latitude</kbd> and <kbd>longitude</kbd> variables from the dataset, as shown in the following code:</li>
</ol>
<pre style="padding-left: 60px">plt.figure(figsize=(20,20))<br/>sns.jointplot(x=dataframe.lat.values, y=dataframe.long.values, size=9)<br/>plt.xlabel('Longitude', fontsize=10)<br/>plt.ylabel('Latitude', fontsize=10)<br/>plt.show()<br/>sns.despine()</pre>
<ol start="5">
<li>Let's also take a look at how the prices compare for houses with different numbers of bedrooms by executing the following commands:</li>
</ol>
<pre style="padding-left: 60px"> plt.figure(figsize=(20,20))<br/>sns.jointplot(x=dataframe.lat.values, y=dataframe.long.values, size=9)<br/>plt.xlabel('Longitude', fontsize=10)<br/>plt.ylabel('Latitude', fontsize=10)<br/>plt.show()<br/>sns.despine()</pre>
<ol start="6">
<li>A plot of the price of houses versus the number of bedrooms is obtained using the following commands:</li>
</ol>
<pre style="padding-left: 60px">plt.figure(figsize=(20,20))<br/>sns.jointplot(x=dataframe.lat.values, y=dataframe.long.values, size=9)<br/>plt.xlabel('Longitude', fontsize=10)<br/>plt.ylabel('Latitude', fontsize=10)<br/>plt.show()<br/>sns.despine()</pre>
<ol start="7">
<li>Similarly, let's see how the price compares to the living area of all the houses sold. This may be done by using the following commands:</li>
</ol>
<pre style="padding-left: 60px">plt.figure(figsize=(8,8))<br/>plt.scatter(dataframe.price, dataframe.sqft_living)<br/>plt.xlabel('Price')<br/>plt.ylabel('Square feet')<br/>plt.show()</pre>
<ol start="8">
<li>The condition of houses sold gives us some important information as well. Let's plot this against the prices to get a better idea of the general trends. This is done using the following commands:</li>
</ol>
<pre style="padding-left: 60px">plt.figure(figsize=(5,5))<br/>plt.bar(dataframe.condition, dataframe.price)<br/>plt.xlabel('Condition')<br/>plt.ylabel('Price')<br/>plt.show()</pre>
<ol start="9">
<li>We can see which zip codes have the most house sales in King County by using the following commands:</li>
</ol>
<pre style="padding-left: 60px">plt.figure(figsize=(8,8))<br/>plt.scatter(dataframe.zipcode, dataframe.price)<br/>plt.xlabel('Zipcode')<br/>plt.ylabel('Price')<br/>plt.show()</pre>
<ol start="10">
<li>Finally, plot the grade of each house versus the price to figure out the trends in house sales based on the grade given to each house using the following commands:</li>
</ol>
<pre style="padding-left: 60px">plt.figure(figsize=(10,10))<br/>plt.scatter(dataframe.grade, dataframe.price)<br/>plt.xlabel('Grade')<br/>plt.ylabel('Price')<br/>plt.show()</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<ol>
<li>The plot of bedroom counts must give an output, as shown in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1452 image-border" src="assets/d450a455-de95-4eef-944f-1e75086c0ca2.png" style="width:41.00em;height:30.17em;"/></div>
<ol start="2">
<li>It is evident that three bedroom houses are sold the most, followed by four bedroom houses, then by two bedroom houses, and then surprisingly by five bedroom and six bedroom houses. </li>
</ol>
<ol start="3">
<li>The pie chart of the number of bedrooms gives an output that looks like the following screenshot:</li>
</ol>
<div class="mce-root CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1453 image-border" src="assets/79c623be-2806-4f2e-842a-7bc0bdeabad6.png" style="width:55.58em;height:31.67em;"/></div>
<ol start="4">
<li>You will notice that three bedroom houses account for roughly 50% of all houses sold in King County. It looks like about 25% are four bedroom houses and the remaining 25% is made up of houses with two, five, six bedrooms, and so on.</li>
</ol>
<ol start="5">
<li>On running the script for most houses sold categorized by the number of floors, we notice the following output:</li>
</ol>
<div class="mce-root CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1454 image-border" src="assets/5d8acf59-ea2b-4372-9f1e-f062b3178fd0.png" style="width:42.08em;height:31.67em;"/></div>
<ol start="6">
<li>It is quite clear that single floor houses sell the most, followed by two-story houses. The count of houses with <span>more t</span>han two stories is rather low, which is perhaps an indication of family sizes and the income of residents living in King County.</li>
<li>On inspecting the density of houses sold at different locations, we obtain an output, as shown in the following screenshots. It is pretty clear that some locations see a higher density of house sales compared to others:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/d08cc1fa-e81d-48a6-8733-f771069b394e.png"/></div>
<div class="CDPAlignCenter CDPAlign"><br/>
<img src="assets/0b39d95e-5e6a-4867-bfe2-ce6c557792dd.png" style="width:40.58em;height:42.17em;"/></div>
<ol start="8">
<li>From the trends observed in the preceding figure, it is easy to notice how a greater number of houses are sold between latitudes -122.2 and -122.4. Similarly, the density of houses sold between longitudes 47.5 and 47.8 is higher compared to other longitudes. This could perhaps be an indication of safer and better-living communities compared to the other communities.</li>
</ol>
<ol start="9">
<li>On plotting the prices of houses versus the number of bedrooms in the house, we realize that the trends regarding the number of bedrooms in a house are directly proportional to the price up to six bedrooms, and then it becomes inversely proportional, as shown in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/576a5f38-1fbf-4f2e-a3ff-2f6afa6231fe.png" style="width:66.67em;height:40.00em;"/></div>
<ol start="10">
<li>Plotting the living area of each house against the price gives us an expected trend of increasing prices with the increasing size of the house. The most expensive house seems to have a living area of 12,000 square feet, as shown in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1455 image-border" src="assets/eb22a794-38a7-444e-9160-571a9c969178.png" style="width:36.58em;height:34.58em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<ol>
<li>On plotting the condition of houses versus price, we again notice an expected trend of increasing prices with higher condition ratings, as shown in the following screenshot. Interestingly, five bedroom prices have a lower mean price compared to four bedroom houses, which is possibly due to lesser buyers for such a big house:</li>
</ol>
<div class="mce-root CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1456 image-border" src="assets/ff3ddb55-21ca-439f-9174-319c28610015.png" style="width:38.17em;height:33.25em;"/></div>
<ol start="2">
<li>A plot of the <span class="packt_screen">Zipcode</span> of the house versus price shows trends in the prices of houses in different zip codes. You may have noticed that certain zip codes, like the ones between 98100 and 98125, have a higher density of houses sold compared to other areas, while the prices of houses in zip codes like 98040 are higher than the average price, perhaps indicating a richer neighborhood, as shown in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1457 image-border" src="assets/9dc53dc8-bfaa-4ad3-a050-a6e44201c4c3.png" style="width:56.33em;height:54.17em;"/></div>
<ol start="3">
<li><span>A plot of the grade of the house versus price shows a consistent increase in price with increasing grade. There seems to be a clear linear relationship between the two, as observed in the output of the following screenshots:</span></li>
</ol>
<div class="CDPAlignCenter CDPAlign"><span><img src="assets/45feb4d4-cb57-4bb2-9347-4e3e161f9b48.png" style="width:36.33em;height:7.33em;"/></span></div>
<div class="CDPAlignCenter CDPAlign"><img src="assets/6d2edae4-4a3f-4318-96c0-ee6037cdf158.png" style="width:42.42em;height:37.08em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p>The following links give a good explanation of why data visualization is so important before running any model on the data:</p>
<ul>
<li><a href="https://www.slideshare.net/Centerline_Digital/the-importance-of-data-visualization">https://www.slideshare.net/Centerline_Digital/the-importance-of-data-visualization</a></li>
<li><a href="https://data-visualization.cioreview.com/cxoinsight/what-is-data-visualization-and-why-is-it-important-nid-11806-cid-163.html">https://data-visualization.cioreview.com/cxoinsight/what-is-data-visualization-and-why-is-it-important-nid-11806-cid-163.html</a></li>
<li><a href="https://www.techchange.org/2015/05/19/data-visualization-analysis-international-development/">https://www.techchange.org/2015/05/19/data-visualization-analysis-international-development/</a></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Plotting correlation between price and other features</h1>
                </header>
            
            <article>
                
<p>Now that the initial exploratory analysis is done, we have a better idea of how the different variables are contributing to the price of each house. However, we have no idea of the importance of each variable when it comes to predicting prices. Since we have 21 variables, it becomes difficult to build models by incorporating all variables in one single model. Therefore, some variables may need to be discarded or neglected if they have lesser significance than other variables.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p class="mce-root">Correlation coefficients are used in statistics to measure how strong the relationship is between two variables. In particular, Pearson's correlation coefficient is the most commonly used coefficient while performing linear regression. The correlation coefficient usually takes on a value between -1 and +1:</p>
<ul>
<li>A correlation coefficient of 1 means that for every positive increase in one variable, there is a positive increase of a fixed proportion in the other. For example, shoe sizes go up in (almost) perfect correlation with foot length.</li>
<li>A correlation coefficient of -1 means that for every positive increase in one variable, there is a negative decrease of a fixed proportion in the other. For example, the amount of gas in a tank decreases in (almost) perfect correlation with acceleration or the gear mechanism (more gas is used up by traveling for longer periods in first gear compared to fourth gear).</li>
<li>Zero means that for every increase, there isn't a positive or negative increase. The two just aren't related.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>Begin by dropping the <kbd>id</kbd> and <kbd>date</kbd> features from the dataset using the following commands. We will not be using them in our predictions as the ID variables are all unique and have no values in our analysis while the dates require a different function to handle them correctly. This is left as an exercise for the reader to do:</li>
</ol>
<pre style="padding-left: 60px"> x_df = dataframe.drop(['id','date',], axis = 1)<br/> x_df</pre>
<ol start="2">
<li>Copy the dependent variable (house prices, in this case) into a new <kbd>dataframe</kbd> using the following commands:</li>
</ol>
<pre style="padding-left: 60px"> y = dataframe[['price']].copy()<br/> y_df = pd.DataFrame(y)<br/> y_df</pre>
<ol start="3">
<li>The correlation between price and every other variable can be manually found using the following script:</li>
</ol>
<pre style="padding-left: 60px"> print('Price Vs Bedrooms: %s' % x_df['price'].corr(x_df['bedrooms']))<br/> print('Price Vs Bathrooms: %s' % x_df['price'].corr(x_df['bathrooms']))<br/> print('Price Vs Living Area: %s' % x_df['price'].corr(x_df['sqft_living']))<br/> print('Price Vs Plot Area: %s' % x_df['price'].corr(x_df['sqft_lot']))<br/> print('Price Vs No. of floors: %s' % x_df['price'].corr(x_df['floors']))<br/> print('Price Vs Waterfront property: %s' % x_df['price'].corr(x_df['waterfront']))<br/> print('Price Vs View: %s' % x_df['price'].corr(x_df['view']))<br/> print('Price Vs Grade: %s' % x_df['price'].corr(x_df['grade']))<br/> print('Price Vs Condition: %s' % x_df['price'].corr(x_df['condition']))<br/> print('Price Vs Sqft Above: %s' % x_df['price'].corr(x_df['sqft_above']))<br/> print('Price Vs Basement Area: %s' % x_df['price'].corr(x_df['sqft_basement']))<br/> print('Price Vs Year Built: %s' % x_df['price'].corr(x_df['yr_built']))<br/> print('Price Vs Year Renovated: %s' % x_df['price'].corr(x_df['yr_renovated']))<br/> print('Price Vs Zipcode: %s' % x_df['price'].corr(x_df['zipcode']))<br/> print('Price Vs Latitude: %s' % x_df['price'].corr(x_df['lat']))<br/> print('Price Vs Longitude: %s' % x_df['price'].corr(x_df['long']))</pre>
<ol start="4">
<li>Besides the preceding method, an easier way to find the correlation between one variable and all other variables (or columns) in a <kbd>dataframe</kbd> is done by using just one line in the following manner:<br/>
<kbd>x_df.corr().iloc[:,-19]</kbd></li>
<li>The correlated variables may be plotted using the <kbd>seaborn</kbd> library and the following script:</li>
</ol>
<pre style="padding-left: 60px"> sns.pairplot(data=x_df,<br/> x_vars=['price'],<br/> y_vars=['bedrooms', 'bathrooms', 'sqft_living',<br/> 'sqft_lot', 'floors', 'waterfront','view',<br/> 'grade','condition','sqft_above','sqft_basement',<br/> 'yr_built','yr_renovated','zipcode','lat','long'],<br/> size = 5)</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<ol>
<li>After dropping the <kbd>id</kbd> and <kbd>date</kbd> variables, the new <kbd>dataframe</kbd>, which is named <kbd>x_df</kbd>, contains 19 variables or columns, as shown in the following screenshots. For the purposes of this book, only the first ten entries are printed out:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/5947e655-ab68-4eae-ae5e-ff998ebb810e.png" style="width:63.17em;height:22.83em;"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">First 10 entries of output<br/>
<br/>
<img src="assets/dd5594a1-ba51-4ff7-8744-9372e4f8304c.png" style="width:24.33em;height:6.33em;"/></div>
<ol start="2">
<li>On creating a new <kbd>dataframe</kbd> with only the dependent variable (price), you will see an output as follows. This new <kbd>dataframe</kbd> is named <kbd>y_df</kbd>. Again, only the first ten entries of the price column are printed for illustration purposes:</li>
</ol>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/a3545d84-7266-45ef-8c49-c41be9c5f646.png" style="text-align: center;color: black;font-size: 1em;width:34.25em;height:31.25em;"/></div>
<ol start="3">
<li>The correlation between price and other variables is shown in the following screenshot:</li>
</ol>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/e7e60e83-8105-406f-9785-a8ac48ce7b1f.png" style="text-align: center;color: black;font-size: 1em;width:48.92em;height:34.33em;"/></div>
<ol start="4">
<li>You may have noticed that the <kbd>sqft_living</kbd> variable is most highly correlated with the price and has a correlation coefficient of 0.702035. The next most highly correlated variable is <kbd>grade</kbd>, with a correlation coefficient of 0.667434 followed by <kbd>sqft_above</kbd>, which has a correlation coefficient of 0.605567. <kbd>Zipcode</kbd> is the least correlated variable with price and has a correlation coefficient of -0.053202.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<ul>
<li>The correlation coefficients found using the simplified code gives the exact same values but also gives the correlation of price with itself, which turns out to be a value of 1.0000, as expected. This is illustrated in the following screenshot:</li>
</ul>
<div class="CDPAlignCenter CDPAlign"><img src="assets/a5d1ae99-b800-4cc2-aa7b-a92ea9c816c4.png" style="width:23.67em;height:26.83em;"/></div>
<ul>
<li>The coefficients of correlation plotted using the <kbd>seaborn</kbd> library are presented in the following screenshots. Note that price is on the x-axis for each plot:</li>
</ul>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/b7fef6eb-566e-4c45-9d9f-188bac6b7f99.png" style="text-align: center;color: black;font-size: 1em;"/></div>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/0fdb0e5e-5dae-41a8-9113-3c9d765b1f0c.png" style="text-align: center;color: black;font-size: 1em;width:33.00em;height:21.42em;"/></div>
<div class="mce-root CDPAlignCenter CDPAlign packt_figref"><span> Plotting of coefficients of correlation</span></div>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/776bc86b-758a-40da-b11d-39383026c764.png" style="color: black;font-size: 1em;width:30.92em;height:27.17em;"/></div>
<div class="CDPAlignCenter CDPAlign"><img src="assets/0f000cb8-e2b8-444e-aca2-0b102b8167b4.png" style="width:31.75em;height:26.58em;"/><br/>
<br/>
<img src="assets/b61392ab-2b70-4f1b-8eb6-58cc9cbd82bc.png" style="width:31.75em;height:25.08em;"/></div>
<div class="mce-root CDPAlignLeft CDPAlign"/>
<div class="CDPAlignCenter CDPAlign"><img src="assets/9bd74848-802a-4f92-b74d-82aafaeebb77.png" style="width:30.83em;height:26.67em;"/><br/>
<br/>
<img src="assets/f0a57645-512a-4e2c-9ae8-a4b444e91017.png" style="width:30.83em;height:27.08em;"/></div>
<div class="CDPAlignCenter CDPAlign"><img src="assets/3f55b2bf-0b18-4d52-b779-0e585dc8922b.png" style="font-size: 1em;width:30.42em;height:26.50em;"/></div>
<div class="CDPAlignCenter CDPAlign"><img src="assets/becf6059-05a3-46a7-b0c4-2dee64fdc8ac.png" style="width:30.42em;height:26.83em;"/></div>
<div class="CDPAlignCenter CDPAlign"><img src="assets/9eee10f5-0829-463f-a515-9dca39b6b5dc.png" style="font-size: 1em;width:30.42em;height:26.92em;"/></div>
<div class="CDPAlignCenter CDPAlign"><img src="assets/4ebbfe26-13c3-4a11-8509-aaf80c8b9367.png" style="width:30.42em;height:25.00em;"/></div>
<div class="CDPAlignCenter CDPAlign"><img src="assets/bda3931f-f6f9-464a-8f13-6e37c6384051.png" style="width:30.42em;height:25.25em;"/><br/>
<br/>
<img src="assets/9b0249f3-bd5e-48eb-9072-b13bcedbc464.png" style="width:30.50em;height:26.83em;"/></div>
<div class="CDPAlignCenter CDPAlign"><img src="assets/ad86e758-0970-49ae-8708-821caf02caa8.png" style="width:29.92em;height:27.25em;"/><br/>
<br/>
<img src="assets/160aeefa-e74f-4429-bcf3-3b6916110947.png" style="width:29.92em;height:26.25em;"/></div>
<div class="CDPAlignCenter CDPAlign"><img src="assets/6966a5ef-0441-4718-9145-f5e06680c4c5.png" style="width:30.42em;height:27.33em;"/><br/>
<br/>
<img src="assets/d5d4c4e5-b53a-4f3b-bf6e-48b33e29713e.png" style="width:30.25em;height:25.08em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p>The following links give an excellent explanation of Pearson's correlation coefficient and how it is manually calculated:<br/>
<a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">https://en.wikipedia.org/wiki/Pearson_correlation_coefficient</a><br/>
<a href="http://www.statisticshowto.com/probability-and-statistics/correlation-coefficient-formula/">http://www.statisticshowto.com/probability-and-statistics/correlation-coefficient-formula/</a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Predicting the price of a house</h1>
                </header>
            
            <article>
                
<p>This section will deal with building a simple linear model to predict house prices using all the features in the current <kbd>dataframe</kbd>. We will then evaluate the model and try to improve the accuracy by using a more complex model in the latter half of the section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>Visit the following links to understand how linear regression works and how to use the linear regression model in the Scikit Learn library:<br/>
<a href="https://en.wikipedia.org/wiki/Linear_regression">https://en.wikipedia.org/wiki/Linear_regression</a></p>
<p><a href="http://www.stat.yale.edu/Courses/1997-98/101/linreg.htm">http://www.stat.yale.edu/Courses/1997-98/101/linreg.htm</a></p>
<p><a href="https://newonlinecourses.science.psu.edu/stat501/node/251/">https://newonlinecourses.science.psu.edu/stat501/node/251/</a></p>
<p><a href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html">http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html</a></p>
<p><a href="http://scikit-learn.org/stable/modules/linear_model.html">http://scikit-learn.org/stable/modules/linear_model.html</a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>Drop the <kbd>Price</kbd> column from the <kbd>x_df</kbd> dataframe and save it into a new <kbd>dataframe</kbd> named <kbd>x_df2</kbd> using the following script:</li>
</ol>
<pre style="padding-left: 60px"> x_df2 = x_df.drop(['price'], axis = 1)</pre>
<ol start="2">
<li>Declare a variable named <kbd>reg</kbd> and equate it to the <kbd>LinearRegression()</kbd> function from the Scikit Learn library using the following script:</li>
</ol>
<pre style="padding-left: 60px"> reg=linear_model.LinearRegression()</pre>
<ol start="3">
<li>Split the dataset into test and train using the following script:</li>
</ol>
<pre style="padding-left: 60px"> x_train,x_test,y_train,y_test = train_test_split(x_df2,y_df,test_size=0.4,random_state=4)</pre>
<ol start="4">
<li>Fit the model over the training set using the following script:</li>
</ol>
<pre style="padding-left: 60px"> reg.fit(x_train,y_train)</pre>
<ol start="5">
<li>Print the coefficients generated from applying linear regression to the training and test sets by using the <kbd>reg.coef_</kbd> command.</li>
<li>Take a look at the column of predictions generated by the model using the following script:</li>
</ol>
<pre style="padding-left: 60px"> predictions=reg.predict(x_test)<br/> predictions</pre>
<ol start="7">
<li>Print the accuracy of the model using the following command:</li>
</ol>
<pre style="padding-left: 60px"> reg.score(x_test,y_test)</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<ol>
<li>The output after fitting the regression model to the training sets must look like the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/ae9a4976-9769-413d-ac56-93fcc083c95e.png" style="width:104.17em;height:23.67em;"/></div>
<ol start="2">
<li>The <kbd>reg.coeff_</kbd> command generates 18 coefficients, one for each variable in the dataset, as shown in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/b6a35bbc-1717-4e16-85de-5c44ab3e0ac6.png" style="width:40.58em;height:10.17em;"/></div>
<ol start="3">
<li>The coefficients of features/variables with the most positive values have a higher significance on price predictions when compared to the coefficients of features/variables which have negative values. This is the main importance of the regression coefficients.</li>
<li>On printing the predictions, you must see an output which is an array of values from 1 to 21,612, one value for each row in the dataset, as shown in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/e892b589-6413-429f-b934-2ec14160be5b.png" style="width:28.33em;height:12.92em;"/></div>
<ol start="5">
<li>Finally, on printing the accuracy of the model, we obtained an accuracy of 70.37%, which is not bad for a linear model. This is illustrated in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/720263f1-805b-4f7a-8bba-6acdba8feb87.png" style="width:27.83em;height:6.00em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>The linear model does alright at its first attempt, but if we want our model to be more accurate, we will have to use a more complex model with some non-linearities in order to fit well to all the data points. XGBoost is the model we will be using in this section in order to try and improve the accuracy obtained through linear regression. This is done in the following manner:</p>
<ol>
<li>Import the <kbd>XGBoost</kbd> library using the <kbd>import xgboost</kbd> command.</li>
<li>In case this produces an error, you will have to do a pip install of the library through the terminal. This can be done by opening up a new terminal window and issuing the following command:</li>
</ol>
<pre style="padding-left: 60px">/<span class="pln">usr</span><span class="pun">/</span><span class="pln">bin</span><span class="pun">/</span><span class="pln">ruby </span><span class="pun">-</span><span class="pln">e </span><span class="str">"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"</span></pre>
<ol start="3">
<li>At this stage, you must see an output which looks like the one shown in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/4b328511-f9b9-4f4c-9987-dca58bb592c3.png" style="width:60.92em;height:25.58em;"/></div>
<ol start="4">
<li>At this stage, you will be prompted to enter your password. After homebrew is installed, you will see an output like the one shown in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/0c8777b2-e2b2-4e1b-b775-50723159d79c.png" style="width:56.50em;height:35.17em;"/></div>
<ol start="5">
<li>Next, install Python using the following command:<br/>
<kbd>brew install python</kbd></li>
<li>Check your installation using the <kbd>brew doctor</kbd> command and follow homebrew's suggestions.</li>
<li>Once <kbd>Homebrew</kbd> is installed, do a pip install of XGBoost using the following command:<br/>
<kbd>pip install xgboost</kbd></li>
<li>Once it finishes installing, you should be able to import XGBoost into the IPython environment.</li>
</ol>
<p style="padding-left: 60px">Once XGBoost is imported successfully into the Jupyter environment, you will be able to use the functions within the library to declare and store the model. This can be done in the following steps:</p>
<ol start="9">
<li>Declare a variable named <kbd>new_model</kbd> to store the model and declare all its hyperparameters using the following command:</li>
</ol>
<pre style="padding-left: 60px">new_model = xgboost.XGBRegressor(n_estimators=750, learning_rate=0.09,         gamma=0, subsample=0.65, colsample_bytree=1, max_depth=7)</pre>
<ol start="10">
<li>The output of the preceding command must look like the one in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/423b4265-fb23-40d7-9e2c-4ccd656ac6b9.png" style="width:121.08em;height:13.42em;"/></div>
<ol start="11">
<li>Split the data into test and training sets and fit the new model to the split data using the following commands:</li>
</ol>
<pre style="padding-left: 60px"> from sklearn.model_selection import train_test_split<br/> traindf, testdf = train_test_split(x_train, test_size = 0.2)<br/> new_model.fit(x_train,y_train)</pre>
<ol start="12">
<li>At this point, you will see an output like the one shown in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/a94abfb7-7ec5-42a3-83a4-4193c2ece623.png" style="width:89.83em;height:27.25em;"/></div>
<ol start="13">
<li>Finally, use the newly fitted model to predict the house prices and evaluate the new model using the following commands:</li>
</ol>
<pre style="padding-left: 60px"> from sklearn.metrics import explained_variance_score<br/> predictions = new_model.predict(x_test)<br/> print(explained_variance_score(predictions,y_test))</pre>
<ol start="14">
<li>On executing the preceding commands, you must see an output like the one shown in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/1be540f0-1845-4248-82ca-95fa0ffebf74.png" style="width:56.75em;height:11.25em;"/></div>
<ol start="15">
<li>Notice that the new model's accuracy is now 87.79 %, which is approximately 88%. This is considered optimal.</li>
<li>In this case, the <kbd>number of estimators</kbd> is set to 750. After experimenting between 100 to 1,000, it was determined that 750 estimators gave the most optimal accuracy. The <kbd>learning rate</kbd> is set to 0.09. <kbd>Subsample rate</kbd> is set at 65%. <kbd>Max_depth</kbd> is set at 7. There didn't seem to be too much influence of <kbd>max_depth</kbd> over the model's accuracy. However, the accuracy did show improvement in using slower learning rates. By experimenting with various hyperparameters, we were able to further improve accuracy to 89%.</li>
<li>Future steps involve one hot encoding variables such as bedrooms, bathrooms, floors, zipcodes, and so on, and normalizing all the variables before model fitting. Try to tune the hyperparameters such as learning rate, number of estimators in the XGBoost model, subsampling rates, and so on to see how they influence model accuracy. This is left as an exercise for the reader.</li>
<li>Also, you may want to try and use cross-validation along with XGBoost in order to figure out the optimal number of trees in the model, which would further improve accuracy. </li>
<li>Another exercise that can be done is using different sizes of test and train datasets as well as incorporating the <kbd>date</kbd> variable during training. In our case, we have split it into a ratio of 80% training data and 20% test data. Try to increase the test set to 40% and see how the model accuracy changes.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p>Visit the following links to understand how to tune the hyperparameters in the XGBoost model as well as how to implement cross-validation with XGBoost:</p>
<p><a href="https://xgboost.readthedocs.io/en/latest/python/index.html">https://xgboost.readthedocs.io/en/latest/python/index.html</a></p>
<p><a href="http://xgboost.readthedocs.io/en/latest/get_started/">http://xgboost.readthedocs.io/en/latest/get_started/</a></p>
<p><a href="https://www.kaggle.com/cast42/xg-cv">https://www.kaggle.com/cast42/xg-cv</a></p>


            </article>

            
        </section>
    </body></html>