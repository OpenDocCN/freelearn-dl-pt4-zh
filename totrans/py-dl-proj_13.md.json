["```py\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom tqdm import tqdm\n\nfrom keras.layers import Input, Conv2D\nfrom keras.layers import AveragePooling2D, BatchNormalization\nfrom keras.layers import UpSampling2D, Flatten, Activation\nfrom keras.models import Model, Sequential\nfrom keras.layers.core import Dense, Dropout\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.optimizers import Adam\nfrom keras import backend as k\n\nfrom keras.datasets import mnist\n```", "```py\n# set seed for reproducibility\nseed_val = 9000\nnp.random.seed(seed_val)\nrandom.seed(seed_val)\n```", "```py\n(X_train, y_train), (X_test, y_test) =  mnist.load_data()\n\nprint('Size of the training_set: ', X_train.shape)\nprint('Size of the test_set: ', X_test.shape)\nprint('Shape of each image: ', X_train[0].shape)\nprint('Total number of classes: ', len(np.unique(y_train)))\nprint('Unique class labels: ', np.unique(y_train))\n```", "```py\n# Plot of 9 random images\nfor i in range(0, 9):\n    plt.subplot(331+i) # plot of 3 rows and 3 columns\n    plt.axis('off') # turn off axis\n    plt.imshow(X_train[i], cmap='gray') # gray scale\n```", "```py\n# plotting image from each class\nfig=plt.figure(figsize=(8, 4))\ncolumns = 5\nrows = 2\nfor i in range(0, rows*columns):\n    fig.add_subplot(rows, columns, i+1)\n    plt.title(str(i)) # label \n    plt.axis('off') # turn off axis\n    plt.imshow(X_train[np.where(y_train==i)][0], cmap='gray') # gray scale\nplt.show()\n```", "```py\nprint('Maximum pixel value in the training_set: ', np.max(X_train))\nprint('Minimum pixel value in the training_set: ', np.min(X_train))\n```", "```py\n# Converting integer values to float types \nX_train = X_train.astype(np.float32)\nX_test = X_test.astype(np.float32)\n\n# Scaling and centering\nX_train = (X_train - 127.5) / 127.5\nX_test = (X_test - 127.5)/ 127.5\nprint('Maximum pixel value in the training_set after Centering and Scaling: ', np.max(X_train))\nprint('Minimum pixel value in the training_set after Centering and Scaling: ', np.min(X_train))\n```", "```py\n# Rescale the pixel values (0 and 255)\ndef upscale(image):\n    return (image*127.5 + 127.5).astype(np.uint8)\n\n# Lets see if this works\nz = upscale(X_train[0])\nprint('Maximum pixel value after upscaling scaled image: ',np.max(z))\nprint('Maximum pixel value after upscaling scaled image: ',np.min(z))\n```", "```py\nfor i in range(0, 9):\n    plt.subplot(331+i) # plot of 3 rows and 3 columns\n    plt.axis('off') # turn off axis\n    plt.imshow(upscale(X_train[i]), cmap='gray') # gray scale\n```", "```py\ndef noising(image):\n    array = np.array(image)\n    i = random.choice(range(8,12)) # x coordinate for the top left corner of the mask\n    j = random.choice(range(8,12)) # y coordinate for the top left corner of the mask\n    array[i:i+8, j:j+8]=-1.0 # setting the pixels in the masked region to -1\n    return array\n\nnoised_train_data = np.array([*map(noising, X_train)])\nnoised_test_data = np.array([*map(noising, X_test)])\nprint('Noised train data Shape/Dimension : ', noised_train_data.shape)\nprint('Noised test data Shape/Dimension : ', noised_train_data.shape)\n```", "```py\n# Plot of 9 scaled noised images after upscaling\nfor i in range(0, 9):\n    plt.subplot(331+i) # plot of 3 rows and 3 columns\n    plt.axis('off') # turn off axis\n    plt.imshow(upscale(noised_train_data[i]), cmap='gray') # gray scale\n```", "```py\n# Reshaping the training data\nX_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\nprint('Size/Shape of the original training set: ', X_train.shape)\n\n# Reshaping the noised training data\nnoised_train_data = noised_train_data.reshape(noised_train_data.shape[0],\n                                              noised_train_data.shape[1],\n                                              noised_train_data.shape[2], 1)\nprint('Size/Shape of the noised training set: ', noised_train_data.shape)\n\n# Reshaping the testing data\nX_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\nprint('Size/Shape of the original test set: ', X_test.shape)\n\n# Reshaping the noised testing data\nnoised_test_data = noised_test_data.reshape(noised_test_data.shape[0],\n                                            noised_test_data.shape[1],\n                                            noised_test_data.shape[2], 1)\nprint('Size/Shape of the noised test set: ', noised_test_data.shape)\n```", "```py\n# input image shape\ninput_shape = (28,28,1)\n\ndef train_mnist(input_shape, X_train, y_train):\n    model = Sequential()\n    model.add(Conv2D(32, (3, 3), strides=2, padding='same',\n                     input_shape=input_shape))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(64, (3, 3), strides=2, padding='same'))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.2)) \n\n    model.add(Conv2D(128, (3, 3), padding='same'))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.2))\n    model.add(Flatten())\n\n    model.add(Dense(1024, activation = 'relu'))\n    model.add(Dense(10, activation='softmax'))\n    model.compile(loss = 'sparse_categorical_crossentropy',\n                  optimizer = 'adam', metrics = ['accuracy'])\n    model.fit(X_train, y_train, batch_size = 128,  \n              epochs = 3, validation_split=0.2, verbose = 1 )\n    return model\n\nmnist_model = train_mnist(input_shape, X_train, y_train)\n```", "```py\n# prediction on the masked images\npred_labels = mnist_model.predict_classes(noised_test_data)\nprint('The model model accuracy on the masked images is:',np.mean(pred_labels==y_test)*100)\n```", "```py\n# Smoothing value\nsmooth_real = 0.9\n\n# Number of epochs\nepochs = 5\n\n# Batchsize\nbatch_size = 128\n\n# Optimizer for the generator\noptimizer_g = Adam(lr=0.0002, beta_1=0.5)\n\n# Optimizer for the discriminator\noptimizer_d = Adam(lr=0.0004, beta_1=0.5)\n\n# Shape of the input image\ninput_shape = (28,28,1)\n```", "```py\ndef img_generator(input_shape):\n    generator = Sequential()\n    generator.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape)) # 32 filters\n    generator.add(BatchNormalization())\n    generator.add(Activation('relu'))\n    generator.add(AveragePooling2D(pool_size=(2, 2)))\n\n    generator.add(Conv2D(64, (3, 3), padding='same')) # 64 filters\n    generator.add(BatchNormalization())\n    generator.add(Activation('relu'))\n    generator.add(AveragePooling2D(pool_size=(2, 2)))\n\n    generator.add(Conv2D(128, (3, 3), padding='same')) # 128 filters\n    generator.add(BatchNormalization())\n    generator.add(Activation('relu')) \n\n    generator.add(Conv2D(128, (3, 3), padding='same')) # 128 filters\n    generator.add(Activation('relu'))\n    generator.add(UpSampling2D((2,2)))\n\n    generator.add(Conv2D(64, (3, 3), padding='same')) # 64 filters\n    generator.add(Activation('relu'))\n    generator.add(UpSampling2D((2,2)))\n\n    generator.add(Conv2D(1, (3, 3), activation='tanh', padding='same')) # 1 filter\n    return generator\n```", "```py\n# print generator summary\nimg_generator(input_shape).summary()\n```", "```py\ndef img_discriminator(input_shape):\n    discriminator = Sequential()\n    discriminator.add(Conv2D(64, (3, 3), strides=2, padding='same', input_shape=input_shape, activation = 'linear'))\n    discriminator.add(LeakyReLU(0.2))\n    discriminator.add(Dropout(0.2))\n\n    discriminator.add(Conv2D(128, (3, 3), strides=2, padding='same', activation = 'linear'))\n    discriminator.add(LeakyReLU(0.2))\n    discriminator.add(Dropout(0.2))\n\n    discriminator.add(Conv2D(256, (3, 3), padding='same', activation = 'linear'))\n    discriminator.add(LeakyReLU(0.2))\n    discriminator.add(Dropout(0.2))\n\n    discriminator.add(Flatten())\n    discriminator.add(Dense(1, activation='sigmoid'))\n\n    return discriminator\n\n# print summary of the discriminator\nimg_discriminator(input_shape).summary()\n```", "```py\ndef dcgan(discriminator, generator, input_shape):\n    # Set discriminator as non trainable before compiling GAN\n    discriminator.trainable = False\n\n    # Accepts the noised input\n    gan_input = Input(shape=input_shape)\n\n    # Generates image by passing the above received input to the generator\n    gen_img = generator(gan_input)\n\n    # Feeds the generated image to the discriminator\n    gan_output = discriminator(gen_img)\n\n    # Compile everything as a model with binary crossentropy loss\n    gan = Model(inputs=gan_input, outputs=gan_output)\n    return gan\n```", "```py\ndef generated_images_plot(original, noised_data, generator):\n\n    print('NOISED')\n    for i in range(9):\n        plt.subplot(331 + i)\n        plt.axis('off')\n        plt.imshow(upscale(np.squeeze(noised_data[i])), cmap='gray') # upscale for plotting\n    plt.show()\n\n    print('GENERATED')\n    for i in range(9):\n        pred = generator.predict(noised_data[i:i+1], verbose=0)\n        plt.subplot(331 + i)\n        plt.axis('off')\n        plt.imshow(upscale(np.squeeze(pred[0])), cmap='gray') # upscale to avoid plotting errors\n    plt.show()\n\n    print('ORIGINAL')\n    for i in range(9):\n        plt.subplot(331 + i)\n        plt.axis('off')\n        plt.imshow(upscale(np.squeeze(original[i])), cmap='gray') # upscale for plotting\n    plt.show()\n```", "```py\ndef plot_generated_images_combined(original, noised_data, generator):\n    rows, cols = 4, 12\n    num = rows * cols\n    image_size = 28\n\n    generated_images = generator.predict(noised_data[0:num])\n\n    imgs = np.concatenate([original[0:num], noised_data[0:num], generated_images])\n    imgs = imgs.reshape((rows * 3, cols, image_size, image_size))\n    imgs = np.vstack(np.split(imgs, rows, axis=1))\n    imgs = imgs.reshape((rows * 3, -1, image_size, image_size))\n    imgs = np.vstack([np.hstack(i) for i in imgs])\n    imgs = upscale(imgs)\n    plt.figure(figsize=(8,16))\n    plt.axis('off')\n    plt.title('Original Images: top rows, '\n              'Corrupted Input: middle rows, '\n              'Generated Images: bottom rows')\n    plt.imshow(imgs, cmap='gray')\n    plt.show() \n```", "```py\ndef train(X_train, noised_train_data,\n input_shape, smooth_real,\n epochs, batch_size,\n optimizer_g, optimizer_d):\n\n    # define two empty lists to store the discriminator\n # and the generator losses\n    discriminator_losses = []\n    generator_losses = []\n\n    # Number of iteration possible with batches of size 128\n    iterations = X_train.shape[0] // batch_size\n\n    # Load the generator and the discriminator\n    generator = img_generator(input_shape)\n    discriminator = img_discriminator(input_shape)\n\n    # Compile the discriminator with binary_crossentropy loss\n    discriminator.compile(loss='binary_crossentropy',optimizer=optimizer_d)\n\n    # Feed the generator and the discriminator to the function dcgan\n # to form the DCGAN architecture\n    gan = dcgan(discriminator, generator, input_shape)\n\n    # Compile the DCGAN with binary_crossentropy loss\n    gan.compile(loss='binary_crossentropy', optimizer=optimizer_g)\n\n    for i in range(epochs):\n        print ('Epoch %d' % (i+1))\n        # Use tqdm to get an estimate of time remaining\n        for j in tqdm(range(1, iterations+1)):\n\n            # batch of original images (batch = batchsize)\n            original = X_train[np.random.randint(0, X_train.shape[0], size=batch_size)]\n\n            # batch of noised images (batch = batchsize)\n            noise = noised_train_data[np.random.randint(0, noised_train_data.shape[0], size=batch_size)]\n\n            # Generate fake images\n            generated_images = generator.predict(noise)\n\n            # Labels for generated data\n            dis_lab = np.zeros(2*batch_size)\n\n            # data for discriminator\n            dis_train = np.concatenate([original, generated_images])\n\n            # label smoothing for original images\n            dis_lab[:batch_size] = smooth_real\n\n            # Train discriminator on original images\n            discriminator.trainable = True\n            discriminator_loss = discriminator.train_on_batch(dis_train, dis_lab)\n\n            # save the losses \n            discriminator_losses.append(discriminator_loss)\n\n            # Train generator\n            gen_lab = np.ones(batch_size)\n            discriminator.trainable = False\n            sample_indices = np.random.randint(0, X_train.shape[0], size=batch_size)\n            original = X_train[sample_indices]\n            noise = noised_train_data[sample_indices]\n\n            generator_loss = gan.train_on_batch(noise, gen_lab)\n\n            # save the losses\n            generator_losses.append(generator_loss)\n\n            if i == 0 and j == 1:\n                print('Iteration - %d', j)\n                generated_images_plot(original, noise, generator)\n                plot_generated_images_combined(original, noise, generator)\n\n        print(\"Discriminator Loss: \", discriminator_loss,\\\n              \", Adversarial Loss: \", generator_loss)\n\n        # training plot 1\n        generated_images_plot(original, noise, generator)\n        # training plot 2\n        plot_generated_images_combined(original, noise, generator)\n\n    # plot the training losses\n    plt.figure()\n    plt.plot(range(len(discriminator_losses)), discriminator_losses,\n             color='red', label='Discriminator loss')\n    plt.plot(range(len(generator_losses)), generator_losses,\n             color='blue', label='Adversarial loss')\n    plt.title('Discriminator and Adversarial loss')\n    plt.xlabel('Iterations')\n    plt.ylabel('Loss (Adversarial/Discriminator)')\n    plt.legend()\n    plt.show()\n\n    return generator\n\ngenerator = train(X_train, noised_train_data,\n                  input_shape, smooth_real,\n                  epochs, batch_size,\n                  optimizer_g, optimizer_d)\n```", "```py\n# restore missing parts of the digit with the generator\ngen_imgs_test = generator.predict(noised_test_data)\n```", "```py\n# predict on the restored/generated digits\ngen_pred_lab = mnist_model.predict_classes(gen_imgs_test)\nprint('The model model accuracy on the generated images is:',np.mean(gen_pred_lab==y_test)*100)\n```", "```py\n# plot of 10 generated images and their predicted label\nfig=plt.figure(figsize=(8, 4))\nplt.title('Generated Images')\nplt.axis('off') \ncolumns = 5\nrows = 2\nfor i in range(0, rows*columns):\n    fig.add_subplot(rows, columns, i+1)\n    plt.title('Act: %d, Pred: %d'%(gen_pred_lab[i],y_test[i])) # label \n    plt.axis('off') # turn off axis\n    plt.imshow(upscale(np.squeeze(gen_imgs_test[i])), cmap='gray') # gray scale\nplt.show()\n```", "```py\n\"\"\"This module is used to train a CNN on mnist.\"\"\"\nfrom keras.layers import Conv2D\nfrom keras.layers import Flatten, Activation\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout\n\ndef train_mnist(input_shape, X_train, y_train):\n    \"\"\"Train CNN on mnist data.\"\"\"\n    model = Sequential()\n    model.add(Conv2D(32, (3, 3), strides=2, padding='same',\n                     input_shape=input_shape))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.2))\n    model.add(Conv2D(64, (3, 3), strides=2, padding='same'))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.2))\n    model.add(Conv2D(128, (3, 3), padding='same'))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.2))\n    model.add(Flatten())\n    model.add(Dense(1024, activation='relu'))\n    model.add(Dense(10, activation='softmax'))\n    model.compile(loss='sparse_categorical_crossentropy',\n                  optimizer='adam', metrics=['accuracy'])\n    model.fit(X_train, y_train, batch_size=128,\n              epochs=3, validation_split=0.2, verbose=1)\n    return model\n```", "```py\n\"\"\"This module contains functions to plot image generated when training GAN.\"\"\"\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef upscale(image):\n    \"\"\"Scale the image to 0-255 scale.\"\"\"\n    return (image*127.5 + 127.5).astype(np.uint8)\n\ndef generated_images_plot(original, noised_data, generator):\n    \"\"\"Plot subplot of images during training.\"\"\"\n    print('NOISED')\n    for i in range(9):\n        plt.subplot(331 + i)\n        plt.axis('off')\n        plt.imshow(upscale(np.squeeze(noised_data[i])), cmap='gray')\n    plt.show()\n    print('GENERATED')\n    for i in range(9):\n        pred = generator.predict(noised_data[i:i+1], verbose=0)\n        plt.subplot(331 + i)\n        plt.axis('off')\n        plt.imshow(upscale(np.squeeze(pred[0])), cmap='gray')\n    plt.show()\n```", "```py\n\"\"\"This module contains the DCGAN components.\"\"\"\nfrom keras.layers import Input, Conv2D, AveragePooling2D\nfrom keras.layers import UpSampling2D, Flatten, Activation, BatchNormalization\nfrom keras.models import Model, Sequential\nfrom keras.layers.core import Dense, Dropout\nfrom keras.layers.advanced_activations import LeakyReLU\n\ndef img_generator(input_shape):\n    \"\"\"Generator.\"\"\"\n    generator = Sequential()\n    generator.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\n    generator.add(BatchNormalization())\n    generator.add(Activation('relu'))\n    generator.add(AveragePooling2D(pool_size=(2, 2)))\n    generator.add(Conv2D(64, (3, 3), padding='same'))\n    generator.add(BatchNormalization())\n    generator.add(Activation('relu'))\n    generator.add(AveragePooling2D(pool_size=(2, 2)))\n    generator.add(Conv2D(128, (3, 3), padding='same'))\n    generator.add(BatchNormalization())\n    generator.add(Activation('relu'))\n    generator.add(Conv2D(128, (3, 3), padding='same'))\n    generator.add(Activation('relu'))\n    generator.add(UpSampling2D((2, 2)))\n    generator.add(Conv2D(64, (3, 3), padding='same'))\n    generator.add(Activation('relu'))\n    generator.add(UpSampling2D((2, 2)))\n    generator.add(Conv2D(1, (3, 3), activation='tanh', padding='same'))\n    return generator\n```", "```py\nimport numpy as np\nfrom training_plots import upscale, generated_images_plot, plot_training_loss\nfrom training_plots import plot_generated_images_combined\nfrom keras.optimizers import Adam\nfrom keras import backend as k\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\nfrom GAN import img_generator, img_discriminator, dcgan\n\nfrom keras.datasets import mnist\nfrom train_mnist import train_mnist\n\n%matplotlib inline\n# Smoothing value\nsmooth_real = 0.9\n# Number of epochs\nepochs = 5\n# Batchsize\nbatch_size = 128\n# Optimizer for the generator\noptimizer_g = Adam(lr=0.0002, beta_1=0.5)\n# Optimizer for the discriminator\noptimizer_d = Adam(lr=0.0004, beta_1=0.5)\n# Shape of the input image\ninput_shape = (28, 28, 1)\n```"]