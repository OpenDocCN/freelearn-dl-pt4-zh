- en: Recurrent Neural Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Recurrent Neural Networks (**RNNs**) make use of sequential or time series data.
    In a regular neural network, we consider that all inputs and outputs are independent
    of each other. For a task where you want to predict the next word in a given sentence,
    it's better to know which words have come before it. RNNs are recurrent as the
    same task is performed for every element in the sequence where the output is dependent
    on the previous calculations. RNNs can be thought of as having a **memory** that
    captures information about what has been computed so far.
  prefs: []
  type: TYPE_NORMAL
- en: Going from feedforward neural networks to recurrent neural networks, we will
    use the concept of sharing parameters across various parts of the model. Parameter
    sharing will make it possible to extend and apply the model to examples of different
    forms (different lengths, here) and generalize across them.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to RNNs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To understand RNNs, we have to understand the basics of feedforward neural networks.
    You can refer to [Chapter 3](73c6bf42-1089-4504-97d5-a7dafae0e59c.xhtml), *Optimization
    for Neural Networks*, for details on feedforward networks. Both feedforward and
    recurrent neural networks are identified from the way they process the information
    or features through a series of mathematical operations performed at the various
    nodes of the network. One feeds information straight through (never touching a
    given node twice), the other cycles it through a loop.
  prefs: []
  type: TYPE_NORMAL
- en: A feedforward neural network is trained on image data until it minimizes the
    loss or error while predicting or classifying the categories for image types.
    With the trained set of hyper parameters or weights, the neural network can classify
    data it has never seen before. A trained feedforward neural network can be shown
    any random collection of images and the first image it classifies will not alter
    how it classifies the other images.
  prefs: []
  type: TYPE_NORMAL
- en: In a nutshell, these networks have no notion of order in time or temporal pattern,
    and the only information they consider is the current example it has been asked
    to classify.
  prefs: []
  type: TYPE_NORMAL
- en: 'RNNs take into account the temporal nature of the input data. An input to the
    RNN cell is both from the current timestep and one step back in time. Details
    are presented in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bb938643-d41f-41f3-91ff-52a9a58becbf.png)'
  prefs: []
  type: TYPE_IMG
- en: RNNs are recurrent in nature because they perform the same computation for every
    element in a sequence where the output is dependent on the previous computations.
    The other way to think about RNNs is that they have memory that can capture the
    information about what has been computed so far. RNNs can make use of the information
    or knowledge in long sequences but practically they are restricted to looking
    back only a few steps.
  prefs: []
  type: TYPE_NORMAL
- en: 'A typical RNN looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3b910d0e-fd5f-4fc8-9a87-dc5bfad83414.png)'
  prefs: []
  type: TYPE_IMG
- en: 'An unwrapped version of the RNN is shown in the following image; by unwrapping
    we mean that we write out the neural network for a complete sequence. Consider
    a sequence of five words; the network will be unwrapped into a five-layer neural
    network, one layer for each word:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1ec29cd0-643a-4f88-ab1f-2e9315c103b6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Computations happening in an RNN are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e7e0812f-609b-45b5-a109-9e6e6d6f6ae9.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/64313d85-a18d-42e1-9793-4f567b969e1b.jpg) denotes the input at timestep
    ![](img/2c8b95fa-cac0-44f7-a919-6ad5e8acd3f6.jpg).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/87c94d1b-1897-42a5-9e5b-c06d45d23745.jpg) denotes the hidden state
    at timestep ![](img/e0b2da69-d7f9-4c8a-86c7-509f4582749b.jpg). The hidden state
    is the memory of the network. ![](img/deba0343-39ab-45a6-80fa-8e5314797374.jpg) is
    computed based on the previously hidden state and the input at the current step, ![](img/f3bdc7a8-b8f6-4dc4-8921-88c9a6324268.jpg).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Function *f* represents non-linearity such as *tanh* or ReLU. The first hidden
    state is typically initialized to all zeroes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/64fa0205-2db6-439c-9ba1-09e3ad190341.jpg) denotes the output at step
    ![](img/18f8876a-fc08-4bcb-bf7a-6dff44642c3e.jpg). To predict the next word in
    a given sentence, it will be a vector of probabilities across the vocabulary, ![](img/738130f6-dc44-4e1e-a2ff-21b10ec81f36.jpg).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: RNN implementation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Following program processes, a sequence of numbers and the goal is to predict
    the next value, with the previous values provided. The input to the RNN network
    at every time step is the current value and a state vector that represents or
    stores what the neural network has seen at timesteps before. This state-vector
    is the encoded memory of the RNN, initially set to zero.
  prefs: []
  type: TYPE_NORMAL
- en: Training data is basically a random binary vector. The output is shifted to
    the right.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Computational graph
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The computational graph is shown as following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b454f847-90e3-4a82-b40a-e1bcf2589066.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The output of the listing is shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: RNN implementation with TensorFlow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will now use the TensorFlow API; the inner workings of the RNN are hidden
    under the hood. The TensorFlow `rnn` package unrolls the RNN and creates the graph
    automatically so that we can remove the for loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Computational graph
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following is the image of computational graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/53cc84ec-3960-4956-8431-37935ea2c8a9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The output of the listing is shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Introduction to long short term memory networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The vanishing gradient problem has appeared as the biggest obstacle to recurrent
    networks.
  prefs: []
  type: TYPE_NORMAL
- en: As the straight line changes along the *x* axis with a slight change in the
    *y* axis, the gradient shows change in all the weights with regard to change in
    error. If we don't know the gradient, we will not be able to adjust the weights
    in a direction that will reduce the loss or error, and our neural network ceases
    to learn.
  prefs: []
  type: TYPE_NORMAL
- en: '**Long short term memories** (**LSTMs**) are designed to overcome the vanishing
    gradient problem. Retaining information for a larger duration of time is effectively
    their implicit behavior.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In standard RNNs, the repeating cell will have an elementary structure, such
    as a single **tanh** layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3ce2d1f5-54e4-4b79-9bfd-9ec6fac73002.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As seen in the preceding image, LSTMs also have a chain-like structure, but
    the recurrent cell has a different structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d56f78b6-5471-44cd-8c0d-b8d983a62edb.png)'
  prefs: []
  type: TYPE_IMG
- en: Life cycle of LSTM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The key to LSTMs is the cell state that is like a conveyor belt. It moves down
    the stream with minor linear interactions. It''s straightforward for data to flow
    as unchanged:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fe8f82d3-8908-45b9-9aea-178576cd8070.png)'
  prefs: []
  type: TYPE_IMG
- en: LSTM networks have the ability to either remove or add information to the cell
    state that is carefully regulated by structures known as gates.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step in an LSTM network is to determine what information we will
    be throwing away from the cell state. The decision is made by a sigmoid layer
    known as the **forget gate** layer. The layer looks at the previous state *h(t-1)*
    and current input *x(t)* and outputs a number between 0 and 1 for each number
    in the cell state *C(t−1)*, where 1 represents **absolutely keep this** while
    a 0 represents **entirely get rid of this**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/20b9c65d-c1a3-4647-a963-46b538b83bfd.png)'
  prefs: []
  type: TYPE_IMG
- en: The next step is to determine what new information we are going to persist in
    the cell state. Firstly, a sigmoid layer known as the input gate layer decides
    which values will be updated. Secondly, a *tanh* layer generates a vector of new
    candidate values *C̃* that could be added to the state.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/b0d4fd69-9c56-44db-8493-4f5120847a16.png)'
  prefs: []
  type: TYPE_IMG
- en: We will now update the old cell state *C(t−1)* to the new cell state *C(t)*.
    We multiply the old state by *f(t)*, forgetting the things we decided to forget
    earlier. Then we add *i(t) ∗ C̃*; these are the new candidate values scaled by
    the amount we decided to update each state value.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/c262f1f2-8163-43d6-aa07-67fa578add3d.png)'
  prefs: []
  type: TYPE_IMG
- en: Finally, we decide on the output, which will be based on our cell state but
    will be a filtered or modified version. Firstly, we execute the sigmoid layer
    that determines what parts of the cell state we're going to output. Following
    which, we put the cell state through tanh to push the values to be between −1
    and 1, and multiply it by the output of the sigmoid gate so that we only output
    the parts we decided to.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/1f22f442-8d01-441d-9a6a-aea5ec3723e7.png)'
  prefs: []
  type: TYPE_IMG
- en: LSTM implementation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'LSTMs remember, forget, and pick what to pass on and then output depending
    on the current state and input. An LSTM has many more moving parts, but using
    the native TensorFlow API, it will be quite straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Computational graph
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following computational graph from TensorBoard describes the working of
    the LSTM network:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fe1361fa-f533-4aee-8456-c7543d327f24.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The output of the listing is shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Sentiment analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will now write an app to predict sentiments of a movie review. Reviews are
    made up of a sequence of words and the order of words encodes very useful information
    to predict sentiment. The first step is to map words to word embeddings. The second
    step is the RNN that receives a sequence of vectors as input and considers the
    order of the vectors to generate the prediction.
  prefs: []
  type: TYPE_NORMAL
- en: Word embeddings
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will now train a neural network for word to vector representation. Given
    a particular word in the center of a sentence, which is the input word, we look
    at the words nearby. The network is going to tell us the probability for every
    word in our vocabulary of being the nearby word that we choose.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/11250af4-f53c-46cb-bf1e-3db2dd354b11.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the listing is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Sentiment analysis with an RNN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following example shows the implementation of sentiment analysis using
    an RNN. It has fixed-length movie reviews encoded as integer values, which are
    then converted to word embedding (embedding vectors) passed to LSTM layers in
    a recurrent manner that pick the last prediction as the output sentiment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Computational graph
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](img/a365b445-98cc-4ede-b781-2a3fd9ea0efc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The output of the listing is shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned the basics of recurrent neural networks and why
    it is a useful mechanism for time series data processing. You learned about basic
    concepts such as states, word embeddings, and long-term memories. This was followed
    by an example to develop sentiment analysis system. We also implement recurrent
    neural networks using tensorflow.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we look at a different kind of neural network called a
    **Generative Model**.
  prefs: []
  type: TYPE_NORMAL
